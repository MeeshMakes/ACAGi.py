# Project Documentation

## Table of Contents
- [Overview](#overview)
- [Python Modules](#python-modules)
- [Images](#images)
- [Other Files](#other-files)

## Overview
This README was generated automatically by analyzing the project contents. Python modules are parsed for docstrings, classes, and functions. Image files are embedded as previews. Executable files (.exe) are listed by name; their contents are intentionally skipped.

## Python Modules

- `Agent-VirtualGameBoy.py`
- `bootstrap_launcher.py`
- `tests\__init__.py`
- `tests\test_action_verification.py`
- `tests\test_brain_confidence.py`
- `tests\test_directive_extractor.py`
- `tests\test_menu_mappings.py`
- `tests\test_naming_macros.py`
- `tests\test_operator_pipeline.py`
- `tests\test_pokemon_ingest.py`
- `tests\test_similarity_thresholds.py`
- `tests\test_timeline_manager.py`
- `tests\test_visual_decomposition.py`
- `tools\__init__.py`
- `tools\codex_pr_sentinel.py`
- `tools\logic_inbox.py`
- `tools\operator_pipeline.py`
- `tools\pokemon_ingest.py`
- `tools\timeline_manager.py`
- `visual_decomposition.py`

## Images

![Agent_Knowledge\images\054a82cef8cba0d8dcf40a197e2d20371e56b935.png](Agent_Knowledge\images\054a82cef8cba0d8dcf40a197e2d20371e56b935.png)
![Agent_Knowledge\images\05ca7ac1014ff38f0cc7a8d9db6b9a2d38e6f3b1.png](Agent_Knowledge\images\05ca7ac1014ff38f0cc7a8d9db6b9a2d38e6f3b1.png)
![Agent_Knowledge\images\060dd37f3663128a966c7a743cd4be260d501e4d.png](Agent_Knowledge\images\060dd37f3663128a966c7a743cd4be260d501e4d.png)
![Agent_Knowledge\images\0878de69036429428207dc45d07d622243640a0f.png](Agent_Knowledge\images\0878de69036429428207dc45d07d622243640a0f.png)
![Agent_Knowledge\images\0bb2bef01854643f2515d04c08057cb0d511a88c.png](Agent_Knowledge\images\0bb2bef01854643f2515d04c08057cb0d511a88c.png)
![Agent_Knowledge\images\154c13e7017ccf3073e4ee4005d7eeeaabe4da1e.png](Agent_Knowledge\images\154c13e7017ccf3073e4ee4005d7eeeaabe4da1e.png)
![Agent_Knowledge\images\177f931f878613827812270d274319c2a8c17d38.png](Agent_Knowledge\images\177f931f878613827812270d274319c2a8c17d38.png)
![Agent_Knowledge\images\19f647d49c492f6f48fefa40184120d3cdf3ca1c.png](Agent_Knowledge\images\19f647d49c492f6f48fefa40184120d3cdf3ca1c.png)
![Agent_Knowledge\images\1a3e95d0a1ea03e2474e0c5d9cca42d46fc12e22.png](Agent_Knowledge\images\1a3e95d0a1ea03e2474e0c5d9cca42d46fc12e22.png)
![Agent_Knowledge\images\1a7909c9b2f3ea1bec926bfe9ce818f2a6faf1b8.png](Agent_Knowledge\images\1a7909c9b2f3ea1bec926bfe9ce818f2a6faf1b8.png)
![Agent_Knowledge\images\1df15219a859cb7ad688e9f6f46b0b6298d0a2ef.png](Agent_Knowledge\images\1df15219a859cb7ad688e9f6f46b0b6298d0a2ef.png)
![Agent_Knowledge\images\1ee440c014e2130f877dcc89a407000f5b798626.png](Agent_Knowledge\images\1ee440c014e2130f877dcc89a407000f5b798626.png)
![Agent_Knowledge\images\2046e2db8016c8384b0c8070121784f874e74400.png](Agent_Knowledge\images\2046e2db8016c8384b0c8070121784f874e74400.png)
![Agent_Knowledge\images\206a1bc2114ccac8a09f97bf01680c93884d874e.png](Agent_Knowledge\images\206a1bc2114ccac8a09f97bf01680c93884d874e.png)
![Agent_Knowledge\images\208660392f87558fb80948db34d4a989975ef859.png](Agent_Knowledge\images\208660392f87558fb80948db34d4a989975ef859.png)
![Agent_Knowledge\images\218cc85794f68cb1a6dca739c04ccd8cdfa6ad66.png](Agent_Knowledge\images\218cc85794f68cb1a6dca739c04ccd8cdfa6ad66.png)
![Agent_Knowledge\images\25dd4f988dc3bdb6059c37ceacf13fd144d41eab.png](Agent_Knowledge\images\25dd4f988dc3bdb6059c37ceacf13fd144d41eab.png)
![Agent_Knowledge\images\2bfde0e1ee842a1cdd0aa837b9bd878fac973b34.png](Agent_Knowledge\images\2bfde0e1ee842a1cdd0aa837b9bd878fac973b34.png)
![Agent_Knowledge\images\2cf372b77ba3d059836e3462cb3fd129e00beafd.png](Agent_Knowledge\images\2cf372b77ba3d059836e3462cb3fd129e00beafd.png)
![Agent_Knowledge\images\2dd38ba7f15bb8b7d818e038a14ae02a8dae996c.png](Agent_Knowledge\images\2dd38ba7f15bb8b7d818e038a14ae02a8dae996c.png)
![Agent_Knowledge\images\3135c54fbca06a1319e51407871e2776dbf5660a.png](Agent_Knowledge\images\3135c54fbca06a1319e51407871e2776dbf5660a.png)
![Agent_Knowledge\images\34eb41c22206ebaeace38ddc6e4f7d9615d74030.png](Agent_Knowledge\images\34eb41c22206ebaeace38ddc6e4f7d9615d74030.png)
![Agent_Knowledge\images\3b7322c7715e0f254763977d49abd5adbd5f72dc.png](Agent_Knowledge\images\3b7322c7715e0f254763977d49abd5adbd5f72dc.png)
![Agent_Knowledge\images\3d89f7b376160c29b7e59ce6a86e74abba23ee8a.png](Agent_Knowledge\images\3d89f7b376160c29b7e59ce6a86e74abba23ee8a.png)
![Agent_Knowledge\images\3e375c48e3592c14acd5c9eb0a4b75bc5e0139cb.png](Agent_Knowledge\images\3e375c48e3592c14acd5c9eb0a4b75bc5e0139cb.png)
![Agent_Knowledge\images\408d3c86efa5bc940954f8dce551494ecacf940f.png](Agent_Knowledge\images\408d3c86efa5bc940954f8dce551494ecacf940f.png)
![Agent_Knowledge\images\437d51824bc51b216473ee7cff53bdd7904a0430.png](Agent_Knowledge\images\437d51824bc51b216473ee7cff53bdd7904a0430.png)
![Agent_Knowledge\images\46c47ba8857ff23a84e60bdeef461f748ae57852.png](Agent_Knowledge\images\46c47ba8857ff23a84e60bdeef461f748ae57852.png)
![Agent_Knowledge\images\489e7bcdbd5dadce7c6133bb9d1111a7e8783f3c.png](Agent_Knowledge\images\489e7bcdbd5dadce7c6133bb9d1111a7e8783f3c.png)
![Agent_Knowledge\images\4a3b6cb25136432d0b95abd2b181edf2e40b477e.png](Agent_Knowledge\images\4a3b6cb25136432d0b95abd2b181edf2e40b477e.png)
![Agent_Knowledge\images\4b6bd193371e7fab25d15da0e388c47807789722.png](Agent_Knowledge\images\4b6bd193371e7fab25d15da0e388c47807789722.png)
![Agent_Knowledge\images\5006b20c9289c8f9525aa723e9ef23f5cd2fd7b4.png](Agent_Knowledge\images\5006b20c9289c8f9525aa723e9ef23f5cd2fd7b4.png)
![Agent_Knowledge\images\512e6360339d83567fd93bc825951369c46808df.png](Agent_Knowledge\images\512e6360339d83567fd93bc825951369c46808df.png)
![Agent_Knowledge\images\55579fac402af2d8c8d48f58684b6d70966a8c3c.png](Agent_Knowledge\images\55579fac402af2d8c8d48f58684b6d70966a8c3c.png)
![Agent_Knowledge\images\56aae58e1e185cbf3dc276d26c0c1f32473044e1.png](Agent_Knowledge\images\56aae58e1e185cbf3dc276d26c0c1f32473044e1.png)
![Agent_Knowledge\images\6318f1ca7f6912050fd4ed867905494c27f2e31c.png](Agent_Knowledge\images\6318f1ca7f6912050fd4ed867905494c27f2e31c.png)
![Agent_Knowledge\images\6352becfb9ea636649a8437293be6d3367e2cb17.png](Agent_Knowledge\images\6352becfb9ea636649a8437293be6d3367e2cb17.png)
![Agent_Knowledge\images\6962e874820aca4401bf6dd3d8063c16ff4f6b4c.png](Agent_Knowledge\images\6962e874820aca4401bf6dd3d8063c16ff4f6b4c.png)
![Agent_Knowledge\images\6a77a74d5848274e561583bff72ba6e24eb5bf3c.png](Agent_Knowledge\images\6a77a74d5848274e561583bff72ba6e24eb5bf3c.png)
![Agent_Knowledge\images\6b65987da376f054dbb4301f34ce6a597a171eae.png](Agent_Knowledge\images\6b65987da376f054dbb4301f34ce6a597a171eae.png)
![Agent_Knowledge\images\70de09773b92d86254893df68daa2adf83b5e118.png](Agent_Knowledge\images\70de09773b92d86254893df68daa2adf83b5e118.png)
![Agent_Knowledge\images\71261ee3487338cfadc389c90533b5f61551e002.png](Agent_Knowledge\images\71261ee3487338cfadc389c90533b5f61551e002.png)
![Agent_Knowledge\images\75d373b784c3b2eabd921d98683d522d6f58e962.png](Agent_Knowledge\images\75d373b784c3b2eabd921d98683d522d6f58e962.png)
![Agent_Knowledge\images\7ba75383f83cf8e6d45032ec5141d8e8618ec18c.png](Agent_Knowledge\images\7ba75383f83cf8e6d45032ec5141d8e8618ec18c.png)
![Agent_Knowledge\images\7d4da45f5cc9daec65f0bbcf3e44d16d0a264d11.png](Agent_Knowledge\images\7d4da45f5cc9daec65f0bbcf3e44d16d0a264d11.png)
![Agent_Knowledge\images\7de011a38be856e2a1ce1b32a35adbd60baa319f.png](Agent_Knowledge\images\7de011a38be856e2a1ce1b32a35adbd60baa319f.png)
![Agent_Knowledge\images\7e672a9cb68ddc199fd79a6f24a161eec8e3d593.png](Agent_Knowledge\images\7e672a9cb68ddc199fd79a6f24a161eec8e3d593.png)
![Agent_Knowledge\images\8065009a260ba143f8351b82c01c7810b530b3f4.png](Agent_Knowledge\images\8065009a260ba143f8351b82c01c7810b530b3f4.png)
![Agent_Knowledge\images\8148e1ef86e4a4f1c82dc92ea9a5bd3358b7be15.png](Agent_Knowledge\images\8148e1ef86e4a4f1c82dc92ea9a5bd3358b7be15.png)
![Agent_Knowledge\images\83dbf07bc741c66ffc17bba361a5e34498d078db.png](Agent_Knowledge\images\83dbf07bc741c66ffc17bba361a5e34498d078db.png)
![Agent_Knowledge\images\847b90b5e4662a75880dcbdbd6c349866dc3de94.png](Agent_Knowledge\images\847b90b5e4662a75880dcbdbd6c349866dc3de94.png)
![Agent_Knowledge\images\865a3da0ed6aef7745ff61d6b8ee678a28342fbe.png](Agent_Knowledge\images\865a3da0ed6aef7745ff61d6b8ee678a28342fbe.png)
![Agent_Knowledge\images\878772701bc6083be8a62b77898a24226653da66.png](Agent_Knowledge\images\878772701bc6083be8a62b77898a24226653da66.png)
![Agent_Knowledge\images\87dd5f588f8ae90de1f356e4f33db2b3ca042ff6.png](Agent_Knowledge\images\87dd5f588f8ae90de1f356e4f33db2b3ca042ff6.png)
![Agent_Knowledge\images\88d126e49a937fc4df9196083a0ef1d0c6762437.png](Agent_Knowledge\images\88d126e49a937fc4df9196083a0ef1d0c6762437.png)
![Agent_Knowledge\images\8b4d5bd337fbf618069961cbd369630980987657.png](Agent_Knowledge\images\8b4d5bd337fbf618069961cbd369630980987657.png)
![Agent_Knowledge\images\8b7aad91e8177f6e800a479a9f6cf9d92fcf647b.png](Agent_Knowledge\images\8b7aad91e8177f6e800a479a9f6cf9d92fcf647b.png)
![Agent_Knowledge\images\8c0aeeb574177bf5b67aaaa114fdce2dab65f199.png](Agent_Knowledge\images\8c0aeeb574177bf5b67aaaa114fdce2dab65f199.png)
![Agent_Knowledge\images\8d8a356f233649c49df28d15bff2d6158a9886bc.png](Agent_Knowledge\images\8d8a356f233649c49df28d15bff2d6158a9886bc.png)
![Agent_Knowledge\images\9041496221efde05c878058a491ae4846ab5c74e.png](Agent_Knowledge\images\9041496221efde05c878058a491ae4846ab5c74e.png)
![Agent_Knowledge\images\907133e8a645cda605501de53de9759173aa61f9.png](Agent_Knowledge\images\907133e8a645cda605501de53de9759173aa61f9.png)
![Agent_Knowledge\images\90d976756d87ef89a9a2ac66aa44003a7c002175.png](Agent_Knowledge\images\90d976756d87ef89a9a2ac66aa44003a7c002175.png)
![Agent_Knowledge\images\95f81e258cb9a32b0cd6e9ce4e49b8413089330f.png](Agent_Knowledge\images\95f81e258cb9a32b0cd6e9ce4e49b8413089330f.png)
![Agent_Knowledge\images\97adf4cde3b04d8d2ff70100ee405d1550ec6c8b.png](Agent_Knowledge\images\97adf4cde3b04d8d2ff70100ee405d1550ec6c8b.png)
![Agent_Knowledge\images\9b9eb9aeaed6d59aac7618e756cbc973975a9c8a.png](Agent_Knowledge\images\9b9eb9aeaed6d59aac7618e756cbc973975a9c8a.png)
![Agent_Knowledge\images\a0f76d89f3d14f92defe0b824edf040561e27673.png](Agent_Knowledge\images\a0f76d89f3d14f92defe0b824edf040561e27673.png)
![Agent_Knowledge\images\a28dc21fd2949c93b325177300c00bb6806eb65e.png](Agent_Knowledge\images\a28dc21fd2949c93b325177300c00bb6806eb65e.png)
![Agent_Knowledge\images\a527575f4b8bbc1d7de4a8bc382a6dad65defb7e.png](Agent_Knowledge\images\a527575f4b8bbc1d7de4a8bc382a6dad65defb7e.png)
![Agent_Knowledge\images\a76bf23d1ac5aaf60df5730fbbfed60400164447.png](Agent_Knowledge\images\a76bf23d1ac5aaf60df5730fbbfed60400164447.png)
![Agent_Knowledge\images\b093d7822a7d99b568979a97e700e04a7c0986ed.png](Agent_Knowledge\images\b093d7822a7d99b568979a97e700e04a7c0986ed.png)
![Agent_Knowledge\images\b1aa5c5670324de31293d27f9fef3d131a828b6e.png](Agent_Knowledge\images\b1aa5c5670324de31293d27f9fef3d131a828b6e.png)
![Agent_Knowledge\images\b3645a42877ea15d0f6c6530706f372ecd19c279.png](Agent_Knowledge\images\b3645a42877ea15d0f6c6530706f372ecd19c279.png)
![Agent_Knowledge\images\b6f3233654357282c9904fc8b2ca547c9fdae6ea.png](Agent_Knowledge\images\b6f3233654357282c9904fc8b2ca547c9fdae6ea.png)
![Agent_Knowledge\images\b785dc981f7c5bb8211e88d58a9dceb72edd7169.png](Agent_Knowledge\images\b785dc981f7c5bb8211e88d58a9dceb72edd7169.png)
![Agent_Knowledge\images\b8b4019fd872d121c3c736a4f1a5cbe676b19a9e.png](Agent_Knowledge\images\b8b4019fd872d121c3c736a4f1a5cbe676b19a9e.png)
![Agent_Knowledge\images\b9f75e6d606ec716e7b327bfd9a796458ca156a0.png](Agent_Knowledge\images\b9f75e6d606ec716e7b327bfd9a796458ca156a0.png)
![Agent_Knowledge\images\bb1575aa67da9a84f2e94643569466ed2d99d7c4.png](Agent_Knowledge\images\bb1575aa67da9a84f2e94643569466ed2d99d7c4.png)
![Agent_Knowledge\images\bf11bc46fc5fad0ff411261eda2877b192e38d1a.png](Agent_Knowledge\images\bf11bc46fc5fad0ff411261eda2877b192e38d1a.png)
![Agent_Knowledge\images\bf1e8f077e2b97a81d5e8d7ecdf591c8e051e853.png](Agent_Knowledge\images\bf1e8f077e2b97a81d5e8d7ecdf591c8e051e853.png)
![Agent_Knowledge\images\c76845e771057e8c7967186deebb9e53f3eebb85.png](Agent_Knowledge\images\c76845e771057e8c7967186deebb9e53f3eebb85.png)
![Agent_Knowledge\images\d06bdd0e753730ea0a251cd4aaa46941b89cff08.png](Agent_Knowledge\images\d06bdd0e753730ea0a251cd4aaa46941b89cff08.png)
![Agent_Knowledge\images\d1f8731272ff649c92d4c73ab0e072e472d391c5.png](Agent_Knowledge\images\d1f8731272ff649c92d4c73ab0e072e472d391c5.png)
![Agent_Knowledge\images\d61971d8fa8a667d728aee3ef9a7dd5469fc5bd8.png](Agent_Knowledge\images\d61971d8fa8a667d728aee3ef9a7dd5469fc5bd8.png)
![Agent_Knowledge\images\d7dfe98c62a707f69502339bea770d80240a7209.png](Agent_Knowledge\images\d7dfe98c62a707f69502339bea770d80240a7209.png)
![Agent_Knowledge\images\d834b3d6c5f4dca0b0385e8a8d0b9b96d47c1b6a.png](Agent_Knowledge\images\d834b3d6c5f4dca0b0385e8a8d0b9b96d47c1b6a.png)
![Agent_Knowledge\images\da15a41ef6d2ffd09f5d3f919e13b1bc7ff50fd6.png](Agent_Knowledge\images\da15a41ef6d2ffd09f5d3f919e13b1bc7ff50fd6.png)
![Agent_Knowledge\images\df9d52e6f2b50b57568ceb12c2037dee4da46d33.png](Agent_Knowledge\images\df9d52e6f2b50b57568ceb12c2037dee4da46d33.png)
![Agent_Knowledge\images\dfd0ccf346248c93af66b09e6f98a7fccc970d4a.png](Agent_Knowledge\images\dfd0ccf346248c93af66b09e6f98a7fccc970d4a.png)
![Agent_Knowledge\images\e1321bec3e4799fd23efc2278530901524577467.png](Agent_Knowledge\images\e1321bec3e4799fd23efc2278530901524577467.png)
![Agent_Knowledge\images\e18c3a72c3f241f0b604be6766612fbbbdb22de3.png](Agent_Knowledge\images\e18c3a72c3f241f0b604be6766612fbbbdb22de3.png)
![Agent_Knowledge\images\ef5aea69f60a6758e8de71f6eec55c2155de3431.png](Agent_Knowledge\images\ef5aea69f60a6758e8de71f6eec55c2155de3431.png)
![Agent_Knowledge\images\f16edb8f5ccd11b2f9eab442a838255d95940017.png](Agent_Knowledge\images\f16edb8f5ccd11b2f9eab442a838255d95940017.png)
![Agent_Knowledge\images\f2278f74b3410f114042c71f86956abec9956f43.png](Agent_Knowledge\images\f2278f74b3410f114042c71f86956abec9956f43.png)
![Agent_Knowledge\mini64\054a82cef8cba0d8dcf40a197e2d20371e56b935.png](Agent_Knowledge\mini64\054a82cef8cba0d8dcf40a197e2d20371e56b935.png)
![Agent_Knowledge\mini64\05ca7ac1014ff38f0cc7a8d9db6b9a2d38e6f3b1.png](Agent_Knowledge\mini64\05ca7ac1014ff38f0cc7a8d9db6b9a2d38e6f3b1.png)
![Agent_Knowledge\mini64\060dd37f3663128a966c7a743cd4be260d501e4d.png](Agent_Knowledge\mini64\060dd37f3663128a966c7a743cd4be260d501e4d.png)
![Agent_Knowledge\mini64\0878de69036429428207dc45d07d622243640a0f.png](Agent_Knowledge\mini64\0878de69036429428207dc45d07d622243640a0f.png)
![Agent_Knowledge\mini64\0bb2bef01854643f2515d04c08057cb0d511a88c.png](Agent_Knowledge\mini64\0bb2bef01854643f2515d04c08057cb0d511a88c.png)
![Agent_Knowledge\mini64\154c13e7017ccf3073e4ee4005d7eeeaabe4da1e.png](Agent_Knowledge\mini64\154c13e7017ccf3073e4ee4005d7eeeaabe4da1e.png)
![Agent_Knowledge\mini64\177f931f878613827812270d274319c2a8c17d38.png](Agent_Knowledge\mini64\177f931f878613827812270d274319c2a8c17d38.png)
![Agent_Knowledge\mini64\19f647d49c492f6f48fefa40184120d3cdf3ca1c.png](Agent_Knowledge\mini64\19f647d49c492f6f48fefa40184120d3cdf3ca1c.png)
![Agent_Knowledge\mini64\1a3e95d0a1ea03e2474e0c5d9cca42d46fc12e22.png](Agent_Knowledge\mini64\1a3e95d0a1ea03e2474e0c5d9cca42d46fc12e22.png)
![Agent_Knowledge\mini64\1a7909c9b2f3ea1bec926bfe9ce818f2a6faf1b8.png](Agent_Knowledge\mini64\1a7909c9b2f3ea1bec926bfe9ce818f2a6faf1b8.png)
![Agent_Knowledge\mini64\1df15219a859cb7ad688e9f6f46b0b6298d0a2ef.png](Agent_Knowledge\mini64\1df15219a859cb7ad688e9f6f46b0b6298d0a2ef.png)
![Agent_Knowledge\mini64\1ee440c014e2130f877dcc89a407000f5b798626.png](Agent_Knowledge\mini64\1ee440c014e2130f877dcc89a407000f5b798626.png)
![Agent_Knowledge\mini64\2046e2db8016c8384b0c8070121784f874e74400.png](Agent_Knowledge\mini64\2046e2db8016c8384b0c8070121784f874e74400.png)
![Agent_Knowledge\mini64\206a1bc2114ccac8a09f97bf01680c93884d874e.png](Agent_Knowledge\mini64\206a1bc2114ccac8a09f97bf01680c93884d874e.png)
![Agent_Knowledge\mini64\208660392f87558fb80948db34d4a989975ef859.png](Agent_Knowledge\mini64\208660392f87558fb80948db34d4a989975ef859.png)
![Agent_Knowledge\mini64\218cc85794f68cb1a6dca739c04ccd8cdfa6ad66.png](Agent_Knowledge\mini64\218cc85794f68cb1a6dca739c04ccd8cdfa6ad66.png)
![Agent_Knowledge\mini64\25dd4f988dc3bdb6059c37ceacf13fd144d41eab.png](Agent_Knowledge\mini64\25dd4f988dc3bdb6059c37ceacf13fd144d41eab.png)
![Agent_Knowledge\mini64\2bfde0e1ee842a1cdd0aa837b9bd878fac973b34.png](Agent_Knowledge\mini64\2bfde0e1ee842a1cdd0aa837b9bd878fac973b34.png)
![Agent_Knowledge\mini64\2cf372b77ba3d059836e3462cb3fd129e00beafd.png](Agent_Knowledge\mini64\2cf372b77ba3d059836e3462cb3fd129e00beafd.png)
![Agent_Knowledge\mini64\2dd38ba7f15bb8b7d818e038a14ae02a8dae996c.png](Agent_Knowledge\mini64\2dd38ba7f15bb8b7d818e038a14ae02a8dae996c.png)
![Agent_Knowledge\mini64\3135c54fbca06a1319e51407871e2776dbf5660a.png](Agent_Knowledge\mini64\3135c54fbca06a1319e51407871e2776dbf5660a.png)
![Agent_Knowledge\mini64\34eb41c22206ebaeace38ddc6e4f7d9615d74030.png](Agent_Knowledge\mini64\34eb41c22206ebaeace38ddc6e4f7d9615d74030.png)
![Agent_Knowledge\mini64\3b7322c7715e0f254763977d49abd5adbd5f72dc.png](Agent_Knowledge\mini64\3b7322c7715e0f254763977d49abd5adbd5f72dc.png)
![Agent_Knowledge\mini64\3d89f7b376160c29b7e59ce6a86e74abba23ee8a.png](Agent_Knowledge\mini64\3d89f7b376160c29b7e59ce6a86e74abba23ee8a.png)
![Agent_Knowledge\mini64\3e375c48e3592c14acd5c9eb0a4b75bc5e0139cb.png](Agent_Knowledge\mini64\3e375c48e3592c14acd5c9eb0a4b75bc5e0139cb.png)
![Agent_Knowledge\mini64\408d3c86efa5bc940954f8dce551494ecacf940f.png](Agent_Knowledge\mini64\408d3c86efa5bc940954f8dce551494ecacf940f.png)
![Agent_Knowledge\mini64\437d51824bc51b216473ee7cff53bdd7904a0430.png](Agent_Knowledge\mini64\437d51824bc51b216473ee7cff53bdd7904a0430.png)
![Agent_Knowledge\mini64\46c47ba8857ff23a84e60bdeef461f748ae57852.png](Agent_Knowledge\mini64\46c47ba8857ff23a84e60bdeef461f748ae57852.png)
![Agent_Knowledge\mini64\489e7bcdbd5dadce7c6133bb9d1111a7e8783f3c.png](Agent_Knowledge\mini64\489e7bcdbd5dadce7c6133bb9d1111a7e8783f3c.png)
![Agent_Knowledge\mini64\4a3b6cb25136432d0b95abd2b181edf2e40b477e.png](Agent_Knowledge\mini64\4a3b6cb25136432d0b95abd2b181edf2e40b477e.png)
![Agent_Knowledge\mini64\4b6bd193371e7fab25d15da0e388c47807789722.png](Agent_Knowledge\mini64\4b6bd193371e7fab25d15da0e388c47807789722.png)
![Agent_Knowledge\mini64\5006b20c9289c8f9525aa723e9ef23f5cd2fd7b4.png](Agent_Knowledge\mini64\5006b20c9289c8f9525aa723e9ef23f5cd2fd7b4.png)
![Agent_Knowledge\mini64\512e6360339d83567fd93bc825951369c46808df.png](Agent_Knowledge\mini64\512e6360339d83567fd93bc825951369c46808df.png)
![Agent_Knowledge\mini64\55579fac402af2d8c8d48f58684b6d70966a8c3c.png](Agent_Knowledge\mini64\55579fac402af2d8c8d48f58684b6d70966a8c3c.png)
![Agent_Knowledge\mini64\56aae58e1e185cbf3dc276d26c0c1f32473044e1.png](Agent_Knowledge\mini64\56aae58e1e185cbf3dc276d26c0c1f32473044e1.png)
![Agent_Knowledge\mini64\6318f1ca7f6912050fd4ed867905494c27f2e31c.png](Agent_Knowledge\mini64\6318f1ca7f6912050fd4ed867905494c27f2e31c.png)
![Agent_Knowledge\mini64\6352becfb9ea636649a8437293be6d3367e2cb17.png](Agent_Knowledge\mini64\6352becfb9ea636649a8437293be6d3367e2cb17.png)
![Agent_Knowledge\mini64\6962e874820aca4401bf6dd3d8063c16ff4f6b4c.png](Agent_Knowledge\mini64\6962e874820aca4401bf6dd3d8063c16ff4f6b4c.png)
![Agent_Knowledge\mini64\6a77a74d5848274e561583bff72ba6e24eb5bf3c.png](Agent_Knowledge\mini64\6a77a74d5848274e561583bff72ba6e24eb5bf3c.png)
![Agent_Knowledge\mini64\6b65987da376f054dbb4301f34ce6a597a171eae.png](Agent_Knowledge\mini64\6b65987da376f054dbb4301f34ce6a597a171eae.png)
![Agent_Knowledge\mini64\70de09773b92d86254893df68daa2adf83b5e118.png](Agent_Knowledge\mini64\70de09773b92d86254893df68daa2adf83b5e118.png)
![Agent_Knowledge\mini64\71261ee3487338cfadc389c90533b5f61551e002.png](Agent_Knowledge\mini64\71261ee3487338cfadc389c90533b5f61551e002.png)
![Agent_Knowledge\mini64\75d373b784c3b2eabd921d98683d522d6f58e962.png](Agent_Knowledge\mini64\75d373b784c3b2eabd921d98683d522d6f58e962.png)
![Agent_Knowledge\mini64\7ba75383f83cf8e6d45032ec5141d8e8618ec18c.png](Agent_Knowledge\mini64\7ba75383f83cf8e6d45032ec5141d8e8618ec18c.png)
![Agent_Knowledge\mini64\7d4da45f5cc9daec65f0bbcf3e44d16d0a264d11.png](Agent_Knowledge\mini64\7d4da45f5cc9daec65f0bbcf3e44d16d0a264d11.png)
![Agent_Knowledge\mini64\7de011a38be856e2a1ce1b32a35adbd60baa319f.png](Agent_Knowledge\mini64\7de011a38be856e2a1ce1b32a35adbd60baa319f.png)
![Agent_Knowledge\mini64\7e672a9cb68ddc199fd79a6f24a161eec8e3d593.png](Agent_Knowledge\mini64\7e672a9cb68ddc199fd79a6f24a161eec8e3d593.png)
![Agent_Knowledge\mini64\8065009a260ba143f8351b82c01c7810b530b3f4.png](Agent_Knowledge\mini64\8065009a260ba143f8351b82c01c7810b530b3f4.png)
![Agent_Knowledge\mini64\8148e1ef86e4a4f1c82dc92ea9a5bd3358b7be15.png](Agent_Knowledge\mini64\8148e1ef86e4a4f1c82dc92ea9a5bd3358b7be15.png)
![Agent_Knowledge\mini64\83dbf07bc741c66ffc17bba361a5e34498d078db.png](Agent_Knowledge\mini64\83dbf07bc741c66ffc17bba361a5e34498d078db.png)
![Agent_Knowledge\mini64\847b90b5e4662a75880dcbdbd6c349866dc3de94.png](Agent_Knowledge\mini64\847b90b5e4662a75880dcbdbd6c349866dc3de94.png)
![Agent_Knowledge\mini64\865a3da0ed6aef7745ff61d6b8ee678a28342fbe.png](Agent_Knowledge\mini64\865a3da0ed6aef7745ff61d6b8ee678a28342fbe.png)
![Agent_Knowledge\mini64\878772701bc6083be8a62b77898a24226653da66.png](Agent_Knowledge\mini64\878772701bc6083be8a62b77898a24226653da66.png)
![Agent_Knowledge\mini64\87dd5f588f8ae90de1f356e4f33db2b3ca042ff6.png](Agent_Knowledge\mini64\87dd5f588f8ae90de1f356e4f33db2b3ca042ff6.png)
![Agent_Knowledge\mini64\88d126e49a937fc4df9196083a0ef1d0c6762437.png](Agent_Knowledge\mini64\88d126e49a937fc4df9196083a0ef1d0c6762437.png)
![Agent_Knowledge\mini64\8b4d5bd337fbf618069961cbd369630980987657.png](Agent_Knowledge\mini64\8b4d5bd337fbf618069961cbd369630980987657.png)
![Agent_Knowledge\mini64\8b7aad91e8177f6e800a479a9f6cf9d92fcf647b.png](Agent_Knowledge\mini64\8b7aad91e8177f6e800a479a9f6cf9d92fcf647b.png)
![Agent_Knowledge\mini64\8c0aeeb574177bf5b67aaaa114fdce2dab65f199.png](Agent_Knowledge\mini64\8c0aeeb574177bf5b67aaaa114fdce2dab65f199.png)
![Agent_Knowledge\mini64\8d8a356f233649c49df28d15bff2d6158a9886bc.png](Agent_Knowledge\mini64\8d8a356f233649c49df28d15bff2d6158a9886bc.png)
![Agent_Knowledge\mini64\9041496221efde05c878058a491ae4846ab5c74e.png](Agent_Knowledge\mini64\9041496221efde05c878058a491ae4846ab5c74e.png)
![Agent_Knowledge\mini64\907133e8a645cda605501de53de9759173aa61f9.png](Agent_Knowledge\mini64\907133e8a645cda605501de53de9759173aa61f9.png)
![Agent_Knowledge\mini64\90d976756d87ef89a9a2ac66aa44003a7c002175.png](Agent_Knowledge\mini64\90d976756d87ef89a9a2ac66aa44003a7c002175.png)
![Agent_Knowledge\mini64\95f81e258cb9a32b0cd6e9ce4e49b8413089330f.png](Agent_Knowledge\mini64\95f81e258cb9a32b0cd6e9ce4e49b8413089330f.png)
![Agent_Knowledge\mini64\97adf4cde3b04d8d2ff70100ee405d1550ec6c8b.png](Agent_Knowledge\mini64\97adf4cde3b04d8d2ff70100ee405d1550ec6c8b.png)
![Agent_Knowledge\mini64\9b9eb9aeaed6d59aac7618e756cbc973975a9c8a.png](Agent_Knowledge\mini64\9b9eb9aeaed6d59aac7618e756cbc973975a9c8a.png)
![Agent_Knowledge\mini64\a0f76d89f3d14f92defe0b824edf040561e27673.png](Agent_Knowledge\mini64\a0f76d89f3d14f92defe0b824edf040561e27673.png)
![Agent_Knowledge\mini64\a28dc21fd2949c93b325177300c00bb6806eb65e.png](Agent_Knowledge\mini64\a28dc21fd2949c93b325177300c00bb6806eb65e.png)
![Agent_Knowledge\mini64\a527575f4b8bbc1d7de4a8bc382a6dad65defb7e.png](Agent_Knowledge\mini64\a527575f4b8bbc1d7de4a8bc382a6dad65defb7e.png)
![Agent_Knowledge\mini64\a76bf23d1ac5aaf60df5730fbbfed60400164447.png](Agent_Knowledge\mini64\a76bf23d1ac5aaf60df5730fbbfed60400164447.png)
![Agent_Knowledge\mini64\b093d7822a7d99b568979a97e700e04a7c0986ed.png](Agent_Knowledge\mini64\b093d7822a7d99b568979a97e700e04a7c0986ed.png)
![Agent_Knowledge\mini64\b1aa5c5670324de31293d27f9fef3d131a828b6e.png](Agent_Knowledge\mini64\b1aa5c5670324de31293d27f9fef3d131a828b6e.png)
![Agent_Knowledge\mini64\b3645a42877ea15d0f6c6530706f372ecd19c279.png](Agent_Knowledge\mini64\b3645a42877ea15d0f6c6530706f372ecd19c279.png)
![Agent_Knowledge\mini64\b6f3233654357282c9904fc8b2ca547c9fdae6ea.png](Agent_Knowledge\mini64\b6f3233654357282c9904fc8b2ca547c9fdae6ea.png)
![Agent_Knowledge\mini64\b785dc981f7c5bb8211e88d58a9dceb72edd7169.png](Agent_Knowledge\mini64\b785dc981f7c5bb8211e88d58a9dceb72edd7169.png)
![Agent_Knowledge\mini64\b8b4019fd872d121c3c736a4f1a5cbe676b19a9e.png](Agent_Knowledge\mini64\b8b4019fd872d121c3c736a4f1a5cbe676b19a9e.png)
![Agent_Knowledge\mini64\b9f75e6d606ec716e7b327bfd9a796458ca156a0.png](Agent_Knowledge\mini64\b9f75e6d606ec716e7b327bfd9a796458ca156a0.png)
![Agent_Knowledge\mini64\bb1575aa67da9a84f2e94643569466ed2d99d7c4.png](Agent_Knowledge\mini64\bb1575aa67da9a84f2e94643569466ed2d99d7c4.png)
![Agent_Knowledge\mini64\bf11bc46fc5fad0ff411261eda2877b192e38d1a.png](Agent_Knowledge\mini64\bf11bc46fc5fad0ff411261eda2877b192e38d1a.png)
![Agent_Knowledge\mini64\bf1e8f077e2b97a81d5e8d7ecdf591c8e051e853.png](Agent_Knowledge\mini64\bf1e8f077e2b97a81d5e8d7ecdf591c8e051e853.png)
![Agent_Knowledge\mini64\c76845e771057e8c7967186deebb9e53f3eebb85.png](Agent_Knowledge\mini64\c76845e771057e8c7967186deebb9e53f3eebb85.png)
![Agent_Knowledge\mini64\d06bdd0e753730ea0a251cd4aaa46941b89cff08.png](Agent_Knowledge\mini64\d06bdd0e753730ea0a251cd4aaa46941b89cff08.png)
![Agent_Knowledge\mini64\d1f8731272ff649c92d4c73ab0e072e472d391c5.png](Agent_Knowledge\mini64\d1f8731272ff649c92d4c73ab0e072e472d391c5.png)
![Agent_Knowledge\mini64\d61971d8fa8a667d728aee3ef9a7dd5469fc5bd8.png](Agent_Knowledge\mini64\d61971d8fa8a667d728aee3ef9a7dd5469fc5bd8.png)
![Agent_Knowledge\mini64\d7dfe98c62a707f69502339bea770d80240a7209.png](Agent_Knowledge\mini64\d7dfe98c62a707f69502339bea770d80240a7209.png)
![Agent_Knowledge\mini64\d834b3d6c5f4dca0b0385e8a8d0b9b96d47c1b6a.png](Agent_Knowledge\mini64\d834b3d6c5f4dca0b0385e8a8d0b9b96d47c1b6a.png)
![Agent_Knowledge\mini64\da15a41ef6d2ffd09f5d3f919e13b1bc7ff50fd6.png](Agent_Knowledge\mini64\da15a41ef6d2ffd09f5d3f919e13b1bc7ff50fd6.png)
![Agent_Knowledge\mini64\df9d52e6f2b50b57568ceb12c2037dee4da46d33.png](Agent_Knowledge\mini64\df9d52e6f2b50b57568ceb12c2037dee4da46d33.png)
![Agent_Knowledge\mini64\dfd0ccf346248c93af66b09e6f98a7fccc970d4a.png](Agent_Knowledge\mini64\dfd0ccf346248c93af66b09e6f98a7fccc970d4a.png)
![Agent_Knowledge\mini64\e1321bec3e4799fd23efc2278530901524577467.png](Agent_Knowledge\mini64\e1321bec3e4799fd23efc2278530901524577467.png)
![Agent_Knowledge\mini64\e18c3a72c3f241f0b604be6766612fbbbdb22de3.png](Agent_Knowledge\mini64\e18c3a72c3f241f0b604be6766612fbbbdb22de3.png)
![Agent_Knowledge\mini64\ef5aea69f60a6758e8de71f6eec55c2155de3431.png](Agent_Knowledge\mini64\ef5aea69f60a6758e8de71f6eec55c2155de3431.png)
![Agent_Knowledge\mini64\f16edb8f5ccd11b2f9eab442a838255d95940017.png](Agent_Knowledge\mini64\f16edb8f5ccd11b2f9eab442a838255d95940017.png)
![Agent_Knowledge\mini64\f2278f74b3410f114042c71f86956abec9956f43.png](Agent_Knowledge\mini64\f2278f74b3410f114042c71f86956abec9956f43.png)
![Agent_Knowledge\region_thumbs\024be72e0bdb36b2e53c0040b8f437820469cd67.png](Agent_Knowledge\region_thumbs\024be72e0bdb36b2e53c0040b8f437820469cd67.png)
![Agent_Knowledge\region_thumbs\041b4e3006f2d8488c0abfe5cef83838da78a409.png](Agent_Knowledge\region_thumbs\041b4e3006f2d8488c0abfe5cef83838da78a409.png)
![Agent_Knowledge\region_thumbs\0554bfdcf6f592d4b6034ea0e8a3cc2669fe09e9.png](Agent_Knowledge\region_thumbs\0554bfdcf6f592d4b6034ea0e8a3cc2669fe09e9.png)
![Agent_Knowledge\region_thumbs\0c3c299dfdec07a1e1b4de3f4fd40b6799ade28f.png](Agent_Knowledge\region_thumbs\0c3c299dfdec07a1e1b4de3f4fd40b6799ade28f.png)
![Agent_Knowledge\region_thumbs\18f585a3be14458cc6e80fe48b95169239d880a1.png](Agent_Knowledge\region_thumbs\18f585a3be14458cc6e80fe48b95169239d880a1.png)
![Agent_Knowledge\region_thumbs\201bc91b5f4c28d2e59aeadbc095c192417b30bd.png](Agent_Knowledge\region_thumbs\201bc91b5f4c28d2e59aeadbc095c192417b30bd.png)
![Agent_Knowledge\region_thumbs\29560c38ccce8ccd06afbee025236da4839cab63.png](Agent_Knowledge\region_thumbs\29560c38ccce8ccd06afbee025236da4839cab63.png)
![Agent_Knowledge\region_thumbs\2fbb55e5da351620fc02017f2eeb1114c3301c4b.png](Agent_Knowledge\region_thumbs\2fbb55e5da351620fc02017f2eeb1114c3301c4b.png)
![Agent_Knowledge\region_thumbs\305c16065ebe1f8b34f78c871e062feaa26903e4.png](Agent_Knowledge\region_thumbs\305c16065ebe1f8b34f78c871e062feaa26903e4.png)
![Agent_Knowledge\region_thumbs\30a78b8903c34e659af4cdba43cba0ee54a6ad2a.png](Agent_Knowledge\region_thumbs\30a78b8903c34e659af4cdba43cba0ee54a6ad2a.png)
![Agent_Knowledge\region_thumbs\36b9cb0aa15307a6b531def122eb76ed3d505e38.png](Agent_Knowledge\region_thumbs\36b9cb0aa15307a6b531def122eb76ed3d505e38.png)
![Agent_Knowledge\region_thumbs\3b6cea6b119fa6444ffb3a7824d8e1f4cf3cea87.png](Agent_Knowledge\region_thumbs\3b6cea6b119fa6444ffb3a7824d8e1f4cf3cea87.png)
![Agent_Knowledge\region_thumbs\3d1effcbff594a57968b9c8029d5adce3203ad9a.png](Agent_Knowledge\region_thumbs\3d1effcbff594a57968b9c8029d5adce3203ad9a.png)
![Agent_Knowledge\region_thumbs\4025d45ef72b8d4f0dfdcb63544c4e3803dbcd0e.png](Agent_Knowledge\region_thumbs\4025d45ef72b8d4f0dfdcb63544c4e3803dbcd0e.png)
![Agent_Knowledge\region_thumbs\47bb490c5184866ec1f11ce4334362b4f2e3630e.png](Agent_Knowledge\region_thumbs\47bb490c5184866ec1f11ce4334362b4f2e3630e.png)
![Agent_Knowledge\region_thumbs\48277ece80468107ebc97cc390c3ef7f61600dcf.png](Agent_Knowledge\region_thumbs\48277ece80468107ebc97cc390c3ef7f61600dcf.png)
![Agent_Knowledge\region_thumbs\497d5dac21fdd15dd968a0793cea4ba3508ed268.png](Agent_Knowledge\region_thumbs\497d5dac21fdd15dd968a0793cea4ba3508ed268.png)
![Agent_Knowledge\region_thumbs\5d55b3575f97257bfa89475136a75993a7ff2af0.png](Agent_Knowledge\region_thumbs\5d55b3575f97257bfa89475136a75993a7ff2af0.png)
![Agent_Knowledge\region_thumbs\631b8fe1a6e3d9d563b832617c0ed38544fc2f36.png](Agent_Knowledge\region_thumbs\631b8fe1a6e3d9d563b832617c0ed38544fc2f36.png)
![Agent_Knowledge\region_thumbs\635f1ec4cc23e08880e6d21e5dabf5ff59be33ab.png](Agent_Knowledge\region_thumbs\635f1ec4cc23e08880e6d21e5dabf5ff59be33ab.png)
![Agent_Knowledge\region_thumbs\63a07d42c961fa3c6e220ba43835cb7d1d2b7f02.png](Agent_Knowledge\region_thumbs\63a07d42c961fa3c6e220ba43835cb7d1d2b7f02.png)
![Agent_Knowledge\region_thumbs\63da20d509c7363bc2e09d9a8f00b614d10d79c0.png](Agent_Knowledge\region_thumbs\63da20d509c7363bc2e09d9a8f00b614d10d79c0.png)
![Agent_Knowledge\region_thumbs\69b6b04264bfb4c4f4441a93ab5cfcd3e55ce409.png](Agent_Knowledge\region_thumbs\69b6b04264bfb4c4f4441a93ab5cfcd3e55ce409.png)
![Agent_Knowledge\region_thumbs\6f5a0b52769037deb61b7015554f22295ae3bb34.png](Agent_Knowledge\region_thumbs\6f5a0b52769037deb61b7015554f22295ae3bb34.png)
![Agent_Knowledge\region_thumbs\771461cccede22a2dc43deffc18df8722e50d986.png](Agent_Knowledge\region_thumbs\771461cccede22a2dc43deffc18df8722e50d986.png)
![Agent_Knowledge\region_thumbs\89f63bea489e521c83ca92988caf3ab3a4fc199b.png](Agent_Knowledge\region_thumbs\89f63bea489e521c83ca92988caf3ab3a4fc199b.png)
![Agent_Knowledge\region_thumbs\8a6f1b27841cbd17115bed7bc98c73ce00142396.png](Agent_Knowledge\region_thumbs\8a6f1b27841cbd17115bed7bc98c73ce00142396.png)
![Agent_Knowledge\region_thumbs\94476e6f4f4bbe7c96a8c156ff398f0e9842c122.png](Agent_Knowledge\region_thumbs\94476e6f4f4bbe7c96a8c156ff398f0e9842c122.png)
![Agent_Knowledge\region_thumbs\95d931c48e12b7cbd5f9ce6fb5c89f7cf49475cb.png](Agent_Knowledge\region_thumbs\95d931c48e12b7cbd5f9ce6fb5c89f7cf49475cb.png)
![Agent_Knowledge\region_thumbs\96173142cb347a4c81a73300a3ae1d26524725eb.png](Agent_Knowledge\region_thumbs\96173142cb347a4c81a73300a3ae1d26524725eb.png)
![Agent_Knowledge\region_thumbs\986b362802948f32e8802f2ed6f88dc34b442745.png](Agent_Knowledge\region_thumbs\986b362802948f32e8802f2ed6f88dc34b442745.png)
![Agent_Knowledge\region_thumbs\9ace036d0177b1ca1c7ea1faa078a715d8e9d713.png](Agent_Knowledge\region_thumbs\9ace036d0177b1ca1c7ea1faa078a715d8e9d713.png)
![Agent_Knowledge\region_thumbs\9c3eafc4de4bad6e1b01387b192103371d1c1018.png](Agent_Knowledge\region_thumbs\9c3eafc4de4bad6e1b01387b192103371d1c1018.png)
![Agent_Knowledge\region_thumbs\ae20dbc178fcbec3b8b7989342b98ea4d9034051.png](Agent_Knowledge\region_thumbs\ae20dbc178fcbec3b8b7989342b98ea4d9034051.png)
![Agent_Knowledge\region_thumbs\b7490be3a33d6355746d9c384b36a27c6dfa0ac3.png](Agent_Knowledge\region_thumbs\b7490be3a33d6355746d9c384b36a27c6dfa0ac3.png)
![Agent_Knowledge\region_thumbs\ba1f83df9f4cf77ecd560dacf993629a7445a09f.png](Agent_Knowledge\region_thumbs\ba1f83df9f4cf77ecd560dacf993629a7445a09f.png)
![Agent_Knowledge\region_thumbs\bb68a25cc8112882148af47e02ffdda5e6684387.png](Agent_Knowledge\region_thumbs\bb68a25cc8112882148af47e02ffdda5e6684387.png)
![Agent_Knowledge\region_thumbs\c1c7a2ec8d6853775672ecbf2f61a43d61f72223.png](Agent_Knowledge\region_thumbs\c1c7a2ec8d6853775672ecbf2f61a43d61f72223.png)
![Agent_Knowledge\region_thumbs\c8435a96adb2cf12ecf7925f25da2f5c3d47c50d.png](Agent_Knowledge\region_thumbs\c8435a96adb2cf12ecf7925f25da2f5c3d47c50d.png)
![Agent_Knowledge\region_thumbs\c9b8296347b7b6e29d3c9b08c9253e5b0eae6420.png](Agent_Knowledge\region_thumbs\c9b8296347b7b6e29d3c9b08c9253e5b0eae6420.png)
![Agent_Knowledge\region_thumbs\d32ad1496fc12d740dcf07fe7a1e3e06f1b2ec3c.png](Agent_Knowledge\region_thumbs\d32ad1496fc12d740dcf07fe7a1e3e06f1b2ec3c.png)
![Agent_Knowledge\region_thumbs\da2bc4730128aa31bda979b7d8c337d853748850.png](Agent_Knowledge\region_thumbs\da2bc4730128aa31bda979b7d8c337d853748850.png)
![Agent_Knowledge\region_thumbs\e56cb74f3f1ac3114a392f781c608a20da4fa927.png](Agent_Knowledge\region_thumbs\e56cb74f3f1ac3114a392f781c608a20da4fa927.png)
![Agent_Knowledge\region_thumbs\eb9fe9179361234528e4f478bf3a5ab8276df057.png](Agent_Knowledge\region_thumbs\eb9fe9179361234528e4f478bf3a5ab8276df057.png)
![Agent_Knowledge\region_thumbs\fb8bb659ec71a7fbb6d04257cc20012e24c0bfac.png](Agent_Knowledge\region_thumbs\fb8bb659ec71a7fbb6d04257cc20012e24c0bfac.png)
![Agent_Knowledge\region_thumbs\ff027cffd74873991e71e76a1aa68d3a03327ac9.png](Agent_Knowledge\region_thumbs\ff027cffd74873991e71e76a1aa68d3a03327ac9.png)
![Agent_Knowledge\regions\024be72e0bdb36b2e53c0040b8f437820469cd67.png](Agent_Knowledge\regions\024be72e0bdb36b2e53c0040b8f437820469cd67.png)
![Agent_Knowledge\regions\041b4e3006f2d8488c0abfe5cef83838da78a409.png](Agent_Knowledge\regions\041b4e3006f2d8488c0abfe5cef83838da78a409.png)
![Agent_Knowledge\regions\0554bfdcf6f592d4b6034ea0e8a3cc2669fe09e9.png](Agent_Knowledge\regions\0554bfdcf6f592d4b6034ea0e8a3cc2669fe09e9.png)
![Agent_Knowledge\regions\0c3c299dfdec07a1e1b4de3f4fd40b6799ade28f.png](Agent_Knowledge\regions\0c3c299dfdec07a1e1b4de3f4fd40b6799ade28f.png)
![Agent_Knowledge\regions\18f585a3be14458cc6e80fe48b95169239d880a1.png](Agent_Knowledge\regions\18f585a3be14458cc6e80fe48b95169239d880a1.png)
![Agent_Knowledge\regions\201bc91b5f4c28d2e59aeadbc095c192417b30bd.png](Agent_Knowledge\regions\201bc91b5f4c28d2e59aeadbc095c192417b30bd.png)
![Agent_Knowledge\regions\29560c38ccce8ccd06afbee025236da4839cab63.png](Agent_Knowledge\regions\29560c38ccce8ccd06afbee025236da4839cab63.png)
![Agent_Knowledge\regions\2fbb55e5da351620fc02017f2eeb1114c3301c4b.png](Agent_Knowledge\regions\2fbb55e5da351620fc02017f2eeb1114c3301c4b.png)
![Agent_Knowledge\regions\305c16065ebe1f8b34f78c871e062feaa26903e4.png](Agent_Knowledge\regions\305c16065ebe1f8b34f78c871e062feaa26903e4.png)
![Agent_Knowledge\regions\30a78b8903c34e659af4cdba43cba0ee54a6ad2a.png](Agent_Knowledge\regions\30a78b8903c34e659af4cdba43cba0ee54a6ad2a.png)
![Agent_Knowledge\regions\36b9cb0aa15307a6b531def122eb76ed3d505e38.png](Agent_Knowledge\regions\36b9cb0aa15307a6b531def122eb76ed3d505e38.png)
![Agent_Knowledge\regions\3b6cea6b119fa6444ffb3a7824d8e1f4cf3cea87.png](Agent_Knowledge\regions\3b6cea6b119fa6444ffb3a7824d8e1f4cf3cea87.png)
![Agent_Knowledge\regions\3d1effcbff594a57968b9c8029d5adce3203ad9a.png](Agent_Knowledge\regions\3d1effcbff594a57968b9c8029d5adce3203ad9a.png)
![Agent_Knowledge\regions\4025d45ef72b8d4f0dfdcb63544c4e3803dbcd0e.png](Agent_Knowledge\regions\4025d45ef72b8d4f0dfdcb63544c4e3803dbcd0e.png)
![Agent_Knowledge\regions\47bb490c5184866ec1f11ce4334362b4f2e3630e.png](Agent_Knowledge\regions\47bb490c5184866ec1f11ce4334362b4f2e3630e.png)
![Agent_Knowledge\regions\48277ece80468107ebc97cc390c3ef7f61600dcf.png](Agent_Knowledge\regions\48277ece80468107ebc97cc390c3ef7f61600dcf.png)
![Agent_Knowledge\regions\497d5dac21fdd15dd968a0793cea4ba3508ed268.png](Agent_Knowledge\regions\497d5dac21fdd15dd968a0793cea4ba3508ed268.png)
![Agent_Knowledge\regions\5d55b3575f97257bfa89475136a75993a7ff2af0.png](Agent_Knowledge\regions\5d55b3575f97257bfa89475136a75993a7ff2af0.png)
![Agent_Knowledge\regions\631b8fe1a6e3d9d563b832617c0ed38544fc2f36.png](Agent_Knowledge\regions\631b8fe1a6e3d9d563b832617c0ed38544fc2f36.png)
![Agent_Knowledge\regions\635f1ec4cc23e08880e6d21e5dabf5ff59be33ab.png](Agent_Knowledge\regions\635f1ec4cc23e08880e6d21e5dabf5ff59be33ab.png)
![Agent_Knowledge\regions\63a07d42c961fa3c6e220ba43835cb7d1d2b7f02.png](Agent_Knowledge\regions\63a07d42c961fa3c6e220ba43835cb7d1d2b7f02.png)
![Agent_Knowledge\regions\63da20d509c7363bc2e09d9a8f00b614d10d79c0.png](Agent_Knowledge\regions\63da20d509c7363bc2e09d9a8f00b614d10d79c0.png)
![Agent_Knowledge\regions\69b6b04264bfb4c4f4441a93ab5cfcd3e55ce409.png](Agent_Knowledge\regions\69b6b04264bfb4c4f4441a93ab5cfcd3e55ce409.png)
![Agent_Knowledge\regions\6f5a0b52769037deb61b7015554f22295ae3bb34.png](Agent_Knowledge\regions\6f5a0b52769037deb61b7015554f22295ae3bb34.png)
![Agent_Knowledge\regions\771461cccede22a2dc43deffc18df8722e50d986.png](Agent_Knowledge\regions\771461cccede22a2dc43deffc18df8722e50d986.png)
![Agent_Knowledge\regions\89f63bea489e521c83ca92988caf3ab3a4fc199b.png](Agent_Knowledge\regions\89f63bea489e521c83ca92988caf3ab3a4fc199b.png)
![Agent_Knowledge\regions\8a6f1b27841cbd17115bed7bc98c73ce00142396.png](Agent_Knowledge\regions\8a6f1b27841cbd17115bed7bc98c73ce00142396.png)
![Agent_Knowledge\regions\94476e6f4f4bbe7c96a8c156ff398f0e9842c122.png](Agent_Knowledge\regions\94476e6f4f4bbe7c96a8c156ff398f0e9842c122.png)
![Agent_Knowledge\regions\95d931c48e12b7cbd5f9ce6fb5c89f7cf49475cb.png](Agent_Knowledge\regions\95d931c48e12b7cbd5f9ce6fb5c89f7cf49475cb.png)
![Agent_Knowledge\regions\96173142cb347a4c81a73300a3ae1d26524725eb.png](Agent_Knowledge\regions\96173142cb347a4c81a73300a3ae1d26524725eb.png)
![Agent_Knowledge\regions\986b362802948f32e8802f2ed6f88dc34b442745.png](Agent_Knowledge\regions\986b362802948f32e8802f2ed6f88dc34b442745.png)
![Agent_Knowledge\regions\9ace036d0177b1ca1c7ea1faa078a715d8e9d713.png](Agent_Knowledge\regions\9ace036d0177b1ca1c7ea1faa078a715d8e9d713.png)
![Agent_Knowledge\regions\9c3eafc4de4bad6e1b01387b192103371d1c1018.png](Agent_Knowledge\regions\9c3eafc4de4bad6e1b01387b192103371d1c1018.png)
![Agent_Knowledge\regions\ae20dbc178fcbec3b8b7989342b98ea4d9034051.png](Agent_Knowledge\regions\ae20dbc178fcbec3b8b7989342b98ea4d9034051.png)
![Agent_Knowledge\regions\b7490be3a33d6355746d9c384b36a27c6dfa0ac3.png](Agent_Knowledge\regions\b7490be3a33d6355746d9c384b36a27c6dfa0ac3.png)
![Agent_Knowledge\regions\ba1f83df9f4cf77ecd560dacf993629a7445a09f.png](Agent_Knowledge\regions\ba1f83df9f4cf77ecd560dacf993629a7445a09f.png)
![Agent_Knowledge\regions\bb68a25cc8112882148af47e02ffdda5e6684387.png](Agent_Knowledge\regions\bb68a25cc8112882148af47e02ffdda5e6684387.png)
![Agent_Knowledge\regions\c1c7a2ec8d6853775672ecbf2f61a43d61f72223.png](Agent_Knowledge\regions\c1c7a2ec8d6853775672ecbf2f61a43d61f72223.png)
![Agent_Knowledge\regions\c8435a96adb2cf12ecf7925f25da2f5c3d47c50d.png](Agent_Knowledge\regions\c8435a96adb2cf12ecf7925f25da2f5c3d47c50d.png)
![Agent_Knowledge\regions\c9b8296347b7b6e29d3c9b08c9253e5b0eae6420.png](Agent_Knowledge\regions\c9b8296347b7b6e29d3c9b08c9253e5b0eae6420.png)
![Agent_Knowledge\regions\d32ad1496fc12d740dcf07fe7a1e3e06f1b2ec3c.png](Agent_Knowledge\regions\d32ad1496fc12d740dcf07fe7a1e3e06f1b2ec3c.png)
![Agent_Knowledge\regions\da2bc4730128aa31bda979b7d8c337d853748850.png](Agent_Knowledge\regions\da2bc4730128aa31bda979b7d8c337d853748850.png)
![Agent_Knowledge\regions\e56cb74f3f1ac3114a392f781c608a20da4fa927.png](Agent_Knowledge\regions\e56cb74f3f1ac3114a392f781c608a20da4fa927.png)
![Agent_Knowledge\regions\eb9fe9179361234528e4f478bf3a5ab8276df057.png](Agent_Knowledge\regions\eb9fe9179361234528e4f478bf3a5ab8276df057.png)
![Agent_Knowledge\regions\fb8bb659ec71a7fbb6d04257cc20012e24c0bfac.png](Agent_Knowledge\regions\fb8bb659ec71a7fbb6d04257cc20012e24c0bfac.png)
![Agent_Knowledge\regions\ff027cffd74873991e71e76a1aa68d3a03327ac9.png](Agent_Knowledge\regions\ff027cffd74873991e71e76a1aa68d3a03327ac9.png)

## Other Files

- `.git\config`
- `.git\description`
- `.git\FETCH_HEAD`
- `.git\HEAD`
- `.git\hooks\applypatch-msg.sample`
- `.git\hooks\commit-msg.sample`
- `.git\hooks\fsmonitor-watchman.sample`
- `.git\hooks\post-update.sample`
- `.git\hooks\pre-applypatch.sample`
- `.git\hooks\pre-commit.sample`
- `.git\hooks\pre-merge-commit.sample`
- `.git\hooks\pre-push.sample`
- `.git\hooks\pre-rebase.sample`
- `.git\hooks\pre-receive.sample`
- `.git\hooks\prepare-commit-msg.sample`
- `.git\hooks\push-to-checkout.sample`
- `.git\hooks\sendemail-validate.sample`
- `.git\hooks\update.sample`
- `.git\index`
- `.git\info\exclude`
- `.git\logs\HEAD`
- `.git\logs\refs\heads\main`
- `.git\logs\refs\remotes\origin\HEAD`
- `.git\logs\refs\remotes\origin\main`
- `.git\objects\02\f22bbd5fee05c25aaf57f636ca0c7a5e6b366b`
- `.git\objects\03\e728c5610a3922df9514296685d6ab0bac14c9`
- `.git\objects\04\0ac8d0d64e738c1ea5d1ef2834fad4b0f26282`
- `.git\objects\04\acb6a1b6d5367fdadefe83deefc841f83d0623`
- `.git\objects\05\2914fc58aed4235d1c8deecec0cdc3e48ae954`
- `.git\objects\06\78b0ab6888d18a8994c031932df05f6d9b1f64`
- `.git\objects\07\ec8c61c59d3fdbc4f6498d16a02d6b9932be24`
- `.git\objects\0d\53c1ac0ae310f54becd2ccb9247d2504c4d59a`
- `.git\objects\15\0cf130506bbc3b2960ed21646d1e56f232bcf2`
- `.git\objects\1c\63e05af7c21f5722136f442894d0a9482e19a7`
- `.git\objects\1e\e88c7b8153afaae4aa2e6b00650248111f56ac`
- `.git\objects\21\0e7520c13f93c50f5670d1af2bf3f10c2a0eee`
- `.git\objects\26\750893c1d5deb016703197db003685f22c5404`
- `.git\objects\29\2b5c936555225cdcdca197f8aadc4ad83c00cd`
- `.git\objects\29\97f36a985a4eb756a9b58e01ac2b52577ea3eb`
- `.git\objects\2c\63aff0c09d6f77cf1fb369de6e9cc39d700695`
- `.git\objects\2d\a5f1139bd1bb8f9026ba379d05f95b91b7e989`
- `.git\objects\3a\6384b321f3f6fe92e731c0761801c898cc93a4`
- `.git\objects\3e\21d3af0c6a062fbefe3ef9870131760ce08e00`
- `.git\objects\46\62fa1e54f4ad536b3fc2c4714bd171e9f8fa93`
- `.git\objects\47\62f88a8f0e8ba619e5f97869a6c346db7b1558`
- `.git\objects\48\cd53f8d2c5647105c1d143ae0922c57944a632`
- `.git\objects\49\7bfa9872442f8541c9d06589105281e8952b72`
- `.git\objects\4c\b336b6b198abfb46d87b7165f38dcf7a9a4ff3`
- `.git\objects\4d\26833a1a34eef00ffc507f23578b5e0d0af7b8`
- `.git\objects\4e\a1788b0d93fa42e27f8837c8d96fb92db81e57`
- `.git\objects\4e\c0ff5f283409f04075dfa6684e09e2817f5e79`
- `.git\objects\4f\9131276e464bbf197b9acffa2272adbe3f309e`
- `.git\objects\51\2c898047bd430211fbe6e9354839008d996afc`
- `.git\objects\54\d63225a8d960bde94ba55b1ed9d780ff9bd0ba`
- `.git\objects\57\52e8843a72e31ecdb6dd16f3d6a953c8b6eb4b`
- `.git\objects\58\0c4a5c59bc21a689d55b93f2b4c06d9cef7bfa`
- `.git\objects\5c\15560bee7dc106cdf742f24b9d4cbcdeacd832`
- `.git\objects\5d\c4c705cf2d4a248203fcb863952a8f209df8bc`
- `.git\objects\65\1ab45cb23d96c01fc9f5de47630fb8f137af1f`
- `.git\objects\67\5aa5fabf99770ca3a2c6dea524d9d9e883ff0c`
- `.git\objects\69\4e589c926493cb15146bf865797829072190f0`
- `.git\objects\6d\fddc0dc4eee8acfa45d62c68ca4c902b28690f`
- `.git\objects\70\2e724ec0f77e3453f03a5b18020fa293a5a72f`
- `.git\objects\70\7eedc5b5f1187da27babf666c36e156e26f4f7`
- `.git\objects\74\ce9f8d534cfd66e7fdd0a4ac06e3307bb78415`
- `.git\objects\7d\34eca82e82ab1a825ba18fe8bcf7b60c2ea6ed`
- `.git\objects\80\0d584c257b961836d5c24872c4d742e2b835c0`
- `.git\objects\88\fe6c63f068b0531eed3c70b91493be8be49dbc`
- `.git\objects\89\6ad76b2701848615bdfe235608106caa2c0736`
- `.git\objects\8a\07dd4d47f6b077b1610782304b3798f25fc753`
- `.git\objects\90\afe1bedded71cf917e3d8b9a1204b125bfba2f`
- `.git\objects\90\f7d050455299ad0002d4d9c51024d09e72ee11`
- `.git\objects\91\7d3803aba74fce759efa2cfbbb5d7936fb054b`
- `.git\objects\98\06356cad3efca2999c90badf66e8a0625d59da`
- `.git\objects\99\d4d985899ff5913413a434749c78c92a86e1c6`
- `.git\objects\9f\0c4d97f967d90d3b37ca9cc5cd0cc8ee1fb73c`
- `.git\objects\a2\8f3e1ee266f0ff9ba5a9f941c976c451983e4d`
- `.git\objects\a4\06a3c38c95ab88dbc303e8d9069c495ccaa636`
- `.git\objects\a4\5a49c4eebf0fbd8f68442bafb32e5920c568f6`
- `.git\objects\a7\4e9e23c6ab6d005368022aa2badcd531a8a9d8`
- `.git\objects\aa\69fe8a9dd45fe926946fc182d132c55ac155db`
- `.git\objects\b6\414b2e962e22970fc34749838fa2a02060ce32`
- `.git\objects\bb\141879faa1faec076dce1f156f91760b359294`
- `.git\objects\bc\065849097e3cb6438517604e14edc936743aef`
- `.git\objects\c7\b602717077f990c12e462b569bc40d5f5cbc69`
- `.git\objects\c9\331964d35d75a3395447263efe41cc694f9e92`
- `.git\objects\ce\5538474504a16cb0b999822f1dbaf88e29783a`
- `.git\objects\cf\d940f60d1ab35dff4080ea4208fa239fd13996`
- `.git\objects\d0\fb29beb881d9565267b28f3bee4021fb148c6c`
- `.git\objects\df\3a9bb3b89bb83e1f53c6bbb3f637272c61e5a6`
- `.git\objects\ea\18bfd7aafb213c4a2d799d4f661c2974d5719a`
- `.git\objects\ed\e2932a5cb72288d05dad4bd71eb30578f7c643`
- `.git\objects\f3\b2df9f23a3ad827dcc242287a8f35a96a49d25`
- `.git\objects\f9\afbd3b59736f942189201dd130c124ca25e64a`
- `.git\objects\pack\pack-5311d9fdaacd0338ad822bf2baf6b25dbe6acb5c.idx`
- `.git\objects\pack\pack-5311d9fdaacd0338ad822bf2baf6b25dbe6acb5c.pack`
- `.git\objects\pack\pack-5311d9fdaacd0338ad822bf2baf6b25dbe6acb5c.rev`
- `.git\packed-refs`
- `.git\refs\heads\main`
- `.git\refs\remotes\origin\HEAD`
- `.git\refs\remotes\origin\main`
- `.github\codex_sentinel.yml`
- `.github\workflows\codex-pr-sentinel.yml`
- `.gitignore`
- `__pycache__\visual_decomposition.cpython-313.pyc`
- `Agent.md`
- `Agent_Knowledge\__init__`
- `Agent_Knowledge\cluster_state.json`
- `Agent_Knowledge\menu_mappings.json`
- `Agent_Knowledge\metadata.jsonl`
- `Agent_Knowledge\Raw_Info\__init__`
- `Agent_Knowledge\Raw_Info\pokemon wiki info.md`
- `Agent_Knowledge\regions.jsonl`
- `Agent_Knowledge\timeline.jsonl`
- `Agent_Knowledge\vectors\__init__`
- `Agent_Knowledge\vectors\text_index.json`
- `Agent_Knowledge\vectors\text_vectors.npy`
- `Agent_Logs\__init__`
- `Agent_Logs\memory_reflections.jsonl`
- `Agent_Logs\similarity_events.jsonl`
- `Assets\__init__`
- `Assets\agent_brain.json`
- `Assets\prompts.json`
- `Assets\vgb_error.log`
- `Assets\vgb_prefs.json`
- `CHANGELOG.md`
- `Extended_README.md`
- `logs\session_2025-09-30.md`
- `logs\session_2025-10-01.md`
- `logs\session_2025-10-02.md`
- `logs\session_2025-10-03.md`
- `logs\session_2025-10-04.md`
- `logs\session_2025-10-05.md`
- `logs\session_2025-10-06.md`
- `logs\session_2025-10-07.md`
- `memory\codex_memory.json`
- `memory\logic_inbox.jsonl`
- `memory\menu_mappings.json`
- `Profiles\__init__`
- `Profiles\Player1\slot.state`
- `README.md`
- `requirements.txt`
- `ROMs\__init__`
- `ROMs\Pokemon Blue.gb`
- `ROMs\Pokemon Green.gb`
- `ROMs\Pokemon Red.gb`
- `ROMs\Pokemon Yellow.gb`
- `setup_venv.bat`
- `tools\__pycache__\__init__.cpython-313.pyc`
- `tools\__pycache__\operator_pipeline.cpython-313.pyc`
- `tools\__pycache__\pokemon_ingest.cpython-313.pyc`
- `tools\__pycache__\timeline_manager.cpython-313.pyc`


## Detailed Module Analyses


## Module `Agent-VirtualGameBoy.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Virtual Game Boy — PyQt6 + PyBoy with Learning Agent

Adds (highlights):
• On-disk learning brain (ε-greedy per screen cluster using pHash + Hamming)
• Smart probe bursts after parse failures (START→A→B→SELECT→D-pad) with early-stop on change
• Cooldowns/backoff to prevent infinite loops and key spam
• Heuristics for “title/press start” and “dialog box” that are gated by learned failures
• User-teaching: when the user presses a key, the agent records before/after and learns from it
• Knowledge store (large + mini64 frames, OCR, caption), timeline summaries, optional embeddings
• RAW Info ingestion (drop files/images in Agent_Knowledge/Raw_Info → vectorized + OCR’d)
• UI polish: white-on-dark for all agent inputs, key highlight on presses, keybind editor, etc.
• HTTP bridge (/status, /frame.png, /press, /release, /start, /pause, /reset, /save_state, /load_state)
"""
from __future__ import annotations
import argparse
import os, sys, time, json, traceback, queue, threading as th, re, io, hashlib, datetime as dt, base64, math, random, unicodedata
from pathlib import Path
from typing import Optional, Dict, List, Tuple, Any, Sequence, Set
from dataclasses import dataclass, field
from collections import deque, defaultdict

# HTTP bridge
import http.server as http
from http import HTTPStatus

from PyQt6 import QtCore, QtGui, QtWidgets
import numpy as np
from PIL import Image

from visual_decomposition import decompose_frame
from tools.pokemon_ingest import PokemonCorpusIngestor
from tools.timeline_manager import TimelineManager
from tools.operator_pipeline import (
    ObservationOperator,
    OperatorAggregator,
    OperatorBundle,
    OperatorResult,
)

try:
    import sounddevice as sd
except Exception:
    sd = None

try:
    from pyboy import PyBoy
    from pyboy.utils import WindowEvent
except Exception as e:
    raise SystemExit(
        "PyBoy failed to import. Install with:\n"
        " pip install pyboy PyQt6 pillow numpy pysdl2-dll sounddevice\n\n"
        f"{e}"
    )

# ------------------------------- Paths & files --------------------------------
def _app_dir() -> Path:
    if getattr(sys, "frozen", False):
        return Path(sys.executable).resolve().parent
    return Path(__file__).resolve().parent

APP_DIR = _app_dir()
ASSETS = APP_DIR / "Assets"; ASSETS.mkdir(parents=True, exist_ok=True)
ROMS_DIR = APP_DIR / "ROMs"; ROMS_DIR.mkdir(parents=True, exist_ok=True)
PROFILES = APP_DIR / "Profiles"; PROFILES.mkdir(parents=True, exist_ok=True)
LOGFILE = ASSETS / "vgb_error.log"
PREFS = ASSETS / "vgb_prefs.json"
PROMPTS = ASSETS / "prompts.json"
AGENT_LOGS = APP_DIR / "Agent_Logs"; AGENT_LOGS.mkdir(exist_ok=True)
SIMILARITY_LOG = AGENT_LOGS / "similarity_events.jsonl"
KNOWLEDGE = APP_DIR / "Agent_Knowledge"; KNOWLEDGE.mkdir(exist_ok=True)
RAW_INFO_DIR = KNOWLEDGE / "Raw_Info"; RAW_INFO_DIR.mkdir(exist_ok=True)
KN_IMG_DIR = KNOWLEDGE / "images"; KN_IMG_DIR.mkdir(exist_ok=True)
KN_MINI_DIR= KNOWLEDGE / "mini64"; KN_MINI_DIR.mkdir(exist_ok=True)
KN_META = KNOWLEDGE / "metadata.jsonl"
KN_REGION_DIR = KNOWLEDGE / "regions"; KN_REGION_DIR.mkdir(exist_ok=True)
KN_REGION_THUMBS = KNOWLEDGE / "region_thumbs"; KN_REGION_THUMBS.mkdir(exist_ok=True)
KN_REGION_META = KNOWLEDGE / "regions.jsonl"
TIMELINE = KNOWLEDGE / "timeline.jsonl"
TIMELINE_WINDOWS = KNOWLEDGE / "timeline_windows.jsonl"
VEC_DIR = KNOWLEDGE / "vectors"; VEC_DIR.mkdir(exist_ok=True)
VEC_NPY = VEC_DIR / "text_vectors.npy"
VEC_IDX = VEC_DIR / "text_index.json"
KN_STATE = KNOWLEDGE / "cluster_state.json"
POKEMON_CACHE = KNOWLEDGE / "pokemon_cache"; POKEMON_CACHE.mkdir(exist_ok=True)
POKEMON_LEXICON = KNOWLEDGE / "pokemon_lexicon.json"
BRAIN_PATH = ASSETS / "agent_brain.json"
TASK_LOG = AGENT_LOGS / "tasks.jsonl"
MEMORY_REFLECTION_LOG = AGENT_LOGS / "memory_reflections.jsonl"
MENU_MAPPINGS_PATH = KNOWLEDGE / "menu_mappings.json"
NAMING_MACROS_PATH = KNOWLEDGE / "naming_macros.json"

def _reset_log():
    try: LOGFILE.write_text("", encoding="utf-8")
    except Exception: pass
_reset_log()

def _excepthook(exc_type, exc, tb):
    msg = "".join(traceback.format_exception(exc_type, exc, tb))
    try:
        with LOGFILE.open("a", encoding="utf-8") as f: f.write(msg + "\n")
    except Exception: pass
    try:
        from PyQt6 import QtWidgets
        box = QtWidgets.QMessageBox()
        box.setIcon(QtWidgets.QMessageBox.Icon.Critical)
        box.setWindowTitle("Virtual Game Boy — crash")
        box.setText(f"An error occurred.\n\nLog saved to:\n{LOGFILE}\n\nClick OK to copy details.")
        box.setDetailedText(msg)
        box.setStandardButtons(QtWidgets.QMessageBox.StandardButton.Ok)
        if box.exec() == QtWidgets.QMessageBox.StandardButton.Ok:
            QtWidgets.QApplication.clipboard().setText(msg)
    except Exception: pass
sys.excepthook = _excepthook

# ----------------------------- Small utilities --------------------------------
def ts() -> str: return dt.datetime.now().strftime("%Y%m%d-%H%M%S")
def sanitize(name: str) -> str: return re.sub(r"[^\w\-\._]", "_", str(name))
def png_bytes_from_rgb(rgb: bytes, w: int, h: int) -> bytes:
    img = Image.frombytes("RGB", (w, h), rgb); bio = io.BytesIO(); img.save(bio, format="PNG"); return bio.getvalue()

def pHash64(img: Image.Image) -> str:
    g = img.convert("L").resize((9, 8), Image.Resampling.LANCZOS)
    a = np.asarray(g, dtype=np.int16)
    diff = a[:,1:] > a[:,:-1]
    bits = 0
    for i, v in enumerate(diff.flatten()):
        if v: bits |= (1 << i)
    return f"{bits:016x}"

def hamming_hex(a: str, b: str) -> int:
    return bin(int(a,16) ^ int(b,16)).count("1")

def sha1_bytes(b: bytes) -> str: return hashlib.sha1(b).hexdigest()

def srgb_tint(rgb: np.ndarray, color: Tuple[int,int,int], strength: float) -> np.ndarray:
    c = np.array(color, dtype=np.float32)
    out = rgb.astype(np.float32)*(1.0-strength) + c*strength
    return np.clip(out, 0, 255).astype(np.uint8)


def log_similarity_event(payload: Dict[str, Any]) -> None:
    try:
        SIMILARITY_LOG.parent.mkdir(parents=True, exist_ok=True)
        with SIMILARITY_LOG.open("a", encoding="utf-8") as fh:
            fh.write(json.dumps(payload) + "\n")
    except Exception:
        pass

# ------------------------------- Ollama client --------------------------------
import requests
OLLAMA_URL = os.environ.get("OLLAMA_URL", "http://127.0.0.1:11434")

def ollama_list() -> List[str]:
    try:
        r = requests.get(f"{OLLAMA_URL}/api/tags", timeout=4); r.raise_for_status()
        return [m["name"] for m in r.json().get("models", [])]
    except Exception: return []

def ollama_generate(model: str, prompt: str, b64_image: Optional[str]=None, system: Optional[str]=None) -> str:
    payload: Dict[str,Any] = {"model": model, "prompt": prompt, "stream": False}
    if b64_image: payload["images"] = [b64_image]
    if system: payload["system"] = system
    r = requests.post(f"{OLLAMA_URL}/api/generate", json=payload, timeout=300); r.raise_for_status()
    return (r.json() or {}).get("response","").strip()

def ollama_embed(model: str, text: str) -> Optional[List[float]]:
    try:
        r = requests.post(f"{OLLAMA_URL}/api/embeddings", json={"model": model, "prompt": text}, timeout=60)
        r.raise_for_status(); return (r.json() or {}).get("embedding")
    except Exception: return None

# ------------------------------- Default prompts ------------------------------
DEFAULT_PROMPTS = {
    "decision": """You are controlling a classic Game Boy Pokémon game using a D-Pad and two buttons.
Choose the next controller plan after seeing one 160x144 monochrome screenshot.

Rules:
- Available inputs: UP, DOWN, LEFT, RIGHT, A, B, START, SELECT, NONE, SAVE, LOAD, RESET, PAUSE
- Plans may contain multiple sequential steps to express holds or combos. Keep each step atomic (one button).
- Provide a brief reason for the overall plan. Individual steps MAY include their own reason text.
- Default step duration is 120 ms; adjust per need. Durations can exceed 600 ms when a sustained hold is required.
- If a title screen or “Press Start” appears, include START as the first step.
- If a dialogue box with ▼ paging arrow is visible, include A until the box should advance.
- If a menu selection caret ▶ is visible, use UP/DOWN to move and A to select.
- Observation JSON includes frame.screen_state (menu/dialog/overworld signals). Use it to reason about cursor_index and menu options before planning.
- Avoid infinite loops on START; vary exploration when progress stalls.
- When progress stalls, experiment with varied walking combos (UP/DOWN/LEFT/RIGHT) and compare before/after frames.
- SAVE/LOAD only if system_info.allow_saveload is true.

Return STRICT JSON ONLY (no prose) using this schema:
{
  "action": {
    "reason": "why this plan should work",
    "decline": false,
    "steps": [
      {"name": "UP|DOWN|LEFT|RIGHT|A|B|START|SELECT|NONE|SAVE|LOAD|RESET|PAUSE", "duration_ms": 120, "reason": "optional"}
    ]
  }
}
If no action is desired, set steps to an empty list or set decline=true.""",
    "ocr": """Output the visible in-dialogue text only (no commentary).""",
    "caption": """Describe the visible screen in one neutral sentence.""",
    "timeline": """You will be given a chronological list of short events the agent experienced
while trying to progress in Pokémon Red/Blue. Summarize what happened, what the agent seems to be
trying to do, what worked vs. didn’t, and propose a compact next-step plan in 3–5 bullet points."""
}

def load_prompts() -> Dict[str,str]:
    if PROMPTS.exists():
        try:
            data = json.loads(PROMPTS.read_text("utf-8"))
            out = dict(DEFAULT_PROMPTS); out.update({k:str(v) for k,v in data.items()})
            return out
        except Exception: pass
    return dict(DEFAULT_PROMPTS)

def save_prompts(d: Dict[str,str]):
    try: PROMPTS.write_text(json.dumps(d, indent=2), encoding="utf-8")
    except Exception: pass

# ------------------------------- Prefs & binds --------------------------------
from PyQt6 import QtCore as QC
def _kb(key: QC.Qt.Key, keypad: bool=False) -> Dict[str, int | bool]:
    return {"key": int(key), "keypad": bool(keypad)}

DEFAULT_KEYBINDS: Dict[str, Dict[str,int|bool]] = {
    "UP": _kb(QC.Qt.Key.Key_W),
    "DOWN": _kb(QC.Qt.Key.Key_S),
    "LEFT": _kb(QC.Qt.Key.Key_A),
    "RIGHT": _kb(QC.Qt.Key.Key_D),
    "A": _kb(QC.Qt.Key.Key_Left),
    "B": _kb(QC.Qt.Key.Key_Right),
    "START": _kb(QC.Qt.Key.Key_Backspace),
    "SELECT": _kb(QC.Qt.Key.Key_Return),
}

EVENTS_PRESS = {
    "UP": WindowEvent.PRESS_ARROW_UP,
    "DOWN": WindowEvent.PRESS_ARROW_DOWN,
    "LEFT": WindowEvent.PRESS_ARROW_LEFT,
    "RIGHT": WindowEvent.PRESS_ARROW_RIGHT,
    "A": WindowEvent.PRESS_BUTTON_A,
    "B": WindowEvent.PRESS_BUTTON_B,
    "START": WindowEvent.PRESS_BUTTON_START,
    "SELECT": WindowEvent.PRESS_BUTTON_SELECT,
}
EVENTS_RELEASE = {
    "UP": WindowEvent.RELEASE_ARROW_UP,
    "DOWN": WindowEvent.RELEASE_ARROW_DOWN,
    "LEFT": WindowEvent.RELEASE_ARROW_LEFT,
    "RIGHT": WindowEvent.RELEASE_ARROW_RIGHT,
    "A": WindowEvent.RELEASE_BUTTON_A,
    "B": WindowEvent.RELEASE_BUTTON_B,
    "START": WindowEvent.RELEASE_BUTTON_START,
    "SELECT": WindowEvent.RELEASE_BUTTON_SELECT,
}

DEFAULT_PREFS = {
    "save_on_reset": True, "save_on_stop": True, "save_on_quit": True,
    "auto_mute_on_pause": True,
    "audio_device": None, "audio_muted": False, "audio_gain": 1.0, "audio_rate": 48000,
    "profile": "Player1", "last_rom": None, "keybinds": DEFAULT_KEYBINDS,
    "bridge_port": 8787,
    "agent_model": "llava-llama3:latest",
    "vision_model": "llava-llama3:latest",
    "reasoning_model": "gemma3:1b",
    "agent_interval_ms": 350,
    "agent_allow_saveload": False,
    "agent_enable_ocr": False,
    "directive_sensitivity": "normal",
    "directive_decay_steps": 2,
    "ocr_model": "benhaotang/Nanonets-OCR-s:latest",
    "embed_model": "snowflake-arctic-embed2:latest",
    "summary_model": "gemma3:4b",
    "prompts": DEFAULT_PROMPTS,
    "lcd_tint_enabled": False,
    "lcd_tint_color": "#ff3b3b",
    "lcd_tint_strength": 0.12,
    "learn_from_user_inputs": True,
    "pokemon_sync_enabled": False,
    "brain_phash_threshold_min": 3,
    "brain_phash_threshold_max": 12,
    "brain_phash_threshold_default": 6,
    "knowledge_phash_threshold_min": 4,
    "knowledge_phash_threshold_max": 18,
    "knowledge_phash_threshold_default": 8,
    "timeline_horizon": 36,
    "timeline_decay": 0.7,
    "timeline_window": 5,
}

PREF_BOOL = {"save_on_reset","save_on_stop","save_on_quit","audio_muted","auto_mute_on_pause",
             "agent_allow_saveload","agent_enable_ocr","lcd_tint_enabled","learn_from_user_inputs",
             "pokemon_sync_enabled"}

def _upgrade_keybinds(raw) -> Dict[str, Dict[str,int|bool]]:
    if isinstance(raw, dict):
        conv: Dict[str, Dict[str,int|bool]] = {}
        for act in DEFAULT_KEYBINDS:
            v = raw.get(act, None)
            if isinstance(v, dict) and "key" in v:
                conv[act] = {"key": int(v["key"]), "keypad": bool(v.get("keypad", False))}
            elif isinstance(v, int):
                conv[act] = {"key": int(v), "keypad": False}
            else:
                conv[act] = dict(DEFAULT_KEYBINDS[act])
        return conv
    return dict(DEFAULT_KEYBINDS)

def load_prefs() -> dict:
    if PREFS.exists():
        try:
            d = json.loads(PREFS.read_text("utf-8"))
            legacy_agent = d.get("agent_model")
            if legacy_agent:
                if "vision_model" not in d:
                    d["vision_model"] = legacy_agent
                if "reasoning_model" not in d:
                    d["reasoning_model"] = legacy_agent
            migrations: Dict[str, Any] = {}
            legacy_knowledge = d.get("knowledge_phash_threshold")
            if legacy_knowledge is not None and "knowledge_phash_threshold_default" not in d:
                try:
                    migrations["knowledge_phash_threshold_default"] = int(legacy_knowledge)
                except Exception:
                    pass
            for bound_key in (
                "brain_phash_threshold_min",
                "brain_phash_threshold_max",
                "brain_phash_threshold_default",
                "knowledge_phash_threshold_min",
                "knowledge_phash_threshold_max",
                "knowledge_phash_threshold_default",
            ):
                if bound_key not in d and bound_key in DEFAULT_PREFS:
                    migrations[bound_key] = DEFAULT_PREFS[bound_key]
            if migrations:
                d.update(migrations)
            for k in PREF_BOOL: d[k] = bool(d.get(k, DEFAULT_PREFS[k]))
            for k, v in DEFAULT_PREFS.items(): d.setdefault(k, v)
            d["keybinds"] = _upgrade_keybinds(d.get("keybinds", DEFAULT_KEYBINDS))
            d["prompts"] = load_prompts()
            if migrations:
                try:
                    save_prefs(d)
                except Exception:
                    pass
            return d
        except Exception: pass
    return DEFAULT_PREFS.copy()

def save_prefs(p: dict):
    pr = p.get("prompts", {}); save_prompts(pr if pr else DEFAULT_PROMPTS)
    out = dict(p); out.pop("prompts", None)
    out.pop("knowledge_phash_threshold", None)
    if out.get("vision_model"):
        out["agent_model"] = out.get("vision_model")
    try: PREFS.write_text(json.dumps(out, indent=2), encoding="utf-8")
    except Exception: pass

# -------------------------------- Profiles ------------------------------------
def sanitize_name(name: str) -> str:
    s = re.sub(r"[^\w\-\s\.]", "_", name).strip(); return s or "Player"
def list_profiles() -> List[str]:
    names = [p.name for p in PROFILES.iterdir() if p.is_dir()]
    if not names: (PROFILES / "Player1").mkdir(parents=True, exist_ok=True); names = ["Player1"]
    names.sort(); return names
def profile_dir(name: str) -> Path: return PROFILES / name
def profile_state_path(name: str) -> Path: return profile_dir(name) / "slot.state"

# --------------------------------- Audio --------------------------------------
class AudioEngine:
    def __init__(self, prefs: dict):
        self.enabled = sd is not None
        self.sample_rate = int(prefs.get("audio_rate", 48000))
        self.samples_per_frame = max(1, self.sample_rate // 60)
        self.device = prefs.get("audio_device", None)
        self.muted = bool(prefs.get("audio_muted", False))
        self.gain = float(prefs.get("audio_gain", 1.0))
        self._q: "queue.Queue[np.ndarray]" = queue.Queue(maxsize=240)
        self._stream = None
        self._lock = th.Lock()
        self._last = np.zeros((self.samples_per_frame, 2), dtype=np.float32)

    def list_outputs(self):
        if not self.enabled: return []
        try: devs = sd.query_devices(); return [(i,d["name"]) for i,d in enumerate(devs) if d.get("max_output_channels",0) >= 2]
        except Exception: return []

    def start(self):
        if not self.enabled: return
        with self._lock:
            if self._stream: return
            try:
                self._stream = sd.OutputStream(
                    device=self.device, samplerate=self.sample_rate, channels=2, dtype="float32",
                    latency="low", blocksize=self.samples_per_frame, callback=self._callback
                ); self._stream.start()
            except Exception:
                try:
                    self.device = None
                    self._stream = sd.OutputStream(
                        samplerate=self.sample_rate, channels=2, dtype="float32",
                        latency="low", blocksize=self.samples_per_frame, callback=self._callback
                    ); self._stream.start()
                except Exception: self._stream = None

    def stop(self):
        if not self.enabled: return
        with self._lock:
            try:
                if self._stream: self._stream.stop(); self._stream.close()
            finally:
                self._stream = None
                with self._q.mutex: self._q.queue.clear()

    def flush(self):
        if not self.enabled: return
        with self._lock:
            with self._q.mutex: self._q.queue.clear()
            self._last[:] = 0

    def set_device(self, device_index: Optional[int]): self.device = device_index; self.stop(); self.start()
    def set_muted(self, muted: bool): self.muted = muted
    def set_gain(self, gain: float): self.gain = max(0.0, min(3.0, gain))

    def _callback(self, outdata, frames, time_info, status):
        try: data = self._q.get_nowait()
        except queue.Empty: data = self._last
        if data.shape[0] == frames: out = data
        elif data.shape[0] < frames:
            reps = (frames + data.shape[0] - 1) // data.shape[0]
            out = np.tile(data, (reps, 1))[:frames]
        else: out = data[:frames]
        self._last = out[-self.samples_per_frame:].copy()
        outdata[:] = (0.0 if self.muted else self.gain) * out

    def push_frame(self, stereo_int8: np.ndarray):
        if not self.enabled or self._stream is None or stereo_int8 is None or stereo_int8.size == 0: return
        f32 = (stereo_int8.astype(np.float32) / 128.0).clip(-1.0, 1.0)
        try: self._q.put_nowait(f32)
        except queue.Full:
            try: _ = self._q.get_nowait(); self._q.put_nowait(f32)
            except Exception: pass

# ------------------------------- Emulation thread -----------------------------
class EmuThread(QtCore.QThread):
    frameReady = QtCore.pyqtSignal(bytes, int, int)
    audioReady = QtCore.pyqtSignal(object)
    statusMsg = QtCore.pyqtSignal(str)
    coreState = QtCore.pyqtSignal(bool)

    def __init__(self, sample_rate: int, parent=None):
        super().__init__(parent)
        self.sample_rate = int(sample_rate)
        self._emu: Optional[PyBoy] = None
        self._running = False
        self._speed = 1.0
        self._cmd_q: "queue.Queue[Tuple[str, object]]" = queue.Queue()
        self._in_q: "queue.Queue[Tuple[str, int]]" = queue.Queue()
        self._stop_flag = False

    def cmd_load(self, rom_path: Path): self._cmd_q.put(("load", str(rom_path)))
    def cmd_reset(self): self._cmd_q.put(("reset", None))
    def cmd_set_running(self, running: bool): self._cmd_q.put(("running", bool(running)))
    def cmd_speed(self, speed: float): self._cmd_q.put(("speed", float(speed)))
    def cmd_stop(self): self._cmd_q.put(("stop", None))
    def cmd_input_press(self, evt: int): self._in_q.put(("press", int(evt)))
    def cmd_input_release(self, evt: int): self._in_q.put(("release", int(evt)))
    def cmd_save(self, path: Path): self._cmd_q.put(("save_state", str(path)))
    def cmd_load_state(self, path: Path):self._cmd_q.put(("load_state", str(path)))

    def _open(self, rom: str):
        self._close()
        self._emu = PyBoy(rom, window="null", sound_volume=100, sound_emulated=True, sound_sample_rate=self.sample_rate)
        try: self._emu.set_emulation_speed(0)
        except Exception: pass
        for _ in range(6): self._emu.tick(1, True)
        self._running = False
        self.coreState.emit(True)
        self.statusMsg.emit(f"Loaded ROM: {Path(rom).name} (paused; press Start)")

    def _close(self):
        try:
            if self._emu: self._emu.stop(save=False)
        except Exception: pass
        self._emu = None
        self._running = False
        self.coreState.emit(False)

    def _reset(self):
        if self._emu:
            try: self._emu.reset()
            except Exception: self._close()

    def run(self):
        t_next = time.perf_counter()
        while not self._stop_flag:
            try:
                while True:
                    cmd, val = self._cmd_q.get_nowait()
                    if cmd == "load": self._open(val)
                    elif cmd == "reset": self._reset()
                    elif cmd == "running": self._running = bool(val)
                    elif cmd == "speed": self._speed = max(0.5, min(3.0, float(val)))
                    elif cmd == "stop": self._close()
                    elif cmd == "save_state":
                        if self._emu:
                            try:
                                p = Path(val); p.parent.mkdir(parents=True, exist_ok=True)
                                with open(p, "wb") as fh: self._emu.save_state(fh)
                                self.statusMsg.emit(f"State saved → {p}")
                            except Exception as e: self.statusMsg.emit(f"Save failed: {e}")
                    elif cmd == "load_state":
                        if self._emu and Path(val).exists():
                            try:
                                with open(val, "rb") as fh: self._emu.load_state(fh)
                                self.statusMsg.emit(f"State loaded ← {val}")
                            except Exception as e: self.statusMsg.emit(f"Load failed: {e}")
                    self._cmd_q.task_done()
            except queue.Empty: pass

            try:
                while True:
                    kind, evt = self._in_q.get_nowait()
                    if self._emu:
                        try: self._emu.send_input(evt)
                        except Exception: pass
                    self._in_q.task_done()
            except queue.Empty: pass

            if self._emu and self._running:
                steps = max(1, int(round(self._speed)))
                for _ in range(steps): self._emu.tick(1, True)
                try: a = self._emu.sound.ndarray
                except Exception: a = None
                if a is not None: self.audioReady.emit(a)
                try: pil = self._emu.screen.image
                except Exception:
                    try: pil = self._emu.screen_image()
                    except Exception: pil = Image.new("RGB", (160, 144), (0,0,0))
                rgb = pil.convert("RGB"); self.frameReady.emit(rgb.tobytes("raw", "RGB"), rgb.width, rgb.height)

            t_next += 1.0/60.0
            dt_sleep = t_next - time.perf_counter()
            if dt_sleep > 0: time.sleep(dt_sleep)
            else: t_next = time.perf_counter()

        self._close()

    def stop_thread(self):
        self._stop_flag = True
        self._cmd_q.put(("stop", None))
        self.wait(2000)

# ------------------------------ HTTP Bridge -----------------------------------
class BridgeHandler(http.BaseHTTPRequestHandler):
    server: 'BridgeServer' # type: ignore
    def log_message(self, fmt, *args): return
    def _send_json(self, code: int, payload: dict):
        b = json.dumps(payload).encode("utf-8")
        self.send_response(code)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.send_header("Content-Length", str(len(b)))
        self.send_header("Cache-Control", "no-store")
        self.end_headers(); self.wfile.write(b)
    def _read_json(self) -> dict:
        try: ln = int(self.headers.get("Content-Length", "0"))
        except Exception: ln = 0
        if ln <= 0: return {}
        raw = self.rfile.read(ln)
        try: return json.loads(raw.decode("utf-8"))
        except Exception: return {}

    def do_GET(self):
        if self.path.startswith("/status"):
            app = self.server.app
            info = {
                "running": app.is_running(),
                "core_loaded": bool(app._core_loaded),
                "muted": bool(app.audio.muted),
                "volume": float(app.audio.gain),
                "speed": float(getattr(app, "_speed", 1.0)),
                "profile": app.prefs.get("profile"),
                "rom": app.prefs.get("last_rom"),
                "vision_model": app.prefs.get("vision_model") or app.prefs.get("agent_model"),
                "reasoning_model": app.prefs.get("reasoning_model") or app.prefs.get("agent_model"),
            }
            self._send_json(200, info); return
        if self.path.startswith("/frame.png"):
            data = getattr(self.server.app, "_last_frame_png", None)
            if not data:
                img = Image.new("RGB", (160, 144), (0,0,0)); bio = io.BytesIO(); img.save(bio,"PNG"); data=bio.getvalue()
            self.send_response(HTTPStatus.OK)
            self.send_header("Content-Type","image/png"); self.send_header("Cache-Control","no-store")
            self.send_header("Content-Length",str(len(data))); self.end_headers(); self.wfile.write(data); return
        self._send_json(404, {"error":"not found"})

    def do_POST(self):
        app = self.server.app; data = self._read_json()
        def ok(): self._send_json(200, {"ok":True})
        def bad(msg="bad request"): self._send_json(400, {"ok":False,"error":msg})

        if self.path == "/press":
            act = (data.get("action") or "").upper()
            if act in EVENTS_PRESS: app.emuThread.cmd_input_press(EVENTS_PRESS[act]); ok(); return
            return bad("unknown action")
        if self.path == "/release":
            act = (data.get("action") or "").upper()
            if act in EVENTS_RELEASE: app.emuThread.cmd_input_release(EVENTS_RELEASE[act]); ok(); return
            return bad("unknown action")
        if self.path == "/start":
            if not app._core_loaded:
                sel = app._rom_from_combo() or app._rom_from_prefs()
                if sel and sel.exists(): app._pending_run_after_load = True; app.emuThread.cmd_load(sel); ok(); return
                return bad("no rom selected")
            app.emuThread.cmd_set_running(True); app._style_start_button(True); ok(); return
        if self.path == "/pause": app.emuThread.cmd_set_running(False); app._style_start_button(False); ok(); return
        if self.path == "/stop": app.stop_emulation(); ok(); return
        if self.path == "/reset":
            if not app._core_loaded:
                sel = app._rom_from_combo() or app._rom_from_prefs()
                if sel and sel.exists(): app._pending_run_after_load = True; app.emuThread.cmd_load(sel); ok(); return
                return bad("no rom loaded")
            if app.prefs.get("save_on_reset", True): app._save_profile_state()
            app.emuThread.cmd_reset(); app.emuThread.cmd_set_running(True); app._style_start_button(True); ok(); return
        if self.path == "/mute":
            enabled = bool(data.get("enabled", True)); app.act_mute.setChecked(enabled); ok(); return
        if self.path == "/speed":
            try: val = float(data.get("value",1.0))
            except Exception: return bad("value must be float")
            val = max(0.5, min(3.0, val)); app._speed = val; app.emuThread.cmd_speed(val); ok(); return
        if self.path == "/save_state": app._save_profile_state(); ok(); return
        if self.path == "/load_state": app._load_profile_state(); ok(); return
        self._send_json(404, {"error":"not found"})

class BridgeServer(http.ThreadingHTTPServer):
    def __init__(self, addr, handler, app): super().__init__(addr, handler); self.app = app

# ----------------------------- Knowledge / Semantics --------------------------
class KnowledgeStore:
    BASIC_LEXICON = [
        "POKEMON","POKEDEX","POKEMON CENTER","START","SELECT","A","B",
        "CHARMANDER","SQUIRTLE","BULBASAUR","RED","BLUE","GREEN","YELLOW",
        "HP","LV","TYPE","SCRATCH","GROWL","TACKLE","TAIL WHIP","BAG","RUN","FIGHT",
        "NEW GAME","OPTION","RIVAL","NAME","END","YES","NO"
    ]
    def __init__(self, prefs: dict, *, state_path: Optional[Path] = None):
        self.prefs = prefs
        self.lexicon = set(self.BASIC_LEXICON)
        lexdir = ASSETS / "lexicon"
        if lexdir.exists():
            for p in lexdir.glob("*.txt"):
                try:
                    for line in p.read_text("utf-8").splitlines():
                        s = line.strip().upper()
                        if s: self.lexicon.add(s)
                except Exception: pass
        self.lexicon_catalog: Dict[str, Dict[str, Any]] = {}
        self.lexicon_forms: Dict[str, List[str]] = defaultdict(list)
        self._pokemon_tokens: Set[str] = set()
        self._load_pokemon_lexicon()
        self.embed_model = str(self.prefs.get("embed_model") or DEFAULT_PREFS.get("embed_model", "snowflake-arctic-embed2:latest"))
        self.vecs: Optional[np.ndarray] = None
        self.vecs_norm: Optional[np.ndarray] = None
        self.index: List[Dict[str,Any]] = []
        self._vector_ready = False
        self.timeline_cache: Dict[str, Dict[str, Any]] = {}
        self._timeline_windows_path = TIMELINE_WINDOWS
        self._entries_by_ts: Dict[str, Dict[str, Any]] = {}
        self.phash_clusters: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        self._regions_by_id: Dict[str, Dict[str, Any]] = {}
        self._regions_by_label: Dict[str, List[str]] = defaultdict(list)
        self._regions_by_parent: Dict[str, List[str]] = defaultdict(list)
        cfg = prefs or {}
        self._state_path = Path(state_path) if state_path else KN_STATE
        self._region_meta_path = KN_REGION_META
        try:
            self._cluster_threshold_min = max(1, int(cfg.get("knowledge_phash_threshold_min", 8)))
        except Exception:
            self._cluster_threshold_min = 4
        try:
            self._cluster_threshold_max = max(self._cluster_threshold_min, int(cfg.get("knowledge_phash_threshold_max", 8)))
        except Exception:
            self._cluster_threshold_max = max(self._cluster_threshold_min, 18)
        try:
            default_raw = int(cfg.get("knowledge_phash_threshold_default", 8))
        except Exception:
            default_raw = 8
        self._cluster_threshold_default = min(
            max(default_raw, self._cluster_threshold_min),
            self._cluster_threshold_max,
        )
        self._cluster_state: Dict[str, Any] = {}
        self._cluster_thresholds: Dict[str, int] = {}
        self._cluster_errors: Dict[str, List[Dict[str, Any]]] = {}
        self._cluster_last_distance: Dict[str, int] = {}
        self._cluster_clean_streaks: Dict[str, int] = {}
        self._threshold_events: deque[Dict[str, Any]] = deque(maxlen=32)
        self._load_cluster_state()
        self._load_vector_store()
        self._build_inverted_index()
        self._load_region_index()

    @staticmethod
    def _normalize_lexicon(text: str) -> str:
        cleaned = unicodedata.normalize("NFKD", str(text))
        ascii_only = "".join(ch for ch in cleaned if ch.isascii())
        return re.sub(r"\s+", " ", ascii_only).strip().upper()

    def _load_pokemon_lexicon(self) -> None:
        for token in getattr(self, "_pokemon_tokens", set()):
            if token not in self.BASIC_LEXICON:
                self.lexicon.discard(token)
        self._pokemon_tokens = set()
        self.lexicon_catalog = {}
        self.lexicon_forms = defaultdict(list)
        if not POKEMON_LEXICON.exists():
            return
        try:
            payload = json.loads(POKEMON_LEXICON.read_text("utf-8"))
        except Exception:
            return
        entries = payload.get("entries") if isinstance(payload, dict) else None
        if not isinstance(entries, dict):
            return
        for entry in entries.values():
            if not isinstance(entry, dict):
                continue
            norm = entry.get("normalized") or entry.get("token") or entry.get("key")
            token = self._normalize_lexicon(norm or "")
            if not token:
                continue
            glyph_est_raw = entry.get("glyph_estimate")
            try:
                glyph_est = int(glyph_est_raw)
            except Exception:
                glyph_est = len(re.sub(r"[^A-Z0-9]", "", token))
            raw_variants = entry.get("raw_variants")
            if not isinstance(raw_variants, list):
                raw_variants = []
            raw_variants = [str(variant) for variant in raw_variants if str(variant).strip()]
            sources = entry.get("sources")
            if not isinstance(sources, list):
                sources = []
            sources = [str(src) for src in sources if str(src).strip()]
            meta = {
                "category": entry.get("category") or "lexicon",
                "sources": sources,
                "raw_variants": raw_variants or [token],
                "glyph_estimate": glyph_est,
            }
            self.lexicon_catalog[token] = meta
            self.lexicon.add(token)
            self._pokemon_tokens.add(token)
            for variant in meta["raw_variants"]:
                if variant not in self.lexicon_forms[token]:
                    self.lexicon_forms[token].append(variant)
                normalized_variant = self._normalize_lexicon(variant)
                if normalized_variant and normalized_variant not in self.lexicon_catalog:
                    self.lexicon.add(normalized_variant)
                    self._pokemon_tokens.add(normalized_variant)

    def refresh_pokemon_lexicon(self) -> int:
        self._load_pokemon_lexicon()
        return len(self.lexicon_catalog)

    def lexicon_suggestions_for_glyphs(self, glyphs: int, *, top_k: int = 3) -> List[str]:
        if glyphs <= 0 or not self.lexicon_catalog:
            return []
        scored: List[Tuple[float, str, Dict[str, Any]]] = []
        for token, meta in self.lexicon_catalog.items():
            try:
                estimate = int(meta.get("glyph_estimate", 0))
            except Exception:
                estimate = len(re.sub(r"[^A-Z0-9]", "", token))
            diff = abs(estimate - glyphs)
            bias = 0.0
            category = str(meta.get("category") or "")
            if category == "ui_label":
                bias -= 0.25
            elif category == "glyph_variant":
                bias -= 0.1
            scored.append((diff + bias, token, meta))
        scored.sort(key=lambda item: (item[0], item[1]))
        suggestions: List[str] = []
        for _, token, meta in scored:
            variants = list(self.lexicon_forms.get(token, [])) or meta.get("raw_variants") or [token]
            for variant in variants:
                if variant not in suggestions:
                    suggestions.append(variant)
                    break
            if len(suggestions) >= top_k:
                break
        return suggestions

    def _load_cluster_state(self) -> None:
        self._cluster_state = {}
        if self._state_path.exists():
            try:
                raw = json.loads(self._state_path.read_text("utf-8"))
                if isinstance(raw, dict):
                    self._cluster_state = raw
            except Exception:
                self._cluster_state = {}
        defaults = self._cluster_state.setdefault("defaults", {})
        defaults["min"] = self._cluster_threshold_min
        defaults["max"] = self._cluster_threshold_max
        defaults["default"] = self._cluster_threshold_default
        self._cluster_thresholds = self._cluster_state.setdefault("thresholds", {})
        self._cluster_errors = self._cluster_state.setdefault("error_history", {})
        self._cluster_last_distance = self._cluster_state.setdefault("last_distance", {})
        self._cluster_state.setdefault("version", 1)

    def _save_cluster_state(self) -> None:
        try:
            data = dict(self._cluster_state)
            data["defaults"] = {
                "min": self._cluster_threshold_min,
                "max": self._cluster_threshold_max,
                "default": self._cluster_threshold_default,
            }
            data["thresholds"] = self._cluster_thresholds
            data["error_history"] = self._cluster_errors
            data["last_distance"] = self._cluster_last_distance
            data["version"] = data.get("version", 1)
            self._state_path.parent.mkdir(parents=True, exist_ok=True)
            self._state_path.write_text(json.dumps(data, indent=2), encoding="utf-8")
        except Exception:
            pass

    def _ensure_cluster_defaults(self, cluster_key: str) -> None:
        key = str(cluster_key)
        if not key:
            return
        if key not in self._cluster_thresholds:
            self._cluster_thresholds[key] = self._cluster_threshold_default
        self._cluster_errors.setdefault(key, [])
        self._cluster_last_distance.setdefault(key, self._cluster_threshold_default)
        self._cluster_clean_streaks.setdefault(key, 0)

    @staticmethod
    def _mini64(img: Image.Image) -> Image.Image: return img.resize((64,64), Image.Resampling.BILINEAR)

    @staticmethod
    def _ts_to_int(ts_value: str) -> int:
        try:
            return int(str(ts_value).replace("-", ""))
        except Exception:
            return 0

    def _load_vector_store(self):
        if not (VEC_NPY.exists() and VEC_IDX.exists()):
            return
        try:
            vecs = np.load(VEC_NPY)
            index = json.loads(VEC_IDX.read_text("utf-8"))
        except Exception:
            return
        if not isinstance(vecs, np.ndarray) or vecs.size == 0:
            return
        if not isinstance(index, list) or len(index) != vecs.shape[0]:
            return
        self.vecs = vecs.astype(np.float32)
        norms = np.linalg.norm(self.vecs, axis=1, keepdims=True)
        norms[norms == 0] = 1.0
        self.vecs_norm = self.vecs / norms
        self.index = list(index)
        self._vector_ready = True

    def _build_inverted_index(self):
        self.timeline_cache = {}
        if TIMELINE.exists():
            try:
                with TIMELINE.open("r", encoding="utf-8") as fh:
                    for line in fh:
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            data = json.loads(line)
                        except Exception:
                            continue
                        ts_key = str(data.get("t") or data.get("ts") or "").strip()
                        if not ts_key:
                            continue
                        self.timeline_cache[ts_key] = {
                            "ts": ts_key,
                            "action": data.get("a"),
                            "changed": data.get("chg"),
                            "caption": data.get("cap"),
                            "ocr": data.get("ocr"),
                        }
            except Exception:
                self.timeline_cache = {}
        self.phash_clusters = defaultdict(list)
        self._entries_by_ts = {}
        if not KN_META.exists():
            return
        rows: List[Dict[str, Any]] = []
        try:
            with KN_META.open("r", encoding="utf-8") as fh:
                for line in fh:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        rows.append(json.loads(line))
                    except Exception:
                        continue
        except Exception:
            return
        rows.sort(key=lambda item: self._ts_to_int(item.get("ts", "")), reverse=True)
        for row in rows:
            self._register_entry(row, None)

    def _load_region_index(self) -> None:
        self._regions_by_id.clear()
        self._regions_by_label.clear()
        self._regions_by_parent.clear()
        if not self._region_meta_path.exists():
            return
        try:
            with self._region_meta_path.open("r", encoding="utf-8") as fh:
                for line in fh:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        entry = json.loads(line)
                    except Exception:
                        continue
                    region_id = str(entry.get("region_id") or "").strip()
                    parent_sha = str(entry.get("parent_sha") or "").strip()
                    label = str(entry.get("label") or "").strip() or "region"
                    if not region_id:
                        continue
                    self._regions_by_id[region_id] = entry
                    if region_id not in self._regions_by_label[label]:
                        self._regions_by_label[label].append(region_id)
                    if parent_sha and region_id not in self._regions_by_parent[parent_sha]:
                        self._regions_by_parent[parent_sha].append(region_id)
        except Exception:
            self._regions_by_id.clear()
            self._regions_by_label.clear()
            self._regions_by_parent.clear()

    def _region_lookup(self, region_id: str) -> Optional[Dict[str, Any]]:
        return self._regions_by_id.get(region_id)

    def find_region_matches(
        self,
        regions: Sequence[Dict[str, Any]],
        *,
        top_k: int = 3,
        label_bias: float = 0.1,
    ) -> List[Dict[str, Any]]:
        matches: List[Dict[str, Any]] = []
        if not regions or not self._regions_by_id:
            return matches
        for region in regions:
            embedding = region.get("embedding")
            if not isinstance(embedding, (list, tuple)):
                continue
            label = str(region.get("label") or "").strip() or "region"
            target = np.asarray(embedding, dtype=np.float32)
            if target.size == 0:
                continue
            label_candidates = self._regions_by_label.get(label) or list(self._regions_by_id.keys())
            scored: List[Tuple[float, Dict[str, Any]]] = []
            for candidate_id in label_candidates:
                entry = self._regions_by_id.get(candidate_id)
                if not entry:
                    continue
                emb = entry.get("embedding")
                if not isinstance(emb, list) or not emb:
                    continue
                cand = np.asarray(emb, dtype=np.float32)
                if cand.size != target.size:
                    continue
                dist = float(np.linalg.norm(target - cand))
                score = 1.0 / (1e-6 + dist)
                if entry.get("label") == label:
                    score += label_bias
                scored.append((score, entry))
            scored.sort(key=lambda item: item[0], reverse=True)
            best = [
                {
                    "region_id": item[1].get("region_id"),
                    "parent_sha": item[1].get("parent_sha"),
                    "label": item[1].get("label"),
                    "score": item[0],
                    "ts": item[1].get("ts"),
                    "bbox": item[1].get("bbox"),
                }
                for item in scored[:top_k]
            ]
            if best:
                matches.append({
                    "query": {
                        "label": label,
                        "bbox": region.get("bbox"),
                        "confidence": region.get("confidence"),
                    },
                    "results": best,
                })
        return matches

    def _assign_cluster_key(self, phash: str, *, changed: Optional[bool] = None) -> str:
        phash = str(phash or "").strip()
        if not phash:
            return phash
        if not self.phash_clusters:
            self._ensure_cluster_defaults(phash)
            return phash
        best_key: Optional[str] = None
        best_d: Optional[int] = None
        for key in self.phash_clusters.keys():
            d = hamming_hex(key, phash)
            if best_d is None or d < best_d:
                best_key, best_d = key, d
                if d == 0:
                    break
        assigned = phash
        if best_key is not None and best_d is not None:
            self._ensure_cluster_defaults(best_key)
            threshold = int(self._cluster_thresholds.get(best_key, self._cluster_threshold_default))
            if best_d <= threshold:
                assigned = best_key
        distance = int(best_d if best_d is not None else 999)
        self._process_cluster_feedback(assigned, best_key, distance, phash, changed)
        if assigned == phash:
            self._ensure_cluster_defaults(phash)
            return phash
        return assigned

    def _process_cluster_feedback(
        self,
        assigned_key: str,
        best_key: Optional[str],
        distance: int,
        phash: str,
        changed: Optional[bool],
    ) -> None:
        state = best_key if isinstance(best_key, str) else assigned_key
        if state:
            self._ensure_cluster_defaults(state)
        if not isinstance(changed, bool) or not state:
            if assigned_key != phash and state:
                self._record_cluster_match(state, distance)
            return
        if changed and assigned_key == state:
            self._register_cluster_event(state, "false_negative", distance, assigned_key, phash)
        elif (not changed) and assigned_key == phash and best_key:
            self._register_cluster_event(best_key, "false_positive", distance, assigned_key, phash)
        elif assigned_key != phash:
            self._record_cluster_match(state, distance)

    def _register_cluster_event(
        self,
        cluster_key: str,
        event_type: str,
        distance: int,
        assigned_key: str,
        phash: str,
    ) -> None:
        key = str(cluster_key)
        if not key:
            return
        self._ensure_cluster_defaults(key)
        timestamp = ts()
        history = self._cluster_errors.setdefault(key, [])
        entry = {
            "ts": timestamp,
            "type": event_type,
            "distance": int(distance),
            "assigned": assigned_key,
            "phash": phash,
        }
        history.append(entry)
        if len(history) > 24:
            del history[:-24]
        self._cluster_last_distance[key] = int(distance)
        self._cluster_clean_streaks[key] = 0
        current = int(self._cluster_thresholds.get(key, self._cluster_threshold_default))
        new_threshold = current
        if event_type == "false_negative" and current < self._cluster_threshold_max:
            new_threshold = min(self._cluster_threshold_max, current + 1)
        elif event_type == "false_positive" and current > self._cluster_threshold_min:
            new_threshold = max(self._cluster_threshold_min, current - 1)
        payload = {
            "ts": timestamp,
            "kind": "knowledge",
            "cluster": key,
            "event": event_type,
            "distance": int(distance),
            "threshold": {"old": current, "new": new_threshold},
        }
        log_similarity_event(payload)
        self._cluster_thresholds[key] = new_threshold
        if new_threshold != current:
            self._threshold_events.append(payload)
        self._save_cluster_state()

    def _record_cluster_match(self, cluster_key: str, distance: int) -> None:
        key = str(cluster_key)
        if not key:
            return
        self._ensure_cluster_defaults(key)
        dist_val = int(distance)
        self._cluster_last_distance[key] = dist_val
        streak = self._cluster_clean_streaks.get(key, 0) + 1
        self._cluster_clean_streaks[key] = streak
        current = int(self._cluster_thresholds.get(key, self._cluster_threshold_default))
        target = self._cluster_threshold_default
        if streak >= 6 and current != target:
            if current > target:
                new_threshold = max(target, current - 1)
            else:
                new_threshold = min(target, current + 1)
            self._cluster_thresholds[key] = new_threshold
            payload = {
                "ts": ts(),
                "kind": "knowledge",
                "cluster": key,
                "event": "drift",
                "distance": dist_val,
                "threshold": {"old": current, "new": new_threshold},
            }
            self._threshold_events.append(payload)
            log_similarity_event(payload)
            self._cluster_clean_streaks[key] = 0
            self._save_cluster_state()

    def drain_threshold_events(self) -> List[Dict[str, Any]]:
        events = list(self._threshold_events)
        self._threshold_events.clear()
        return events

    def cluster_threshold_snapshot(self, phash: str) -> Dict[str, Any]:
        phash = str(phash or "").strip()
        if not phash or not self.phash_clusters:
            return {
                "cluster": None,
                "current": self._cluster_threshold_default,
                "default": self._cluster_threshold_default,
                "min": self._cluster_threshold_min,
                "max": self._cluster_threshold_max,
                "false_positive": 0,
                "false_negative": 0,
                "last_distance": None,
            }
        best_key: Optional[str] = None
        best_d: Optional[int] = None
        for key in self.phash_clusters.keys():
            d = hamming_hex(key, phash)
            if best_d is None or d < best_d:
                best_key, best_d = key, d
        if best_key is None:
            return {
                "cluster": None,
                "current": self._cluster_threshold_default,
                "default": self._cluster_threshold_default,
                "min": self._cluster_threshold_min,
                "max": self._cluster_threshold_max,
                "false_positive": 0,
                "false_negative": 0,
                "last_distance": None,
            }
        self._ensure_cluster_defaults(best_key)
        history = self._cluster_errors.get(best_key, [])
        false_pos = sum(1 for item in history if item.get("type") == "false_positive")
        false_neg = sum(1 for item in history if item.get("type") == "false_negative")
        last_distance = self._cluster_last_distance.get(best_key)
        current = int(self._cluster_thresholds.get(best_key, self._cluster_threshold_default))
        return {
            "cluster": best_key,
            "current": current,
            "default": self._cluster_threshold_default,
            "min": self._cluster_threshold_min,
            "max": self._cluster_threshold_max,
            "false_positive": false_pos,
            "false_negative": false_neg,
            "last_distance": last_distance,
            "distance": int(best_d) if best_d is not None else None,
        }

    def _register_entry(
        self,
        entry: Dict[str, Any],
        timeline: Optional[Dict[str, Any]] = None,
    ) -> None:
        ts_key = str(entry.get("ts") or "").strip()
        phash = str(entry.get("phash") or "").strip()
        if not ts_key or not phash:
            return
        if timeline is None:
            timeline_data = self.timeline_cache.get(ts_key)
        else:
            normalized = {
                "ts": ts_key,
                "action": timeline.get("action") or timeline.get("a"),
                "changed": timeline.get("changed") if "changed" in timeline else timeline.get("chg"),
                "caption": timeline.get("caption") or timeline.get("cap"),
                "ocr": timeline.get("ocr"),
            }
            self.timeline_cache[ts_key] = normalized
            timeline_data = normalized
        if timeline_data is None:
            timeline_data = {}
        payload = {
            "ts": ts_key,
            "phash": phash,
            "sha1": entry.get("sha1"),
            "action": entry.get("action") or (timeline_data or {}).get("action"),
            "changed": entry.get("changed") if entry.get("changed") is not None else (timeline_data or {}).get("changed"),
            "caption": entry.get("caption") or (timeline_data or {}).get("caption"),
            "ocr": entry.get("ocr_raw") or (timeline_data or {}).get("ocr"),
            "meta": {k: entry.get(k) for k in ("rom", "profile") if entry.get(k) is not None},
            "_ts_sort": self._ts_to_int(ts_key),
        }
        existing = self._entries_by_ts.get(ts_key)
        if existing:
            prev_cluster = existing.get("cluster_key")
            if prev_cluster and prev_cluster in self.phash_clusters:
                self.phash_clusters[prev_cluster] = [itm for itm in self.phash_clusters[prev_cluster] if itm.get("ts") != ts_key]
        changed_flag = payload.get("changed")
        if isinstance(changed_flag, bool):
            cluster_key = self._assign_cluster_key(phash, changed=changed_flag)
        else:
            cluster_key = self._assign_cluster_key(phash)
        payload["cluster_key"] = cluster_key
        bucket = self.phash_clusters.setdefault(cluster_key, [])
        bucket.insert(0, payload)
        if len(bucket) > 24:
            del bucket[24:]
        self._entries_by_ts[ts_key] = payload
        if cluster_key == phash:
            self._save_cluster_state()

    def search_by_phash(self, phash: str, limit: int = 5) -> List[Dict[str, Any]]:
        phash = str(phash or "").strip()
        if not phash or not self.phash_clusters:
            return []
        cluster_scores: List[Tuple[int, str]] = []
        for key in self.phash_clusters.keys():
            dist = hamming_hex(phash, key)
            cluster_scores.append((dist, key))
        if not cluster_scores:
            return []
        cluster_scores.sort(key=lambda item: item[0])
        ranked: List[Dict[str, Any]] = []
        for cluster_dist, key in cluster_scores:
            for item in self.phash_clusters.get(key, []):
                entry = dict(item)
                entry.pop("_ts_sort", None)
                entry["cluster_distance"] = cluster_dist
                entry["phash_distance"] = hamming_hex(phash, entry["phash"])
                ranked.append(entry)
            if len(ranked) >= limit * 2:
                break
        ranked.sort(key=lambda e: (e.get("phash_distance", 999), -self._ts_to_int(e.get("ts", ""))))
        out: List[Dict[str, Any]] = []
        seen_ts: set[str] = set()
        for entry in ranked:
            ts_key = str(entry.get("ts", ""))
            if ts_key in seen_ts:
                continue
            seen_ts.add(ts_key)
            out.append(entry)
            if len(out) >= limit:
                break
        return out

    def search_by_text(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        query = str(query or "").strip()
        if not query or not self._vector_ready or self.vecs_norm is None:
            return []
        emb = ollama_embed(self.embed_model, query)
        if emb is None:
            return []
        vec = np.array(emb, dtype=np.float32)
        if vec.ndim != 1 or vec.shape[0] != self.vecs_norm.shape[1]:
            return []
        norm = np.linalg.norm(vec)
        if not np.isfinite(norm) or norm == 0:
            return []
        vec = vec / norm
        scores = self.vecs_norm @ vec
        if scores.size == 0:
            return []
        order = np.argsort(scores)[::-1]
        results: List[Dict[str, Any]] = []
        for idx in order[: max(top_k * 3, top_k)]:
            score = float(scores[idx])
            if score <= 0:
                continue
            meta = dict(self.index[idx]) if idx < len(self.index) else {}
            meta["score"] = round(score, 4)
            results.append(meta)
            if len(results) >= top_k:
                break
        return results

    @property
    def vector_ready(self) -> bool:
        return bool(self._vector_ready)

    def add(
        self,
        img: Image.Image,
        meta: Dict[str,Any],
        ocr_text: Optional[str]=None,
        caption: Optional[str]=None,
        action: Optional[str]=None,
        changed: Optional[bool]=None,
        movement: Optional[Dict[str, Any]] = None,
        ocr_fallback: Optional[Dict[str, Any]] = None,
        regions: Optional[List[Dict[str, Any]]] = None,
    ):
        bio = io.BytesIO(); img.save(bio, "PNG"); data = bio.getvalue()
        sha = sha1_bytes(data)
        full_path = KN_IMG_DIR / f"{sha}.png"
        if not full_path.exists():
            full_path.write_bytes(data)
            self._mini64(img).save(KN_MINI_DIR / f"{sha}.png", "PNG")
        ph = pHash64(img)
        entry = {"ts": ts(), "sha1": sha, "phash": ph, **meta}
        if ocr_text: entry["ocr_raw"] = ocr_text
        if caption: entry["caption"] = caption
        if action: entry["action"] = action
        if changed is not None: entry["changed"] = bool(changed)
        if movement:
            entry["movement"] = movement
        if ocr_fallback:
            entry["ocr_fallback"] = dict(ocr_fallback)
        try:
            with KN_META.open("a", encoding="utf-8") as f: f.write(json.dumps(entry) + "\n")
        except Exception:
            pass
        if regions:
            try:
                self._persist_regions(img, sha, regions, entry.get("ts"))
            except Exception:
                pass
        timeline_entry = {
            "t": entry["ts"],
            "a": action,
            "chg": changed,
            "cap": caption,
            "ocr": ocr_text[:160] if ocr_text else None,
            "mov": movement,
        }
        if ocr_fallback:
            fb = {
                "text": ocr_fallback.get("text"),
                "line_count": ocr_fallback.get("line_count"),
                "cursor_index": ocr_fallback.get("cursor_index"),
                "confidence": ocr_fallback.get("confidence"),
                "source": ocr_fallback.get("source"),
            }
            lines = ocr_fallback.get("lines") if isinstance(ocr_fallback, dict) else None
            if isinstance(lines, list) and lines:
                fb_lines: List[Dict[str, Any]] = []
                for line in lines[:4]:
                    if not isinstance(line, dict):
                        continue
                    entry_line: Dict[str, Any] = {}
                    if isinstance(line.get("index"), int):
                        entry_line["index"] = int(line["index"])
                    if isinstance(line.get("glyphs"), int):
                        entry_line["glyphs"] = int(line["glyphs"])
                    if isinstance(line.get("hint"), str):
                        entry_line["hint"] = line["hint"]
                    fb_lines.append(entry_line)
                if fb_lines:
                    fb["lines"] = fb_lines
            timeline_entry["ocr_fb"] = fb
        try:
            with TIMELINE.open("a", encoding="utf-8") as f: f.write(json.dumps(timeline_entry) + "\n")
        except Exception:
            pass
        try:
            self._register_entry(entry, timeline_entry)
        except Exception:
            pass

    def record_timeline_window(self, window: Dict[str, Any]) -> None:
        if not isinstance(window, dict) or not window:
            return
        payload: Dict[str, Any] = {}
        for key in ("start_ts", "end_ts", "primary_mode", "summary", "actions"):
            if key not in window:
                continue
            value = window[key]
            if key == "actions" and isinstance(value, (list, tuple)):
                payload[key] = [str(item) for item in value[:12]]
            else:
                payload[key] = value
        if not payload:
            return
        try:
            with self._timeline_windows_path.open("a", encoding="utf-8") as fh:
                fh.write(json.dumps(payload) + "\n")
        except Exception:
            pass

    @staticmethod
    def _region_thumb(img: Image.Image, size: int = 48) -> Image.Image:
        w, h = img.size
        if w <= 0 or h <= 0:
            raise ValueError("Empty region crop")
        scale = max(w, h)
        if scale <= size:
            return img.copy()
        return img.resize((max(1, int(round(w * size / scale))), max(1, int(round(h * size / scale)))), Image.Resampling.BILINEAR)

    def _persist_regions(
        self,
        full_img: Image.Image,
        parent_sha: str,
        regions: Sequence[Dict[str, Any]],
        timestamp: Optional[str],
    ) -> None:
        if not regions:
            return
        arr = np.asarray(full_img, dtype=np.uint8)
        frame_h, frame_w = arr.shape[0], arr.shape[1]
        ts_value = timestamp or ts()
        for idx, region in enumerate(regions):
            if not isinstance(region, dict):
                continue
            bbox = region.get("bbox")
            if not isinstance(bbox, (list, tuple)) or len(bbox) != 4:
                continue
            x, y, w_box, h_box = bbox
            try:
                x_i = max(0, int(x))
                y_i = max(0, int(y))
                w_i = max(1, int(w_box))
                h_i = max(1, int(h_box))
            except Exception:
                continue
            if x_i >= frame_w or y_i >= frame_h:
                continue
            x2 = min(frame_w, x_i + w_i)
            y2 = min(frame_h, y_i + h_i)
            if x2 <= x_i or y2 <= y_i:
                continue
            crop = full_img.crop((x_i, y_i, x2, y2))
            crop_arr = np.asarray(crop, dtype=np.uint8)
            if crop_arr.size == 0:
                continue
            label = str(region.get("label") or "region").strip() or "region"
            facing = region.get("facing")
            confidence = float(region.get("confidence") or 0.0)
            embedding = region.get("embedding")
            if not isinstance(embedding, (list, tuple)) or not embedding:
                mean_rgb = crop_arr.mean(axis=(0, 1)) / 255.0
                std_rgb = crop_arr.std(axis=(0, 1)) / 255.0
                area = (crop_arr.shape[0] * crop_arr.shape[1]) / float(frame_w * frame_h)
                embedding = [
                    float(mean_rgb[0]),
                    float(mean_rgb[1]),
                    float(mean_rgb[2]),
                    float(std_rgb.mean()),
                    float(area),
                ]
            else:
                embedding = [float(v) for v in embedding]
            summary = f"{label} {w_i}x{h_i} conf={confidence:.2f}"
            region_id = sha1_bytes(
                f"{parent_sha}:{label}:{x_i}:{y_i}:{w_i}:{h_i}:{idx}".encode("utf-8")
            )
            if region_id in self._regions_by_id:
                # Region already persisted for this frame; skip re-writing to avoid
                # duplicate rows in the metadata log.
                continue
            thumb = self._region_thumb(crop)
            thumb_name = f"{region_id}.png"
            crop_name = f"{region_id}.png"
            try:
                crop.save(KN_REGION_DIR / crop_name, "PNG")
            except Exception:
                pass
            try:
                thumb.save(KN_REGION_THUMBS / thumb_name, "PNG")
            except Exception:
                pass
            entry = {
                "ts": ts_value,
                "parent_sha": parent_sha,
                "region_id": region_id,
                "label": label,
                "bbox": [x_i, y_i, x2 - x_i, y2 - y_i],
                "confidence": confidence,
                "facing": facing,
                "embedding": embedding,
                "summary": summary,
                "thumb": thumb_name,
                "crop": crop_name,
            }
            try:
                with self._region_meta_path.open("a", encoding="utf-8") as fh:
                    fh.write(json.dumps(entry) + "\n")
            except Exception:
                pass
            self._regions_by_id[region_id] = entry
            if region_id not in self._regions_by_label[label]:
                self._regions_by_label[label].append(region_id)
            if region_id not in self._regions_by_parent[parent_sha]:
                self._regions_by_parent[parent_sha].append(region_id)

# ----------------------------- RAW Info ingestion -----------------------------
class RawInfoIngestor(QtCore.QObject):
    # Very lightweight “agent DB” builder: walk RAW_INFO_DIR, OCR images, vectorize texts.
    progress = QtCore.pyqtSignal(str)

    def __init__(self, prefs: dict):
        super().__init__()
        self.prefs = prefs

    def ingest(self):
        emb_model = self.prefs.get("embed_model", "snowflake-arctic-embed2:latest")
        ocr_model = self.prefs.get("ocr_model", "")
        texts: List[str] = []
        index: List[Dict[str,Any]] = []
        # pull existing vectors to append
        if VEC_NPY.exists() and VEC_IDX.exists():
            try:
                prev = np.load(VEC_NPY)
                prev_idx = json.loads(VEC_IDX.read_text("utf-8"))
                self.progress.emit(f"Loaded existing vectors: {prev.shape}")
                self._vecs = [prev]; self._idx = list(prev_idx)
            except Exception:
                self._vecs, self._idx = [], []
        else:
            self._vecs, self._idx = [], []

        for p in sorted(RAW_INFO_DIR.rglob("*")):
            if p.is_dir(): continue
            ext = p.suffix.lower()
            try:
                if ext in (".txt", ".md"):
                    text = p.read_text("utf-8", errors="ignore")
                    texts.append(text)
                    index.append({"kind":"text","path":str(p.relative_to(RAW_INFO_DIR)),"len":len(text)})
                    self.progress.emit(f"Text: {p.name} ({len(text)} chars)")
                elif ext in (".png",".jpg",".jpeg",".bmp",".gif"):
                    # OCR summary via vision model if possible
                    try:
                        b64 = base64.b64encode(p.read_bytes()).decode("ascii")
                        vision_model = self.prefs.get("vision_model") or self.prefs.get("agent_model", "llava-llama3:latest")
                        cap = ollama_generate(ocr_model or vision_model,
                                              "Summarize this Pokémon-related image in one or two sentences for a knowledge base.", b64_image=b64)
                    except Exception:
                        cap = f"Image: {p.name}"
                    texts.append(cap)
                    index.append({"kind":"image","path":str(p.relative_to(RAW_INFO_DIR)),"caption":cap})
                    self.progress.emit(f"Image: {p.name} (OCR/caption)")
                else:
                    # fallback: store filename
                    texts.append(p.name)
                    index.append({"kind":"file","path":str(p.relative_to(RAW_INFO_DIR))})
            except Exception as e:
                self.progress.emit(f"Skip {p.name}: {e}")

        if not texts:
            self.progress.emit("No RAW items found."); return

        # embeddings
        vecs = []
        for i, t in enumerate(texts, 1):
            v = ollama_embed(emb_model, t)
            if v is None: self.progress.emit("Embedding failed; abort."); return
            vecs.append(v)
            if i % 10 == 0: self.progress.emit(f"Embedded {i}/{len(texts)} items…")

        vecs_np = np.array(vecs, dtype=np.float32)
        if self._vecs:
            vecs_np = np.vstack([self._vecs[0], vecs_np])
            index = self._idx + index

        np.save(VEC_NPY, vecs_np)
        VEC_IDX.write_text(json.dumps(index, indent=2), encoding="utf-8")
        self.progress.emit(f"Ingestion complete: {vecs_np.shape[0]} vectors.")

# ------------------------------ Prompt Manager --------------------------------
class PromptsDialog(QtWidgets.QDialog):
    def __init__(self, prompts: Dict[str,str], parent=None):
        super().__init__(parent)
        self.setWindowTitle("Prompt Manager"); self.setMinimumSize(820, 700)
        self.setStyleSheet("QDialog{background:#151515;color:#eaeaea;} QPlainTextEdit{background:#20232a;border:1px solid #3c404a;border-radius:8px;color:#eaeaea;padding:8px;} QPushButton{background:#2f80ed;color:white;border:1px solid #2563eb;border-radius:6px;padding:6px 12px;} QPushButton#flat{background:#555;border-color:#444;} QLabel{color:#dfe6ff;}")
        lay = QtWidgets.QGridLayout(self); lay.setHorizontalSpacing(12); lay.setVerticalSpacing(10)
        self.ed_dec = QtWidgets.QPlainTextEdit(prompts.get("decision",""))
        self.ed_ocr = QtWidgets.QPlainTextEdit(prompts.get("ocr",""))
        self.ed_cap = QtWidgets.QPlainTextEdit(prompts.get("caption",""))
        self.ed_tl  = QtWidgets.QPlainTextEdit(prompts.get("timeline",""))
        lay.addWidget(QtWidgets.QLabel("Decision prompt"), 0,0); lay.addWidget(self.ed_dec, 1,0)
        lay.addWidget(QtWidgets.QLabel("OCR prompt"), 2,0); lay.addWidget(self.ed_ocr, 3,0)
        lay.addWidget(QtWidgets.QLabel("Caption prompt"), 4,0); lay.addWidget(self.ed_cap, 5,0)
        lay.addWidget(QtWidgets.QLabel("Timeline summary prompt"), 6,0); lay.addWidget(self.ed_tl, 7,0)
        btns = QtWidgets.QHBoxLayout()
        self.btn_reset = QtWidgets.QPushButton("Reset to defaults"); self.btn_reset.setObjectName("flat")
        self.btn_cancel= QtWidgets.QPushButton("Cancel"); self.btn_cancel.setObjectName("flat")
        self.btn_ok = QtWidgets.QPushButton("Save")
        btns.addStretch(1); btns.addWidget(self.btn_reset); btns.addWidget(self.btn_cancel); btns.addWidget(self.btn_ok)
        lay.addLayout(btns, 8,0)
        self.btn_reset.clicked.connect(self._reset); self.btn_cancel.clicked.connect(self.reject); self.btn_ok.clicked.connect(self.accept)
    def values(self) -> Dict[str,str]:
        return {"decision": self.ed_dec.toPlainText(), "ocr": self.ed_ocr.toPlainText(), "caption": self.ed_cap.toPlainText(), "timeline": self.ed_tl.toPlainText()}
    def _reset(self):
        self.ed_dec.setPlainText(DEFAULT_PROMPTS["decision"])
        self.ed_ocr.setPlainText(DEFAULT_PROMPTS["ocr"])
        self.ed_cap.setPlainText(DEFAULT_PROMPTS["caption"])
        self.ed_tl.setPlainText(DEFAULT_PROMPTS["timeline"])

# ------------------------------ Learning Brain --------------------------------
ACTIONS = ["UP","DOWN","LEFT","RIGHT","A","B","START","SELECT","NONE","SAVE","LOAD","RESET","PAUSE"]
LEARNABLE = ["A","B","START","SELECT","UP","DOWN","LEFT","RIGHT"]
D_PAD_BUTTONS = {"UP", "DOWN", "LEFT", "RIGHT"}

BUTTON_DEFINITIONS: Dict[str, str] = {
    "UP": "Move or walk north/upwards on the overworld, climb menu selections upward.",
    "DOWN": "Move or walk south/downwards on the overworld, advance menu selections downward.",
    "LEFT": "Move or walk west/left on the overworld, shift menu cursors to the left when available.",
    "RIGHT": "Move or walk east/right on the overworld, shift menu cursors to the right when available.",
    "A": "Primary confirm/interaction button. Talk to NPCs, confirm menu items, advance dialogue boxes.",
    "B": "Secondary/cancel button. Exit menus, close dialogue faster, sometimes runs from encounters.",
    "START": "Opens the pause menu or confirms title screen prompts such as 'Press Start'.",
    "SELECT": "Toggles overlays or swaps highlighted menu panes depending on the game context.",
}

EXPLORATION_COMBOS: List[Tuple[str, Tuple[str, ...]]] = [
    ("walk_north", ("UP", "UP", "UP")),
    ("walk_south", ("DOWN", "DOWN", "DOWN")),
    ("walk_east", ("RIGHT", "RIGHT", "RIGHT")),
    ("walk_west", ("LEFT", "LEFT", "LEFT")),
    ("pace_vertical", ("UP", "DOWN", "UP", "DOWN")),
    ("pace_horizontal", ("LEFT", "RIGHT", "LEFT", "RIGHT")),
    ("confirm_dialog", ("A", "A", "A")),
    ("cancel_dialog", ("B", "B")),
    ("start_menu", ("START", "A")),
    ("select_toggle", ("SELECT", "A")),
    ("menu_scroll", ("START", "DOWN", "DOWN", "A")),
    ("walk_diagonal_up_right", ("UP", "RIGHT", "UP", "RIGHT")),
    ("walk_diagonal_up_left", ("UP", "LEFT", "UP", "LEFT")),
    ("walk_diagonal_down_right", ("DOWN", "RIGHT", "DOWN", "RIGHT")),
    ("walk_diagonal_down_left", ("DOWN", "LEFT", "DOWN", "LEFT")),
]


DIRECTIVE_SENSITIVITY_THRESHOLDS: Dict[str, float] = {
    "low": 2.2,
    "normal": 1.5,
    "high": 0.9,
}

_DIRECTIVE_VERBS = [
    "press",
    "go",
    "head",
    "talk",
    "speak",
    "find",
    "defeat",
    "beat",
    "collect",
    "return",
    "deliver",
    "bring",
    "catch",
    "choose",
    "select",
    "use",
    "open",
    "check",
    "search",
    "visit",
    "help",
    "explore",
    "investigate",
]

_VERB_PATTERN = "|".join(sorted(set(_DIRECTIVE_VERBS)))
_DIRECTIVE_START_RE = re.compile(rf"^\s*(?:{_VERB_PATTERN})\b", re.IGNORECASE)
_DIRECTIVE_INLINE_RE = re.compile(rf"\b(?:{_VERB_PATTERN})\b", re.IGNORECASE)
_DIRECTIVE_BUTTON_RE = re.compile(
    r"\b(press|hit|tap|hold)\s+(?:the\s+)?(start|select|a|b|up|down|left|right)\b",
    re.IGNORECASE,
)
_DIRECTIVE_QUEST_RE = re.compile(
    r"\b(objective|quest|mission|goal|task|request|assignment|duty)\b",
    re.IGNORECASE,
)
_DIRECTIVE_MARKER_RE = re.compile(r"^\s*[\[\(<«【]*(objective|quest|mission|goal|task)\b", re.IGNORECASE)
_DIRECTIVE_HINT_RE = re.compile(r"\b(hint|tip|advice)\b", re.IGNORECASE)
_DIRECTIVE_STEP_RE = re.compile(r"\b(step|stage)\s+\d+\b", re.IGNORECASE)
_DIRECTIVE_EXCLAIM_RE = re.compile(r"!+")


def _normalize_directive_text(text: str) -> str:
    cleaned = re.sub(r"[•▶➤➜→◆◇■★☆☞⇨⇾❯❱]+", " ", text or "")
    cleaned = cleaned.replace("—", " ").replace("–", " ")
    cleaned = re.sub(r"\s+", " ", cleaned).strip()
    return cleaned[:220]


def _iter_directive_segments(text: str) -> List[str]:
    segments: List[str] = []
    if not isinstance(text, str):
        return segments
    for raw_line in str(text).splitlines():
        line = raw_line.strip()
        if not line:
            continue
        line = re.sub(r"[•▶➤➜→◆◇■★☆☞⇨⇾❯❱]", " ", line)
        pieces = re.split(r"(?<=[.!?])\s+(?=[A-Z0-9])", line)
        if not pieces:
            pieces = [line]
        for piece in pieces:
            candidate = piece.strip(" -•▶➤➜→◆◇■★☆☞⇨⇾❯❱<>[]{}()\"\'")
            candidate = _normalize_directive_text(candidate)
            if len(candidate) >= 4:
                segments.append(candidate)
    return segments


def _score_directive(text: str, origin: str) -> Tuple[float, List[str]]:
    score = 0.0
    tags: List[str] = []
    if _DIRECTIVE_QUEST_RE.search(text):
        score += 1.5
        tags.append("quest")
    if _DIRECTIVE_MARKER_RE.search(text):
        score += 0.6
        tags.append("marker")
    if _DIRECTIVE_START_RE.search(text):
        score += 1.2
        tags.append("imperative")
    elif _DIRECTIVE_INLINE_RE.search(text):
        score += 0.4
        tags.append("imperative")
    if _DIRECTIVE_BUTTON_RE.search(text):
        score += 1.0
        tags.append("button")
    if _DIRECTIVE_HINT_RE.search(text):
        score += 0.5
        tags.append("hint")
    if _DIRECTIVE_STEP_RE.search(text):
        score += 0.3
        tags.append("step")
    if _DIRECTIVE_EXCLAIM_RE.search(text):
        score += 0.2
        tags.append("emphasis")
    if origin == "fallback_hint":
        score += 0.3
        tags.append("fallback")
    deduped_tags: List[str] = []
    for tag in tags:
        if tag not in deduped_tags:
            deduped_tags.append(tag)
    return score, deduped_tags


def extract_screen_directives(
    ocr_text: Optional[str],
    ocr_fallback: Optional[Dict[str, Any]],
    *,
    sensitivity: str = "normal",
) -> List[Dict[str, Any]]:
    level = str(sensitivity or "normal").strip().lower()
    threshold = DIRECTIVE_SENSITIVITY_THRESHOLDS.get(level, DIRECTIVE_SENSITIVITY_THRESHOLDS["normal"])
    candidates: List[Tuple[str, str]] = []
    if isinstance(ocr_text, str) and ocr_text.strip():
        for segment in _iter_directive_segments(ocr_text):
            candidates.append(("ocr_text", segment))
    if isinstance(ocr_fallback, dict):
        fb_text = ocr_fallback.get("text")
        if isinstance(fb_text, str) and fb_text.strip():
            for segment in _iter_directive_segments(fb_text):
                candidates.append(("ocr_fallback", segment))
        lines = ocr_fallback.get("lines")
        if isinstance(lines, list):
            for entry in lines:
                if not isinstance(entry, dict):
                    continue
                hint = entry.get("hint") or entry.get("text")
                if isinstance(hint, str) and hint.strip():
                    for segment in _iter_directive_segments(hint):
                        candidates.append(("fallback_hint", segment))

    directives: Dict[str, Dict[str, Any]] = {}
    for origin, segment in candidates:
        normalized = _normalize_directive_text(segment)
        if len(normalized) < 4:
            continue
        score, tags = _score_directive(normalized, origin)
        if score < threshold:
            continue
        key = normalized.lower()
        evidence_line = f"{origin}: {segment.strip()}"
        directive = directives.get(key)
        if directive:
            provenance = directive.get("provenance", {})
            existing_score = float(provenance.get("score", 0.0) or 0.0)
            provenance["score"] = round(max(existing_score, score), 2)
            existing_sources = set(str(src) for src in provenance.get("sources", []))
            existing_sources.add(origin)
            provenance["sources"] = sorted(existing_sources)
            existing_tags = set(provenance.get("tags", []))
            existing_tags.update(tags)
            provenance["tags"] = sorted(existing_tags)
            provenance["threshold"] = threshold
            provenance["sensitivity"] = level
            directive["provenance"] = provenance
            evidence = directive.get("evidence", [])
            if evidence_line not in evidence:
                evidence.append(evidence_line)
            directive["evidence"] = evidence
            needs = directive.get("needs", [])
            if isinstance(needs, list):
                combined_needs = list(dict.fromkeys([str(n) for n in needs] + tags))
                directive["needs"] = combined_needs
            continue
        task_id = f"screen-{hashlib.sha1(normalized.encode('utf-8')).hexdigest()[:10]}"
        directives[key] = {
            "task_id": task_id,
            "goal": normalized,
            "status": "active",
            "needs": list(dict.fromkeys(tags)),
            "evidence": [evidence_line],
            "source": "screen",
            "provenance": {
                "score": round(score, 2),
                "tags": sorted(tags),
                "sources": [origin],
                "threshold": threshold,
                "sensitivity": level,
            },
        }

    ordered = sorted(
        directives.values(),
        key=lambda entry: float(((entry.get("provenance") or {}).get("score") or 0.0)),
        reverse=True,
    )
    return ordered


@dataclass
class CognitiveTask:
    task_id: str
    goal: str
    needs: List[str] = field(default_factory=list)
    status: str = "active"
    evidence: List[str] = field(default_factory=list)
    created_at: str = field(default_factory=ts)
    updated_at: str = field(default_factory=ts)
    source: str = "llm"
    provenance: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_id": self.task_id,
            "goal": self.goal,
            "needs": list(self.needs),
            "status": self.status,
            "evidence": list(self.evidence),
            "created_at": self.created_at,
            "updated_at": self.updated_at,
            "source": self.source,
            "provenance": dict(self.provenance),
        }


@dataclass
class TaskManager:
    path: Path
    tasks: Dict[str, CognitiveTask] = field(default_factory=dict)

    def __post_init__(self):
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self._screen_tracker: Dict[str, Dict[str, Any]] = {}
        self._screen_generation: int = 0
        self._load()

    def _load(self):
        if not self.path.exists():
            return
        last_snapshot: Optional[Dict[str, Any]] = None
        try:
            with self.path.open("r", encoding="utf-8") as fh:
                for line in fh:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        last_snapshot = json.loads(line)
                    except Exception:
                        continue
        except Exception:
            return
        if last_snapshot is not None:
            self._apply_full_state(last_snapshot.get("tasks", []))

    def _apply_full_state(self, raw_tasks: List[Dict[str, Any]]):
        now = ts()
        new_map: Dict[str, CognitiveTask] = {}
        for raw in raw_tasks:
            task = self._normalize_task(raw, now)
            if task:
                prev = self.tasks.get(task.task_id)
                if prev:
                    task.created_at = prev.created_at
                    if prev.to_dict() == task.to_dict():
                        task.updated_at = prev.updated_at
                new_map[task.task_id] = task
        self.tasks = new_map

    @staticmethod
    def _coerce_list(values: Any) -> List[str]:
        if values is None:
            return []
        if isinstance(values, (list, tuple, set)):
            return [str(v).strip() for v in values if str(v).strip()]
        text = str(values).strip()
        return [text] if text else []

    @staticmethod
    def _coerce_provenance(raw: Any) -> Dict[str, Any]:
        if not isinstance(raw, dict):
            return {}
        clean: Dict[str, Any] = {}
        for key, value in raw.items():
            k = str(key)
            if isinstance(value, (str, int, float, bool)) or value is None:
                clean[k] = value
            elif isinstance(value, (list, tuple, set)):
                vals: List[Any] = []
                for item in value:
                    if isinstance(item, (str, int, float, bool)) or item is None:
                        vals.append(item)
                clean[k] = vals
            elif isinstance(value, dict):
                clean[k] = TaskManager._coerce_provenance(value)
        return clean

    def _normalize_task(self, raw: Dict[str, Any], timestamp: Optional[str] = None) -> Optional[CognitiveTask]:
        if not isinstance(raw, dict):
            return None
        goal = str(raw.get("goal", "")).strip()
        if not goal:
            return None
        tid = str(raw.get("id") or raw.get("task_id") or "").strip()
        if not tid:
            tid = hashlib.sha1(goal.encode("utf-8")).hexdigest()[:12]
        needs = self._coerce_list(raw.get("needs"))
        evidence = self._coerce_list(raw.get("evidence"))
        status = str(raw.get("status", "active")) or "active"
        created = str(raw.get("created_at") or ts())
        updated = str(raw.get("updated_at") or (timestamp or ts()))
        source_raw = raw.get("source") or raw.get("origin") or "llm"
        source = str(source_raw).strip().lower() or "llm"
        provenance = self._coerce_provenance(raw.get("provenance"))
        return CognitiveTask(
            task_id=tid,
            goal=goal,
            needs=needs,
            status=status,
            evidence=evidence,
            created_at=created,
            updated_at=updated,
            source=source,
            provenance=provenance,
        )

    def update_from_model(self, raw_tasks: Optional[List[Dict[str, Any]]]) -> bool:
        if raw_tasks is None:
            return False
        now = ts()
        existing = dict(self.tasks)
        screen_tasks = {
            tid: task
            for tid, task in existing.items()
            if getattr(task, "source", "llm") == "screen"
        }
        non_screen_before = {
            tid: task
            for tid, task in existing.items()
            if getattr(task, "source", "llm") != "screen"
        }
        new_map: Dict[str, CognitiveTask] = {}
        changed = False
        for raw in raw_tasks:
            task = self._normalize_task(raw, now)
            if not task:
                continue
            if not task.source:
                task.source = "llm"
            prev = self.tasks.get(task.task_id)
            if prev:
                task.created_at = prev.created_at
                if (
                    prev.goal == task.goal
                    and prev.status == task.status
                    and prev.needs == task.needs
                    and prev.evidence == task.evidence
                    and prev.source == task.source
                    and prev.provenance == task.provenance
                ):
                    task.updated_at = prev.updated_at
                else:
                    changed = True
            else:
                changed = True
            new_map[task.task_id] = task
        dropped = set(non_screen_before.keys()) - set(new_map.keys())
        if dropped:
            changed = True
        final_map: Dict[str, CognitiveTask] = dict(screen_tasks)
        final_map.update(new_map)
        if not changed:
            if set(final_map.keys()) != set(self.tasks.keys()):
                changed = True
            else:
                for tid, task in final_map.items():
                    prev = self.tasks.get(tid)
                    if not prev or prev.to_dict() != task.to_dict():
                        changed = True
                        break
        self.tasks = final_map
        return changed

    def active_tasks(self) -> List[CognitiveTask]:
        active: List[CognitiveTask] = []
        for task in self.tasks.values():
            status_lower = task.status.lower()
            if status_lower in {
                "done",
                "complete",
                "completed",
                "archived",
                "cancelled",
                "canceled",
                "resolved",
            }:
                continue
            active.append(task)
        return active

    def to_serializable(self, only_active: bool = True) -> List[Dict[str, Any]]:
        tasks = self.active_tasks() if only_active else list(self.tasks.values())
        return [t.to_dict() for t in tasks]

    def persist_snapshot(self):
        payload = {"ts": ts(), "tasks": [t.to_dict() for t in self.tasks.values()]}
        try:
            with self.path.open("a", encoding="utf-8") as fh:
                fh.write(json.dumps(payload) + "\n")
        except Exception:
            pass

    @staticmethod
    def _merge_provenance(old: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
        merged = TaskManager._coerce_provenance(old)
        incoming = TaskManager._coerce_provenance(new)
        for key, value in incoming.items():
            if key == "score":
                try:
                    merged[key] = max(float(merged.get(key, 0.0) or 0.0), float(value or 0.0))
                except Exception:
                    merged[key] = value
            elif key in {"tags", "sources"}:
                existing = merged.get(key, [])
                if not isinstance(existing, list):
                    existing = []
                combined = list(dict.fromkeys([str(v) for v in existing] + [str(v) for v in value]))
                merged[key] = combined
            else:
                merged[key] = value
        return merged

    def merge_screen_directives(
        self,
        directives: Optional[List[Dict[str, Any]]],
        *,
        decay_steps: int = 2,
    ) -> bool:
        if directives is None:
            directives = []
        now = ts()
        self._screen_generation += 1
        generation = self._screen_generation
        seen: Set[str] = set()
        changed = False
        decay_limit = max(1, int(decay_steps))
        for raw in directives:
            task = self._normalize_task(raw, now)
            if not task:
                continue
            task.source = "screen"
            provenance = self._coerce_provenance(raw.get("provenance"))
            if provenance:
                task.provenance = provenance
            existing = self.tasks.get(task.task_id)
            if existing:
                task.created_at = existing.created_at
                combined_needs = list(dict.fromkeys(existing.needs + task.needs))
                task.needs = combined_needs
                combined_evidence = list(dict.fromkeys(existing.evidence + task.evidence))
                task.evidence = combined_evidence
                task.provenance = self._merge_provenance(existing.provenance, task.provenance)
                if (
                    existing.goal == task.goal
                    and existing.status == task.status
                    and existing.needs == task.needs
                    and existing.evidence == task.evidence
                    and existing.source == task.source
                    and existing.provenance == task.provenance
                ):
                    task.updated_at = existing.updated_at
                else:
                    changed = True
            else:
                changed = True
            self.tasks[task.task_id] = task
            self._screen_tracker[task.task_id] = {"last_seen": generation, "decay": 0, "limit": decay_limit}
            seen.add(task.task_id)

        for task_id, meta in list(self._screen_tracker.items()):
            if task_id in seen:
                meta["decay"] = 0
                meta["last_seen"] = generation
                continue
            meta["decay"] = meta.get("decay", 0) + 1
            limit = max(1, int(meta.get("limit", decay_limit)))
            task = self.tasks.get(task_id)
            if meta["decay"] >= limit:
                if task and task.status.lower() not in {"resolved", "done", "complete", "completed", "archived"}:
                    task.status = "resolved"
                    task.updated_at = now
                    changed = True
            if meta["decay"] >= limit + 2:
                if task_id in self.tasks:
                    del self.tasks[task_id]
                    changed = True
                self._screen_tracker.pop(task_id, None)

        return changed


class Brain:
    """
    Persistent bandit by screen cluster:
      key = pHash cluster center (nearest ≤ HAM_LIMIT), else new.
      stats[action] stores interaction reward metrics plus rolling confidence metadata.
    ε-greedy; per-(state,action) cooldown to reduce spam after repeated failures.
    """

    HAM_LIMIT = 6
    RECENT_LIMIT = 15

    def __init__(self, path: Path, *, prefs: Optional[Dict[str, Any]] = None):
        self.path = path
        self.data: Dict[str, Dict[str, Any]] = {}
        self.cooldowns: Dict[str, Dict[str, float]] = {}
        cfg = prefs or {}
        try:
            self._threshold_min = max(1, int(cfg.get("brain_phash_threshold_min", self.HAM_LIMIT)))
        except Exception:
            self._threshold_min = max(1, self.HAM_LIMIT)
        try:
            self._threshold_max = max(self._threshold_min, int(cfg.get("brain_phash_threshold_max", self.HAM_LIMIT)))
        except Exception:
            self._threshold_max = max(self._threshold_min, self.HAM_LIMIT)
        try:
            default_raw = int(cfg.get("brain_phash_threshold_default", self.HAM_LIMIT))
        except Exception:
            default_raw = self.HAM_LIMIT
        self._threshold_default = min(max(default_raw, self._threshold_min), self._threshold_max)
        self._meta: Dict[str, Any] = {}
        self._threshold_events: deque[Dict[str, Any]] = deque(maxlen=32)
        self._last_distances: Dict[str, int] = {}
        self._clean_streaks: Dict[str, int] = {}
        self._load()

    @staticmethod
    def _default_stat() -> Dict[str, Any]:
        return {
            "wins": 0.0,
            "tries": 0,
            "motion_sum": 0.0,
            "motion_samples": 0,
            "motion_max": 0.0,
            "successes": 0,
            "failures": 0,
            "elapsed_success_sum": 0.0,
            "elapsed_success_samples": 0,
            "recent": [],
            "last_elapsed": None,
            "screen_modes": {},
            "alternate_success": {},
        }

    def _ensure_stat_structure(self, stat: Any) -> Dict[str, Any]:
        if not isinstance(stat, dict):
            return self._default_stat()
        defaults = self._default_stat()
        for key, val in defaults.items():
            if key == "recent":
                stat.setdefault(key, [])
            else:
                stat.setdefault(key, val)
        recent = stat.get("recent")
        if not isinstance(recent, list):
            stat["recent"] = []
        elif len(recent) > self.RECENT_LIMIT:
            stat["recent"] = recent[-self.RECENT_LIMIT :]
        if not isinstance(stat.get("screen_modes"), dict):
            stat["screen_modes"] = {}
        if not isinstance(stat.get("alternate_success"), dict):
            stat["alternate_success"] = {}
        return stat

    def _ensure_state_structure(self, state_key: str) -> Dict[str, Any]:
        st = self.data.setdefault(
            state_key,
            {"stats": {a: self._default_stat() for a in LEARNABLE}, "seen": 0, "last_seen": 0.0},
        )
        stats = st.setdefault("stats", {})
        for action in LEARNABLE:
            stats[action] = self._ensure_stat_structure(stats.get(action, {}))
        thresholds = self._meta.setdefault("thresholds", {})
        thresholds.setdefault(state_key, self._threshold_default)
        return st

    def _load(self):
        self.data = {}
        self._meta = {}
        if self.path.exists():
            try:
                raw = json.loads(self.path.read_text("utf-8"))
            except Exception:
                raw = {}
            if isinstance(raw, dict):
                meta = raw.get("_meta")
                if isinstance(meta, dict):
                    self._meta = meta
                for key, value in raw.items():
                    if key == "_meta":
                        continue
                    if isinstance(value, dict):
                        self.data[key] = value
        self._ensure_meta_defaults()
        last_dist = self._meta.get("last_distance", {})
        if isinstance(last_dist, dict):
            parsed: Dict[str, int] = {}
            for k, v in last_dist.items():
                try:
                    parsed[str(k)] = int(v)
                except Exception:
                    continue
            self._last_distances = parsed
        for key in list(self.data.keys()):
            try:
                self._ensure_state_structure(key)
            except Exception:
                self.data[key] = {"stats": {a: self._default_stat() for a in LEARNABLE}, "seen": 0, "last_seen": 0.0}

    def _ensure_meta_defaults(self) -> None:
        if not isinstance(self._meta, dict):
            self._meta = {}
        defaults = self._meta.setdefault("defaults", {})
        defaults["min"] = self._threshold_min
        defaults["max"] = self._threshold_max
        defaults["default"] = self._threshold_default
        self._meta.setdefault("thresholds", {})
        self._meta.setdefault("error_history", {})
        self._meta.setdefault("last_event", {})
        self._meta.setdefault("last_distance", {})
        self._meta.setdefault("version", 2)

    def _save(self):
        try:
            payload = dict(self.data)
            payload["_meta"] = self._meta
            self.path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        except Exception:
            pass

    def _current_threshold(self, key: Optional[str]) -> int:
        if not key:
            return self._threshold_default
        thresholds = self._meta.get("thresholds", {})
        if isinstance(thresholds, dict) and key in thresholds:
            try:
                return int(thresholds[key])
            except Exception:
                return self._threshold_default
        return self._threshold_default

    def _nearest_key(
        self,
        phash: str,
        *,
        feedback: Optional[Dict[str, Any]] = None,
    ) -> Tuple[str, int]:
        if not self.data:
            self._process_similarity_feedback(feedback, phash, 999, phash, None)
            return (phash, 999)
        best_key: Optional[str] = None
        best_d = 999
        for k in self.data.keys():
            if k == "_meta":
                continue
            d = hamming_hex(k, phash)
            if d < best_d:
                best_key, best_d = k, d
                if best_d == 0:
                    break
        assigned_key = phash
        if best_key is not None:
            threshold = self._current_threshold(best_key)
            if best_d <= threshold:
                assigned_key = best_key
        report_distance = best_d if assigned_key != phash else 999
        if assigned_key != phash and best_key is not None:
            self._last_distances[assigned_key] = best_d
            self._meta.setdefault("last_distance", {})[assigned_key] = int(best_d)
        self._process_similarity_feedback(feedback, assigned_key, best_d, phash, best_key)
        return (assigned_key, report_distance)

    def _process_similarity_feedback(
        self,
        feedback: Optional[Dict[str, Any]],
        assigned_key: str,
        distance: int,
        phash: str,
        best_key: Optional[str],
    ) -> None:
        if not feedback:
            if assigned_key != phash:
                self._record_clean_match(assigned_key, distance)
            return
        changed = feedback.get("changed") if isinstance(feedback, dict) else None
        source_state = str(feedback.get("source_state") or "") if isinstance(feedback, dict) else ""
        target_state = source_state or (best_key if isinstance(best_key, str) else assigned_key)
        if not isinstance(changed, bool) or not target_state:
            if assigned_key != phash:
                self._record_clean_match(assigned_key, distance)
            return
        event_type: Optional[str] = None
        if changed and assigned_key == source_state:
            event_type = "false_negative"
        elif (not changed) and assigned_key != source_state:
            event_type = "false_positive"
        if event_type:
            self._register_similarity_event(target_state, event_type, distance, assigned_key, phash)
        elif assigned_key != phash:
            self._record_clean_match(assigned_key, distance)

    def _register_similarity_event(
        self,
        state: str,
        event_type: str,
        distance: int,
        assigned_key: str,
        phash: str,
    ) -> None:
        if not state:
            return
        timestamp = ts()
        history = self._meta.setdefault("error_history", {}).setdefault(state, [])
        entry = {
            "ts": timestamp,
            "type": event_type,
            "distance": int(distance),
            "assigned": assigned_key,
            "phash": phash,
        }
        history.append(entry)
        if len(history) > 24:
            del history[:-24]
        self._meta.setdefault("last_event", {})[state] = entry
        self._meta.setdefault("last_distance", {})[state] = int(distance)
        self._clean_streaks[state] = 0
        thresholds = self._meta.setdefault("thresholds", {})
        current = int(thresholds.get(state, self._threshold_default))
        new_threshold = current
        if event_type == "false_negative" and current < self._threshold_max:
            new_threshold = min(self._threshold_max, current + 1)
        elif event_type == "false_positive" and current > self._threshold_min:
            new_threshold = max(self._threshold_min, current - 1)
        payload = {
            "ts": timestamp,
            "kind": "brain",
            "state": state,
            "event": event_type,
            "distance": int(distance),
            "threshold": {"old": current, "new": new_threshold},
        }
        self._append_similarity_log(payload)
        thresholds[state] = new_threshold
        if new_threshold != current:
            self._threshold_events.append(payload)
        self._save()

    def _record_clean_match(self, state: str, distance: int) -> None:
        if not state:
            return
        try:
            dist_val = int(distance)
        except Exception:
            dist_val = 999
        self._last_distances[state] = dist_val
        self._meta.setdefault("last_distance", {})[state] = dist_val
        streak = self._clean_streaks.get(state, 0) + 1
        self._clean_streaks[state] = streak
        thresholds = self._meta.setdefault("thresholds", {})
        current = int(thresholds.get(state, self._threshold_default))
        target = self._threshold_default
        if streak >= 6 and current != target:
            if current > target:
                new_threshold = max(target, current - 1)
            else:
                new_threshold = min(target, current + 1)
            thresholds[state] = new_threshold
            payload = {
                "ts": ts(),
                "kind": "brain",
                "state": state,
                "event": "drift",
                "distance": dist_val,
                "threshold": {"old": current, "new": new_threshold},
            }
            self._threshold_events.append(payload)
            self._append_similarity_log(payload)
            self._clean_streaks[state] = 0
            self._save()

    def _append_similarity_log(self, payload: Dict[str, Any]) -> None:
        log_similarity_event(payload)

    def note_similarity_feedback(self, state: str, phash: str, changed: bool) -> Tuple[str, int]:
        feedback = {"source_state": state, "changed": changed}
        return self._nearest_key(phash, feedback=feedback)

    def drain_threshold_events(self) -> List[Dict[str, Any]]:
        events = list(self._threshold_events)
        self._threshold_events.clear()
        return events

    def threshold_snapshot(self, state: str) -> Dict[str, Any]:
        thresholds = self._meta.get("thresholds", {})
        current = int(thresholds.get(state, self._threshold_default)) if isinstance(thresholds, dict) else self._threshold_default
        history = self._meta.get("error_history", {}).get(state, []) if isinstance(self._meta.get("error_history"), dict) else []
        false_pos = sum(1 for item in history if item.get("type") == "false_positive")
        false_neg = sum(1 for item in history if item.get("type") == "false_negative")
        last_event = None
        meta_events = self._meta.get("last_event", {})
        if isinstance(meta_events, dict):
            last_event = meta_events.get(state)
        last_distance = self._meta.get("last_distance", {}).get(state) if isinstance(self._meta.get("last_distance"), dict) else None
        return {
            "state": state,
            "current": current,
            "default": self._threshold_default,
            "min": self._threshold_min,
            "max": self._threshold_max,
            "false_positive": false_pos,
            "false_negative": false_neg,
            "last_event": last_event,
            "last_distance": last_distance,
        }

    def get_state(self, phash: str) -> str:
        key, d = self._nearest_key(phash)
        if key not in self.data:
            self.data[key] = {"stats": {}, "seen": 0, "last_seen": 0.0}
            for a in LEARNABLE:
                self.data[key]["stats"][a] = self._default_stat()
            self._save()
        else:
            self._ensure_state_structure(key)
        return key

    def record_result(
        self,
        state: str,
        action: str,
        changed: bool,
        movement: Optional[Dict[str, Any]] = None,
        elapsed: Optional[float] = None,
        *,
        screen_state: Optional[str] = None,
        alternates: Optional[Sequence[str]] = None,
        verification: Optional[Dict[str, Any]] = None,
    ):
        st = self._ensure_state_structure(state)
        stat = self._ensure_stat_structure(st["stats"].setdefault(action, self._default_stat()))
        if screen_state:
            mode_label = str(screen_state).lower()
            modes = stat.get("screen_modes")
            if not isinstance(modes, dict):
                modes = {}
                stat["screen_modes"] = modes
            modes[mode_label] = int(modes.get(mode_label, 0)) + 1
        motion_mag = 0.0
        if isinstance(movement, dict):
            try:
                motion_mag = float(movement.get("magnitude", 0.0) or 0.0)
            except Exception:
                motion_mag = 0.0
        stat["tries"] += 1
        reward = 1.0 if changed else 0.0
        if motion_mag > 0.0:
            reward += min(motion_mag / 10.0, 1.0)
            stat["motion_sum"] = stat.get("motion_sum", 0.0) + motion_mag
            stat["motion_samples"] = stat.get("motion_samples", 0) + 1
            stat["motion_max"] = max(stat.get("motion_max", 0.0), motion_mag)
        else:
            stat.setdefault("motion_sum", 0.0)
            stat.setdefault("motion_samples", 0)
            stat.setdefault("motion_max", 0.0)
        verification_class = None
        if isinstance(verification, dict):
            verification_class = str(verification.get("classification") or "").lower()
            counts = stat.get("verification_counts")
            if not isinstance(counts, dict):
                counts = {}
                stat["verification_counts"] = counts
            counts[verification_class] = int(counts.get(verification_class, 0)) + 1
        if verification_class == "mismatch":
            reward = 0.0
        elif verification_class == "partial":
            reward *= 0.6

        stat["wins"] = stat.get("wins", 0.0) + reward
        st["seen"] += 1
        st["last_seen"] = time.time()
        effective_change = changed or motion_mag >= 1.0
        if verification_class == "mismatch":
            effective_change = False
        if effective_change:
            stat["successes"] = int(stat.get("successes", 0)) + 1
            if elapsed is not None:
                stat["elapsed_success_sum"] = float(stat.get("elapsed_success_sum", 0.0)) + float(elapsed)
                stat["elapsed_success_samples"] = int(stat.get("elapsed_success_samples", 0)) + 1
        else:
            stat["failures"] = int(stat.get("failures", 0)) + 1
        if elapsed is not None:
            stat["last_elapsed"] = float(elapsed)
        recent = stat.setdefault("recent", [])
        entry = {
            "ts": float(time.time()),
            "success": bool(effective_change),
            "elapsed": float(elapsed) if elapsed is not None else None,
        }
        if verification_class:
            entry["verification"] = verification_class
        if isinstance(recent, list):
            recent.append(entry)
            if len(recent) > self.RECENT_LIMIT:
                stat["recent"] = recent[-self.RECENT_LIMIT :]
        else:
            stat["recent"] = [entry]
        if effective_change and alternates:
            alt_map = stat.get("alternate_success")
            if not isinstance(alt_map, dict):
                alt_map = {}
                stat["alternate_success"] = alt_map
            for alt in alternates:
                alt_name = str(alt or "").upper()
                if not alt_name or alt_name == action:
                    continue
                alt_map[alt_name] = int(alt_map.get(alt_name, 0)) + 1
        # Backoff: after 3 more failures than wins => 3s cooldown
        if not effective_change and (stat["tries"] - stat.get("wins", 0.0) >= 3):
            self.cooldowns.setdefault(state, {})[action] = time.time() + 3.0
        self._save()

    def confidence_profile(self, state: str, action: str) -> Dict[str, Any]:
        st = self._ensure_state_structure(state)
        stat = self._ensure_stat_structure(st["stats"].get(action, self._default_stat()))
        successes = int(stat.get("successes", 0))
        failures = int(stat.get("failures", 0))
        total_outcomes = successes + failures
        tries = int(stat.get("tries", 0))
        success_rate = successes / total_outcomes if total_outcomes else 0.0
        smoothing = min(1.0, total_outcomes / 6.0)
        confidence_from_rate = success_rate * smoothing + 0.15 * (1 - smoothing)
        avg_elapsed = None
        elapsed_samples = int(stat.get("elapsed_success_samples", 0))
        if elapsed_samples > 0:
            try:
                avg_elapsed = float(stat.get("elapsed_success_sum", 0.0)) / max(1, elapsed_samples)
            except Exception:
                avg_elapsed = None
        if avg_elapsed is None:
            last_elapsed = stat.get("last_elapsed")
            if isinstance(last_elapsed, (int, float)):
                avg_elapsed = float(last_elapsed)
        if avg_elapsed is not None:
            speed_score = max(0.0, min(1.0, 1.0 - max(0.0, avg_elapsed - 0.35) / 1.15))
        else:
            speed_score = 0.5
        confidence = max(0.0, min(1.0, 0.1 + 0.65 * confidence_from_rate + 0.25 * speed_score))
        if confidence >= 0.82:
            hold_scale = 0.75
            repeat_delay = 0.32
            verification_delay = 0.05
        elif confidence >= 0.65:
            hold_scale = 0.88
            repeat_delay = 0.45
            verification_delay = 0.08
        elif confidence <= 0.28:
            hold_scale = 1.35
            repeat_delay = 1.5
            verification_delay = 0.3
        elif confidence <= 0.45:
            hold_scale = 1.18
            repeat_delay = 1.1
            verification_delay = 0.2
        else:
            hold_scale = 1.0
            repeat_delay = 0.65
            verification_delay = 0.12
        recent = stat.get("recent") if isinstance(stat.get("recent"), list) else []
        return {
            "confidence": float(round(confidence, 3)),
            "success_rate": float(round(success_rate, 3)),
            "tries": tries,
            "successes": successes,
            "failures": failures,
            "avg_elapsed": float(round(avg_elapsed, 3)) if avg_elapsed is not None else None,
            "hold_scale": float(round(hold_scale, 3)),
            "recommended_hold_ms": int(max(40, min(2000, round(120 * hold_scale)))),
            "repeat_delay_s": float(round(repeat_delay, 3)),
            "verification_delay_s": float(round(verification_delay, 3)),
            "recent": recent[-self.RECENT_LIMIT :],
        }

    def _is_on_cooldown(self, state: str, action: str) -> bool:
        until = self.cooldowns.get(state, {}).get(action, 0.0)
        if until and time.time() < until: return True
        if until and time.time() >= until:
            try: del self.cooldowns[state][action]
            except Exception: pass
        return False

    def suggest(self, state: str, epsilon: float=0.15) -> Tuple[str, str]:
        options = [a for a in LEARNABLE if not self._is_on_cooldown(state, a)]
        if not options: options = list(LEARNABLE)
        st = self.data.get(state, {}); stats = st.get("stats", {})
        if random.random() < epsilon:
            return random.choice(options), "explore"
        best_a, best_q = None, -1.0
        for a in options:
            s = stats.get(a, {"wins":0,"tries":0})
            q = (s["wins"] + 1) / (s["tries"] + 1)
            if q > best_q: best_a, best_q = a, q
        return best_a or random.choice(options), "exploit"

class MenuMappingStore:
    """Persists menu/dialogue interaction outcomes keyed by brain screen clusters."""

    TRACKED_MODES = {"menu", "dialogue"}

    def __init__(self, path: Path):
        self.path = path
        self.data: Dict[str, Any] = {}
        self._load()

    @staticmethod
    def _normalize_option(text: Any) -> str:
        if not isinstance(text, str):
            return ""
        cleaned = unicodedata.normalize("NFKD", text)
        ascii_only = "".join(ch for ch in cleaned if ch.isascii())
        return ascii_only.upper().strip()

    @staticmethod
    def _coerce_int(value: Any) -> Optional[int]:
        try:
            if value is None:
                return None
            return int(value)
        except Exception:
            return None

    def _load(self) -> None:
        self.data = {}
        if not self.path.exists():
            return
        try:
            raw = json.loads(self.path.read_text("utf-8"))
        except Exception:
            raw = {}
        if isinstance(raw, dict):
            self.data = raw
        else:
            self.data = {}

    def _save(self) -> None:
        try:
            self.path.parent.mkdir(parents=True, exist_ok=True)
            self.path.write_text(json.dumps(self.data, indent=2, sort_keys=True), encoding="utf-8")
        except Exception:
            pass

    def signature_for(self, screen_state: Optional[Dict[str, Any]]) -> Optional[str]:
        if not isinstance(screen_state, dict):
            return None
        mode = str(screen_state.get("mode") or "").lower()
        if mode not in self.TRACKED_MODES:
            return None
        cursor_index = self._coerce_int(screen_state.get("cursor_index"))
        options: List[str] = []
        if mode == "menu":
            raw_options = screen_state.get("options")
            if isinstance(raw_options, list):
                for opt in raw_options:
                    text = str(opt)
                    if text.strip():
                        options.append(text.strip())
        normalized = [self._normalize_option(opt) for opt in options]
        payload = {"mode": mode, "cursor": cursor_index, "options": normalized}
        try:
            return json.dumps(payload, sort_keys=True)
        except Exception:
            return None

    def _variant_for(self, state_key: str, signature: Optional[str]) -> Optional[Dict[str, Any]]:
        if not state_key or not signature:
            return None
        state_entry = self.data.get(state_key)
        if not isinstance(state_entry, dict):
            return None
        variants = state_entry.get("variants")
        if not isinstance(variants, dict):
            return None
        variant = variants.get(signature)
        return variant if isinstance(variant, dict) else None

    def record_interaction(
        self,
        state_key: Optional[str],
        screen_state: Optional[Dict[str, Any]],
        action: str,
        success: bool,
    ) -> Optional[Dict[str, Any]]:
        if not state_key or not isinstance(screen_state, dict):
            return None
        mode = str(screen_state.get("mode") or "").lower()
        if mode not in self.TRACKED_MODES:
            return None
        cursor_index = self._coerce_int(screen_state.get("cursor_index"))
        options: List[str] = []
        if mode == "menu":
            raw_options = screen_state.get("options")
            if isinstance(raw_options, list):
                for opt in raw_options:
                    text = str(opt)
                    if text.strip():
                        options.append(text.strip())
        normalized_options = [self._normalize_option(opt) for opt in options]
        signature = self.signature_for(screen_state)
        if signature is None:
            return None
        now = time.time()
        state_entry = self.data.setdefault(state_key, {"variants": {}, "last_seen": 0.0})
        state_entry["last_seen"] = now
        variants = state_entry.setdefault("variants", {})
        variant = variants.setdefault(
            signature,
            {
                "mode": mode,
                "cursor_index": cursor_index,
                "options": options,
                "normalized_options": normalized_options,
                "stats": {},
                "last_seen": now,
            },
        )
        variant["mode"] = mode
        variant["cursor_index"] = cursor_index
        variant["options"] = options
        variant["normalized_options"] = normalized_options
        variant["last_seen"] = now
        stats = variant.setdefault("stats", {})
        act = str(action or "").upper()
        if act:
            action_stat = stats.setdefault(
                act,
                {"success": 0, "failure": 0, "last_ts": 0.0, "last_outcome": None},
            )
            if success:
                action_stat["success"] = int(action_stat.get("success", 0)) + 1
                action_stat["last_outcome"] = "success"
            else:
                action_stat["failure"] = int(action_stat.get("failure", 0)) + 1
                action_stat["last_outcome"] = "failure"
            action_stat["last_ts"] = now
        self._save()
        return variant

    def best_actions(
        self,
        state_key: Optional[str],
        screen_state: Optional[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        signature = self.signature_for(screen_state)
        variant = self._variant_for(state_key or "", signature)
        if not variant:
            return []
        stats = variant.get("stats")
        if not isinstance(stats, dict):
            return []
        actions: List[Dict[str, Any]] = []
        for act, raw in stats.items():
            if not isinstance(raw, dict):
                continue
            success = int(raw.get("success", 0) or 0)
            failure = int(raw.get("failure", 0) or 0)
            total = success + failure
            if success <= 0:
                continue
            last_ts = float(raw.get("last_ts", 0.0) or 0.0)
            confidence = success / total if total else 0.0
            actions.append(
                {
                    "action": str(act),
                    "success": success,
                    "failure": failure,
                    "total": total,
                    "confidence": round(confidence, 4),
                    "last_outcome": raw.get("last_outcome"),
                    "last_ts": last_ts,
                }
            )
        actions.sort(key=lambda item: (item["confidence"], item["success"], item["last_ts"]), reverse=True)
        return actions

    def summary_for(
        self,
        state_key: Optional[str],
        screen_state: Optional[Dict[str, Any]],
    ) -> Optional[Dict[str, Any]]:
        signature = self.signature_for(screen_state)
        variant = self._variant_for(state_key or "", signature)
        if not variant:
            return None
        summary: Dict[str, Any] = {
            "signature": signature,
            "mode": variant.get("mode"),
            "cursor_index": variant.get("cursor_index"),
            "options": list(variant.get("options") or []),
            "last_seen": variant.get("last_seen"),
        }
        best = self.best_actions(state_key, screen_state)
        if best:
            summary["primary"] = dict(best[0])
            summary["alternates"] = [dict(entry) for entry in best[1:]]
        else:
            summary["primary"] = None
            summary["alternates"] = []
        return summary

    def successful_actions(
        self,
        state_key: Optional[str],
        screen_state: Optional[Dict[str, Any]],
    ) -> List[str]:
        return [entry["action"] for entry in self.best_actions(state_key, screen_state) if entry.get("success", 0) > 0]


class NamingMacroStore:
    """Caches naming layouts and action macros keyed by screen cluster."""

    def __init__(self, path: Path):
        self.path = path
        self.data: Dict[str, Any] = {}
        self._load()

    # ---- persistence -----------------------------------------------------
    def _load(self) -> None:
        if not self.path.exists():
            self.data = {}
            return
        try:
            raw = json.loads(self.path.read_text("utf-8"))
        except Exception:
            raw = {}
        if isinstance(raw, dict):
            self.data = raw
        else:
            self.data = {}

    def _save(self) -> None:
        try:
            self.path.parent.mkdir(parents=True, exist_ok=True)
            self.path.write_text(json.dumps(self.data, indent=2, sort_keys=True), encoding="utf-8")
        except Exception:
            pass

    # ---- layout helpers --------------------------------------------------
    @staticmethod
    def _canonical_target(name: Optional[str]) -> str:
        if not isinstance(name, str):
            return "UNKNOWN"
        cleaned = unicodedata.normalize("NFKD", name)
        ascii_only = "".join(ch for ch in cleaned if ch.isascii())
        label = ascii_only.strip()
        return label.upper() or "UNKNOWN"

    @staticmethod
    def _grid_signature(grid: Optional[Dict[str, Any]]) -> Optional[str]:
        if not isinstance(grid, dict):
            return None
        cells = grid.get("cells")
        if not isinstance(cells, list):
            return None
        key_rows: List[Tuple[int, int, int, int]] = []
        for cell in cells:
            if not isinstance(cell, dict):
                continue
            row = cell.get("row")
            col = cell.get("col")
            bounds = cell.get("bounds") if isinstance(cell.get("bounds"), (list, tuple)) else None
            if bounds is None or len(bounds) < 4:
                continue
            try:
                row_i = int(row)
                col_i = int(col)
                cx = int(round((bounds[0] + bounds[2]) / 2.0))
                cy = int(round((bounds[1] + bounds[3]) / 2.0))
            except Exception:
                continue
            key_rows.append((row_i, col_i, cx, cy))
        if not key_rows:
            return None
        key_rows.sort()
        payload = json.dumps(key_rows)
        return hashlib.sha1(payload.encode("utf-8")).hexdigest()[:16]

    def update_layout(self, state_key: Optional[str], screen_state: Optional[Dict[str, Any]]) -> None:
        if not state_key or not isinstance(screen_state, dict):
            return
        mode = str(screen_state.get("mode") or "").lower()
        if mode != "naming":
            return
        grid = screen_state.get("grid") if isinstance(screen_state.get("grid"), dict) else None
        movement = screen_state.get("movement") if isinstance(screen_state.get("movement"), dict) else {}
        signature = screen_state.get("grid_signature") or self._grid_signature(grid)
        if not signature:
            return
        state_entry = self.data.setdefault(state_key, {"layouts": {}, "macros": {}, "last_seen": 0.0})
        state_entry["last_seen"] = time.time()
        layout_entry = {
            "signature": signature,
            "updated": time.time(),
            "grid": grid or {},
            "movement": movement,
        }
        layouts = state_entry.setdefault("layouts", {})
        layouts[signature] = layout_entry
        self._save()

    # ---- macro helpers ---------------------------------------------------
    @staticmethod
    def _actions_fingerprint(actions: Sequence[Dict[str, Any]]) -> str:
        serial: List[Tuple[str, int]] = []
        for step in actions:
            if not isinstance(step, dict):
                continue
            name = str(step.get("name") or "").upper()
            try:
                dur = int(step.get("duration_ms", 0))
            except Exception:
                dur = 0
            serial.append((name, dur))
        return hashlib.sha1(json.dumps(serial).encode("utf-8")).hexdigest()[:12] if serial else ""

    def record_macro(
        self,
        *,
        state_key: Optional[str],
        target_name: Optional[str],
        actions: Sequence[Dict[str, Any]],
        total_ms: float,
        layout_signature: Optional[str],
        success: bool,
    ) -> None:
        if not state_key or not actions:
            return
        target = self._canonical_target(target_name)
        state_entry = self.data.setdefault(state_key, {"layouts": {}, "macros": {}, "last_seen": 0.0})
        state_entry["last_seen"] = time.time()
        macros = state_entry.setdefault("macros", {})
        macro_entry = macros.setdefault(
            target,
            {
                "signature": layout_signature,
                "variants": [],
                "success": 0,
                "failure": 0,
                "preferred": None,
                "target": target,
            },
        )
        if layout_signature:
            macro_entry["signature"] = layout_signature
        macro_entry["target"] = target
        if success:
            macro_entry["success"] = int(macro_entry.get("success", 0) or 0) + 1
        else:
            macro_entry["failure"] = int(macro_entry.get("failure", 0) or 0) + 1
        fingerprint = self._actions_fingerprint(actions)
        variants: List[Dict[str, Any]] = [v for v in macro_entry.get("variants", []) if isinstance(v, dict)]
        existing = None
        for variant in variants:
            if variant.get("fingerprint") == fingerprint:
                existing = variant
                break
        now = time.time()
        record = {
            "actions": [
                {"name": str(step.get("name") or "").upper(), "duration_ms": int(step.get("duration_ms", 0))}
                for step in actions
                if isinstance(step, dict) and step.get("name")
            ],
            "total_ms": float(total_ms),
            "last_ts": now,
            "fingerprint": fingerprint or hashlib.sha1(str(now).encode("utf-8")).hexdigest()[:12],
        }
        if success:
            record["success"] = int(existing.get("success", 0) if isinstance(existing, dict) else 0) + 1
            record["failure"] = int(existing.get("failure", 0) if isinstance(existing, dict) else 0)
        else:
            record["success"] = int(existing.get("success", 0) if isinstance(existing, dict) else 0)
            record["failure"] = int(existing.get("failure", 0) if isinstance(existing, dict) else 0) + 1
        if existing:
            variants = [v for v in variants if v is not existing]
        variants.append(record)
        variants.sort(key=lambda v: (float(v.get("total_ms", 0.0) or 0.0), -float(v.get("success", 0) or 0)))
        macro_entry["variants"] = variants
        macro_entry["preferred"] = variants[0]["fingerprint"] if variants else None
        macros[target] = macro_entry
        self._save()

    def preferred_macro(
        self,
        state_key: Optional[str],
        *,
        target_name: Optional[str] = None,
        layout_signature: Optional[str] = None,
    ) -> Optional[Dict[str, Any]]:
        if not state_key or state_key not in self.data:
            return None
        target = self._canonical_target(target_name)
        state_entry = self.data.get(state_key) or {}
        macros = state_entry.get("macros") if isinstance(state_entry, dict) else {}
        if not isinstance(macros, dict) or not macros:
            return None
        candidates: List[Dict[str, Any]] = []
        if target in macros:
            entry = macros.get(target)
            if isinstance(entry, dict):
                candidates.append(entry)
        if not candidates:
            candidates = [entry for entry in macros.values() if isinstance(entry, dict)]
        best_variant = None
        best_conf = -1.0
        for entry in candidates:
            variants = entry.get("variants") if isinstance(entry, dict) else None
            if not variants:
                continue
            preferred_key = entry.get("preferred")
            variant = None
            for item in variants:
                if not isinstance(item, dict):
                    continue
                if preferred_key and item.get("fingerprint") == preferred_key:
                    variant = item
                    break
            if variant is None:
                variant = variants[0]
            if not isinstance(variant, dict):
                continue
            success = float(entry.get("success", 0) or 0.0)
            failure = float(entry.get("failure", 0) or 0.0)
            conf = success / (success + failure + 1.0)
            if layout_signature and entry.get("signature") and entry.get("signature") != layout_signature:
                conf *= 0.25
            if conf > best_conf:
                best_conf = conf
                best_variant = {
                    "target": entry.get("target", target),
                    "actions": variant.get("actions", []),
                    "total_ms": variant.get("total_ms", 0.0),
                    "confidence": conf,
                    "layout_signature": entry.get("signature"),
                }
        return best_variant

    def layout_signature(self, state_key: Optional[str]) -> Optional[str]:
        if not state_key or state_key not in self.data:
            return None
        entry = self.data.get(state_key) or {}
        layouts = entry.get("layouts") if isinstance(entry, dict) else {}
        if not isinstance(layouts, dict) or not layouts:
            return None
        latest = max(layouts.values(), key=lambda item: item.get("updated", 0.0))
        sig = latest.get("signature") if isinstance(latest, dict) else None
        return sig

# ------------------------------ Agent worker ----------------------------------


@dataclass
class _ObservationContext:
    image: Image.Image
    frame_array: np.ndarray
    base64_image: str
    state_key: str
    phash: str
    frame_digest: Optional[str]
    movement: Dict[str, Any]
    allow_saveload: bool
    meta: Dict[str, Any]
    ocr_enabled: bool
    ocr_model: str
    ocr_prompt: str
    vision_model: str
    caption_prompt: str
    knowledge_store: 'KnowledgeStore'
    menu_store: 'MenuMappingStore'
    brain: 'Brain'
    vector_ready: bool


class AgentWorker(QtCore.QThread):
    log = QtCore.pyqtSignal(str)
    status= QtCore.pyqtSignal(str)
    uiFlash = QtCore.pyqtSignal(str, int)  # highlight a key in UI
    progress = QtCore.pyqtSignal(str)      # for RAW ingestion
    tasksUpdated = QtCore.pyqtSignal(list)
    narrativeReady = QtCore.pyqtSignal(str)
    memorySnapshot = QtCore.pyqtSignal(dict)

    PROBE_ORDER = ["START","A","B","SELECT","UP","DOWN","LEFT","RIGHT"]

    def __init__(self, app_ref: 'VirtualGameBoy'):
        super().__init__()
        self.app = app_ref
        self.stop_flag = False
        self.frame_q: "deque[Tuple[bytes,int,int]]" = app_ref.frame_deque
        self.ks = KnowledgeStore(app_ref.prefs)
        self.brain = Brain(BRAIN_PATH, prefs=app_ref.prefs)
        self.menu_mappings = MenuMappingStore(MENU_MAPPINGS_PATH)
        self.naming_macros = NamingMacroStore(NAMING_MACROS_PATH)
        self.task_manager = TaskManager(TASK_LOG)
        self.last_state: Optional[str] = None
        self.last_phash: Optional[str] = None
        self.last_action: Optional[str] = None
        self.last_screen_state: Optional[Dict[str, Any]] = None
        sensitivity_pref = str(app_ref.prefs.get("directive_sensitivity", "normal")).strip().lower()
        if sensitivity_pref not in DIRECTIVE_SENSITIVITY_THRESHOLDS:
            sensitivity_pref = "normal"
        self.directive_sensitivity = sensitivity_pref
        try:
            decay_pref = int(app_ref.prefs.get("directive_decay_steps", 2))
        except Exception:
            decay_pref = 2
        self.directive_decay_steps = max(1, min(6, decay_pref))
        self.fail_parse_streak = 0
        self.no_change_streak = 0
        self.timeline_buf: List[str] = []
        self.narrative_history: deque[str] = deque(maxlen=12)
        self.knowledge_buf: deque[Dict[str, Any]] = deque(maxlen=6)
        self.failure_buf: deque[Dict[str, str]] = deque(maxlen=8)
        self.pending_actions: deque[Dict[str, Any]] = deque()
        self._current_plan_meta: Optional[Dict[str, Any]] = None
        self.current_vision_model = DEFAULT_PREFS["vision_model"]
        self.current_reasoning_model = DEFAULT_PREFS["reasoning_model"]
        self._reasoning_label = self.current_reasoning_model
        self._reasoning_tag = self._model_tag(self.current_reasoning_model)
        self._last_memory_snapshot: Dict[str, Any] = {}
        self._last_memory_reflection: Optional[Dict[str, Any]] = None
        self._prev_frame_array: Optional[np.ndarray] = None
        self._last_motion_estimate: Dict[str, Any] = {
            "dx": 0.0,
            "dy": 0.0,
            "magnitude": 0.0,
            "confidence": 0.0,
            "pos_pixels": 0,
            "neg_pixels": 0,
            "scale": 1,
        }
        self._last_distinct_digest: Optional[str] = None
        self._last_distinct_digest_ts: float = 0.0
        self._watchdog_cooldown_until: float = 0.0
        self._watchdog_timeout: float = 3.0
        self._cooldown_annotations: Dict[str, Dict[str, Any]] = {}
        self.transition_journal: deque[Dict[str, Any]] = deque(maxlen=10)
        self._exploration_queue: deque[List[Dict[str, Any]]] = deque()
        self._last_phase_cycles: deque[Dict[str, Any]] = deque(maxlen=5)
        self._mapping_retry_plan: Optional[Dict[str, Any]] = None
        self._last_sprite_payload: Dict[str, Any] = {}
        self._pending_mismatch_escalation: Optional[str] = None
        self._naming_action_buffer: List[Dict[str, Any]] = []
        self._naming_active_state: Optional[str] = None
        tl_prefs = app_ref.prefs if isinstance(app_ref.prefs, dict) else {}
        horizon = tl_prefs.get("timeline_horizon", DEFAULT_PREFS["timeline_horizon"])
        decay = tl_prefs.get("timeline_decay", DEFAULT_PREFS["timeline_decay"])
        window = tl_prefs.get("timeline_window", DEFAULT_PREFS["timeline_window"])
        self.timeline_manager = TimelineManager(
            knowledge_store=self.ks,
            horizon=int(horizon) if horizon is not None else DEFAULT_PREFS["timeline_horizon"],
            decay=float(decay) if decay is not None else DEFAULT_PREFS["timeline_decay"],
            window_size=int(window) if window is not None else DEFAULT_PREFS["timeline_window"],
        )
        self._latest_timeline_context: Dict[str, Any] = {}
        self._operator_aggregator = OperatorAggregator()
        self._last_operator_bundle: Optional[OperatorBundle] = None

    def stop(self): self.stop_flag = True

    def _grab_latest(self) -> Optional[Tuple[bytes,int,int]]:
        t0 = time.time()
        while time.time()-t0 < 1.0:
            if self.frame_q: return self.frame_q[-1]
            time.sleep(0.01)
        return None

    @staticmethod
    def _b64_png(rgb: bytes, w: int, h: int) -> str:
        img = Image.frombytes("RGB", (w, h), rgb); bio = io.BytesIO(); img.save(bio, "PNG")
        return base64.b64encode(bio.getvalue()).decode("ascii")

    @staticmethod
    def _model_tag(model: str) -> str:
        if not model:
            return "model"
        base = model.split("/")[-1]
        tag = base or model
        return tag.replace(":", "@")

    @staticmethod
    def _normalize_token(text: str) -> str:
        if not isinstance(text, str):
            return ""
        cleaned = unicodedata.normalize("NFKD", text)
        return "".join(ch for ch in cleaned if ch.isascii()).upper().strip()

    @staticmethod
    def _screen_mode_label(screen_state: Optional[Dict[str, Any]]) -> Optional[str]:
        if not isinstance(screen_state, dict):
            return None
        mode = screen_state.get("mode")
        if isinstance(mode, str):
            return mode.lower()
        return None

    def _infer_naming_target(self) -> Optional[str]:
        texts: List[str] = []
        if isinstance(self._current_plan_meta, dict):
            reason = self._current_plan_meta.get("reason")
            summary = self._current_plan_meta.get("summary")
            if isinstance(reason, str):
                texts.append(reason)
            if isinstance(summary, str):
                texts.append(summary)
        recent_status = self.timeline_buf[-3:]
        for entry in reversed(recent_status):
            if isinstance(entry, str) and "name" in entry.lower():
                texts.append(entry)
        for text in texts:
            if not text:
                continue
            quoted = re.search(r"[\"']([^\"']{1,16})[\"']", text)
            if quoted:
                candidate = quoted.group(1).strip()
                if candidate:
                    return candidate
            name_match = re.search(r"name\s+(?:as|is|to)?\s*([A-Za-z0-9]{1,16})", text, re.IGNORECASE)
            if name_match:
                candidate = name_match.group(1).strip()
                if candidate:
                    return candidate
        return None

    def _estimate_motion(
        self,
        prev_frame: Optional[np.ndarray],
        curr_frame: Optional[np.ndarray],
        *,
        downsample: int = 4,
        threshold: float = 12.0,
    ) -> Dict[str, Any]:
        if prev_frame is None or curr_frame is None:
            return {
                "dx": 0.0,
                "dy": 0.0,
                "magnitude": 0.0,
                "confidence": 0.0,
                "pos_pixels": 0,
                "neg_pixels": 0,
                "scale": downsample,
            }
        if prev_frame.shape != curr_frame.shape:
            return {
                "dx": 0.0,
                "dy": 0.0,
                "magnitude": 0.0,
                "confidence": 0.0,
                "pos_pixels": 0,
                "neg_pixels": 0,
                "scale": downsample,
            }
        try:
            prev_small = prev_frame[::downsample, ::downsample, :3]
            curr_small = curr_frame[::downsample, ::downsample, :3]
            weights = np.array([0.299, 0.587, 0.114], dtype=np.float32)
            prev_gray = np.tensordot(prev_small.astype(np.float32), weights, axes=([-1], [0]))
            curr_gray = np.tensordot(curr_small.astype(np.float32), weights, axes=([-1], [0]))
            delta = curr_gray - prev_gray
            pos_mask = delta > threshold
            neg_mask = delta < -threshold
            pos_pixels = int(pos_mask.sum())
            neg_pixels = int(neg_mask.sum())
            if pos_pixels == 0 and neg_pixels == 0:
                return {
                    "dx": 0.0,
                    "dy": 0.0,
                    "magnitude": 0.0,
                    "confidence": 0.0,
                    "pos_pixels": 0,
                    "neg_pixels": 0,
                    "scale": downsample,
                }
            dx = dy = 0.0
            confidence = 0.0
            pos_center = neg_center = None
            if pos_pixels:
                pos_weights = delta[pos_mask]
                pos_coords = np.argwhere(pos_mask)
                py = float(np.average(pos_coords[:, 0], weights=pos_weights))
                px = float(np.average(pos_coords[:, 1], weights=pos_weights))
                pos_center = (px, py)
            if neg_pixels:
                neg_weights = -delta[neg_mask]
                neg_coords = np.argwhere(neg_mask)
                ny = float(np.average(neg_coords[:, 0], weights=neg_weights))
                nx = float(np.average(neg_coords[:, 1], weights=neg_weights))
                neg_center = (nx, ny)
            if pos_center and neg_center:
                dx = (pos_center[0] - neg_center[0]) * downsample
                dy = (pos_center[1] - neg_center[1]) * downsample
                confidence = min(1.0, (pos_pixels + neg_pixels) / 200.0)
            elif pos_center:
                dx = dy = 0.0
                confidence = min(1.0, pos_pixels / 200.0)
            elif neg_center:
                dx = dy = 0.0
                confidence = min(1.0, neg_pixels / 200.0)
            magnitude = float(math.hypot(dx, dy))
            return {
                "dx": float(dx),
                "dy": float(dy),
                "magnitude": magnitude,
                "confidence": float(confidence),
                "pos_pixels": pos_pixels,
                "neg_pixels": neg_pixels,
                "scale": downsample,
                "pos_center": [float(pos_center[0] * downsample), float(pos_center[1] * downsample)] if pos_center else None,
                "neg_center": [float(neg_center[0] * downsample), float(neg_center[1] * downsample)] if neg_center else None,
            }
        except Exception:
            return {
                "dx": 0.0,
                "dy": 0.0,
                "magnitude": 0.0,
                "confidence": 0.0,
                "pos_pixels": 0,
                "neg_pixels": 0,
                "scale": downsample,
            }

    @staticmethod
    def _frame_digest(frame: Optional[np.ndarray]) -> Optional[str]:
        if frame is None:
            return None
        try:
            return hashlib.sha1(frame.tobytes()).hexdigest()
        except Exception:
            return None

    @staticmethod
    def _sanitize_motion(movement: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        if not isinstance(movement, dict):
            return {}
        fields: Dict[str, Any] = {}
        for key in ("dx", "dy", "magnitude", "confidence"):
            try:
                fields[key] = round(float(movement.get(key, 0.0)), 3)
            except Exception:
                fields[key] = 0.0
        for key in ("pos_pixels", "neg_pixels", "scale"):
            try:
                fields[key] = int(movement.get(key, 0))
            except Exception:
                fields[key] = 0
        return fields

    @staticmethod
    def _player_region_from_payload(payload: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        if not isinstance(payload, dict):
            return None
        regions = payload.get("regions")
        if not isinstance(regions, list):
            decomposition = payload.get("decomposition") if isinstance(payload.get("decomposition"), dict) else None
            if isinstance(decomposition, dict):
                regions = decomposition.get("regions")
        if not isinstance(regions, list):
            return None
        for region in regions:
            label = str(region.get("label") or "").lower()
            if label == "player_sprite":
                return region if isinstance(region, dict) else None
        return None

    @staticmethod
    def _player_facing(region: Optional[Dict[str, Any]]) -> Optional[str]:
        if not isinstance(region, dict):
            return None
        facing = region.get("facing")
        if isinstance(facing, str) and facing:
            return facing.lower()
        details = region.get("details")
        if isinstance(details, dict):
            hinted = details.get("facing") or details.get("facing_hint")
            if isinstance(hinted, str) and hinted:
                return hinted.lower()
        return None

    def _compute_expected_deltas(
        self,
        action: str,
        *,
        screen_state: Optional[Dict[str, Any]],
        mapping_summary: Optional[Dict[str, Any]],
        sprite_payload: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        expectation: Dict[str, Any] = {}
        act = str(action or "").upper()
        mode: Optional[str] = None
        cursor_index: Optional[int] = None
        options: List[str] = []
        line_count: Optional[int] = None
        if isinstance(screen_state, dict):
            raw_mode = screen_state.get("mode")
            if isinstance(raw_mode, str):
                mode = raw_mode.lower()
            raw_cursor = screen_state.get("cursor_index")
            if isinstance(raw_cursor, (int, float)) and np.isfinite(raw_cursor):
                cursor_index = int(raw_cursor)
            raw_options = screen_state.get("options")
            if isinstance(raw_options, list):
                options = [str(opt) for opt in raw_options]
            raw_line_count = screen_state.get("line_count")
            if isinstance(raw_line_count, (int, float)) and np.isfinite(raw_line_count):
                line_count = int(raw_line_count)

        if mode in {"menu", "dialogue"}:
            menu_expect: Dict[str, Any] = {
                "mode": mode,
                "cursor_before": cursor_index,
                "line_count_before": line_count,
            }
            if act in {"UP", "DOWN"} and cursor_index is not None and options:
                delta = -1 if act == "UP" else 1
                expected_cursor = cursor_index + delta
                expected_cursor = max(0, min(len(options) - 1, expected_cursor))
                menu_expect.update(
                    {
                        "cursor_delta": delta,
                        "cursor_after": expected_cursor,
                        "option_count": len(options),
                    }
                )
            if act == "A" and mode == "dialogue":
                menu_expect["dialogue_advance"] = True
            if menu_expect:
                expectation["menu"] = menu_expect

        if mapping_summary and isinstance(mapping_summary, dict):
            mapping_expect: Dict[str, Any] = {
                "signature": mapping_summary.get("signature"),
                "cursor_index": mapping_summary.get("cursor_index"),
                "options": mapping_summary.get("options"),
            }
            primary = mapping_summary.get("primary") if isinstance(mapping_summary.get("primary"), dict) else None
            if isinstance(primary, dict):
                mapping_expect["primary_action"] = primary.get("action")
                mapping_expect["primary_confidence"] = primary.get("confidence")
            expectation["menu_mapping"] = mapping_expect

        direction_vectors = {
            "UP": (0.0, -1.0, "up"),
            "DOWN": (0.0, 1.0, "down"),
            "LEFT": (-1.0, 0.0, "left"),
            "RIGHT": (1.0, 0.0, "right"),
        }
        if act in direction_vectors:
            base_dx, base_dy, direction_label = direction_vectors[act]
            min_magnitude = 0.8 if mode not in {"menu", "dialogue"} else 0.3
            sprite_expect: Dict[str, Any] = {
                "direction": direction_label,
                "vector": (base_dx, base_dy),
                "min_magnitude": min_magnitude,
            }
            player_region = self._player_region_from_payload(sprite_payload)
            if player_region:
                sprite_expect["before_bbox"] = player_region.get("bbox")
                sprite_expect["facing_before"] = self._player_facing(player_region)
            expectation["sprite"] = sprite_expect

        expectation["action"] = act
        if mode:
            expectation["mode"] = mode
        return expectation

    def _verify_action_outcome(
        self,
        *,
        action: str,
        expectation: Optional[Dict[str, Any]],
        before_screen: Optional[Dict[str, Any]],
        after_frame: Optional[Tuple[bytes, int, int]],
        movement: Optional[Dict[str, Any]],
        changed: bool,
        elapsed: float,
    ) -> Dict[str, Any]:
        expectation = expectation or {}
        checks: List[Dict[str, Any]] = []
        after_screen: Optional[Dict[str, Any]] = None
        after_player_region: Optional[Dict[str, Any]] = None
        after_image: Optional[Image.Image] = None
        if after_frame is not None:
            try:
                rgb_bytes, width, height = after_frame
                after_image = Image.frombytes("RGB", (width, height), rgb_bytes)
            except Exception:
                after_image = None
        if after_image is not None:
            try:
                after_screen = self._classify_screen(
                    image=after_image,
                    ocr_text=None,
                    caption=None,
                    ocr_fallback=None,
                )
            except Exception:
                after_screen = None
            try:
                decomposition = decompose_frame(after_image)
            except Exception:
                decomposition = None
            after_player_region = self._player_region_from_payload(decomposition if isinstance(decomposition, dict) else None)

        menu_expect = expectation.get("menu") if isinstance(expectation.get("menu"), dict) else None
        if menu_expect:
            expected_cursor = menu_expect.get("cursor_after")
            evaluated = expected_cursor is not None
            actual_cursor = None
            if isinstance(after_screen, dict):
                actual_cursor_raw = after_screen.get("cursor_index")
                if isinstance(actual_cursor_raw, (int, float)) and np.isfinite(actual_cursor_raw):
                    actual_cursor = int(actual_cursor_raw)
            passed = True
            if evaluated:
                passed = actual_cursor == expected_cursor
            elif changed:
                evaluated = False
            checks.append(
                {
                    "type": "cursor",
                    "evaluated": evaluated,
                    "expected": expected_cursor,
                    "actual": actual_cursor,
                    "passed": passed if evaluated else bool(changed),
                    "before": menu_expect.get("cursor_before"),
                }
            )
            if menu_expect.get("dialogue_advance"):
                before_lines = menu_expect.get("line_count_before")
                after_lines = None
                if isinstance(after_screen, dict):
                    raw_after_lines = after_screen.get("line_count")
                    if isinstance(raw_after_lines, (int, float)) and np.isfinite(raw_after_lines):
                        after_lines = int(raw_after_lines)
                evaluable = before_lines is not None and after_lines is not None
                passed_dialogue = bool(after_lines is not None and before_lines is not None and after_lines < before_lines)
                checks.append(
                    {
                        "type": "dialogue",
                        "evaluated": evaluable,
                        "before": before_lines,
                        "after": after_lines,
                        "passed": passed_dialogue if evaluable else bool(changed),
                    }
                )

        sprite_expect = expectation.get("sprite") if isinstance(expectation.get("sprite"), dict) else None
        if sprite_expect:
            min_mag = float(sprite_expect.get("min_magnitude", 0.0) or 0.0)
            actual_dx = float(movement.get("dx", 0.0)) if isinstance(movement, dict) else 0.0
            actual_dy = float(movement.get("dy", 0.0)) if isinstance(movement, dict) else 0.0
            actual_mag = float(movement.get("magnitude", math.hypot(actual_dx, actual_dy))) if isinstance(movement, dict) else math.hypot(actual_dx, actual_dy)
            vector = sprite_expect.get("vector") if isinstance(sprite_expect.get("vector"), (list, tuple)) else None
            direction_passed = True
            evaluated = True
            if vector:
                exp_dx, exp_dy = vector
                expected_mag = math.hypot(exp_dx, exp_dy)
                if expected_mag > 0 and actual_mag > 0:
                    dot = (actual_dx * exp_dx + actual_dy * exp_dy) / (expected_mag * actual_mag)
                    direction_passed = dot >= 0.2
                else:
                    direction_passed = actual_mag == 0.0 and min_mag <= 0.0
            motion_passed = actual_mag >= min_mag
            facing_after = self._player_facing(after_player_region)
            facing_expected = sprite_expect.get("direction")
            facing_passed = True
            facing_evaluated = False
            if facing_after and isinstance(facing_expected, str):
                facing_evaluated = True
                facing_passed = facing_after == facing_expected
            checks.append(
                {
                    "type": "sprite_motion",
                    "evaluated": evaluated,
                    "passed": motion_passed and direction_passed,
                    "magnitude": round(actual_mag, 3),
                    "min_magnitude": round(min_mag, 3),
                    "direction_ok": direction_passed,
                }
            )
            if facing_evaluated:
                checks.append(
                    {
                        "type": "sprite_facing",
                        "evaluated": True,
                        "expected": facing_expected,
                        "actual": facing_after,
                        "passed": facing_passed,
                    }
                )

        evaluated_checks = [check for check in checks if check.get("evaluated")]
        passed_checks = [check for check in evaluated_checks if check.get("passed")]
        if evaluated_checks:
            if len(passed_checks) == len(evaluated_checks):
                classification = "match"
            elif passed_checks:
                classification = "partial"
            else:
                classification = "mismatch"
        else:
            classification = "match" if changed else "mismatch"

        summary_parts: List[str] = []
        for check in checks:
            label = check.get("type")
            status = "✓" if check.get("passed") else "✗"
            if not check.get("evaluated"):
                status = "?"
            if label == "cursor":
                summary_parts.append(
                    f"cursor {check.get('before')}→{check.get('actual')} (exp {check.get('expected')}) {status}"
                )
            elif label == "dialogue":
                summary_parts.append(
                    f"dialogue {check.get('before')}→{check.get('after')} {status}"
                )
            elif label == "sprite_motion":
                summary_parts.append(
                    f"motion {check.get('magnitude', 0.0):.2f}/{check.get('min_magnitude', 0.0):.2f} {status}"
                )
            elif label == "sprite_facing":
                summary_parts.append(
                    f"facing {check.get('actual')} (exp {check.get('expected')}) {status}"
                )
        if not summary_parts:
            summary_parts.append("no expectations")
        summary = "; ".join(summary_parts)

        result = {
            "classification": classification,
            "checks": checks,
            "summary": summary,
            "after_screen": after_screen,
            "changed": bool(changed),
            "elapsed": float(elapsed),
            "movement": self._sanitize_motion(movement),
        }
        if expectation:
            result["expectation"] = expectation
        if before_screen is not None:
            result["before_screen"] = before_screen
        if after_player_region:
            result["after_player_region"] = after_player_region
        return result

    def _resolve_cadence(
        self,
        state: str,
        action: str,
        base_hold_ms: int,
    ) -> Tuple[int, float, float, Optional[Dict[str, Any]]]:
        profile: Optional[Dict[str, Any]] = None
        hold_ms = max(40, min(4000, int(base_hold_ms)))
        repeat_delay = 0.75
        verification_delay = 0.12
        if action in LEARNABLE:
            try:
                profile = self.brain.confidence_profile(state, action)
            except Exception:
                profile = None
        if profile:
            try:
                scale = float(profile.get("hold_scale", 1.0))
                hold_ms = int(max(40, min(4000, round(base_hold_ms * scale))))
            except Exception:
                hold_ms = max(40, min(4000, int(base_hold_ms)))
            try:
                repeat_delay = float(profile.get("repeat_delay_s", repeat_delay))
            except Exception:
                repeat_delay = 0.75
            try:
                verification_delay = float(profile.get("verification_delay_s", verification_delay))
            except Exception:
                verification_delay = 0.12
        return hold_ms, repeat_delay, verification_delay, profile

    def _resolve_mapping_choice(
        self,
        state_key: Optional[str],
        screen_state: Optional[Dict[str, Any]],
        global_cooldowns: Dict[str, float],
    ) -> Optional[Dict[str, Any]]:
        if not state_key or not isinstance(screen_state, dict):
            self._mapping_retry_plan = None
            return None
        try:
            choices = self.menu_mappings.best_actions(state_key, screen_state)
            summary = self.menu_mappings.summary_for(state_key, screen_state)
            signature = self.menu_mappings.signature_for(screen_state)
        except Exception:
            choices = []
            summary = None
            signature = self.menu_mappings.signature_for(screen_state)
        if not choices:
            self._mapping_retry_plan = None
            return None
        now = time.time()
        existing = self._mapping_retry_plan
        if existing:
            expiry = float(existing.get("ts", 0.0) or 0.0)
            if (
                existing.get("state") != state_key
                or existing.get("signature") != signature
                or (now - expiry) > 20.0
            ):
                existing = None
                self._mapping_retry_plan = None
        if existing and existing.get("alternates"):
            alternates: List[str] = list(existing.get("alternates", []))
            while alternates:
                candidate = alternates.pop(0)
                if now < global_cooldowns.get(candidate, 0.0):
                    continue
                info = next((entry for entry in choices if entry.get("action") == candidate), None)
                if info:
                    existing["alternates"] = alternates
                    existing["ts"] = now
                    return {
                        "choice": dict(info),
                        "alternates": [dict(entry) for entry in choices if entry.get("action") != info.get("action")],
                        "summary": summary,
                        "signature": signature,
                    }
            self._mapping_retry_plan = None
        for info in choices:
            action_name = info.get("action")
            if not isinstance(action_name, str):
                continue
            if now < global_cooldowns.get(action_name, 0.0):
                continue
            remaining = [entry.get("action") for entry in choices if entry.get("action") != action_name]
            remaining = [act for act in remaining if isinstance(act, str)]
            if remaining:
                self._mapping_retry_plan = {
                    "state": state_key,
                    "signature": signature,
                    "alternates": remaining,
                    "ts": now,
                }
            else:
                self._mapping_retry_plan = None
            return {
                "choice": dict(info),
                "alternates": [dict(entry) for entry in choices if entry.get("action") != action_name],
                "summary": summary,
                "signature": signature,
            }
        # All candidates on cooldown — pick the top-ranked option anyway.
        top = dict(choices[0])
        remaining = [entry.get("action") for entry in choices[1:]]
        remaining = [act for act in remaining if isinstance(act, str)]
        if remaining:
            self._mapping_retry_plan = {
                "state": state_key,
                "signature": signature,
                "alternates": remaining,
                "ts": now,
            }
        else:
            self._mapping_retry_plan = None
        return {
            "choice": top,
            "alternates": [dict(entry) for entry in choices[1:]],
            "summary": summary,
            "signature": signature,
        }

    def _register_transition(
        self,
        *,
        action: str,
        duration_ms: int,
        changed: bool,
        movement: Optional[Dict[str, Any]],
        source: str,
        before_digest: Optional[str],
        after_frame: Optional[Tuple[bytes, int, int]] = None,
        state_key: Optional[str] = None,
    ) -> None:
        after_digest: Optional[str] = None
        after_screen: Optional[Dict[str, Any]] = None
        if after_frame is not None:
            try:
                rgb_after, w_after, h_after = after_frame
                after_arr = np.frombuffer(rgb_after, dtype=np.uint8).reshape((h_after, w_after, 3))
                after_digest = self._frame_digest(after_arr)
                try:
                    after_img = Image.frombytes("RGB", (w_after, h_after), rgb_after)
                    after_screen = self._classify_screen(
                        image=after_img,
                        ocr_text=None,
                        caption=None,
                        ocr_fallback=None,
                    )
                except Exception:
                    after_screen = None
            except Exception:
                after_digest = None
        before_screen = self.last_screen_state if isinstance(self.last_screen_state, dict) else None
        sanitized_motion = self._sanitize_motion(movement)
        entry = {
            "ts": ts(),
            "action": action,
            "duration_ms": int(duration_ms),
            "source": source,
            "changed": bool(changed),
            "before_digest": before_digest,
            "after_digest": after_digest,
            "motion": sanitized_motion,
            "state_key": state_key,
            "before_screen": before_screen,
            "after_screen": after_screen,
        }
        self.transition_journal.append(entry)
        try:
            self.timeline_manager.record_transition(
                ts=entry["ts"],
                action=action,
                duration_ms=int(duration_ms),
                changed=bool(changed),
                source=source,
                before_digest=before_digest,
                after_digest=after_digest,
                movement=sanitized_motion,
                state_key=state_key,
                before_screen=before_screen,
                after_screen=after_screen,
            )
        except Exception:
            pass

        mapping_variant: Optional[Dict[str, Any]] = None
        if state_key and before_screen:
            try:
                mapping_variant = self.menu_mappings.record_interaction(
                    state_key,
                    before_screen,
                    action,
                    bool(changed),
                )
            except Exception as exc:
                self.log.emit(f"Menu mapping update error: {exc}")
        mapping_summary: Optional[Dict[str, Any]] = None
        if mapping_variant and isinstance(before_screen, dict):
            try:
                mapping_summary = self.menu_mappings.summary_for(state_key, before_screen)
            except Exception:
                mapping_summary = None
        if mapping_summary and bool(before_screen.get("mode") in {"menu", "dialogue"}) and changed:
            primary = mapping_summary.get("primary") or {}
            primary_action = str(primary.get("action") or action)
            try:
                confidence_val = float(primary.get("confidence") or 0.0)
            except Exception:
                confidence_val = 0.0
            alternates = [
                str(alt.get("action"))
                for alt in mapping_summary.get("alternates", [])
                if isinstance(alt, dict) and alt.get("action")
            ]
            cursor_idx = mapping_summary.get("cursor_index")
            options = [str(opt) for opt in mapping_summary.get("options", [])][:3]
            preview = ", ".join(options)
            label = state_key[:8] if state_key else "?"
            log_msg = f"{ts()} mapping[{label}] primary={primary_action} conf={confidence_val:.2f}"
            if cursor_idx is not None:
                log_msg += f" cursor={cursor_idx}"
            if preview:
                log_msg += f" options={preview}"
            if alternates:
                log_msg += f" alt={','.join(alternates[:3])}"
            self.log.emit(log_msg)
            try:
                status_msg = f"Menu mapping {label[:6]} → {primary_action} ({confidence_val:.0%})"
                if alternates:
                    status_msg += f" | alt {alternates[0]}"
                self.status.emit(status_msg)
            except Exception:
                pass

        before_mode = before_screen.get("mode") if isinstance(before_screen, dict) else None
        after_mode = after_screen.get("mode") if isinstance(after_screen, dict) else None
        if before_mode == "naming":
            if self._naming_active_state != state_key:
                self._naming_action_buffer.clear()
            buffer_copy = list(self._naming_action_buffer)
            if buffer_copy:
                total_ms = sum(max(0, int(step.get("duration_ms", 0))) for step in buffer_copy)
                layout_sig = before_screen.get("grid_signature")
                target = self._infer_naming_target()
                try:
                    self.naming_macros.record_macro(
                        state_key=state_key,
                        target_name=target,
                        actions=buffer_copy,
                        total_ms=total_ms,
                        layout_signature=layout_sig,
                        success=bool(after_mode != "naming" or changed),
                    )
                except Exception:
                    pass
            if after_mode != "naming":
                self._naming_action_buffer.clear()
                self._naming_active_state = None

    def _prepare_exploration_sequences(self) -> None:
        combos = list(EXPLORATION_COMBOS)
        random.shuffle(combos)
        prepared: deque[List[Dict[str, Any]]] = deque()
        for label, combo in combos:
            steps: List[Dict[str, Any]] = []
            total = len(combo)
            for idx, button in enumerate(combo, start=1):
                hold = 220 if button in D_PAD_BUTTONS else 160
                steps.append(
                    {
                        "name": button,
                        "duration_ms": hold,
                        "reason": f"explore:{label} {idx}/{total}",
                    }
                )
            steps.append(
                {
                    "name": "NONE",
                    "duration_ms": 140,
                    "reason": f"explore:{label} settle",
                }
            )
            prepared.append(list(steps))
        self._exploration_queue.extend(prepared)

    def _queue_exploration_plan(self, *, reason: str) -> bool:
        if not self._exploration_queue:
            self._prepare_exploration_sequences()
        if not self._exploration_queue:
            return False
        sequence = self._exploration_queue.popleft()
        queued = self._set_pending_plan(sequence, reason, "exploration")
        if queued:
            self.timeline_buf.append(f"{ts()} exploration_plan → {reason}")
        return queued

    def _ocr_fallback(self, image: Image.Image) -> Optional[Dict[str, Any]]:
        gray = image.convert("L")
        arr = np.asarray(gray, dtype=np.uint8)
        if arr.ndim != 2:
            return None
        h, w = arr.shape
        try:
            thresh = int(np.percentile(arr, 35))
        except Exception:
            thresh = int(arr.mean()) if arr.size else 128
        thresh = max(40, min(200, thresh))
        mask = arr < thresh
        coverage = float(mask.mean()) if mask.size else 0.0
        if coverage < 0.01:
            return None

        ys, xs = np.nonzero(mask)
        if ys.size == 0:
            return None
        visited = np.zeros_like(mask, dtype=bool)
        components: List[Dict[str, Any]] = []
        for y, x in zip(ys.tolist(), xs.tolist()):
            if visited[y, x]:
                continue
            stack = [(y, x)]
            visited[y, x] = True
            pixels: List[Tuple[int, int]] = []
            while stack:
                cy, cx = stack.pop()
                pixels.append((cy, cx))
                y0 = max(0, cy - 1)
                y1 = min(h, cy + 2)
                x0 = max(0, cx - 1)
                x1 = min(w, cx + 2)
                for ny in range(y0, y1):
                    for nx in range(x0, x1):
                        if visited[ny, nx] or not mask[ny, nx]:
                            continue
                        visited[ny, nx] = True
                        stack.append((ny, nx))
            area = len(pixels)
            if area < 6:
                continue
            ys_comp = [p[0] for p in pixels]
            xs_comp = [p[1] for p in pixels]
            y_min, y_max = min(ys_comp), max(ys_comp) + 1
            x_min, x_max = min(xs_comp), max(xs_comp) + 1
            height = y_max - y_min
            width = x_max - x_min
            if height < 2 or width < 2:
                continue
            if area > w * h * 0.15:
                continue
            comp = {
                "y0": y_min,
                "y1": y_max,
                "x0": x_min,
                "x1": x_max,
                "height": height,
                "width": width,
                "area": area,
                "cy": (y_min + y_max) / 2.0,
                "cx": (x_min + x_max) / 2.0,
            }
            components.append(comp)
        if not components:
            return None
        components.sort(key=lambda c: c["cy"])

        line_groups: List[Dict[str, Any]] = []
        for comp in components:
            assigned = False
            for group in line_groups:
                band = max(group.get("band", 0.0), group.get("avg_height", 0.0))
                if abs(comp["cy"] - group["cy_mean"]) <= max(3.0, band * 0.6 + comp["height"] * 0.3):
                    group["components"].append(comp)
                    n = len(group["components"])
                    group["cy_mean"] = (group["cy_mean"] * (n - 1) + comp["cy"]) / n
                    group["avg_height"] = (group.get("avg_height", comp["height"]) * (n - 1) + comp["height"]) / n
                    group["band"] = max(group.get("band", 0.0), comp["height"])
                    assigned = True
                    break
            if not assigned:
                line_groups.append(
                    {
                        "components": [comp],
                        "cy_mean": comp["cy"],
                        "avg_height": comp["height"],
                        "band": comp["height"],
                    }
                )
        if not line_groups:
            return None
        line_groups.sort(key=lambda g: g["cy_mean"])

        fallback_lines: List[Dict[str, Any]] = []
        cursor_candidates: List[Tuple[int, float]] = []
        total_density = 0.0
        for idx, group in enumerate(line_groups):
            comps = group["components"]
            y0 = min(comp["y0"] for comp in comps)
            y1 = max(comp["y1"] for comp in comps)
            x0 = min(comp["x0"] for comp in comps)
            x1 = max(comp["x1"] for comp in comps)
            glyph_count = len(comps)
            width = x1 - x0
            height = y1 - y0
            area_total = sum(comp["area"] for comp in comps)
            span_area = max(1, width * height)
            total_density += min(1.0, area_total / span_area)
            suggestions: List[str] = []
            if hasattr(self, "ks") and self.ks:
                try:
                    suggestions = self.ks.lexicon_suggestions_for_glyphs(glyph_count, top_k=3)
                except Exception:
                    suggestions = []
            if suggestions:
                primary = suggestions[0]
                hint = f"Line {idx + 1} ≈ {primary} (glyphs={glyph_count})"
            else:
                hint = f"Line {idx + 1} glyphs={glyph_count}"
            fallback_lines.append(
                {
                    "index": idx,
                    "bounds": [int(x0), int(y0), int(x1), int(y1)],
                    "glyphs": int(glyph_count),
                    "hint": hint,
                    "y_center": float(group["cy_mean"]),
                    "width": int(width),
                    "height": int(height),
                    "suggestions": suggestions[:3],
                }
            )
            for comp in comps:
                if comp["x0"] < w * 0.25 and comp["width"] <= max(8, w * 0.18) and comp["height"] >= 6:
                    cursor_candidates.append((idx, comp["cx"]))
        if not fallback_lines:
            return None
        avg_density = total_density / len(fallback_lines)
        cursor_index = None
        if cursor_candidates:
            cursor_candidates.sort(key=lambda item: item[1])
            cursor_index = cursor_candidates[0][0]
        text_lines = [line["hint"] for line in fallback_lines]
        confidence = min(0.95, coverage * 3.0 + len(fallback_lines) * 0.08 + avg_density * 0.3)
        return {
            "text": "\n".join(text_lines),
            "lines": fallback_lines,
            "cursor_index": cursor_index,
            "glyph_count": sum(line["glyphs"] for line in fallback_lines),
            "line_count": len(fallback_lines),
            "confidence": float(confidence),
            "threshold": int(thresh),
            "binary_ratio": coverage,
            "source": "binary_fallback",
        }

    def _detect_naming_screen(
        self,
        arr: np.ndarray,
        *,
        ocr_text: Optional[str] = None,
    ) -> Optional[Dict[str, Any]]:
        if arr.ndim != 2:
            return None
        h, w = arr.shape
        if h < 60 or w < 60:
            return None
        try:
            thresh = int(np.percentile(arr, 40))
        except Exception:
            thresh = int(arr.mean()) if arr.size else 160
        thresh = max(60, min(170, thresh))
        mask = arr < thresh
        if mask.mean() < 0.03:
            return None
        visited = np.zeros_like(mask, dtype=bool)
        components: List[Dict[str, Any]] = []
        for y in range(1, h - 1):
            for x in range(1, w - 1):
                if not mask[y, x] or visited[y, x]:
                    continue
                stack = [(y, x)]
                visited[y, x] = True
                pixels: List[Tuple[int, int]] = []
                while stack:
                    cy, cx = stack.pop()
                    pixels.append((cy, cx))
                    for ny in range(max(0, cy - 1), min(h, cy + 2)):
                        for nx in range(max(0, cx - 1), min(w, cx + 2)):
                            if mask[ny, nx] and not visited[ny, nx]:
                                visited[ny, nx] = True
                                stack.append((ny, nx))
                area = len(pixels)
                if area < 6 or area > w * h * 0.12:
                    continue
                ys = [p[0] for p in pixels]
                xs = [p[1] for p in pixels]
                y0, y1 = min(ys), max(ys) + 1
                x0, x1 = min(xs), max(xs) + 1
                height = y1 - y0
                width = x1 - x0
                if height < 4 or width < 3 or height > 20 or width > 18:
                    continue
                cy = (y0 + y1) / 2.0
                cx = (x0 + x1) / 2.0
                if cy < h * 0.15:
                    continue
                comp = {
                    "y0": y0,
                    "y1": y1,
                    "x0": x0,
                    "x1": x1,
                    "height": height,
                    "width": width,
                    "area": area,
                    "cy": cy,
                    "cx": cx,
                }
                components.append(comp)
        if not components:
            return None
        components.sort(key=lambda c: (c["cy"], c["cx"]))

        rows: List[Dict[str, Any]] = []
        for comp in components:
            assigned = False
            for row in rows:
                if abs(comp["cy"] - row["cy"]) <= max(4.0, row["height"] * 0.5):
                    row["items"].append(comp)
                    row["cy"] = (row["cy"] * (len(row["items"]) - 1) + comp["cy"]) / len(row["items"])
                    row["height"] = max(row["height"], comp["height"])
                    assigned = True
                    break
            if not assigned:
                rows.append({"cy": comp["cy"], "height": comp["height"], "items": [comp]})
        if len(rows) < 2:
            return None
        rows.sort(key=lambda r: r["cy"])

        usable_rows: List[Dict[str, Any]] = []
        for row in rows:
            row_items = row.get("items", [])
            if len(row_items) < 5:
                continue
            span = max(item["x1"] for item in row_items) - min(item["x0"] for item in row_items)
            if span < w * 0.35:
                continue
            usable_rows.append(row)
        if len(usable_rows) < 3:
            return None

        cells: List[Dict[str, Any]] = []
        grid_x0 = w
        grid_y0 = h
        grid_x1 = 0
        grid_y1 = 0
        widths: List[float] = []
        heights: List[float] = []
        max_cols = 0
        for row_index, row in enumerate(usable_rows):
            row_items = sorted(row["items"], key=lambda c: c["cx"])
            max_cols = max(max_cols, len(row_items))
            for col_index, comp in enumerate(row_items):
                x0 = int(comp["x0"])
                y0 = int(comp["y0"])
                x1 = int(comp["x1"])
                y1 = int(comp["y1"])
                mean_val = float(arr[y0:y1, x0:x1].mean()) if y1 > y0 and x1 > x0 else 255.0
                cell = {
                    "row": row_index,
                    "col": col_index,
                    "bounds": [x0, y0, x1, y1],
                    "center": [int((x0 + x1) / 2), int((y0 + y1) / 2)],
                    "mean": mean_val,
                }
                cells.append(cell)
                grid_x0 = min(grid_x0, x0)
                grid_y0 = min(grid_y0, y0)
                grid_x1 = max(grid_x1, x1)
                grid_y1 = max(grid_y1, y1)
                widths.append(comp["width"])
                heights.append(comp["height"])
        if not cells:
            return None

        grid = {
            "bounds": [int(grid_x0), int(grid_y0), int(grid_x1), int(grid_y1)],
            "row_count": len(usable_rows),
            "column_estimate": max_cols,
            "rows": [
                {
                    "index": idx,
                    "y_center": float(row["cy"]),
                    "count": len(sorted(row["items"], key=lambda c: c["cx"]))
                }
                for idx, row in enumerate(usable_rows)
            ],
            "cells": cells,
            "cell_size": {
                "width": float(np.median(widths)) if widths else 0.0,
                "height": float(np.median(heights)) if heights else 0.0,
            },
        }
        signature = NamingMacroStore._grid_signature(grid)

        cursor_cell = min(cells, key=lambda c: c.get("mean", 255.0))
        cursor = {
            "row": int(cursor_cell.get("row", 0)),
            "col": int(cursor_cell.get("col", 0)),
            "bounds": list(cursor_cell.get("bounds", [])),
            "mean": float(cursor_cell.get("mean", 0.0)),
        }

        rightmost_col = max(cell.get("col", 0) for cell in cells)
        rightmost_cells = [cell for cell in cells if cell.get("col") == rightmost_col]
        buttons: Dict[str, Any] = {}
        if rightmost_cells:
            rightmost_cells.sort(key=lambda c: c.get("row", 0))
            top = rightmost_cells[0]
            buttons["backspace"] = {
                "row": int(top.get("row", 0)),
                "col": int(top.get("col", rightmost_col)),
                "bounds": list(top.get("bounds", [])),
            }
            if len(rightmost_cells) > 1:
                bottom = rightmost_cells[-1]
                buttons["confirm"] = {
                    "row": int(bottom.get("row", 0)),
                    "col": int(bottom.get("col", rightmost_col)),
                    "bounds": list(bottom.get("bounds", [])),
                }

        confidence = 0.55 + min(0.25, 0.08 * (len(usable_rows) - 3))
        if buttons:
            confidence += 0.05
        confidence = min(0.95, confidence)
        movement = {"UP": (0, -1), "DOWN": (0, 1), "LEFT": (-1, 0), "RIGHT": (1, 0), "wrap": False}

        return {
            "mode": "naming",
            "confidence": float(confidence),
            "grid": grid,
            "grid_signature": signature,
            "cursor": cursor,
            "buttons": buttons,
            "movement": movement,
        }

    def _classify_screen(
        self,
        *,
        image: Image.Image,
        ocr_text: Optional[str],
        caption: Optional[str],
        ocr_fallback: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        gray = image.convert("L")
        arr = np.asarray(gray, dtype=np.uint8)
        h, w = arr.shape
        state: Dict[str, Any] = {"mode": "unknown", "confidence": 0.0}

        naming = self._detect_naming_screen(arr, ocr_text=ocr_text)
        if naming:
            if ocr_fallback:
                naming["fallback"] = ocr_fallback
            return naming

        arrow_symbols = ("▶", "▸", "►", ">", "»", "➤", "➔")
        menu_lines: List[Tuple[str, int]] = []
        cursor_index: Optional[int] = None
        fallback_lines_info: List[Dict[str, Any]] = []
        if isinstance(ocr_fallback, dict):
            cursor_idx_val = ocr_fallback.get("cursor_index")
            if isinstance(cursor_idx_val, int):
                cursor_index = cursor_idx_val
            lines_meta = ocr_fallback.get("lines")
            if isinstance(lines_meta, list):
                fallback_lines_info = [line for line in lines_meta if isinstance(line, dict)]
        if ocr_text:
            raw_lines = [line.strip() for line in ocr_text.splitlines()]
            for raw_idx, raw_line in enumerate(raw_lines):
                if not raw_line:
                    continue
                has_arrow = any(sym in raw_line for sym in arrow_symbols)
                cleaned = raw_line
                for sym in arrow_symbols:
                    cleaned = cleaned.replace(sym, " ")
                cleaned = re.sub(r"^[\-\*\•\·\>\s]+", "", cleaned)
                cleaned = cleaned.strip(" .:;>-·•")
                if not cleaned:
                    continue
                normalized = self._normalize_token(cleaned)
                if not normalized:
                    continue
                tokens = normalized.split()
                alpha_tokens = [tok for tok in tokens if tok.isalpha()]
                plausible = bool(alpha_tokens) and all(len(tok) <= 12 for tok in tokens)
                if not plausible:
                    continue
                menu_lines.append((cleaned, raw_idx))
                if has_arrow and cursor_index is None:
                    cursor_index = len(menu_lines) - 1
        if fallback_lines_info:
            for line in fallback_lines_info:
                hint = str(line.get("hint") or "").strip()
                if not hint:
                    continue
                cleaned = re.sub(r"^[\-\*\•\·\>\s]+", "", hint)
                cleaned = cleaned.strip(" .:;>-·•")
                if not cleaned:
                    continue
                normalized = self._normalize_token(cleaned)
                if not normalized:
                    continue
                tokens = normalized.split()
                alpha_tokens = [tok for tok in tokens if tok.isalpha()]
                plausible = bool(alpha_tokens) and all(len(tok) <= 12 for tok in tokens)
                if not plausible:
                    continue
                menu_lines.append((cleaned, len(menu_lines)))
                if cursor_index is None and isinstance(line.get("index"), int):
                    cursor_index = line.get("index")

        left_x = int(w * 0.15)
        right_x = int(w * 0.65)
        slice_arr = arr[:, left_x:right_x]
        dark_mask = slice_arr < 110
        dark_ratio = dark_mask.mean(axis=1) if slice_arr.size else np.zeros(h, dtype=np.float32)
        row_groups: List[Tuple[int, int]] = []
        start: Optional[int] = None
        threshold = 0.18
        for y in range(h):
            if dark_ratio[y] > threshold:
                if start is None:
                    start = y
            else:
                if start is not None:
                    row_groups.append((start, y - 1))
                    start = None
        if start is not None:
            row_groups.append((start, h - 1))
        line_centers = [int((a + b) / 2) for a, b in row_groups if b - a >= 2]

        caret_rows: List[int] = []
        search_width = max(4, int(w * 0.4))
        dark_full = arr < 110
        for y in range(2, h - 2):
            row_found = False
            for x in range(2, min(search_width, w - 2)):
                if not dark_full[y, x]:
                    continue
                if dark_full[y, x + 1] and (dark_full[y - 1, x + 1] or dark_full[y + 1, x + 1]):
                    if not dark_full[y, x - 1]:
                        caret_rows.append(y)
                        row_found = True
                        break
            if row_found:
                continue
        caret_clusters: List[int] = []
        for y in caret_rows:
            if not caret_clusters or abs(y - caret_clusters[-1]) > 2:
                caret_clusters.append(y)
        caret_y: Optional[int] = None
        if caret_clusters:
            caret_y = int(np.median(caret_clusters))

        menu_score = 0.0
        if menu_lines:
            menu_score += 0.45
        if len(menu_lines) >= 2:
            menu_score += 0.15
        if caret_y is not None:
            menu_score += 0.3
        if len(line_centers) >= 2:
            menu_score += 0.2
        if caption and "menu" in caption.lower():
            menu_score += 0.1
        menu_score = min(menu_score, 0.99)

        if menu_score >= 0.55:
            options = [name for name, _ in menu_lines]
            if not options and line_centers:
                options = [f"Option {i+1}" for i in range(len(line_centers))]
            if caret_y is not None and line_centers:
                idx_by_distance = int(np.argmin([abs(caret_y - c) for c in line_centers])) if line_centers else None
                if idx_by_distance is not None:
                    cursor_index = idx_by_distance
            if cursor_index is not None and options:
                cursor_index = int(max(0, min(cursor_index, len(options) - 1)))
            state = {
                "mode": "menu",
                "confidence": round(float(menu_score), 3),
                "options": options,
                "cursor_index": cursor_index,
                "line_count": len(line_centers),
                "caret_detected": caret_y is not None,
            }
            if caret_y is not None:
                state["caret_row"] = int(caret_y)
            if ocr_fallback:
                state["fallback"] = ocr_fallback
        else:
            bottom_slice = arr[int(h * 0.65) :, :]
            if bottom_slice.size:
                dark_bottom = (bottom_slice < 90).mean()
                if dark_bottom > 0.35:
                    state = {"mode": "dialogue", "confidence": round(float(dark_bottom), 3)}
                else:
                    state = {"mode": "overworld", "confidence": 0.4}
            else:
                state = {"mode": "overworld", "confidence": 0.2}
            if ocr_fallback:
                state["fallback"] = ocr_fallback

        return state

    def _human_hint(self, img: Image.Image, state: str) -> Optional[Tuple[str,int,str]]:
        # Heuristics gated by cooldowns
        g = img.convert("L"); arr = np.asarray(g, dtype=np.uint8)
        bright = (arr > 210).mean(); dark = (arr < 50).mean()
        screen_state = self.last_screen_state if isinstance(self.last_screen_state, dict) else {}
        if screen_state.get("mode") == "menu":
            options = screen_state.get("options") or []
            cursor_index = screen_state.get("cursor_index")
            option_label = None
            if isinstance(cursor_index, int) and 0 <= cursor_index < len(options):
                option_label = options[cursor_index]
            normalized_option = self._normalize_token(option_label) if option_label else ""
            avoid_confirm = {"EXIT", "CANCEL", "BACK", "OPTION", "OPTIONS"}
            safe_to_confirm = normalized_option not in avoid_confirm if normalized_option else True
            if safe_to_confirm and not self.brain._is_on_cooldown(state, "A"):
                label = str(option_label) if option_label is not None else "current option"
                return ("A", 140, f"Menu heuristic: confirm {label}")
            if isinstance(cursor_index, int) and len(options) >= 2:
                if cursor_index >= len(options) - 1:
                    if not self.brain._is_on_cooldown(state, "UP"):
                        return ("UP", 120, "Menu heuristic: move up to reach other options")
                else:
                    if not self.brain._is_on_cooldown(state, "DOWN"):
                        return ("DOWN", 120, "Menu heuristic: explore next option")
            if not self.brain._is_on_cooldown(state, "A"):
                return ("A", 120, "Menu heuristic: confirm selection")
        # title-like contrast: heavy whites & blacks → try START, unless cooled
        if bright > 0.12 and dark > 0.15 and not self.brain._is_on_cooldown(state, "START"):
            return ("START", 150, "Heuristic: title-like contrast; try START")
        # dialog-like black box bottom third → try A
        h = arr.shape[0]; bot = arr[int(h*0.66):,:]
        if (bot < 80).mean() > 0.35 and not self.brain._is_on_cooldown(state, "A"):
            return ("A", 120, "Heuristic: dialog box likely; try A")
        return None

    def _record_failure(self, note: str):
        entry = {"ts": ts(), "note": note}
        self.failure_buf.append(entry)

    @staticmethod
    def _summarize_memory_entry(entry: Dict[str, Any]) -> Dict[str, Any]:
        caption = (entry.get("caption") or "")
        ocr = (entry.get("ocr") or "")
        if isinstance(caption, str) and len(caption) > 160:
            caption = caption[:157] + "…"
        if isinstance(ocr, str) and len(ocr) > 160:
            ocr = ocr[:157] + "…"
        return {
            "ts": entry.get("ts"),
            "action": entry.get("action"),
            "changed": entry.get("changed"),
            "caption": caption,
            "ocr": ocr,
            "phash_distance": entry.get("phash_distance"),
            "cluster_distance": entry.get("cluster_distance"),
        }

    @staticmethod
    def _summarize_fallback_hint(data: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        if not isinstance(data, dict):
            return None
        summary: Dict[str, Any] = {"source": data.get("source", "fallback")}
        text = data.get("text")
        if isinstance(text, str):
            trimmed = text.strip()
            if len(trimmed) > 160:
                trimmed = trimmed[:157] + "…"
            if trimmed:
                summary["text"] = trimmed
        for key in ("confidence", "binary_ratio"):
            val = data.get(key)
            if isinstance(val, (int, float)) and np.isfinite(val):
                summary[key] = float(val)
        line_count = data.get("line_count")
        if isinstance(line_count, (int, float)):
            summary["line_count"] = int(line_count)
        lines_meta = data.get("lines")
        if isinstance(lines_meta, list):
            sample: List[Dict[str, Any]] = []
            for line in lines_meta[:8]:
                if not isinstance(line, dict):
                    continue
                entry: Dict[str, Any] = {}
                idx_val = line.get("index")
                if isinstance(idx_val, (int, float)):
                    entry["index"] = int(idx_val)
                glyphs_val = line.get("glyphs")
                if isinstance(glyphs_val, (int, float)):
                    entry["glyphs"] = int(glyphs_val)
                bounds = line.get("bounds")
                if isinstance(bounds, (list, tuple)):
                    coords: List[int] = []
                    for coord in list(bounds)[:4]:
                        if isinstance(coord, (int, float)):
                            coords.append(int(coord))
                    if coords:
                        entry["bounds"] = coords
                hint = line.get("hint")
                if isinstance(hint, str) and hint.strip():
                    entry["hint"] = hint.strip()
                y_center = line.get("y_center")
                if isinstance(y_center, (int, float)) and np.isfinite(y_center):
                    entry["y_center"] = float(y_center)
                if entry:
                    sample.append(entry)
            if sample:
                summary["lines"] = sample
                if "line_count" not in summary:
                    summary["line_count"] = len(sample)
        cursor_idx = data.get("cursor_index")
        if isinstance(cursor_idx, (int, float)):
            summary["cursor_index"] = int(cursor_idx)
        glyph_total = data.get("glyph_count")
        if isinstance(glyph_total, (int, float)):
            summary["glyph_count"] = int(glyph_total)
        thresh = data.get("threshold")
        if isinstance(thresh, (int, float)):
            summary["threshold"] = int(thresh)
        return summary or None

    # ---- operator pipeline ---------------------------------------------------
    def _operator_ocr(self, ctx: _ObservationContext) -> OperatorResult:
        payload: Dict[str, Any] = {}
        summary_parts: List[str] = []
        errors: List[str] = []
        confidence = 0.15
        caption: Optional[str] = None
        try:
            caption = ollama_generate(
                ctx.vision_model,
                ctx.caption_prompt,
                b64_image=ctx.base64_image,
            )
            if isinstance(caption, str) and caption.strip():
                caption = caption.strip()
                payload["caption"] = caption
                summary_parts.append(f"caption:{caption[:48]}")
                confidence += 0.25
        except Exception as exc:
            errors.append(f"caption:{exc}")
        ocr_text: Optional[str] = None
        if ctx.ocr_enabled and ctx.ocr_model:
            try:
                ocr_text = ollama_generate(
                    ctx.ocr_model,
                    ctx.ocr_prompt,
                    b64_image=ctx.base64_image,
                )
                if isinstance(ocr_text, str) and ocr_text.strip():
                    ocr_text = ocr_text.strip()
                    payload["ocr_text"] = ocr_text
                    summary_parts.append(f"ocr:{ocr_text[:48]}")
                    confidence += 0.3
            except Exception as exc:
                errors.append(f"ocr:{exc}")
        try:
            fallback_raw = self._ocr_fallback(ctx.image)
        except Exception as exc:
            fallback_raw = None
            errors.append(f"fallback:{exc}")
        if fallback_raw:
            payload["fallback_raw"] = fallback_raw
        fallback_summary = self._summarize_fallback_hint(fallback_raw)
        if fallback_summary:
            payload["fallback_summary"] = fallback_summary
        summary = " | ".join(summary_parts) if summary_parts else "no-vision"
        error_text = "; ".join(errors) if errors else None
        return OperatorResult(
            name="ocr_interpreter",
            summary=summary,
            confidence=min(1.0, max(0.0, confidence)),
            payload=payload,
            error=error_text,
        )

    def _operator_sprite(self, ctx: _ObservationContext) -> OperatorResult:
        payload: Dict[str, Any] = {"movement": dict(ctx.movement)}
        errors: List[str] = []
        summary_parts: List[str] = []
        confidence = 0.2
        try:
            decomposition = decompose_frame(ctx.image)
        except Exception as exc:
            decomposition = {"frame_size": ctx.image.size, "regions": [], "stats": {}, "error": str(exc)}
            errors.append(f"decompose:{exc}")
        regions = decomposition.get("regions") if isinstance(decomposition, dict) else None
        if not isinstance(regions, list):
            regions = []
        payload["decomposition"] = decomposition
        payload["regions"] = regions
        summary_parts.append(f"regions:{len(regions)}")
        confidence += min(0.3, 0.05 * len(regions))
        try:
            matches = ctx.knowledge_store.find_region_matches(regions)
        except Exception as exc:
            matches = []
            errors.append(f"regions:{exc}")
        payload["matches"] = matches
        try:
            motion_mag = float(ctx.movement.get("magnitude", 0.0) or 0.0)
        except Exception:
            motion_mag = 0.0
        if motion_mag:
            summary_parts.append(f"motion:{motion_mag:.2f}")
            try:
                confidence += min(0.2, float(ctx.movement.get("confidence", 0.0) or 0.0))
            except Exception:
                pass
        summary = " | ".join(summary_parts) if summary_parts else "no-sprite"
        error_text = "; ".join(errors) if errors else None
        return OperatorResult(
            name="sprite_tracker",
            summary=summary,
            confidence=min(1.0, max(0.0, confidence)),
            payload=payload,
            error=error_text,
        )

    def _operator_ui_classifier(
        self,
        ctx: _ObservationContext,
        ocr_text: Optional[str],
        caption: Optional[str],
        fallback_raw: Optional[Dict[str, Any]],
    ) -> OperatorResult:
        errors: List[str] = []
        confidence = 0.2
        screen_state: Optional[Dict[str, Any]] = None
        summary = "unclassified"
        try:
            screen_state = self._classify_screen(
                image=ctx.image,
                ocr_text=ocr_text,
                caption=caption,
                ocr_fallback=fallback_raw,
            )
            if isinstance(screen_state, dict):
                payload_conf = float(screen_state.get("confidence", 0.0) or 0.0)
                mode = screen_state.get("mode") or "unknown"
                summary = f"mode:{mode}".strip()
                confidence = max(confidence, min(1.0, payload_conf))
        except Exception as exc:
            errors.append(str(exc))
        payload = {"screen_state": screen_state}
        error_text = "; ".join(errors) if errors else None
        return OperatorResult(
            name="ui_classifier",
            summary=summary,
            confidence=min(1.0, max(0.0, confidence if not errors else confidence * 0.5)),
            payload=payload,
            error=error_text,
        )

    def _operator_similarity(
        self,
        ctx: _ObservationContext,
        ocr_text: Optional[str],
        caption: Optional[str],
        fallback_summary: Optional[Dict[str, Any]],
    ) -> OperatorResult:
        payload: Dict[str, Any] = {"vector_ready": bool(ctx.vector_ready)}
        errors: List[str] = []
        confidence = 0.25
        text_parts: List[str] = []
        for candidate in (caption, ocr_text):
            if isinstance(candidate, str) and candidate.strip():
                text_parts.append(candidate.strip())
        if isinstance(fallback_summary, dict):
            fb_text = fallback_summary.get("text")
            if isinstance(fb_text, str) and fb_text.strip():
                text_parts.append(fb_text.strip())
        text_query = " \n".join(text_parts)
        payload["text_query"] = text_query
        try:
            phash_matches = ctx.knowledge_store.search_by_phash(ctx.phash, limit=4)
        except Exception as exc:
            phash_matches = []
            errors.append(f"phash:{exc}")
        payload["phash_matches"] = phash_matches
        confidence += 0.1 if phash_matches else 0.02
        text_matches: List[Dict[str, Any]] = []
        text_status = "idle"
        if text_query:
            if ctx.vector_ready:
                try:
                    text_matches = ctx.knowledge_store.search_by_text(text_query, top_k=4)
                    text_status = "ok" if text_matches else "no_matches"
                except Exception as exc:
                    text_status = f"error:{exc.__class__.__name__}"
                    errors.append(f"text:{exc}")
            else:
                text_status = "vector_store_unavailable"
        payload["text_matches"] = text_matches
        payload["text_status"] = text_status
        summary = f"phash:{len(phash_matches)} text:{len(text_matches)}"
        error_text = "; ".join(errors) if errors else None
        return OperatorResult(
            name="similarity_retriever",
            summary=summary,
            confidence=min(1.0, max(0.0, confidence)),
            payload=payload,
            error=error_text,
        )

    def _operator_policy_advisor(
        self,
        ctx: _ObservationContext,
        screen_state: Optional[Dict[str, Any]],
        similarity_payload: Optional[Dict[str, Any]],
    ) -> OperatorResult:
        payload: Dict[str, Any] = {}
        errors: List[str] = []
        summary_parts: List[str] = []
        confidence = 0.2
        mapping_summary: Optional[Dict[str, Any]] = None
        if isinstance(screen_state, dict):
            try:
                mapping_summary = ctx.menu_store.summary_for(ctx.state_key, screen_state)
            except Exception as exc:
                errors.append(f"mapping:{exc}")
        payload["mapping"] = mapping_summary
        proposal: Optional[Dict[str, Any]] = None
        if mapping_summary:
            primary = mapping_summary.get("primary") if isinstance(mapping_summary, dict) else None
            if isinstance(primary, dict):
                candidate = str(primary.get("action") or "").upper()
                if candidate in ACTIONS and candidate:
                    conf_val = 0.0
                    try:
                        conf_val = float(primary.get("confidence", 0.0) or 0.0)
                    except Exception:
                        conf_val = 0.0
                    proposal = {
                        "action": candidate,
                        "confidence": conf_val,
                        "reason": primary.get("reason") or "menu_mapping",
                    }
                    summary_parts.append(f"menu:{candidate}")
                    confidence = max(confidence, min(1.0, conf_val))
        if proposal is None:
            bandit_profiles: Dict[str, Any] = {}
            try:
                for act in LEARNABLE:
                    bandit_profiles[act] = ctx.brain.confidence_profile(ctx.state_key, act)
                best_act = max(
                    LEARNABLE,
                    key=lambda act: float(bandit_profiles.get(act, {}).get("confidence", 0.0) or 0.0),
                )
                best_profile = bandit_profiles.get(best_act, {})
                conf_val = float(best_profile.get("confidence", 0.0) or 0.0)
                proposal = {
                    "action": best_act,
                    "confidence": conf_val,
                    "reason": "bandit_profile",
                }
                summary_parts.append(f"bandit:{best_act}")
                confidence = max(confidence, min(1.0, conf_val))
            except Exception as exc:
                errors.append(f"brain:{exc}")
            payload["confidence_profiles"] = bandit_profiles
        if proposal:
            payload["proposal"] = proposal
        if similarity_payload:
            payload["similarity_snapshot"] = similarity_payload
        summary = " | ".join(summary_parts) if summary_parts else "no-advice"
        error_text = "; ".join(errors) if errors else None
        return OperatorResult(
            name="policy_advisor",
            summary=summary,
            confidence=min(1.0, max(0.0, confidence)),
            payload=payload,
            error=error_text,
        )

    def _operator_verifier(
        self,
        ctx: _ObservationContext,
        screen_state: Optional[Dict[str, Any]],
        policy_result: Optional[OperatorResult],
        similarity_payload: Optional[Dict[str, Any]],
    ) -> OperatorResult:
        issues: List[str] = []
        confidence = 0.85
        proposal = None
        if isinstance(policy_result, OperatorResult) and isinstance(policy_result.payload, dict):
            proposal = policy_result.payload.get("proposal")
        if isinstance(screen_state, dict):
            mode = screen_state.get("mode")
            if mode == "menu" and isinstance(proposal, dict):
                candidate = str(proposal.get("action") or "").upper()
                if candidate not in {"UP", "DOWN", "LEFT", "RIGHT", "A", "B"}:
                    issues.append("menu-action-mismatch")
                    confidence -= 0.25
        if isinstance(similarity_payload, dict):
            if not similarity_payload.get("phash_matches"):
                issues.append("no-phash-match")
                confidence -= 0.1
            if similarity_payload.get("text_status") == "vector_store_unavailable":
                issues.append("vector-store-offline")
                confidence -= 0.05
        if isinstance(policy_result, OperatorResult) and policy_result.error:
            issues.append("policy-error")
            confidence -= 0.1
        payload = {
            "issues": issues,
            "status": "ok" if not issues else "degraded",
        }
        summary = "ok" if not issues else ", ".join(issues)
        return OperatorResult(
            name="verifier",
            summary=summary,
            confidence=max(0.0, min(1.0, confidence)),
            payload=payload,
            error=None,
        )

    def _build_operator_advisories(self, bundle: OperatorBundle) -> List[Dict[str, Any]]:
        advisories: List[Dict[str, Any]] = []
        for name, result in bundle.results.items():
            payload = result.payload if isinstance(result.payload, dict) else {}
            if name == "policy_advisor" and isinstance(payload.get("proposal"), dict):
                proposal = payload["proposal"]
                advisories.append(
                    {
                        "name": "policy_advisor",
                        "message": f"Recommend {proposal.get('action')} ({proposal.get('reason', 'unknown')})",
                        "confidence": float(proposal.get("confidence", 0.0) or 0.0),
                    }
                )
            if name == "verifier" and payload.get("issues"):
                issues = [str(item) for item in payload.get("issues", [])]
                advisories.append(
                    {
                        "name": "verifier",
                        "message": "; ".join(issues),
                        "confidence": float(result.confidence),
                    }
                )
        return advisories

    def _synthesize_operator_feedback(self, advisories: Sequence[Dict[str, Any]]) -> List[str]:
        if not advisories:
            return []
        operators: List[ObservationOperator] = []
        for idx, item in enumerate(advisories):
            op_name = f"advisory_{idx}_{str(item.get('name', 'op')).lower()}"

            def _make(item=item, op_name=op_name) -> ObservationOperator:
                def _fn() -> OperatorResult:
                    label = str(item.get("name", op_name))
                    message = str(item.get("message", "")).strip()
                    confidence = float(item.get("confidence", 0.0) or 0.0)
                    text = f"{label}: {message}".strip()
                    return OperatorResult(
                        name=op_name,
                        summary=text,
                        confidence=confidence,
                        payload={"advice": text, "source": label, "confidence": confidence},
                    )

                return ObservationOperator(name=op_name, func=_fn)

            operators.append(_make())
        results = self._operator_aggregator.run_group(operators, timeout=2.0)
        lines: List[str] = []
        for result in results.values():
            payload = result.payload if isinstance(result.payload, dict) else {}
            advice = payload.get("advice") if isinstance(payload.get("advice"), str) else result.summary
            if isinstance(advice, str) and advice:
                lines.append(advice)
        return sorted(lines)

    def _collect_operator_bundle(
        self,
        *,
        image: Image.Image,
        frame_array: np.ndarray,
        base64_image: str,
        state: str,
        phash: str,
        frame_digest: Optional[str],
        movement: Dict[str, Any],
        allow_saveload: bool,
        meta: Dict[str, Any],
        ocr_enabled: bool,
        ocr_model: str,
        ocr_prompt: str,
        vision_model: str,
        caption_prompt: str,
    ) -> OperatorBundle:
        ctx = _ObservationContext(
            image=image,
            frame_array=frame_array,
            base64_image=base64_image,
            state_key=state,
            phash=phash,
            frame_digest=frame_digest,
            movement=movement,
            allow_saveload=allow_saveload,
            meta=meta,
            ocr_enabled=ocr_enabled,
            ocr_model=ocr_model,
            ocr_prompt=ocr_prompt,
            vision_model=vision_model,
            caption_prompt=caption_prompt,
            knowledge_store=self.ks,
            menu_store=self.menu_mappings,
            brain=self.brain,
            vector_ready=self.ks.vector_ready,
        )
        results: Dict[str, OperatorResult] = {}

        stage1 = [
            ObservationOperator(name="ocr_interpreter", func=lambda ctx=ctx: self._operator_ocr(ctx)),
            ObservationOperator(name="sprite_tracker", func=lambda ctx=ctx: self._operator_sprite(ctx)),
        ]
        results.update(self._operator_aggregator.run_group(stage1, timeout=12.0))
        ocr_res = results.get("ocr_interpreter")
        ocr_payload = ocr_res.payload if isinstance(ocr_res, OperatorResult) else {}
        ocr_text = ocr_payload.get("ocr_text") if isinstance(ocr_payload, dict) else None
        caption = ocr_payload.get("caption") if isinstance(ocr_payload, dict) else None
        fallback_raw = ocr_payload.get("fallback_raw") if isinstance(ocr_payload, dict) else None
        fallback_summary = ocr_payload.get("fallback_summary") if isinstance(ocr_payload, dict) else None

        stage2 = [
            ObservationOperator(
                name="ui_classifier",
                func=lambda ctx=ctx, ocr_text=ocr_text, caption=caption, fallback_raw=fallback_raw: self._operator_ui_classifier(
                    ctx,
                    ocr_text,
                    caption,
                    fallback_raw,
                ),
            ),
            ObservationOperator(
                name="similarity_retriever",
                func=lambda ctx=ctx, ocr_text=ocr_text, caption=caption, fallback_summary=fallback_summary: self._operator_similarity(
                    ctx,
                    ocr_text,
                    caption,
                    fallback_summary,
                ),
            ),
        ]
        results.update(self._operator_aggregator.run_group(stage2, timeout=10.0))
        ui_res = results.get("ui_classifier")
        screen_state = None
        if isinstance(ui_res, OperatorResult) and isinstance(ui_res.payload, dict):
            screen_state = ui_res.payload.get("screen_state")
        similarity_res = results.get("similarity_retriever")
        similarity_payload = (
            similarity_res.payload
            if isinstance(similarity_res, OperatorResult) and isinstance(similarity_res.payload, dict)
            else {}
        )

        policy_result = self._operator_aggregator.run_group(
            [
                ObservationOperator(
                    name="policy_advisor",
                    func=lambda ctx=ctx, screen_state=screen_state, similarity_payload=similarity_payload: self._operator_policy_advisor(
                        ctx,
                        screen_state,
                        similarity_payload,
                    ),
                )
            ],
            timeout=8.0,
        )
        results.update(policy_result)
        policy_op = results.get("policy_advisor")

        verifier_result = self._operator_aggregator.run_group(
            [
                ObservationOperator(
                    name="verifier",
                    func=lambda ctx=ctx, screen_state=screen_state, policy_op=policy_op, similarity_payload=similarity_payload: self._operator_verifier(
                        ctx,
                        screen_state,
                        policy_op,
                        similarity_payload,
                    ),
                )
            ],
            timeout=6.0,
        )
        results.update(verifier_result)

        bundle = self._operator_aggregator.assemble(results)
        bundle.advisories = self._build_operator_advisories(bundle)
        self._last_operator_bundle = bundle
        return bundle

    def _record_memory_reflection(self, action: str, changed: bool, source: str, reason: str = ""):
        snapshot = self._last_memory_snapshot or {}
        consulted: List[Any] = []
        for key in ("phash_matches", "text_matches"):
            vals = snapshot.get(key)
            if isinstance(vals, list):
                consulted.extend(vals)
        helped = bool(consulted) and bool(changed)
        reflection = {
            "ts": ts(),
            "action": action,
            "source": source,
            "reason": reason,
            "changed": bool(changed),
            "helped": helped,
            "state": snapshot.get("state_key"),
            "phash_query": snapshot.get("phash_query"),
            "text_query": snapshot.get("text_query"),
            "consulted": consulted,
        }
        try:
            with MEMORY_REFLECTION_LOG.open("a", encoding="utf-8") as fh:
                fh.write(json.dumps(reflection) + "\n")
        except Exception:
            pass
        self._last_memory_reflection = reflection
        if consulted:
            marker = "OK" if helped else "…"
            self.timeline_buf.append(f"{reflection['ts']} memory:{action} {marker}")

    def _build_observation_context(
        self,
        *,
        caption: Optional[str],
        ocr_text: Optional[str],
        ocr_fallback: Optional[Dict[str, Any]],
        image: Image.Image,
        state: str,
        phash: str,
        frame_digest: Optional[str],
        allow_saveload: bool,
        meta: Dict[str, Any],
        decision_prompt: str,
        movement_estimate: Dict[str, Any],
        visual: Optional[Dict[str, Any]] = None,
        memory_override: Optional[Dict[str, Any]] = None,
        screen_state_override: Optional[Dict[str, Any]] = None,
        screen_directives: Optional[List[Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        knowledge_entries: List[Dict[str, Any]] = list(self.knowledge_buf)
        failures = list(self.failure_buf)
        phash_matches: List[Dict[str, Any]] = []
        text_matches: List[Dict[str, Any]] = []
        text_status = "idle"
        text_query_parts = []
        if caption:
            text_query_parts.append(str(caption))
        if ocr_text:
            text_query_parts.append(str(ocr_text))
        if ocr_fallback and isinstance(ocr_fallback, dict):
            fb_text = ocr_fallback.get("text")
            if isinstance(fb_text, str):
                text_query_parts.append(fb_text)
        text_query = " \n".join([p.strip() for p in text_query_parts if p.strip()])
        vector_ready = self.ks.vector_ready
        if isinstance(memory_override, dict):
            phash_matches = list(memory_override.get("phash_matches", []))
            text_matches = list(memory_override.get("text_matches", []))
            text_status = str(memory_override.get("text_status", "precomputed"))
            override_query = memory_override.get("text_query")
            if isinstance(override_query, str) and override_query.strip():
                text_query = override_query.strip()
            if "vector_ready" in memory_override:
                try:
                    vector_ready = bool(memory_override.get("vector_ready"))
                except Exception:
                    vector_ready = self.ks.vector_ready
        else:
            try:
                if phash:
                    phash_matches = self.ks.search_by_phash(phash, limit=4)
            except Exception as e:
                self.log.emit(f"Knowledge search (pHash) failed: {e}")
            if text_query:
                if self.ks.vector_ready:
                    try:
                        text_matches = self.ks.search_by_text(text_query, top_k=4)
                        text_status = "ok" if text_matches else "no_matches"
                    except Exception as e:
                        text_status = f"error:{e.__class__.__name__}"
                        self.log.emit(f"Knowledge search (text) failed: {e}")
                else:
                    text_status = "vector_store_unavailable"
        memory_snapshot = {
            "ts": ts(),
            "state_key": state,
            "phash_query": phash,
            "text_query": text_query,
            "phash_matches": phash_matches,
            "text_matches": text_matches,
            "vector_ready": vector_ready,
            "text_status": text_status,
            "visual": visual or {},
        }
        phash_digest = [self._summarize_memory_entry(entry) for entry in phash_matches]
        memory_digest = {
            "phash_matches": phash_digest,
            "text_matches": text_matches,
            "vector_ready": vector_ready,
            "text_query": text_query,
            "text_status": text_status,
        }
        if screen_state_override is not None:
            screen_state = screen_state_override
        else:
            screen_state = self._classify_screen(
                image=image,
                ocr_text=ocr_text,
                caption=caption,
                ocr_fallback=ocr_fallback,
            )
        self.last_screen_state = screen_state
        if state and isinstance(screen_state, dict) and screen_state.get("mode") == "naming":
            try:
                self.naming_macros.update_layout(state, screen_state)
            except Exception:
                pass
        mapping_summary: Optional[Dict[str, Any]] = None
        if state and isinstance(screen_state, dict):
            try:
                mapping_summary = self.menu_mappings.summary_for(state, screen_state)
            except Exception:
                mapping_summary = None
        timeline_summary = None
        timeline_prediction: Dict[str, Any] = {}
        timeline_history: List[Dict[str, Any]] = []
        if frame_digest:
            try:
                self.timeline_manager.annotate_screen_state(
                    digest=frame_digest,
                    screen_state=screen_state,
                    state_key=state,
                )
            except Exception:
                pass
        try:
            timeline_summary = self.timeline_manager.recent_summary()
            timeline_prediction = self.timeline_manager.predictive_hint()
            timeline_history = self.timeline_manager.scored_history(limit=8)
        except Exception:
            timeline_summary = None
            timeline_prediction = {}
            timeline_history = []
        timeline_context = {
            "summary": timeline_summary,
            "prediction": timeline_prediction,
            "history": timeline_history,
        }
        self._latest_timeline_context = timeline_context
        memory_snapshot["timeline"] = timeline_context
        self._last_memory_snapshot = memory_snapshot
        try:
            self.memorySnapshot.emit(memory_snapshot)
        except Exception:
            pass
        cooldown_notes = {
            act: {
                "ts": note.get("ts"),
                "until": note.get("until"),
                "source": note.get("source"),
                "reason": note.get("reason"),
                "watchdog": bool(note.get("watchdog")),
            }
            for act, note in self._cooldown_annotations.items()
        }
        confidence_profiles: Dict[str, Any] = {}
        for act in LEARNABLE:
            try:
                confidence_profiles[act] = self.brain.confidence_profile(state, act)
            except Exception as e:
                confidence_profiles[act] = {"confidence": 0.0, "error": e.__class__.__name__}
        brain_similarity = self.brain.threshold_snapshot(state)
        knowledge_similarity = self.ks.cluster_threshold_snapshot(phash)

        open_tasks = [t.to_dict() for t in self.task_manager.active_tasks()]
        source_counts: Dict[str, int] = {}
        for task in open_tasks:
            source = str(task.get("source", "llm") or "llm")
            source_counts[source] = source_counts.get(source, 0) + 1
        directives_payload: List[Dict[str, Any]] = []
        if isinstance(screen_directives, list):
            for entry in screen_directives:
                if isinstance(entry, dict):
                    directives_payload.append(dict(entry))

        context = {
            "timestamp": ts(),
            "rom": meta.get("rom"),
            "profile": meta.get("profile"),
            "emulator": {
                "allow_saveload": allow_saveload,
                "running": bool(self.app.is_running()),
                "fail_parse_streak": self.fail_parse_streak,
                "no_change_streak": self.no_change_streak,
                "last_action": self.last_action,
                "cooldown_notes": cooldown_notes,
            },
            "frame": {
                "state_key": state,
                "phash": phash,
                "caption": caption,
                "ocr": ocr_text,
                "ocr_fallback": ocr_fallback,
                "screen_state": screen_state,
                "menu_mapping": mapping_summary,
                "visual": visual or {},
            },
            "open_tasks": open_tasks,
            "task_sources": source_counts,
            "screen_directives": directives_payload,
            "recent_timeline": self.timeline_buf[-10:],
            "recent_narratives": list(self.narrative_history),
            "recent_knowledge": knowledge_entries,
            "recent_failures": failures,
            "recent_transitions": list(self.transition_journal),
            "operator_guidance": decision_prompt,
            "memory_recall": memory_digest,
            "movement_estimate": movement_estimate,
            "control_knowledge": BUTTON_DEFINITIONS,
            "phase_history": list(self._last_phase_cycles),
            "brain_confidence": confidence_profiles,
            "similarity_metrics": {
                "brain": brain_similarity,
                "knowledge": knowledge_similarity,
            },
            "timeline": timeline_context,
        }
        return context

    def _normalize_action_plan(self, payload: Any) -> Dict[str, Any]:
        plan: Dict[str, Any] = {"steps": [], "reason": "", "decline": False}
        if not isinstance(payload, dict):
            return plan
        plan_reason = str(payload.get("reason") or payload.get("plan_reason") or "").strip()
        decline = bool(payload.get("decline"))
        steps: List[Dict[str, Any]] = []
        raw_steps = payload.get("steps")
        raw_items: List[Any]
        if isinstance(raw_steps, list):
            raw_items = raw_steps
        else:
            raw_items = [payload]
        for item in raw_items:
            if not isinstance(item, dict):
                continue
            name = str(item.get("name") or item.get("action") or "").upper()
            if not name:
                continue
            try:
                dur_raw = item.get("duration_ms", item.get("press_duration_ms", item.get("duration")))
            except Exception:
                dur_raw = None
            try:
                dur = int(dur_raw) if dur_raw is not None else 120
            except Exception:
                dur = 120
            dur = max(40, min(5000, dur))
            step_reason = str(item.get("reason") or "").strip()
            steps.append({"name": name, "duration_ms": dur, "reason": step_reason})
        if steps and not plan_reason:
            plan_reason = steps[0].get("reason") or ""
        plan["steps"] = steps
        plan["reason"] = plan_reason
        plan["decline"] = decline
        return plan

    def _set_pending_plan(self, steps: List[Dict[str, Any]], plan_reason: str, source: str) -> bool:
        self.pending_actions.clear()
        valid_entries: List[Dict[str, Any]] = []
        plan_reason = str(plan_reason or "").strip()
        for idx, step in enumerate(steps, start=1):
            if not isinstance(step, dict):
                continue
            name = str(step.get("name") or "").upper()
            if name not in ACTIONS:
                continue
            try:
                dur = int(step.get("duration_ms", 120))
            except Exception:
                dur = 120
            dur = max(40, min(5000, dur))
            step_reason = str(step.get("reason") or "").strip() or plan_reason or "cognitive plan"
            valid_entries.append({
                "name": name,
                "duration_ms": dur,
                "reason": step_reason,
                "plan_reason": plan_reason,
                "source": source,
                "index": idx,
            })
        if not valid_entries:
            self._current_plan_meta = None
            return False
        total = len(valid_entries)
        for idx, entry in enumerate(valid_entries, start=1):
            entry["index"] = idx
            entry["total"] = total
        for entry in valid_entries:
            self.pending_actions.append(entry)
        summary = " -> ".join([f"{e['name']}({e['duration_ms']}ms)" for e in valid_entries])
        context_reason = plan_reason or valid_entries[0].get("reason") or "cognitive plan"
        self._current_plan_meta = {
            "total": total,
            "reason": context_reason,
            "source": source,
            "summary": summary,
        }
        self.log.emit(f"{ts()} → queued plan ({total} steps) — {context_reason}: {summary}")
        self.status.emit(f"Plan queued ({total} steps): {summary}")
        return True

    def _plan_remaining_summary(self, limit: int = 5) -> str:
        if not self.pending_actions:
            return ""
        preview = list(self.pending_actions)[:limit]
        text = " -> ".join([f"{step['name']}({step['duration_ms']}ms)" for step in preview])
        if len(self.pending_actions) > limit:
            text += " → …"
        return text

    def _try_queue_naming_macro(
        self,
        state_key: Optional[str],
        screen_state: Optional[Dict[str, Any]],
        *,
        target: Optional[str] = None,
    ) -> bool:
        if not state_key or not isinstance(screen_state, dict):
            return False
        layout_sig = screen_state.get("grid_signature")
        macro = self.naming_macros.preferred_macro(
            state_key,
            target_name=target,
            layout_signature=layout_sig,
        )
        if not macro:
            return False
        macro_layout = macro.get("layout_signature")
        if layout_sig and macro_layout and macro_layout != layout_sig:
            self.log.emit(
                f"{ts()} naming macro skipped: layout mismatch ({macro_layout} != {layout_sig}); queuing exploration"
            )
            self._queue_exploration_plan(reason="naming_layout_mismatch")
            return False
        actions = macro.get("actions") if isinstance(macro, dict) else None
        if not isinstance(actions, list):
            return False
        confidence = float(macro.get("confidence", 0.0) or 0.0)
        pace = 1.0 - (confidence - 0.5) * 0.4
        pace = max(0.7, min(1.3, pace))
        reason = f"naming_macro:{macro.get('target') or target or 'UNKNOWN'}"
        steps: List[Dict[str, Any]] = []
        for entry in actions:
            if not isinstance(entry, dict):
                continue
            name = str(entry.get("name") or "").upper()
            if name not in ACTIONS:
                continue
            try:
                dur = int(entry.get("duration_ms", 120))
            except Exception:
                dur = 120
            dur = int(max(40, min(4000, round(dur * pace))))
            steps.append({"name": name, "duration_ms": dur, "reason": reason})
        if not steps:
            return False
        queued = self._set_pending_plan(steps, reason, "naming_macro")
        if queued:
            self.log.emit(
                f"{ts()} → queued naming macro ({len(steps)} steps, conf={confidence:.2f}, pace={pace:.2f})"
            )
        return queued

    def _multi_phase_cognition(self, observation: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        max_phases = 1
        if self.no_change_streak >= 2:
            max_phases = 2
        if self.no_change_streak >= 4:
            max_phases = 3
        phases: List[Dict[str, Any]] = []
        result: Optional[Dict[str, Any]] = None
        for phase in range(1, max_phases + 1):
            enriched_obs = dict(observation)
            enriched_obs["cognitive_phase"] = phase
            enriched_obs["prior_phase_summaries"] = phases
            enriched_obs["stagnation_metrics"] = {
                "no_change_streak": self.no_change_streak,
                "fail_parse_streak": self.fail_parse_streak,
                "pending_actions": len(self.pending_actions),
            }
            cycle = self._run_cognitive_cycle(enriched_obs)
            if not cycle:
                break
            cycle_plan = cycle.get("plan") if isinstance(cycle, dict) else None
            plan_dict = cycle_plan if isinstance(cycle_plan, dict) else {}
            step_count = len(plan_dict.get("steps", [])) if isinstance(plan_dict.get("steps"), list) else 0
            plan_state = "queued" if cycle.get("plan_queued") else "steps" if step_count else "decline" if plan_dict.get("decline") else "empty"
            self.timeline_buf.append(
                f"{ts()} think:{self._reasoning_tag} phase {phase} → {plan_state}"
            )
            snapshot = {
                "phase": phase,
                "narrative": cycle.get("narrative"),
                "plan_state": plan_state,
                "step_count": step_count,
            }
            phases.append(snapshot)
            try:
                self._last_phase_cycles.append({"ts": ts(), **snapshot})
            except Exception:
                pass
            result = cycle
            if cycle.get("plan_queued") or step_count:
                break
        return result

    def _run_cognitive_cycle(self, observation: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        operator_bundle = observation.get("operator_bundle") if isinstance(observation, dict) else None
        if isinstance(operator_bundle, dict):
            advisories = operator_bundle.get("advisories")
            if advisories and "operator_feedback" not in observation:
                feedback_lines = self._synthesize_operator_feedback(advisories)
                if feedback_lines:
                    observation["operator_feedback"] = feedback_lines
        system_prompt = (
            "You are the cognitive control loop for a Game Boy agent. "
            "Use the observation to maintain a task list, narrate intent, and select an ordered plan of controller steps. "
            "Respond with strict JSON containing keys tasks (list), narrative (string), and action (object). "
            "Each task must include goal, status, needs, and evidence. "
            "The action object must include reason, decline (bool), and steps (ordered array of step objects with name and duration_ms)."
        )
        last_narrative = self.narrative_history[-1] if self.narrative_history else ""
        obs_text = json.dumps(observation, indent=2, ensure_ascii=False)
        prompt = (
            f"Assistant:\nPrevious self-narrative: {last_narrative or 'None yet.'}\n\n"
            "User:\nHere is the latest observation for the VirtualGameBoy agent. "
            "Update tasks and choose the next action.\n"
            f"Observation:\n{obs_text}\n\n"
            "Assistant:\nReturn a JSON object with keys tasks, narrative, action."
        )
        model_name = self.current_reasoning_model or DEFAULT_PREFS["reasoning_model"]
        try:
            raw = ollama_generate(model_name, prompt, system=system_prompt)
        except Exception as e:
            self._record_failure(f"ollama error: {e}")
            self.log.emit(f"Cognitive cycle error ({model_name}): {e}")
            return None
        if not raw:
            self._record_failure("empty response from cognitive model")
            return None
        try:
            snippet = raw[raw.find("{") : raw.rfind("}") + 1]
            payload = json.loads(snippet)
        except Exception as e:
            self._record_failure(f"json parse failure: {e}")
            self.log.emit(f"Cognitive JSON parse failure: {e}; raw={raw[:160]}...")
            return None
        tasks_payload = payload.get("tasks") if isinstance(payload, dict) else None
        tasks_changed = False
        if isinstance(tasks_payload, list):
            tasks_changed = self.task_manager.update_from_model(tasks_payload)
            if tasks_changed:
                self.task_manager.persist_snapshot()
        if tasks_payload is not None:
            self.tasksUpdated.emit(self.task_manager.to_serializable())
        narrative = str(payload.get("narrative", "")) if isinstance(payload, dict) else ""
        if narrative.strip():
            narrative_clean = narrative.strip()
            self.narrative_history.append(narrative_clean)
            self.narrativeReady.emit(narrative_clean)
        action_payload = payload.get("action") if isinstance(payload, dict) else None
        plan = self._normalize_action_plan(action_payload)
        plan_queued = False
        if plan.get("decline"):
            self.pending_actions.clear()
            self._current_plan_meta = None
        elif plan.get("steps"):
            plan_queued = self._set_pending_plan(plan["steps"], plan.get("reason", ""), self._reasoning_tag)
        result = {
            "action": action_payload if isinstance(action_payload, dict) else None,
            "narrative": narrative.strip(),
            "plan": plan,
            "plan_queued": plan_queued,
        }
        return result

    def _press_and_check(
        self,
        action: str,
        dur_ms: int,
        ph_before: str,
        frame_before: Optional[np.ndarray],
    ) -> Tuple[bool, str, Dict[str, Any], Optional[Tuple[bytes, int, int]], float]:
        start_time = time.time()
        self._send_action(action, dur_ms, f"trial:{action}")
        time.sleep(0.10)
        latest = self._grab_latest()
        elapsed = time.time() - start_time
        if not latest:
            return (
                False,
                ph_before,
                self._estimate_motion(frame_before, None),
                None,
                elapsed,
            )
        rgb2, w2, h2 = latest
        ph2 = pHash64(Image.frombytes("RGB",(w2,h2),rgb2))
        changed = hamming_hex(ph_before, ph2) >= 8
        after_arr = np.frombuffer(rgb2, dtype=np.uint8).reshape((h2, w2, 3))
        movement = self._estimate_motion(frame_before, after_arr)
        return (changed, ph2, movement, latest, elapsed)

    def _probe_burst(
        self,
        ph: str,
        state: str,
        frame_before: Optional[np.ndarray],
    ) -> Tuple[
        bool,
        str,
        str,
        int,
        Optional[Dict[str, Any]],
        Optional[Tuple[bytes, int, int]],
        Optional[Dict[str, Any]],
    ]:
        """Try every key in PROBE_ORDER quickly, early-stop on change."""
        baseline = frame_before
        for act in self.PROBE_ORDER:
            base_dur = 150 if act == "START" else 120
            hold_ms, repeat_delay, verification_delay, profile = self._resolve_cadence(state, act, base_dur)
            changed, new_ph, movement, after_frame, elapsed = self._press_and_check(
                act,
                hold_ms,
                ph,
                baseline,
            )
            mode_label = self._screen_mode_label(self.last_screen_state)
            self.brain.record_result(
                state,
                act,
                changed,
                movement,
                elapsed,
                screen_state=mode_label,
            )
            if new_ph:
                try:
                    self.brain.note_similarity_feedback(state, new_ph, changed)
                except Exception:
                    pass
            self._drain_similarity_events()
            cadence_note = f"hold={hold_ms}ms"
            if profile:
                cadence_note += f" conf={profile.get('confidence', 0.0)}"
            self.log.emit(
                f"{ts()} → {act} ({hold_ms}ms) — Probe after parse failure: {act} [{cadence_note}]\n"
                f"{ts()} → probe {act}: {'CHANGED' if changed else 'no change'}"
            )
            if changed:
                return (
                    True,
                    new_ph,
                    act,
                    hold_ms,
                    movement,
                    after_frame,
                    {
                        "repeat_delay": repeat_delay,
                        "verification_delay": verification_delay,
                        "profile": profile,
                    },
                )
            if after_frame is not None:
                rgb_after, w_after, h_after = after_frame
                baseline = np.frombuffer(rgb_after, dtype=np.uint8).reshape((h_after, w_after, 3))
            if not changed and verification_delay > 0:
                time.sleep(min(verification_delay, 0.5))
            elif repeat_delay > 0.15:
                time.sleep(min(max(0.0, repeat_delay - 0.1), 0.6))
        return False, ph, "", 0, None, None, None

    def _timeline_note(self, txt: str):
        self.timeline_buf.append(txt)
        if len(self.timeline_buf) > 24:
            self.timeline_buf.pop(0)

    def _annotate_cooldown(
        self,
        action: str,
        until: float,
        source: str,
        reason: str,
        *,
        watchdog: bool = False,
    ) -> None:
        if not action:
            return
        note = {
            "ts": ts(),
            "until": float(until),
            "source": str(source),
            "reason": str(reason),
            "watchdog": bool(watchdog),
        }
        self._cooldown_annotations[action] = note

    def _drain_similarity_events(self) -> None:
        for event in self.brain.drain_threshold_events():
            state = str(event.get("state") or "")
            threshold = event.get("threshold", {}) if isinstance(event.get("threshold"), dict) else {}
            old = threshold.get("old")
            new = threshold.get("new")
            label = state[:8] if state else "?"
            reason = str(event.get("event") or "update")
            msg = f"{ts()} → Brain threshold[{label}] {old}→{new} ({reason})"
            self.log.emit(msg)
            try:
                self.status.emit(f"Brain similarity[{label}] {old}→{new} ({reason})")
            except Exception:
                pass
        for event in self.ks.drain_threshold_events():
            cluster = str(event.get("cluster") or "")
            threshold = event.get("threshold", {}) if isinstance(event.get("threshold"), dict) else {}
            old = threshold.get("old")
            new = threshold.get("new")
            label = cluster[:8] if cluster else "?"
            reason = str(event.get("event") or "update")
            msg = f"{ts()} → Knowledge threshold[{label}] {old}→{new} ({reason})"
            self.log.emit(msg)
            try:
                self.status.emit(f"Knowledge similarity[{label}] {old}→{new} ({reason})")
            except Exception:
                pass

    def _update_distinct_digest_from_array(self, frame: Optional[np.ndarray]) -> None:
        if frame is None:
            return
        digest = self._frame_digest(frame)
        if digest:
            self._last_distinct_digest = digest
            self._last_distinct_digest_ts = time.time()

    def _update_distinct_digest_from_tuple(
        self, frame_tuple: Optional[Tuple[bytes, int, int]]
    ) -> None:
        if frame_tuple is None:
            return
        try:
            rgb_bytes, width, height = frame_tuple
            arr = np.frombuffer(rgb_bytes, dtype=np.uint8).reshape((height, width, 3))
        except Exception:
            return
        self._update_distinct_digest_from_array(arr)

    # ---- user teaching --------------------------------------------------------
    def user_teach(self, act: str):
        """Called from UI thread (non-blocking). Spawn a tiny worker that records reward for user's action."""
        th.Thread(target=self._teach_from_user_worker, args=(act,), daemon=True).start()

    def _teach_from_user_worker(self, act: str):
        latest = self._grab_latest()
        if not latest: return
        rgb, w, h = latest
        frame_before = np.frombuffer(rgb, dtype=np.uint8).reshape((h, w, 3))
        ph_before = pHash64(Image.frombytes("RGB",(w,h),rgb))
        state = self.brain.get_state(ph_before)
        time.sleep(0.25)  # allow effect to appear
        latest2 = self._grab_latest()
        if not latest2: return
        rgb2, w2, h2 = latest2
        frame_after = np.frombuffer(rgb2, dtype=np.uint8).reshape((h2, w2, 3))
        ph_after = pHash64(Image.frombytes("RGB",(w2,h2),rgb2))
        changed = hamming_hex(ph_before, ph_after) >= 8
        movement = self._estimate_motion(frame_before, frame_after)
        mode_label = self._screen_mode_label(self.last_screen_state)
        self.brain.record_result(
            state,
            act.upper(),
            changed,
            movement,
            0.25,
            screen_state=mode_label,
        )
        try:
            self.brain.note_similarity_feedback(state, ph_after, changed)
        except Exception:
            pass
        self._drain_similarity_events()
        motion_mag = movement.get("magnitude", 0.0) if isinstance(movement, dict) else 0.0
        self.log.emit(
            f"{ts()} → USER_INPUT {act.upper()} — {'CHANGED' if changed else 'no change'} | motion {motion_mag:.2f} (state={state[:8]})"
        )
        # store knowledge snapshot
        try:
            img = Image.frombytes("RGB",(w2,h2),rgb2)
            self.ks.add(img, {"src":"user_teach"}, action=act.upper(), changed=changed, movement=movement)
            self._drain_similarity_events()
        except Exception: pass

    # ---- summarizer -----------------------------------------------------------
    def _maybe_summarize(self, model: str, timeline_prompt: str):
        if len(self.timeline_buf) < 8: return
        try:
            text = "\n".join(self.timeline_buf[-24:])
            resp = ollama_generate(model, f"{timeline_prompt}\n\nEvents:\n{text}\n\nSummary + plan:")
            out = AGENT_LOGS / f"summary_{ts()}.txt"
            out.write_text(resp, encoding="utf-8")
            self.log.emit(f"{ts()} → timeline summary saved → {out.name}")
        except Exception as e:
            self.log.emit(f"Timeline summary error: {e}")

    def run(self):
        prefs = self.app.prefs
        vision_model = str(prefs.get("vision_model") or prefs.get("agent_model") or DEFAULT_PREFS["vision_model"])
        reasoning_model = str(prefs.get("reasoning_model") or prefs.get("agent_model") or DEFAULT_PREFS["reasoning_model"])
        self.current_vision_model = vision_model
        self.current_reasoning_model = reasoning_model
        self._reasoning_label = reasoning_model
        self._reasoning_tag = self._model_tag(reasoning_model)
        interval = int(prefs.get("agent_interval_ms",350))
        allow_saveload = bool(prefs.get("agent_allow_saveload", False))
        enable_ocr = bool(prefs.get("agent_enable_ocr", False))
        ocr_model = str(prefs.get("ocr_model",""))
        decision_prompt = prefs.get("prompts", DEFAULT_PROMPTS).get("decision", DEFAULT_PROMPTS["decision"])
        ocr_prompt = prefs.get("prompts", DEFAULT_PROMPTS).get("ocr", DEFAULT_PROMPTS["ocr"])
        caption_prompt = prefs.get("prompts", DEFAULT_PROMPTS).get("caption", DEFAULT_PROMPTS["caption"])
        timeline_prompt = prefs.get("prompts", DEFAULT_PROMPTS).get("timeline", DEFAULT_PROMPTS["timeline"])
        summary_model = str(prefs.get("summary_model","gemma3:4b"))
        try:
            stasis_timeout = float(prefs.get("agent_stasis_timeout_s", 3.0))
        except Exception:
            stasis_timeout = 3.0
        if not math.isfinite(stasis_timeout):
            stasis_timeout = 3.0
        stasis_timeout = max(0.5, stasis_timeout)
        self._watchdog_timeout = stasis_timeout

        # Log keybinds
        kb = prefs.get("keybinds", {})
        try:
            from PyQt6.QtGui import QKeySequence
            def _klabel(code, keypad):
                txt = QKeySequence(int(code)).toString() or f"Key({code})"
                return f"{'Numpad ' if keypad and txt.isdigit() else ''}{txt}"
        except Exception:
            def _klabel(code, keypad): return f"Key({code})"
        kb_text = ", ".join([f"{k}={_klabel(v.get('key'), v.get('keypad'))}" for k,v in kb.items() if isinstance(v, dict)])
        self.log.emit(f"{ts()} → keybinds: {kb_text}")
        self.status.emit(f"Agent running (vision: {vision_model}, reasoning: {reasoning_model})")

        # Global cooldowns
        global_cool: Dict[str, float] = {a: 0.0 for a in LEARNABLE}
        # Push any restored tasks to UI
        self.tasksUpdated.emit(self.task_manager.to_serializable())
        if self.narrative_history:
            self.narrativeReady.emit(self.narrative_history[-1])

        while not self.stop_flag:
            t0 = time.perf_counter()
            now = time.time()
            expired = [
                act
                for act, note in list(self._cooldown_annotations.items())
                if note.get("until") and now >= float(note.get("until"))
            ]
            for act in expired:
                self._cooldown_annotations.pop(act, None)
            latest = self._grab_latest()
            if not latest:
                self.log.emit("No frame.")
                time.sleep(interval/1000.0); continue

            rgb, w, h = latest
            frame_arr = np.frombuffer(rgb, dtype=np.uint8).reshape((h, w, 3))
            movement = self._estimate_motion(self._prev_frame_array, frame_arr)
            self._prev_frame_array = frame_arr.copy()
            self._last_motion_estimate = movement if isinstance(movement, dict) else {}
            frame_digest = self._frame_digest(frame_arr)
            now = time.time()
            if self._last_distinct_digest is None and frame_digest:
                self._last_distinct_digest = frame_digest
                self._last_distinct_digest_ts = now
            elif frame_digest and frame_digest != self._last_distinct_digest:
                self._last_distinct_digest = frame_digest
                self._last_distinct_digest_ts = now
            if self._last_distinct_digest_ts == 0.0:
                self._last_distinct_digest_ts = now
            movement_mag = 0.0
            if isinstance(movement, dict):
                try:
                    movement_mag = float(movement.get("magnitude", 0.0) or 0.0)
                except Exception:
                    movement_mag = 0.0
            if movement_mag >= 0.35:
                self._last_distinct_digest_ts = now
            if movement_mag >= 0.5:
                self._timeline_note(
                    f"{ts()} movement dx={movement.get('dx', 0.0):.1f} dy={movement.get('dy', 0.0):.1f} mag={movement.get('magnitude', 0.0):.2f}"
                )
            img = Image.frombytes("RGB", (w, h), rgb)
            ph = pHash64(img)
            state = self.brain.get_state(ph)
            self.brain.data[state]["last_seen"] = time.time()

            # Operator pipeline & shared observation data
            b64 = self._b64_png(rgb, w, h)
            meta = {"rom": self.app.prefs.get("last_rom"), "profile": self.app.prefs.get("profile")}
            bundle = self._collect_operator_bundle(
                image=img,
                frame_array=frame_arr,
                base64_image=b64,
                state=state,
                phash=ph,
                frame_digest=frame_digest,
                movement=movement if isinstance(movement, dict) else {},
                allow_saveload=allow_saveload,
                meta=meta,
                ocr_enabled=bool(enable_ocr and ocr_model),
                ocr_model=str(ocr_model or ""),
                ocr_prompt=ocr_prompt,
                vision_model=vision_model,
                caption_prompt=caption_prompt,
            )
            bundle_dict = bundle.to_dict()
            ocr_result = bundle.results.get("ocr_interpreter") if isinstance(bundle.results, dict) else None
            ocr_payload = ocr_result.payload if isinstance(ocr_result, OperatorResult) else {}
            ocr_text = ocr_payload.get("ocr_text") if isinstance(ocr_payload, dict) else None
            caption = ocr_payload.get("caption") if isinstance(ocr_payload, dict) else None
            fallback_summary = ocr_payload.get("fallback_summary") if isinstance(ocr_payload, dict) else None
            fallback_raw = ocr_payload.get("fallback_raw") if isinstance(ocr_payload, dict) else None
            sprite_result = bundle.results.get("sprite_tracker") if isinstance(bundle.results, dict) else None
            sprite_payload = sprite_result.payload if isinstance(sprite_result, OperatorResult) else {}
            decomposition = sprite_payload.get("decomposition") if isinstance(sprite_payload, dict) else None
            if not isinstance(decomposition, dict):
                decomposition = {"frame_size": (w, h), "regions": [], "stats": {}}
            region_pack = sprite_payload.get("regions") if isinstance(sprite_payload, dict) else []
            if not isinstance(region_pack, list):
                region_pack = []
            region_matches = sprite_payload.get("matches") if isinstance(sprite_payload, dict) else []
            if not isinstance(region_matches, list):
                region_matches = []
            self._last_sprite_payload = sprite_payload if isinstance(sprite_payload, dict) else {}
            visual_payload = {"decomposition": decomposition, "matches": region_matches}
            similarity_result = bundle.results.get("similarity_retriever") if isinstance(bundle.results, dict) else None
            similarity_payload = (
                similarity_result.payload
                if isinstance(similarity_result, OperatorResult) and isinstance(similarity_result.payload, dict)
                else None
            )
            ui_result = bundle.results.get("ui_classifier") if isinstance(bundle.results, dict) else None
            screen_state = (
                ui_result.payload.get("screen_state")
                if isinstance(ui_result, OperatorResult) and isinstance(ui_result.payload, dict)
                else None
            )
            policy_result = bundle.results.get("policy_advisor") if isinstance(bundle.results, dict) else None
            policy_payload = (
                policy_result.payload
                if isinstance(policy_result, OperatorResult) and isinstance(policy_result.payload, dict)
                else {}
            )
            if bundle.health.get("failed"):
                self.log.emit(
                    f"{ts()} → operator pipeline degraded (failed={bundle.health['failed']}, conf={bundle.confidence:.2f})"
                )
                self.timeline_buf.append(
                    f"{ts()} operators degraded:{bundle.health['failed']} conf={bundle.confidence:.2f}"
                )

            # Knowledge snapshot (no reward yet)
            try:
                self.ks.add(
                    img,
                    meta,
                    ocr_text=ocr_text,
                    caption=caption,
                    movement=movement,
                    ocr_fallback=fallback_summary,
                    regions=region_pack,
                )
                self._drain_similarity_events()
            except Exception:
                pass
            snippet = {
                "ts": ts(),
                "movement_estimate": movement,
                "operator_confidence": bundle.confidence,
                "operator_health": dict(bundle.health),
            }
            if caption is not None:
                snippet["caption"] = caption
            if ocr_text is not None:
                snippet["ocr"] = ocr_text
            if fallback_summary is not None:
                snippet["ocr_fallback"] = dict(fallback_summary)
            if isinstance(policy_payload, dict) and policy_payload.get("proposal"):
                snippet["policy_proposal"] = dict(policy_payload["proposal"])
            self.knowledge_buf.append(snippet)

            screen_directives = extract_screen_directives(
                ocr_text,
                fallback_summary,
                sensitivity=self.directive_sensitivity,
            )
            screen_changed = self.task_manager.merge_screen_directives(
                screen_directives,
                decay_steps=self.directive_decay_steps,
            )
            if screen_changed:
                self.task_manager.persist_snapshot()
                self.tasksUpdated.emit(self.task_manager.to_serializable())

            observation = self._build_observation_context(
                caption=caption,
                ocr_text=ocr_text,
                ocr_fallback=fallback_summary,
                image=img,
                state=state,
                phash=ph,
                frame_digest=frame_digest,
                allow_saveload=allow_saveload,
                meta=meta,
                decision_prompt=decision_prompt,
                movement_estimate=movement,
                visual=visual_payload,
                memory_override=similarity_payload if isinstance(similarity_payload, dict) else None,
                screen_state_override=screen_state if isinstance(screen_state, dict) else None,
                screen_directives=screen_directives,
            )
            observation["operator_bundle"] = bundle_dict

            now_watchdog = time.time()
            stagnation_elapsed = (
                now_watchdog - self._last_distinct_digest_ts
                if self._last_distinct_digest_ts
                else 0.0
            )
            if (
                self._last_distinct_digest_ts
                and stagnation_elapsed >= self._watchdog_timeout
                and now_watchdog >= self._watchdog_cooldown_until
            ):
                impulse_tag = f"watchdog:{stagnation_elapsed:.1f}s"
                self._watchdog_cooldown_until = now_watchdog + max(1.0, self._watchdog_timeout * 0.5)
                self.timeline_buf.append(f"{ts()} watchdog trigger → {impulse_tag}")
                self.log.emit(
                    f"{ts()} → WATCHDOG impulse (digest stalled {stagnation_elapsed:.2f}s)"
                )
                if self.pending_actions:
                    self.pending_actions.clear()
                    self._current_plan_meta = None
                if self._queue_exploration_plan(reason=impulse_tag):
                    self.timeline_buf.append(
                        f"{ts()} watchdog queued exploration plan — {impulse_tag}"
                    )
                    try:
                        self.status.emit(f"Watchdog exploration plan queued ({impulse_tag})")
                    except Exception:
                        pass
                    continue
                before_digest = frame_digest
                (
                    changed,
                    ph2,
                    impulse_action,
                    impulse_dur,
                    impulse_movement,
                    impulse_after,
                    impulse_cadence,
                ) = self._probe_burst(
                    ph, state, frame_arr
                )
                if impulse_action:
                    self._register_transition(
                        action=impulse_action,
                        duration_ms=impulse_dur or 0,
                        changed=changed,
                        movement=impulse_movement,
                        source="watchdog",
                        before_digest=before_digest,
                        after_frame=impulse_after,
                        state_key=state,
                    )
                motion_mag = 0.0
                if isinstance(impulse_movement, dict):
                    try:
                        motion_mag = float(impulse_movement.get("magnitude", 0.0) or 0.0)
                    except Exception:
                        motion_mag = 0.0
                if impulse_action:
                    repeat_delay = 0.5 if changed else 1.2
                    if isinstance(impulse_cadence, dict):
                        try:
                            repeat_delay = float(
                                impulse_cadence.get("repeat_delay", repeat_delay * (0.6 if changed else 1.0))
                            )
                            if changed:
                                repeat_delay = max(0.2, repeat_delay * 0.6)
                        except Exception:
                            repeat_delay = 0.5 if changed else 1.2
                    until = time.time() + repeat_delay
                    global_cool[impulse_action] = until
                    self._annotate_cooldown(
                        impulse_action,
                        until,
                        "watchdog",
                        f"{impulse_tag} probe",
                        watchdog=True,
                    )
                    try:
                        if impulse_after is not None:
                            rgb_after, w_after, h_after = impulse_after
                            post_img = Image.frombytes("RGB", (w_after, h_after), rgb_after)
                        else:
                            post_img = Image.frombytes("RGB", (w, h), rgb)
                        self.ks.add(
                            post_img,
                            meta,
                            action=impulse_action,
                            changed=changed,
                            movement=impulse_movement,
                        )
                        self._drain_similarity_events()
                    except Exception:
                        pass
                    self.timeline_buf.append(
                        f"{ts()} watchdog probe:{impulse_action} {'OK' if changed else '…'} | motion {motion_mag:.2f}"
                    )
                    profile_note = ""
                    if isinstance(impulse_cadence, dict):
                        prof = impulse_cadence.get("profile")
                        if isinstance(prof, dict):
                            profile_note = f" conf={prof.get('confidence', 0.0)}"
                    self.log.emit(
                        f"{ts()} → {impulse_action} ({impulse_dur}ms) — watchdog impulse {impulse_tag}{profile_note} — {'CHANGED' if changed else 'no change'} | motion {motion_mag:.2f} (state={state[:8]})"
                    )
                    if impulse_after is not None:
                        self._update_distinct_digest_from_tuple(impulse_after)
                    self.last_action = impulse_action
                    if changed:
                        self.last_phash = ph2
                        self.no_change_streak = 0
                    else:
                        self.no_change_streak += 1
                        if isinstance(impulse_cadence, dict):
                            try:
                                verify = float(impulse_cadence.get("verification_delay", 0.0))
                            except Exception:
                                verify = 0.0
                            if verify > 0.0:
                                time.sleep(min(verify, 0.5))
                        self._record_failure(f"no change after watchdog {impulse_action}")
                else:
                    self.timeline_buf.append(f"{ts()} watchdog probe exhausted")
                    self.no_change_streak += 1
                self._record_memory_reflection(
                    impulse_action or "NONE",
                    changed,
                    "watchdog",
                    impulse_tag,
                )
                continue

            observation = self._build_observation_context(
                caption=caption,
                ocr_text=ocr_text,
                ocr_fallback=fallback_summary,
                image=img,
                state=state,
                phash=ph,
                frame_digest=frame_digest,
                allow_saveload=allow_saveload,
                meta=meta,
                decision_prompt=decision_prompt,
                movement_estimate=movement,
                visual=visual_payload,
                memory_override=similarity_payload if isinstance(similarity_payload, dict) else None,
                screen_state_override=screen_state if isinstance(screen_state, dict) else None,
                screen_directives=screen_directives,
            )
            cycle = None
            if not self.pending_actions and isinstance(observation, dict):
                frame_info = observation.get("frame") if isinstance(observation.get("frame"), dict) else {}
                naming_state = frame_info.get("screen_state") if isinstance(frame_info, dict) else None
                if isinstance(naming_state, dict) and naming_state.get("mode") == "naming":
                    target_hint = self._infer_naming_target()
                    if self._try_queue_naming_macro(state, naming_state, target=target_hint):
                        continue
            if not self.pending_actions:
                cycle = self._multi_phase_cognition(observation)

            plan_info: Dict[str, Any] = {}
            action_payload = None
            plan_reason = ""
            if cycle is None and not self.pending_actions:
                self.fail_parse_streak += 1
                self.log.emit(f"{ts()} → NONE — Cognitive cycle unavailable; initiating probe")
                before_digest = frame_digest
                (
                    changed,
                    ph2,
                    probe_act,
                    probe_dur,
                    probe_movement,
                    probe_after,
                    probe_cadence,
                ) = self._probe_burst(ph, state, frame_arr)
                action_label = probe_act or "NONE"
                self._record_memory_reflection(action_label, changed, "probe_burst", "probe after cognitive failure")
                if probe_act:
                    self._register_transition(
                        action=probe_act,
                        duration_ms=probe_dur or 0,
                        changed=changed,
                        movement=probe_movement,
                        source="probe",
                        before_digest=before_digest,
                        after_frame=probe_after,
                        state_key=state,
                    )
                if changed and probe_act:
                    self.no_change_streak = 0
                    self.timeline_buf.append(f"{ts()} changed via probe:{probe_act}")
                    try:
                        if probe_after is not None:
                            rgb_after, w_after, h_after = probe_after
                            post_img = Image.frombytes("RGB", (w_after, h_after), rgb_after)
                        else:
                            post_img = Image.frombytes("RGB", (w, h), rgb)
                        self.ks.add(post_img, meta, action=probe_act, changed=True, movement=probe_movement)
                        self._drain_similarity_events()
                    except Exception:
                        pass
                    repeat_delay = 0.5
                    if isinstance(probe_cadence, dict):
                        try:
                            repeat_delay = float(probe_cadence.get("repeat_delay", repeat_delay))
                            repeat_delay = max(0.2, repeat_delay * 0.6)
                        except Exception:
                            repeat_delay = 0.5
                    until = time.time() + repeat_delay
                    global_cool[probe_act] = until
                    self._annotate_cooldown(
                        probe_act,
                        until,
                        "probe",
                        "probe after cognitive failure",
                        watchdog=False,
                    )
                    self.last_phash = ph2
                    if probe_after is not None:
                        self._update_distinct_digest_from_tuple(probe_after)
                else:
                    self.no_change_streak += 1
                    if isinstance(probe_cadence, dict):
                        try:
                            verify = float(probe_cadence.get("verification_delay", 0.0))
                        except Exception:
                            verify = 0.0
                        if verify > 0.0:
                            time.sleep(min(verify, 0.6))
                continue

            if cycle is not None:
                self.fail_parse_streak = 0
                narrative = (cycle.get("narrative") or "") if isinstance(cycle, dict) else ""
                if narrative:
                    entry = f"{ts()} [narrative] {narrative}"
                    self.timeline_buf.append(entry)
                    self.log.emit(entry)
                if isinstance(cycle, dict):
                    action_payload = cycle.get("action")
                    plan_info = cycle.get("plan") or {}
                    plan_reason = str(plan_info.get("reason") or "").strip()

            if not self.pending_actions and self._pending_mismatch_escalation:
                if self._queue_exploration_plan(reason=self._pending_mismatch_escalation):
                    self.log.emit(f"{ts()} → queued exploration due to {self._pending_mismatch_escalation}")
                self._pending_mismatch_escalation = None

            if not self.pending_actions and self.no_change_streak >= 2:
                self._queue_exploration_plan(reason=f"streak:{self.no_change_streak}|{state[:6]}")

            if not self.pending_actions:
                self.log.emit(f"{ts()} → NONE — {self._reasoning_label} deferred; using bandit fallback")
                fail_reason = plan_reason or (str(action_payload.get("reason")) if isinstance(action_payload, dict) else "")
                if plan_info.get("decline"):
                    self._record_failure(f"{self._reasoning_label} declined to act")
                elif fail_reason:
                    self._record_failure(f"{self._reasoning_label} deferred: {fail_reason}")
                else:
                    self._record_failure(f"{self._reasoning_label} deferred action")
                picked_by = ""
                action = "NONE"
                dur = 120
                reason = plan_reason or "bandit fallback"
                screen_state = self.last_screen_state if isinstance(self.last_screen_state, dict) else {}
                mapping_data = self._resolve_mapping_choice(state, screen_state, global_cool)
                mapping_choice = mapping_data.get("choice") if isinstance(mapping_data, dict) else None
                mapping_alternate_infos = (
                    [entry for entry in mapping_data.get("alternates", []) if isinstance(entry, dict)]
                    if isinstance(mapping_data, dict)
                    else []
                )
                mapping_confidence = 0.0
                mapping_used = False
                if mapping_choice:
                    candidate = str(mapping_choice.get("action") or "").upper()
                    if candidate in ACTIONS and candidate != "NONE":
                        try:
                            mapping_confidence = float(mapping_choice.get("confidence") or 0.0)
                        except Exception:
                            mapping_confidence = 0.0
                        action = candidate
                        picked_by = "menu_mapping"
                        reason = f"menu_mapping ({mapping_confidence:.0%})"
                        if action == "START":
                            dur = 160
                        elif action in {"A", "B", "SELECT"}:
                            dur = 140
                        else:
                            dur = 120
                        mapping_used = True
                        alt_preview = ",".join(
                            str(entry.get("action"))
                            for entry in mapping_alternate_infos
                            if entry.get("action") and str(entry.get("action")).upper() != action
                        )
                        log_msg = f"{ts()} → mapping select {action} conf={mapping_confidence:.2f}"
                        if alt_preview:
                            log_msg += f" alt={alt_preview}"
                        self.log.emit(log_msg)
                    else:
                        mapping_used = False
                        if not mapping_alternate_infos:
                            self._mapping_retry_plan = None
                else:
                    self._mapping_retry_plan = None
                if not mapping_used:
                    hint = self._human_hint(img, state)
                    if hint:
                        act, hdur, rsn = hint
                        if time.time() >= global_cool.get(act, 0.0):
                            action, dur, reason, picked_by = act, hdur, rsn, "heuristic"
                if action == "NONE":
                    if screen_state.get("mode") == "menu":
                        options = screen_state.get("options") or []
                        cursor_index = screen_state.get("cursor_index")
                        option_label = None
                        if isinstance(cursor_index, int) and 0 <= cursor_index < len(options):
                            option_label = options[cursor_index]
                        normalized_option = self._normalize_token(option_label) if option_label else ""
                        avoid_confirm = {"EXIT", "CANCEL", "BACK", "OPTION", "OPTIONS"}
                        if option_label and normalized_option not in avoid_confirm and time.time() >= global_cool.get("A", 0.0):
                            label_text = str(option_label)
                            action = "A"
                            dur = 140
                            reason = f"menu_classifier: confirm {label_text}"
                            picked_by = "menu_classifier"
                        else:
                            nav: Optional[str] = None
                            if isinstance(cursor_index, int) and len(options) >= 2:
                                if cursor_index >= len(options) - 1:
                                    nav = "UP"
                                else:
                                    nav = "DOWN"
                            elif len(options) >= 2:
                                nav = "DOWN"
                            if nav and time.time() >= global_cool.get(nav, 0.0):
                                action = nav
                                dur = 120
                                reason = f"menu_classifier: cycle {nav.lower()}"
                                picked_by = "menu_classifier"
                if action == "NONE":
                    action, picked_by = self.brain.suggest(state, epsilon=0.18)
                    dur = 120
                    reason = f"{picked_by} via brain"
                if time.time() < global_cool.get(action, 0.0):
                    alt, picked_by = self.brain.suggest(state, epsilon=0.5)
                    action, dur, reason = alt, 120, f"alt({picked_by}) due to cooldown"
                hold_ms, repeat_delay, verification_delay, profile = self._resolve_cadence(state, action, dur)
                mode_label = self._screen_mode_label(screen_state)
                mapping_success_for_brain: List[str] = []
                if isinstance(screen_state, dict):
                    try:
                        mapping_success_for_brain = [
                            act
                            for act in self.menu_mappings.successful_actions(state, screen_state)
                            if act != action
                        ]
                    except Exception:
                        mapping_success_for_brain = []
                fallback_expectation = self._compute_expected_deltas(
                    action,
                    screen_state=screen_state,
                    mapping_summary=mapping_data.get("summary") if isinstance(mapping_data, dict) else None,
                    sprite_payload=self._last_sprite_payload,
                )
                before_digest = self._frame_digest(frame_arr)
                changed, ph2, movement_after, after_frame, elapsed = self._press_and_check(action, hold_ms, ph, frame_arr)
                transition_source = picked_by or "fallback"
                verification = self._verify_action_outcome(
                    action=action,
                    expectation=fallback_expectation,
                    before_screen=screen_state,
                    after_frame=after_frame,
                    movement=movement_after,
                    changed=changed,
                    elapsed=elapsed,
                )
                verification_class = str(verification.get("classification") or "")
                effective_changed = changed and verification_class != "mismatch"
                verification_summary = verification.get("summary") or ""
                verify_label = verification_class or ("match" if effective_changed else "mismatch")
                try:
                    self.status.emit(f"Verify {action}: {verify_label} — {verification_summary}")
                except Exception:
                    pass
                self.log.emit(f"{ts()} → verify {action}: {verify_label} — {verification_summary}")
                self.timeline_buf.append(f"{ts()} verify:{action} {verify_label} | {verification_summary}")
                if verification_class == "mismatch" and not self._pending_mismatch_escalation:
                    self._pending_mismatch_escalation = f"verify:{action}"
                self._register_transition(
                    action=action,
                    duration_ms=hold_ms,
                    changed=changed,
                    movement=movement_after,
                    source=transition_source,
                    before_digest=before_digest,
                    after_frame=after_frame,
                    state_key=state,
                )
                if action in LEARNABLE:
                    self.brain.record_result(
                        state,
                        action,
                        effective_changed,
                        movement_after,
                        elapsed,
                        screen_state=mode_label,
                        alternates=mapping_success_for_brain,
                        verification=verification,
                    )
                    if ph2:
                        try:
                            self.brain.note_similarity_feedback(state, ph2, effective_changed)
                        except Exception:
                            pass
                    self._drain_similarity_events()
                cool_delay = repeat_delay * (0.6 if effective_changed else 1.0)
                if effective_changed:
                    cool_delay = max(0.2, cool_delay)
                else:
                    cool_delay = max(0.6, cool_delay)
                cool_delay = min(2.5, cool_delay)
                cool_until = time.time() + cool_delay
                global_cool[action] = cool_until
                log_reason = f"{reason}"
                motion_mag = movement_after.get("magnitude", 0.0) if isinstance(movement_after, dict) else 0.0
                profile_note = ""
                if profile:
                    profile_note = f" conf={profile.get('confidence', 0.0)}"
                self.log.emit(
                    f"{ts()} → {action} ({hold_ms}ms) — {log_reason}{profile_note} — {verify_label.upper()} | motion {motion_mag:.2f} (state={state[:8]})"
                )
                try:
                    if after_frame is not None:
                        rgb_after, w_after, h_after = after_frame
                        post_img = Image.frombytes("RGB", (w_after, h_after), rgb_after)
                    else:
                        post_img = Image.frombytes("RGB", (w, h), rgb)
                    self.ks.add(post_img, meta, action=action, changed=effective_changed, movement=movement_after)
                    self._drain_similarity_events()
                except Exception:
                    pass
                self._update_distinct_digest_from_tuple(after_frame)
                self.timeline_buf.append(
                    f"{ts()} fallback:{action} {verify_label} | motion {motion_mag:.2f}"
                )
                self.last_phash = ph2
                self.last_action = action
                self._annotate_cooldown(
                    action,
                    cool_until,
                    transition_source,
                    log_reason,
                    watchdog=str(transition_source).startswith("watchdog"),
                )
                self._record_memory_reflection(action, effective_changed, "fallback", log_reason)
                if not effective_changed:
                    self._record_failure(f"verification {verify_label} after fallback {action}")
                    if verification_delay > 0.0:
                        time.sleep(min(verification_delay, 0.6))
                self.no_change_streak = 0 if effective_changed else (self.no_change_streak + 1)
                if effective_changed:
                    self._mapping_retry_plan = None
                continue

            executing_step = self.pending_actions.popleft()
            action = str(executing_step.get("name") or "NONE").upper()
            dur = int(executing_step.get("duration_ms", 120))
            dur = max(40, min(5000, dur))
            step_reason = executing_step.get("reason") or plan_reason or "cognitive plan"
            step_index = int(executing_step.get("index", 1))
            step_total = int(executing_step.get("total", max(1, step_index)))
            remaining_summary = self._plan_remaining_summary()
            hold_ms, repeat_delay, verification_delay, profile = self._resolve_cadence(state, action, dur)
            plan_screen_state = self.last_screen_state if isinstance(self.last_screen_state, dict) else {}
            plan_mode_label = self._screen_mode_label(plan_screen_state)
            plan_mapping_success: List[str] = []
            if isinstance(plan_screen_state, dict):
                try:
                    plan_mapping_success = [
                        act
                        for act in self.menu_mappings.successful_actions(state, plan_screen_state)
                        if act != action
                    ]
                except Exception:
                    plan_mapping_success = []
                try:
                    plan_mapping_summary = self.menu_mappings.summary_for(state, plan_screen_state)
                except Exception:
                    plan_mapping_summary = None
            else:
                plan_mapping_summary = None
            status_msg = (
                f"Executing plan step {step_index}/{step_total}: {action} ({hold_ms}ms"  # actual hold
                + (f" planned {dur}ms" if hold_ms != dur else "")
                + f") — {step_reason}"
                + (f" | Remaining: {remaining_summary}" if remaining_summary else "")
            )
            self.status.emit(status_msg)
            plan_source = executing_step.get("source", self._reasoning_tag)
            if plan_screen_state.get("mode") == "naming":
                if self._naming_active_state != state:
                    self._naming_action_buffer.clear()
                self._naming_active_state = state
                self._naming_action_buffer.append(
                    {
                        "name": action,
                        "duration_ms": hold_ms,
                        "ts": time.time(),
                        "screen_signature": plan_screen_state.get("grid_signature"),
                    }
                )
                if len(self._naming_action_buffer) > 64:
                    self._naming_action_buffer = self._naming_action_buffer[-64:]
            else:
                self._naming_action_buffer.clear()
                self._naming_active_state = None
            before_digest = self._frame_digest(frame_arr)
            step_expectation = self._compute_expected_deltas(
                action,
                screen_state=plan_screen_state,
                mapping_summary=plan_mapping_summary,
                sprite_payload=self._last_sprite_payload,
            )
            executing_step["expectation"] = step_expectation
            changed, ph2, movement_after, after_frame, elapsed = self._press_and_check(action, hold_ms, ph, frame_arr)
            verification = self._verify_action_outcome(
                action=action,
                expectation=step_expectation,
                before_screen=plan_screen_state,
                after_frame=after_frame,
                movement=movement_after,
                changed=changed,
                elapsed=elapsed,
            )
            executing_step["verification"] = verification
            verification_class = str(verification.get("classification") or "")
            effective_changed = changed and verification_class != "mismatch"
            verification_summary = verification.get("summary") or ""
            verify_label = verification_class or ("match" if effective_changed else "mismatch")
            self.timeline_buf.append(f"{ts()} verify:{action} {verify_label} | {verification_summary}")
            self.log.emit(f"{ts()} → verify {action}: {verify_label} — {verification_summary}")
            try:
                self.status.emit(f"Verify {action}: {verify_label} — {verification_summary}")
            except Exception:
                pass
            if verification_class == "mismatch" and not self._pending_mismatch_escalation:
                self._pending_mismatch_escalation = f"verify:{action}"
            self._register_transition(
                action=action,
                duration_ms=hold_ms,
                changed=changed,
                movement=movement_after,
                source=str(plan_source),
                before_digest=before_digest,
                after_frame=after_frame,
                state_key=state,
            )
            if action in LEARNABLE:
                self.brain.record_result(
                    state,
                    action,
                    effective_changed,
                    movement_after,
                    elapsed,
                    screen_state=plan_mode_label,
                    alternates=plan_mapping_success,
                    verification=verification,
                )
                if ph2:
                    try:
                        self.brain.note_similarity_feedback(state, ph2, effective_changed)
                    except Exception:
                        pass
                self._drain_similarity_events()
            plan_reason_from_step = str(executing_step.get("plan_reason") or plan_reason or "")
            is_watchdog_plan = plan_reason_from_step.startswith("watchdog:")
            cool_delay = repeat_delay * (0.6 if effective_changed else 1.0)
            if effective_changed:
                cool_delay = max(0.2, cool_delay)
            else:
                cool_delay = max(0.6, cool_delay)
            cool_delay = min(2.5, cool_delay)
            cool_until = time.time() + cool_delay
            global_cool[action] = cool_until
            log_reason = step_reason or plan_reason_from_step or "cognitive cycle"
            if is_watchdog_plan and step_reason:
                log_reason = f"{plan_reason_from_step} | {step_reason}"
            motion_mag = movement_after.get("magnitude", 0.0) if isinstance(movement_after, dict) else 0.0
            profile_note = ""
            if profile:
                profile_note = f" conf={profile.get('confidence', 0.0)}"
            self.log.emit(
                f"{ts()} → {action} ({hold_ms}ms) — {plan_source} plan step {step_index}/{step_total}: {log_reason}{profile_note} — {verify_label.upper()} | motion {motion_mag:.2f} (state={state[:8]})"
            )
            try:
                if after_frame is not None:
                    rgb_after, w_after, h_after = after_frame
                    post_img = Image.frombytes("RGB", (w_after, h_after), rgb_after)
                else:
                    post_img = Image.frombytes("RGB", (w, h), rgb)
                self.ks.add(post_img, meta, action=action, changed=effective_changed, movement=movement_after)
                self._drain_similarity_events()
            except Exception:
                pass
            self._update_distinct_digest_from_tuple(after_frame)
            self.timeline_buf.append(
                f"{ts()} {self._reasoning_tag}:{action} {verify_label} | motion {motion_mag:.2f}"
            )
            self.last_phash = ph2
            self.last_action = action
            self._annotate_cooldown(
                action,
                cool_until,
                str(plan_source),
                log_reason,
                watchdog=is_watchdog_plan,
            )
            self._record_memory_reflection(action, effective_changed, "cognitive", log_reason)
            if not effective_changed:
                self._record_failure(f"verification {verify_label} after {action}")
                if verification_delay > 0.0:
                    time.sleep(min(verification_delay, 0.6))
            self.no_change_streak = 0 if effective_changed else (self.no_change_streak + 1)

            if not self.pending_actions:
                plan_meta = self._current_plan_meta or {}
                plan_reason = plan_meta.get("reason") if isinstance(plan_meta, dict) else ""
                complete_msg = "Plan complete."
                if plan_reason:
                    complete_msg = f"Plan complete — {plan_reason}"
                self.status.emit(complete_msg)
                self._current_plan_meta = None

            # If stuck too long, force a short probe (but not every frame)
            if self.no_change_streak >= 6:
                self.no_change_streak = 0
                self.log.emit(f"{ts()} → stagnation; short probe")
                before_digest = frame_digest
                ch, ph2, act, dur, move_after, probe_after = self._probe_burst(ph, state, frame_arr)
                if act:
                    self._register_transition(
                        action=act,
                        duration_ms=dur or 0,
                        changed=ch,
                        movement=move_after,
                        source="stagnation_probe",
                        before_digest=before_digest,
                        after_frame=probe_after,
                        state_key=state,
                    )
                if ch and act:
                    self.timeline_buf.append(f"{ts()} unstuck via {act}")
                    self.last_phash = ph2
                    if probe_after is not None:
                        self._update_distinct_digest_from_tuple(probe_after)
                    if act in LEARNABLE:
                        until = time.time() + 0.6
                        global_cool[act] = until
                        self._annotate_cooldown(
                            act,
                            until,
                            "stagnation_probe",
                            "stagnation relief",
                            watchdog=False,
                        )

            # Summarize occasionally
            if len(self.timeline_buf) >= 12 and (time.time() % 30) < 0.5:
                self._maybe_summarize(summary_model, timeline_prompt)

            # pacing
            elapsed = (time.perf_counter()-t0)*1000.0
            wait_ms = max(40, interval - int(elapsed))
            time.sleep(wait_ms/1000.0)

        self.status.emit("Agent stopped.")

    def _send_action(self, act: str, dur_ms: int, reason: str):
        act = act.upper(); dur_ms = int(max(0, dur_ms))
        if act == "NONE":
            self.log.emit(f"{ts()} → NONE — {reason}"); return
        if act in ("SAVE","LOAD","RESET","PAUSE"):
            if act == "SAVE": self.app._save_profile_state()
            elif act == "LOAD": self.app._load_profile_state()
            elif act == "RESET": self.app.reset_emulation()
            elif act == "PAUSE": self.app.start_emulation()
            self.log.emit(f"{ts()} → {act} — {reason}")
            return
        evp = EVENTS_PRESS.get(act); evr = EVENTS_RELEASE.get(act)
        if evp is None or evr is None:
            self.log.emit(f"{ts()} → INVALID {act} — {reason}"); return
        self.uiFlash.emit(act, min(dur_ms, 1200))
        self.app.emuThread.cmd_input_press(evp)
        remaining = dur_ms / 1000.0
        try:
            while remaining > 0:
                if self.stop_flag:
                    break
                chunk = min(0.25, remaining)
                time.sleep(chunk)
                remaining -= chunk
        finally:
            self.app.emuThread.cmd_input_release(evr)
        if remaining > 0:
            self.log.emit(f"{ts()} → {act} hold interrupted early — stop requested")

# ------------------------------ LCD canvas ------------------------------------
class LCDCanvas(QtWidgets.QLabel):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        self.setStyleSheet("background:#0b0b0b;border:2px solid #2e2e2e;")
    def set_frame_bytes(self, rgb_bytes: bytes, w: int, h: int):
        if not rgb_bytes: return
        qimg = QtGui.QImage(rgb_bytes, w, h, QtGui.QImage.Format.Format_RGB888)
        pm = QtGui.QPixmap.fromImage(qimg)
        scaled = pm.scaled(self.size(), QtCore.Qt.AspectRatioMode.KeepAspectRatio, QtCore.Qt.TransformationMode.SmoothTransformation)
        self.setPixmap(scaled)

# ------------------------------ Safe ComboBox ---------------------------------
class SafeComboBox(QtWidgets.QComboBox):
    def __init__(self, is_locked_callable, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._is_locked = is_locked_callable
        self.setFocusPolicy(QtCore.Qt.FocusPolicy.ClickFocus)
    def keyPressEvent(self, e: QtGui.QKeyEvent):
        if self._is_locked() and e.key() in (QC.Qt.Key.Key_Up, QC.Qt.Key.Key_Down, QC.Qt.Key.Key_PageUp, QC.Qt.Key.Key_PageDown, QC.Qt.Key.Key_Home, QC.Qt.Key.Key_End):
            e.ignore(); return
        super().keyPressEvent(e)
    def wheelEvent(self, e: QtGui.QWheelEvent):
        if self._is_locked(): e.ignore(); return
        super().wheelEvent(e)

# ------------------------------ Keybind dialogs -------------------------------
def _key_to_text(keycode: int, keypad: bool=False) -> str:
    base = QtGui.QKeySequence(keycode).toString() or f"Key({keycode})"
    if keypad and base and base.isdigit(): return f"Numpad {base}"
    return base + (" (Keypad)" if keypad and not base.isdigit() else "")

class KeyCaptureDialog(QtWidgets.QDialog):
    def __init__(self, action_name: str, parent=None):
        super().__init__(parent)
        self.setWindowTitle(f"Bind key for {action_name}")
        self.setModal(True); self.setFixedSize(420, 180)
        self.setStyleSheet("QDialog { background-color: #1f1f1f; } QLabel { color: #f2f2f2; } #big{font-size:22px;font-weight:700;} #hint{color:#cfcfcf;}")
        self.captured: Optional[Tuple[int,bool]] = None
        title = QtWidgets.QLabel(f"Press a key for {action_name}"); title.setObjectName("big")
        hint = QtWidgets.QLabel("ESC to cancel. Numpad keys supported."); hint.setObjectName("hint")
        self.live = QtWidgets.QLabel("Waiting…"); self.live.setAlignment(QtCore.Qt.AlignmentFlag.AlignCenter)
        self.live.setStyleSheet("font-size: 16px; color:#8ad; margin-top:8px;")
        lay = QtWidgets.QVBoxLayout(self); lay.addStretch(1); lay.addWidget(title,0,QC.Qt.AlignmentFlag.AlignHCenter)
        lay.addWidget(hint,0,QC.Qt.AlignmentFlag.AlignHCenter); lay.addWidget(self.live); lay.addStretch(1)
    def keyPressEvent(self, e: QtGui.QKeyEvent):
        if e.key() == QC.Qt.Key.Key_Escape: self.captured=None; self.reject(); return
        keycode = int(e.key()); keypad = bool(e.modifiers() & QC.Qt.KeyboardModifier.KeypadModifier)
        self.live.setText(f"Captured: {_key_to_text(keycode, keypad)}"); self.captured=(keycode,keypad)
        QtCore.QTimer.singleShot(120, self.accept)

class KeybindsDialog(QtWidgets.QDialog):
    keybindsChanged = QtCore.pyqtSignal(dict)
    ACTIONS = ["UP","DOWN","LEFT","RIGHT","A","B","START","SELECT"]
    def __init__(self, prefs: dict, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Keybinds"); self.setMinimumSize(560, 380); self.setModal(True)
        self.prefs = prefs; self.kb = dict(prefs.get("keybinds"))
        self.setStyleSheet("QDialog{background:#151515;color:#f5f5f5;} QLabel{color:#f2f2f2;} #hdr{font-weight:700;color:#ffffff;} QPushButton{color:#f2f2f2;background:#2a2a2a;border:1px solid #525252;border-radius:8px;padding:6px 12px;} QPushButton:hover{background:#343434;} QPushButton:pressed{background:#1e1e1e;} QFrame#card{background:#1b1b1b;border:1px solid #2e2e2e;border-radius:10px;}")
        header = QtWidgets.QLabel("Click “Rebind…” next to an action, then press your key."); header.setObjectName("hdr")
        card = QtWidgets.QFrame(); card.setObjectName("card"); grid = QtWidgets.QGridLayout(card)
        grid.addWidget(self._hdr("Action"),0,0); grid.addWidget(self._hdr("Key"),0,1); grid.addWidget(self._hdr(" "),0,2)
        self.rows_widgets={}
        for r, act in enumerate(self.ACTIONS, start=1):
            w_act=QtWidgets.QLabel(act); w_key=QtWidgets.QLabel(self._key_label(act)); w_key.setStyleSheet("font-weight:600; color:#dfe6ff;")
            w_btn=QtWidgets.QPushButton("Rebind…"); w_btn.clicked.connect(lambda _,a=act:self._start_capture(a))
            grid.addWidget(w_act,r,0); grid.addWidget(w_key,r,1); grid.addWidget(w_btn,r,2)
            self.rows_widgets[act]=(w_act,w_key,w_btn)
        btn_reset=QtWidgets.QPushButton("Reset to defaults"); btn_reset.clicked.connect(self._reset_defaults)
        btn_close=QtWidgets.QPushButton("Close"); btn_close.clicked.connect(self.accept)
        buttons=QtWidgets.QHBoxLayout(); buttons.addStretch(1); buttons.addWidget(btn_reset); buttons.addWidget(btn_close)
        lay=QtWidgets.QVBoxLayout(self); lay.addWidget(header); lay.addWidget(card); lay.addStretch(1); lay.addLayout(buttons)
    def _hdr(self, text: str)->QtWidgets.QLabel:
        lab=QtWidgets.QLabel(text); lab.setStyleSheet("font-weight:700;color:#9fb3ff;"); return lab
    def _key_label(self, act: str)->str:
        d=self.kb.get(act, DEFAULT_KEYBINDS[act]); return _key_to_text(int(d["key"]), bool(d.get("keypad", False)))
    def _reset_defaults(self):
        self.kb=dict(DEFAULT_KEYBINDS); self._refresh_labels(); self._save()
    def _refresh_labels(self):
        for act,(_,keylab,_) in self.rows_widgets.items(): keylab.setText(self._key_label(act))
    def _save(self):
        self.prefs["keybinds"] = {k: {"key": int(v["key"]), "keypad": bool(v.get("keypad", False))} for k,v in self.kb.items()}
        save_prefs(self.prefs); self.keybindsChanged.emit(self.prefs["keybinds"])
    def _start_capture(self, action: str):
        cap=KeyCaptureDialog(action,self)
        if cap.exec()==QtWidgets.QDialog.DialogCode.Accepted and cap.captured:
            keycode,keypad=cap.captured; self.kb[action]={"key":int(keycode),"keypad":bool(keypad)}
            self._refresh_labels(); self._save()

# ------------------------------ Main window -----------------------------------
class VirtualGameBoy(QtWidgets.QMainWindow):
    def __init__(self, rom_path: Optional[Path]=None, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Virtual Game Boy — PyQt6 + PyBoy (with Agent)")
        self.setStyleSheet("""
            QMainWindow { background:#0e0e0e; }
            QMenuBar, QMenu, QStatusBar, QLabel, QPushButton { color:#f5f5f5; background:transparent; }
            QStatusBar { background:#151515; }
            QToolBar { background:#111; border:none; spacing:6px; }
            QDockWidget { color:#f5f5f5; }
            QDockWidget::title { background:#1a1a1a; padding:6px; color:#eaeaea; }
        """)
        self.setDockOptions(QtWidgets.QMainWindow.DockOption.AllowNestedDocks |
                            QtWidgets.QMainWindow.DockOption.AllowTabbedDocks |
                            QtWidgets.QMainWindow.DockOption.AnimatedDocks)
        self.resize(1280, 820); self.setMinimumSize(980, 700)
        self.setFocusPolicy(QC.Qt.FocusPolicy.StrongFocus)

        self.prefs = load_prefs()
        self.keybinds = dict(self.prefs.get("keybinds", DEFAULT_KEYBINDS))
        self._muted_before_pause = bool(self.prefs.get("audio_muted", False))
        self._speed = 1.0
        self.prompts = load_prompts()
        self._core_loaded = False
        self._pending_run_after_load = False
        self._current_rom_name: Optional[str] = None

        center = QtWidgets.QWidget(self); self.setCentralWidget(center)
        self.lcd = LCDCanvas(center)
        lay = QtWidgets.QVBoxLayout(center); lay.setContentsMargins(16,16,16,16); lay.addWidget(self.lcd, 1)

        self.status = self.statusBar(); self.status.showMessage("Ready")

        self.audio = AudioEngine(self.prefs);
        if self.audio.enabled: self.audio.start()

        self.emuThread = EmuThread(sample_rate=int(self.prefs.get("audio_rate", 48000)))
        self.emuThread.frameReady.connect(self._on_frame_bytes)
        self.emuThread.audioReady.connect(self.audio.push_frame)
        self.emuThread.statusMsg.connect(self.status.showMessage)
        self.emuThread.coreState.connect(self._on_core_state)
        self.emuThread.start()

        self.frame_deque: "deque[Tuple[bytes,int,int]]" = deque(maxlen=1)
        self._last_frame_png: Optional[bytes] = None

        self.setAcceptDrops(True)

        self._build_menu()
        self._build_toolbar()
        self._build_controls_dock()
        self._build_agent_dock()
        self._bind_shortcuts()
        self._populate_roms()

        rom_cli = rom_path or self._rom_from_prefs() or self._rom_from_combo()
        if rom_cli and Path(rom_cli).exists(): self._load_rom_and_remember(Path(rom_cli))

        self._bridge: Optional[BridgeServer] = None
        self._bridge_thread: Optional[th.Thread] = None
        self._start_http_bridge(int(self.prefs.get("bridge_port", 8787)))

        self.agent_worker: Optional[AgentWorker] = None
        self._latest_memory_snapshot: Dict[str, Any] = {}

    # ---------------- ROM helpers ----------------
    def _rom_from_prefs(self) -> Optional[Path]:
        r = self.prefs.get("last_rom"); 
        if not r: return None
        p = Path(r); 
        if not p.is_absolute(): p = ROMS_DIR / r
        return p
    def _rom_from_combo(self) -> Optional[Path]:
        if not hasattr(self, "rom_combo"): return None
        name = self.rom_combo.currentText().strip()
        if not name or name.startswith("("): return None
        return ROMS_DIR / name
    def _rel_rom(self, p: Path) -> str:
        try: return str(p.resolve().relative_to(ROMS_DIR.resolve()))
        except Exception: return str(p)

    # ---------------- UI ----------------
    def _build_menu(self):
        mbar = self.menuBar()
        filem = mbar.addMenu("&File")
        act_open = filem.addAction("Open ROM…"); act_open.triggered.connect(self.action_open_rom)
        filem.addSeparator(); filem.addAction("Quit", self.close)

        emum = mbar.addMenu("&Emulator")
        emum.addAction("Screenshot (F12)").triggered.connect(self.action_screenshot)
        emum.addSeparator()
        emum.addAction("Save State (F5)").triggered.connect(self.action_save_state)
        emum.addAction("Load State (F9)").triggered.connect(self.action_load_state)
        emum.addSeparator()
        emum.addAction("Quit-Emu (unload core)").triggered.connect(self.quit_emulation)
        emum.addSeparator()
        emum.addAction("Speed Up (+)").triggered.connect(lambda: self.adjust_speed(0.1))
        emum.addAction("Speed Down (−)").triggered.connect(lambda: self.adjust_speed(-0.1))
        emum.addSeparator()
        emum.addAction("Toggle Fullscreen (F11)").triggered.connect(self.toggle_fullscreen)

        self.settings_menu = mbar.addMenu("&Settings")
        self._add_check(self.settings_menu, "Save Game State on Reset-Emu", "save_on_reset")
        self._add_check(self.settings_menu, "Save Game State on Stop-Emu", "save_on_stop")
        self._add_check(self.settings_menu, "Save Game State on Quit-Emu", "save_on_quit")
        self.settings_menu.addSeparator()
        self._add_check(self.settings_menu, "Auto mute audio when paused", "auto_mute_on_pause")
        self._add_check(self.settings_menu, "Learn from user keyboard/gamepad inputs", "learn_from_user_inputs")
        self.settings_menu.addSeparator()

        audio_menu = self.settings_menu.addMenu("Audio Output")
        self.audio_group = QtGui.QActionGroup(self); self.audio_group.setExclusive(True)
        def add_audio_option(text, device_index):
            act=audio_menu.addAction(text); act.setCheckable(True)
            act.setChecked(device_index == self.prefs.get("audio_device", None))
            act.triggered.connect(lambda: self._select_audio_device(device_index))
            self.audio_group.addAction(act)
        add_audio_option("Default (System)", None)
        if self.audio.enabled:
            for idx, name in self.audio.list_outputs(): add_audio_option(f"{idx}: {name}", idx)
        else: audio_menu.addAction("Audio disabled (install 'sounddevice')").setEnabled(False)

        self.act_mute = QtGui.QAction("Mute Audio", self, checkable=True)
        self.act_mute.setChecked(bool(self.prefs.get("audio_muted", False)))
        self.act_mute.toggled.connect(self._toggle_mute); self.settings_menu.addAction(self.act_mute)

        self.settings_menu.addSeparator()
        self.settings_menu.addAction("Keybinds…", self._open_keybinds)
        self.settings_menu.addSeparator()
        vid = self.settings_menu.addMenu("Video")
        self.act_tint = QtGui.QAction("Enable LCD Tint", self, checkable=True)
        self.act_tint.setChecked(bool(self.prefs.get("lcd_tint_enabled", False)))
        self.act_tint.toggled.connect(lambda v: self._set_tint_enabled(v)); vid.addAction(self.act_tint)
        vid.addAction("Choose Tint Color…", self._choose_tint_color)
        vid.addAction("Set Tint Strength…", self._choose_tint_strength)

        self.settings_menu.addSeparator()
        self.settings_menu.addAction("Prompts…", self._open_prompts)

        viewm = mbar.addMenu("&View")
        self.act_controls = viewm.addAction("Show Controls Dock", self._toggle_controls_dock)
        self.act_controls.setCheckable(True); self.act_controls.setChecked(True)
        self.act_agent = viewm.addAction("Show Agent Dock", self._toggle_agent_dock)
        self.act_agent.setCheckable(True); self.act_agent.setChecked(True)
        viewm.addAction("Redock Controls Now", self._force_redock_controls)

        pm = mbar.addMenu("&Profile")
        pm.addAction("New Profile…").triggered.connect(self._new_profile_dialog)
        pm.addSeparator()
        pm.addAction("Open Profiles Folder").triggered.connect(
            lambda: QtGui.QDesktopServices.openUrl(QtCore.QUrl.fromLocalFile(str(PROFILES)))
        )

    def _build_toolbar(self):
        tb = QtWidgets.QToolBar("Main", self); tb.setMovable(False); tb.setIconSize(QtCore.QSize(20,20))
        self.addToolBar(QtCore.Qt.ToolBarArea.TopToolBarArea, tb)

        self.btn_startstop = QtWidgets.QToolButton(self); self._style_start_button(False)
        self.btn_startstop.clicked.connect(self._toggle_start_stop)

        self.btn_reset = QtWidgets.QToolButton(self); self.btn_reset.setText("Reset")
        self.btn_reset.setStyleSheet("QToolButton{background:#3a3a3a;color:#f5f5f5;border:1px solid #666;border-radius:6px;padding:4px 10px;} QToolButton:hover{background:#4a4a4a;} QToolButton:pressed{background:#2a2a2a;}")
        self.btn_reset.clicked.connect(self.reset_emulation)

        self.btn_stop = QtWidgets.QToolButton(self); self.btn_stop.setText("Stop")
        self.btn_stop.setStyleSheet("QToolButton{background:#505050;color:#f5f5f5;border:1px solid #777;border-radius:6px;padding:4px 10px;} QToolButton:hover{background:#5a5a5a;} QToolButton:pressed{background:#3a3a3a;}")
        self.btn_stop.clicked.connect(self.stop_emulation)

        self.profile_combo = SafeComboBox(lambda: self.is_running(), self); self.profile_combo.setMinimumContentsLength(12)
        self._refresh_profiles(); self.profile_combo.currentTextChanged.connect(self._on_profile_selected)
        btn_new = QtWidgets.QToolButton(self); btn_new.setText("New…")
        btn_new.setStyleSheet("QToolButton{background:#2563eb;color:#fff;border:1px solid #1d4ed8;border-radius:6px;padding:4px 10px;} QToolButton:hover{background:#2b6cf6;} QToolButton:pressed{background:#1b4fd1;}")
        btn_new.clicked.connect(self._new_profile_dialog)

        self.rom_combo = SafeComboBox(lambda: self.is_running(), self); self.rom_combo.setMinimumContentsLength(24)
        self.rom_combo.textActivated.connect(self._rom_selected)
        btn_refresh = QtWidgets.QToolButton(self); btn_refresh.setText("Refresh")
        btn_refresh.setStyleSheet("QToolButton{background:#16a34a;color:#fff;border:1px solid #15803d;border-radius:6px;padding:4px 10px;} QToolButton:hover{background:#18b653;} QToolButton:pressed{background:#127a36;}")
        btn_refresh.clicked.connect(self._populate_roms)

        vol_lab = QtWidgets.QLabel("Vol")
        self.vol_slider = QtWidgets.QSlider(QtCore.Qt.Orientation.Horizontal, self)
        self.vol_slider.setRange(0, 300); self.vol_slider.setFixedWidth(120)
        self.vol_slider.setValue(int(self.prefs.get("audio_gain", 1.0) * 100))
        self.vol_slider.valueChanged.connect(lambda v: self._set_volume(v/100.0))

        tb.addWidget(self.btn_startstop); tb.addSeparator()
        tb.addWidget(self.btn_reset); tb.addWidget(self.btn_stop); tb.addSeparator()
        tb.addWidget(QtWidgets.QLabel("Profile: ")); tb.addWidget(self.profile_combo); tb.addWidget(btn_new); tb.addSeparator()
        tb.addWidget(QtWidgets.QLabel("ROM: ")); tb.addWidget(self.rom_combo); tb.addWidget(btn_refresh); tb.addSeparator()
        tb.addWidget(vol_lab); tb.addWidget(self.vol_slider)

    def _build_controls_dock(self):
        dock = QtWidgets.QDockWidget("Controls", self); dock.setObjectName("controlsDock")
        dock.setAllowedAreas(QtCore.Qt.DockWidgetArea.LeftDockWidgetArea | QtCore.Qt.DockWidgetArea.RightDockWidgetArea)
        dock.setFeatures(QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetMovable | QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetFloatable | QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetClosable)
        dock.setStyleSheet("QDockWidget { background:#121212; color:#f5f5f5; } QDockWidget::title { background:#1a1a1a; padding:6px; color:#eaeaea; } QDockWidget QWidget { background:#151515; }")
        w = QtWidgets.QWidget(dock); w.setObjectName("controlContainer"); w.setStyleSheet("#controlContainer{background:#151515;}")
        grid = QtWidgets.QGridLayout(w); grid.setContentsMargins(14,14,14,14); grid.setHorizontalSpacing(22); grid.setVerticalSpacing(18)

        def style_round(diam, border="#7a3a3a"):
            r = diam//2
            return f"QPushButton {{background:#222; color:#eee; border:2px solid {border}; border-radius:{r}px; font-weight:700; min-width:{diam}px; min-height:{diam}px; max-width:{diam}px; max-height:{diam}px;}} QPushButton:hover {{ background:#2d2d2d; }} QPushButton:pressed{{ background:#161616; }}"
        def style_pill(wid,h=28):
            return f"QPushButton {{ background:#222; color:#eaeaea; border:2px solid #666; border-radius:{h//2}px; min-width:{wid}px; max-width:{wid}px; min-height:{h}px; max-height:{h}px; font-weight:600; }} QPushButton:hover {{ background:#2d2d2d; }} QPushButton:pressed{{ background:#161616; }}"
        def style_arrow():
            return "QPushButton { background:#222; color:#eaeaea; border:2px solid #555; border-radius:6px; min-width:44px; max-width:44px; min-height:28px; max-height:28px; font-weight:700; } QPushButton:hover { background:#2d2d2d; } QPushButton:pressed{ background:#161616; }"

        self.btn_up = QtWidgets.QPushButton("▲"); self.btn_up.setStyleSheet(style_arrow()); self.btn_up.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)
        self.btn_left = QtWidgets.QPushButton("◄"); self.btn_left.setStyleSheet(style_arrow()); self.btn_left.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)
        self.btn_right = QtWidgets.QPushButton("►"); self.btn_right.setStyleSheet(style_arrow()); self.btn_right.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)
        self.btn_down = QtWidgets.QPushButton("▼"); self.btn_down.setStyleSheet(style_arrow()); self.btn_down.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)
        self.btn_a = QtWidgets.QPushButton("A"); self.btn_a.setStyleSheet(style_round(56)); self.btn_a.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)
        self.btn_b = QtWidgets.QPushButton("B"); self.btn_b.setStyleSheet(style_round(56)); self.btn_b.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)
        self.btn_select = QtWidgets.QPushButton("Select"); self.btn_select.setStyleSheet(style_pill(120)); self.btn_select.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)
        self.btn_start = QtWidgets.QPushButton("Start"); self.btn_start.setStyleSheet(style_pill(120)); self.btn_start.setFocusPolicy(QC.Qt.FocusPolicy.NoFocus)

        grid.addWidget(self.btn_up,0,0,1,1,QC.Qt.AlignmentFlag.AlignHCenter)
        grid.addWidget(self.btn_left,1,0,1,1,QC.Qt.AlignmentFlag.AlignLeft)
        grid.addWidget(self.btn_right,1,1,1,1,QC.Qt.AlignmentFlag.AlignLeft)
        grid.addWidget(self.btn_down,2,0,1,1,QC.Qt.AlignmentFlag.AlignHCenter)
        grid.addItem(QtWidgets.QSpacerItem(12,12, QtWidgets.QSizePolicy.Policy.Fixed, QtWidgets.QSizePolicy.Policy.Fixed), 1, 2)
        grid.addWidget(self.btn_a,0,3,1,1,QC.Qt.AlignmentFlag.AlignHCenter)
        grid.addWidget(self.btn_b,1,3,1,1,QC.Qt.AlignmentFlag.AlignHCenter)
        grid.addWidget(self.btn_select,2,3,1,1,QC.Qt.AlignmentFlag.AlignLeft)
        grid.addWidget(self.btn_start,3,3,1,1,QC.Qt.AlignmentFlag.AlignLeft)

        dock.setWidget(w)
        self.addDockWidget(QtCore.Qt.DockWidgetArea.LeftDockWidgetArea, dock)
        self.controls_dock = dock
        dock.visibilityChanged.connect(lambda vis: self.act_controls.setChecked(bool(vis)))
        dock.topLevelChanged.connect(self._on_dock_top_level_changed)

        def wire(btn, press_evt, release_evt, name: str):
            btn.pressed.connect(lambda: self._press(press_evt, name))
            btn.released.connect(lambda: self._release(release_evt, name))
        wire(self.btn_up, WindowEvent.PRESS_ARROW_UP, WindowEvent.RELEASE_ARROW_UP, "UP")
        wire(self.btn_down, WindowEvent.PRESS_ARROW_DOWN, WindowEvent.RELEASE_ARROW_DOWN, "DOWN")
        wire(self.btn_left, WindowEvent.PRESS_ARROW_LEFT, WindowEvent.RELEASE_ARROW_LEFT, "LEFT")
        wire(self.btn_right, WindowEvent.PRESS_ARROW_RIGHT, WindowEvent.RELEASE_ARROW_RIGHT, "RIGHT")
        wire(self.btn_a, WindowEvent.PRESS_BUTTON_A, WindowEvent.RELEASE_BUTTON_A, "A")
        wire(self.btn_b, WindowEvent.PRESS_BUTTON_B, WindowEvent.RELEASE_BUTTON_B, "B")
        wire(self.btn_start, WindowEvent.PRESS_BUTTON_START, WindowEvent.RELEASE_BUTTON_START, "START")
        wire(self.btn_select, WindowEvent.PRESS_BUTTON_SELECT, WindowEvent.RELEASE_BUTTON_SELECT, "SELECT")

    def _build_agent_dock(self):
        dock = QtWidgets.QDockWidget("Agent Bridge + Loop", self); dock.setObjectName("agentDock")
        dock.setAllowedAreas(QtCore.Qt.DockWidgetArea.LeftDockWidgetArea | QtCore.Qt.DockWidgetArea.RightDockWidgetArea)
        dock.setFeatures(QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetMovable | QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetFloatable | QtWidgets.QDockWidget.DockWidgetFeature.DockWidgetClosable)
        dock.setStyleSheet("QDockWidget { background:#121212; color:#f5f5f5; } QDockWidget::title { background:#1a1a1a; padding:6px; color:#eaeaea; } QDockWidget QWidget { background:#151515; }")
        w = QtWidgets.QWidget(dock); lay = QtWidgets.QGridLayout(w); lay.setContentsMargins(10,10,10,10); lay.setHorizontalSpacing(10); lay.setVerticalSpacing(8)

        # Force readable text/inputs
        w.setStyleSheet("""
            QLabel, QCheckBox, QComboBox, QLineEdit, QPlainTextEdit, QSpinBox { color:#ffffff; }
            QPlainTextEdit, QLineEdit { background:#1a1a1a; border:1px solid #3a3a3a; selection-background-color:#3a6df0; selection-color:#ffffff; }
            QComboBox QAbstractItemView { color:#ffffff; background:#1a1a1a; selection-background-color:#3a6df0; selection-color:#ffffff; border:1px solid #3a3a3a; }
            QPushButton { color:#ffffff; border:1px solid #2d2d2d; border-radius:6px; padding:4px 10px; }
            QPlainTextEdit#agentLogs { color:#ffffff; background:#121212; border:1px solid #2f2f2f; }
        """)

        self.ollama_url = QtWidgets.QLineEdit(OLLAMA_URL)
        self.vision_model_combo = QtWidgets.QComboBox(); self.vision_model_combo.setEditable(True)
        self.reasoning_model_combo = QtWidgets.QComboBox(); self.reasoning_model_combo.setEditable(True)
        models = self._preferred_models()
        self.vision_model_combo.addItems(models)
        self.reasoning_model_combo.addItems(models)
        self.vision_model_combo.setCurrentText(self.prefs.get("vision_model", self.prefs.get("agent_model", "llava-llama3:latest")))
        self.reasoning_model_combo.setCurrentText(self.prefs.get("reasoning_model", "gemma3:1b"))
        self.vision_model_combo.setToolTip("Multimodal vision stack used for captions/OCR. Pull LLaVA or similar with `ollama pull llava-llama3:latest`.")
        self.reasoning_model_combo.setToolTip("Language reasoning stack that drives the task loop. Install Gemma locally via `ollama pull gemma3:1b`.")
        btn_refresh = QtWidgets.QPushButton("Refresh"); btn_refresh.clicked.connect(self._refresh_models)

        lay.addWidget(QtWidgets.QLabel("Ollama URL:"), 0,0); lay.addWidget(self.ollama_url, 0,1,1,2)
        lay.addWidget(QtWidgets.QLabel("Vision model (captions/OCR):"), 1,0); lay.addWidget(self.vision_model_combo, 1,1); lay.addWidget(btn_refresh, 1,2)
        lay.addWidget(QtWidgets.QLabel("Reasoning model (control loop):"), 2,0); lay.addWidget(self.reasoning_model_combo, 2,1,1,2)

        self.prompt_edit = QtWidgets.QPlainTextEdit(self.prefs.get("prompts", DEFAULT_PROMPTS)["decision"])
        self.prompt_edit.setMinimumHeight(120)
        lay.addWidget(QtWidgets.QLabel("Decision Prompt"), 3,0,1,3)
        lay.addWidget(self.prompt_edit, 4,0,1,3)

        self.spin_interval = QtWidgets.QSpinBox(); self.spin_interval.setRange(50,2000); self.spin_interval.setValue(int(self.prefs.get("agent_interval_ms",350)))
        self.chk_cheats = QtWidgets.QCheckBox("Allow SAVE/LOAD actions (cheats)"); self.chk_cheats.setChecked(bool(self.prefs.get("agent_allow_saveload",False)))
        self.chk_ocr = QtWidgets.QCheckBox("Enable OCR secondary pass"); self.chk_ocr.setChecked(bool(self.prefs.get("agent_enable_ocr",False)))
        self.ocr_model = QtWidgets.QLineEdit(self.prefs.get("ocr_model","benhaotang/Nanonets-OCR-s:latest"))
        self.directive_sensitivity_combo = QtWidgets.QComboBox()
        self.directive_sensitivity_combo.addItem("Low", "low")
        self.directive_sensitivity_combo.addItem("Normal", "normal")
        self.directive_sensitivity_combo.addItem("High", "high")
        pref_sensitivity = str(self.prefs.get("directive_sensitivity", "normal")).strip().lower()
        if pref_sensitivity not in {"low", "normal", "high"}:
            pref_sensitivity = "normal"
        idx = self.directive_sensitivity_combo.findData(pref_sensitivity)
        if idx >= 0:
            self.directive_sensitivity_combo.setCurrentIndex(idx)
        else:
            self.directive_sensitivity_combo.setCurrentText(pref_sensitivity.title())

        self.embed_model = QtWidgets.QLineEdit(self.prefs.get("embed_model","snowflake-arctic-embed2:latest"))
        self.summary_model = QtWidgets.QLineEdit(self.prefs.get("summary_model","gemma3:4b"))
        lay.addWidget(QtWidgets.QLabel("Embed model:"), 5,0); lay.addWidget(self.embed_model, 5,1,1,2)
        lay.addWidget(QtWidgets.QLabel("Summarizer model:"), 6,0); lay.addWidget(self.summary_model, 6,1,1,2)

        btn_start = QtWidgets.QPushButton("Start"); btn_start.setStyleSheet("QPushButton{background:#19a05e; color:#ffffff;}")
        btn_stop = QtWidgets.QPushButton("Stop"); btn_stop.setStyleSheet("QPushButton{background:#c53b3b; color:#ffffff;}")
        btn_start.clicked.connect(self._start_agent); btn_stop.clicked.connect(self._stop_agent)

        lay.addWidget(QtWidgets.QLabel("Step interval (ms):"), 7,0); lay.addWidget(self.spin_interval, 7,1); lay.addWidget(self.chk_cheats, 7,2)
        lay.addWidget(self.chk_ocr, 8,0); lay.addWidget(self.ocr_model, 8,1,1,2)
        lay.addWidget(QtWidgets.QLabel("Directive sensitivity:"), 9,0)
        lay.addWidget(self.directive_sensitivity_combo, 9,1,1,2)

        self.agent_tabs = QtWidgets.QTabWidget()
        self.agent_tabs.setDocumentMode(True)
        self.agent_tabs.setStyleSheet("QTabWidget::pane{border:1px solid #2f2f2f; border-radius:6px;} QTabBar::tab{background:#1a1a1a;padding:6px 12px;border:1px solid #2f2f2f;border-bottom:0px;} QTabBar::tab:selected{background:#242424;} QTabBar::tab:!selected{color:#9aa5b1;}")

        # Logs tab
        self.agent_logs = QtWidgets.QPlainTextEdit(); self.agent_logs.setObjectName("agentLogs")
        self.agent_logs.setReadOnly(True); self.agent_logs.setMinimumHeight(160)
        logs_tab = QtWidgets.QWidget(); logs_lay = QtWidgets.QVBoxLayout(logs_tab)
        logs_lay.setContentsMargins(6,6,6,6); logs_lay.addWidget(self.agent_logs)

        # Tasks tab
        self.task_tree = QtWidgets.QTreeWidget()
        self.task_tree.setHeaderLabels(["Goal", "Status", "Needs"])
        self.task_tree.setRootIsDecorated(False)
        self.task_tree.setAlternatingRowColors(True)
        self.task_tree.setStyleSheet("QTreeWidget{background:#121212;border:1px solid #2f2f2f;color:#f0f0f0;} QHeaderView::section{background:#1f1f1f;color:#cfd8ff;border:1px solid #2f2f2f;}")
        self.tasks_tab = QtWidgets.QWidget(); tasks_lay = QtWidgets.QVBoxLayout(self.tasks_tab)
        tasks_lay.setContentsMargins(6,6,6,6); tasks_lay.addWidget(self.task_tree)

        # Memory tab
        self.memory_list = QtWidgets.QListWidget()
        self.memory_list.setViewMode(QtWidgets.QListView.ViewMode.IconMode)
        self.memory_list.setIconSize(QtCore.QSize(72, 72))
        self.memory_list.setSpacing(8)
        self.memory_list.setResizeMode(QtWidgets.QListView.ResizeMode.Adjust)
        self.memory_list.setMovement(QtWidgets.QListView.Movement.Static)
        self.memory_list.setStyleSheet(
            "QListWidget{background:#121212;border:1px solid #2f2f2f;color:#f0f0f0;}"
        )
        self.memory_matches = QtWidgets.QPlainTextEdit()
        self.memory_matches.setReadOnly(True)
        self.memory_matches.setMinimumHeight(96)
        self.memory_matches.setStyleSheet(
            "QPlainTextEdit{background:#101010;border:1px solid #2f2f2f;color:#b8c2ff;}"
        )
        self.memory_tab = QtWidgets.QWidget()
        memory_lay = QtWidgets.QVBoxLayout(self.memory_tab)
        memory_lay.setContentsMargins(6,6,6,6)
        memory_lay.addWidget(self.memory_list)
        memory_lay.addWidget(QtWidgets.QLabel("Recent region matches:"))
        memory_lay.addWidget(self.memory_matches)

        # Narrative tab
        self.narrative_view = QtWidgets.QPlainTextEdit()
        self.narrative_view.setReadOnly(True)
        self.narrative_view.setStyleSheet("QPlainTextEdit{background:#121212;border:1px solid #2f2f2f;color:#f0f0f0;}")
        self.narrative_tab = QtWidgets.QWidget(); narrative_lay = QtWidgets.QVBoxLayout(self.narrative_tab)
        narrative_lay.setContentsMargins(6,6,6,6); narrative_lay.addWidget(self.narrative_view)

        self.agent_tabs.addTab(logs_tab, "Logs")
        self.agent_tabs.addTab(self.tasks_tab, "Tasks")
        self.agent_tabs.addTab(self.memory_tab, "Memory")
        self.agent_tabs.addTab(self.narrative_tab, "Narrative")
        self.timeline_view = QtWidgets.QPlainTextEdit()
        self.timeline_view.setReadOnly(True)
        self.timeline_view.setStyleSheet("QPlainTextEdit{background:#121212;border:1px solid #2f2f2f;color:#f0f0f0;}")
        self.timeline_tab = QtWidgets.QWidget()
        timeline_lay = QtWidgets.QVBoxLayout(self.timeline_tab)
        timeline_lay.setContentsMargins(6,6,6,6)
        timeline_lay.addWidget(self.timeline_view)
        self.agent_tabs.addTab(self.timeline_tab, "Timeline")
        lay.addWidget(self.agent_tabs, 10,0,1,3)

        # RAW ingestion controls
        self.btn_ingest = QtWidgets.QPushButton("Ingest RAW Info Folder")
        self.btn_ingest.setToolTip(f"Scans {RAW_INFO_DIR} for text/images; OCR + embed; updates vectors.")
        lay.addWidget(self.btn_ingest, 11,0,1,2)
        self.btn_ingest.clicked.connect(self._ingest_raw_info)

        self.btn_open_raw = QtWidgets.QPushButton("Open RAW Info Folder")
        self.btn_open_raw.clicked.connect(lambda: QtGui.QDesktopServices.openUrl(QtCore.QUrl.fromLocalFile(str(RAW_INFO_DIR))))
        lay.addWidget(self.btn_open_raw, 11,2,1,1)

        next_row = 12
        self.btn_sync_pokemon: Optional[QtWidgets.QPushButton] = None
        if self.prefs.get("pokemon_sync_enabled", False):
            self.btn_sync_pokemon = QtWidgets.QPushButton("Sync Pokémon Corpus")
            self.btn_sync_pokemon.setToolTip(
                "Fetch official Pokémon vocabulary (pokemon.com & Wikipedia) and refresh the agent lexicon."
            )
            self.btn_sync_pokemon.clicked.connect(self._sync_pokemon_corpus)
            lay.addWidget(self.btn_sync_pokemon, next_row,0,1,3)
            next_row += 1

        self.btn_inspect_memories = QtWidgets.QPushButton("Inspect retrieved memories")
        self.btn_inspect_memories.setToolTip("Show the most recent memory recall context from the cognition loop.")
        self.btn_inspect_memories.clicked.connect(self._inspect_memories)
        lay.addWidget(self.btn_inspect_memories, next_row,0,1,3)
        next_row += 1

        h = QtWidgets.QHBoxLayout(); h.addStretch(1); h.addWidget(btn_start); h.addWidget(btn_stop)
        lay.addLayout(h, next_row,0,1,3)

        dock.setWidget(w)
        self.addDockWidget(QtCore.Qt.DockWidgetArea.LeftDockWidgetArea, dock)
        self.agent_dock = dock
        dock.visibilityChanged.connect(lambda vis: self.act_agent.setChecked(bool(vis)))

    def _preferred_models(self) -> List[str]:
        defaults = [
            "llava-llama3:latest",
            "llava:7b",
            "gemma3:1b",
            "gemma3:4b",
            "benhaotang/Nanonets-OCR-s:latest",
            "yasserrmd/Nanonets-OCR-s:latest",
        ]
        installed = ollama_list()
        pref = [m for m in defaults if m in installed]
        rest = [m for m in installed if m not in pref]
        return pref + rest if (pref or rest) else defaults

    # ---------------- Dock toggles ----------------
    def _on_dock_top_level_changed(self, floating: bool):
        if floating:
            self.controls_dock.setStyleSheet("QDockWidget { background:#121212; color:#f5f5f5; } QDockWidget::title { background:#1a1a1a; padding:6px; color:#eaeaea; } QDockWidget QWidget { background:#151515; }")
    def _toggle_controls_dock(self):
        if self.controls_dock.isHidden():
            self._force_redock_controls(); self.controls_dock.show(); self.act_controls.setChecked(True)
        else:
            self.controls_dock.hide(); self.act_controls.setChecked(False)
    def _toggle_agent_dock(self):
        if self.agent_dock.isHidden(): self.agent_dock.show(); self.act_agent.setChecked(True)
        else: self.agent_dock.hide(); self.act_agent.setChecked(False)
    def _force_redock_controls(self):
        try: self.controls_dock.setFloating(False)
        except Exception: pass
        self.addDockWidget(QtCore.Qt.DockWidgetArea.LeftDockWidgetArea, self.controls_dock)

    # ---------------- Shortcuts ----------------
    def _bind_shortcuts(self):
        QtGui.QShortcut(QtGui.QKeySequence("Ctrl+O"), self, activated=self.action_open_rom)
        QtGui.QShortcut(QtGui.QKeySequence("Ctrl+R"), self, activated=self.reset_emulation)
        QtGui.QShortcut(QtGui.QKeySequence("Ctrl+Shift+Q"), self, activated=self.quit_emulation)
        QtGui.QShortcut(QtGui.QKeySequence("F12"), self, activated=self.action_screenshot)
        QtGui.QShortcut(QtGui.QKeySequence("F5"), self, activated=self.action_save_state)
        QtGui.QShortcut(QtGui.QKeySequence("F9"), self, activated=self.action_load_state)
        QtGui.QShortcut(QtGui.QKeySequence("+"), self, activated=lambda: self.adjust_speed(0.1))
        QtGui.QShortcut(QtGui.QKeySequence("-"), self, activated=lambda: self.adjust_speed(-0.1))
        QtGui.QShortcut(QtGui.QKeySequence("F11"), self, activated=self.toggle_fullscreen)

    def _style_start_button(self, running: bool):
        if running:
            self.btn_startstop.setText("Pause")
            self.btn_startstop.setStyleSheet("QToolButton{background:#b3261e;color:#fff;border:1px solid #9a1f19;border-radius:6px;padding:4px 10px;} QToolButton:hover{background:#c5362d;} QToolButton:pressed{background:#8a1c16;}")
        else:
            self.btn_startstop.setText("Start")
            self.btn_startstop.setStyleSheet("QToolButton{background:#1e88e5;color:#fff;border:1px solid #1976d2;border-radius:6px;padding:4px 10px;} QToolButton:hover{background:#2196f3;} QToolButton:pressed{background:#1565c0;}")

    def _add_check(self, menu: QtWidgets.QMenu, label: str, key: str) -> QtGui.QAction:
        act = QtGui.QAction(label, self, checkable=True); act.setChecked(bool(self.prefs.get(key, True)))
        def toggle(v): self.prefs[key] = bool(v); save_prefs(self.prefs); self.status.showMessage(f"{label}: {'ON' if v else 'OFF'}")
        act.toggled.connect(toggle); menu.addAction(act); return act

    # ---------------- Profiles ----------------
    def _refresh_profiles(self):
        names = list_profiles()
        self.profile_combo.blockSignals(True)
        self.profile_combo.clear(); self.profile_combo.addItems(names)
        cur = self.prefs.get("profile", "Player1")
        if cur not in names:
            cur = names[0]; self.prefs["profile"] = cur; save_prefs(self.prefs)
        self.profile_combo.setCurrentText(cur)
        self.profile_combo.blockSignals(False)

    def _new_profile_dialog(self):
        name, ok = QtWidgets.QInputDialog.getText(self, "New Player Profile", "Player name:")
        if not ok or not name.strip(): return
        name = sanitize_name(name)
        pdir = profile_dir(name)
        if not pdir.exists(): pdir.mkdir(parents=True, exist_ok=True)
        else: QtWidgets.QMessageBox.information(self, "Profile", f"Profile '{name}' already exists.")
        self._refresh_profiles()

    def _on_profile_selected(self, name: str):
        if self.prefs.get("profile") == name: return
        if self.is_running():
            res = QtWidgets.QMessageBox.question(self, "Switch profile?",
                f"Save current state for '{self.prefs.get('profile')}' before switching to '{name}'?",
                QtWidgets.QMessageBox.StandardButton.Yes | QtWidgets.QMessageBox.StandardButton.No | QtWidgets.QMessageBox.StandardButton.Cancel)
            if res == QtWidgets.QMessageBox.StandardButton.Cancel:
                self.profile_combo.blockSignals(True); self.profile_combo.setCurrentText(self.prefs.get("profile")); self.profile_combo.blockSignals(False); return
            if res == QtWidgets.QMessageBox.StandardButton.Yes: self._save_profile_state()
        self.prefs["profile"] = name; save_prefs(self.prefs)
        if self._core_loaded: self._load_profile_state(); self.status.showMessage(f"Switched profile → {name}")

    # ---------------- ROMs ----------------
    def _populate_roms(self):
        self.rom_combo.blockSignals(True); self.rom_combo.clear()
        roms = sorted([p.name for p in ROMS_DIR.glob("*.gb")])
        if not roms:
            self.rom_combo.addItem("(no ROMs found)"); self._current_rom_name = None
        else:
            self.rom_combo.addItems(roms)
            lr = self._rom_from_prefs()
            if lr and lr.exists(): self.rom_combo.setCurrentText(lr.name); self._current_rom_name = lr.name
            else: self._current_rom_name = roms[0]; self.rom_combo.setCurrentText(self._current_rom_name)
        self.rom_combo.blockSignals(False)

    def _rom_selected(self, rom_name: str):
        if self.is_running():
            res = QtWidgets.QMessageBox.question(self, "Change ROM while running?",
                "Emulator is running.\nStop current game (save if enabled) and load the new ROM?",
                QtWidgets.QMessageBox.StandardButton.Yes | QtWidgets.QMessageBox.StandardButton.No)
            if res != QtWidgets.QMessageBox.StandardButton.Yes:
                self.rom_combo.blockSignals(True)
                if self._current_rom_name: self.rom_combo.setCurrentText(self._current_rom_name)
                self.rom_combo.blockSignals(False); return
            self.stop_emulation()
        p = ROMS_DIR / rom_name
        if p.exists(): self._load_rom_and_remember(p); self._current_rom_name = rom_name

    # ---------------- Prompts manager ----------------
    def _open_prompts(self):
        dlg = PromptsDialog(self.prefs.get("prompts", DEFAULT_PROMPTS), self)
        if dlg.exec() == QtWidgets.QDialog.DialogCode.Accepted:
            self.prefs["prompts"] = dlg.values(); save_prefs(self.prefs)
            self.prompt_edit.setPlainText(self.prefs["prompts"]["decision"])
            self.status.showMessage("Prompts saved")

    # ---------------- Video tint ----------------
    def _set_tint_enabled(self, v: bool):
        self.prefs["lcd_tint_enabled"] = bool(v); save_prefs(self.prefs)
    def _choose_tint_color(self):
        col = QtWidgets.QColorDialog.getColor(QtGui.QColor(self.prefs.get("lcd_tint_color","#ff3b3b")), self, "Choose LCD Tint Color")
        if col.isValid(): self.prefs["lcd_tint_color"] = col.name(); save_prefs(self.prefs)
    def _choose_tint_strength(self):
        val, ok = QtWidgets.QInputDialog.getDouble(self, "LCD Tint Strength", "0.00 .. 1.00", float(self.prefs.get("lcd_tint_strength",0.12)), 0.0, 1.0, 2)
        if ok: self.prefs["lcd_tint_strength"] = float(val); save_prefs(self.prefs)

    # ---------------- Keybinds ----------------
    def _open_keybinds(self):
        dlg = KeybindsDialog(self.prefs, self); dlg.keybindsChanged.connect(self._apply_keybinds_live); dlg.exec()
    def _apply_keybinds_live(self, kb_map: dict):
        self.keybinds = dict(kb_map); self.status.showMessage("Keybinds updated (live)")

    # ---------------- Drag & drop ----------------
    def dragEnterEvent(self, e: QtGui.QDragEnterEvent):
        if e.mimeData().hasUrls() and any(u.toLocalFile().lower().endswith(".gb") for u in e.mimeData().urls()):
            e.acceptProposedAction()
    def dropEvent(self, e: QtGui.QDropEvent):
        for u in e.mimeData().urls():
            p = Path(u.toLocalFile())
            if p.suffix.lower() == ".gb" and p.exists():
                self._load_rom_and_remember(p)
                self._current_rom_name = p.name if p.parent.resolve()==ROMS_DIR.resolve() else self._current_rom_name
                break

    # ---------------- Core control ----------------
    def _load_rom_and_remember(self, path: Path):
        self.prefs["last_rom"] = self._rel_rom(path); save_prefs(self.prefs)
        self._apply_auto_tint(path.name)
        self.emuThread.cmd_load(path)
        if path.parent.resolve() == ROMS_DIR.resolve():
            self.rom_combo.blockSignals(True); self.rom_combo.setCurrentText(path.name); self.rom_combo.blockSignals(False); self._current_rom_name = path.name
        self.status.showMessage(f"Loaded ROM: {path.name} (paused; press Start)")

    def _apply_auto_tint(self, rom_name: str):
        name = rom_name.lower(); auto = None
        if "red" in name: auto = "#ff3b3b"
        elif "blue" in name: auto = "#3b6bff"
        elif "green" in name: auto = "#3bff6b"
        elif "yellow" in name: auto = "#ffd23b"
        if auto and not self.prefs.get("lcd_tint_enabled", False):
            self.prefs["lcd_tint_color"] = auto; save_prefs(self.prefs)

    def _on_core_state(self, loaded: bool):
        self._core_loaded = loaded
        if not loaded:
            self._style_start_button(False)
            self._set_idle_screen()
            self.audio.flush(); self.audio.set_muted(True)
            if hasattr(self, "act_mute"): self.act_mute.setChecked(True)
        else:
            if self._pending_run_after_load:
                self._pending_run_after_load = False
                self.emuThread.cmd_set_running(True)
                if self.prefs.get("auto_mute_on_pause", True):
                    self.audio.set_muted(self._muted_before_pause)
                    if hasattr(self, "act_mute"): self.act_mute.setChecked(self._muted_before_pause)
                self._style_start_button(True); self.status.showMessage("Emulation running")

    def start_emulation(self):
        if not self._core_loaded:
            sel = self._rom_from_combo() or self._rom_from_prefs()
            if not (sel and sel.exists()):
                self.status.showMessage("No ROM selected. Use the ROM dropdown or File → Open ROM…"); return
            self._pending_run_after_load = True; self._style_start_button(True); self.emuThread.cmd_load(sel)
            self.status.showMessage(f"Loading {sel.name}…"); return
        toggle_to = not self.is_running()
        self.emuThread.cmd_set_running(toggle_to); self._style_start_button(toggle_to)
        if toggle_to:
            if self.prefs.get("auto_mute_on_pause", True):
                self.audio.set_muted(self._muted_before_pause)
                if hasattr(self, "act_mute"): self.act_mute.setChecked(self._muted_before_pause)
            self.status.showMessage("Emulation running")
        else:
            if self.prefs.get("auto_mute_on_pause", True):
                self._muted_before_pause = self.audio.muted
                self.audio.set_muted(True)
                if hasattr(self, "act_mute"): self.act_mute.setChecked(True)
            self.status.showMessage("Emulation paused")

    def stop_emulation(self):
        if not self._core_loaded:
            self._style_start_button(False); self._set_idle_screen()
            self.audio.flush(); self.audio.set_muted(True)
            if hasattr(self, "act_mute"): self.act_mute.setChecked(True); return
        if self.prefs.get("save_on_stop", True): self._save_profile_state()
        self._pending_run_after_load = False; self.emuThread.cmd_set_running(False); self.emuThread.cmd_stop()
        self.audio.flush(); self.audio.set_muted(True)
        if hasattr(self, "act_mute"): self.act_mute.setChecked(True)
        self._set_idle_screen(); self.status.showMessage("Emulation stopped (core unloaded)")

    def reset_emulation(self):
        if not self._core_loaded:
            sel = self._rom_from_combo() or self._rom_from_prefs()
            if not (sel and sel.exists()):
                self.status.showMessage("No ROM selected to reset into."); return
            self._pending_run_after_load = True; self._style_start_button(True)
            self.emuThread.cmd_load(sel); self.status.showMessage(f"Loading {sel.name}…"); return
        if self.prefs.get("save_on_reset", True): self._save_profile_state()
        self.emuThread.cmd_reset(); self.emuThread.cmd_set_running(True); self._style_start_button(True)
        self.status.showMessage("Emulation reset")

    def quit_emulation(self):
        if not self._core_loaded: return
        if self.prefs.get("save_on_quit", True): self._save_profile_state()
        self._pending_run_after_load = False; self.emuThread.cmd_set_running(False); self.emuThread.cmd_stop()
        self.audio.flush(); self.audio.set_muted(True)
        if hasattr(self, "act_mute"): self.act_mute.setChecked(True)
        self._set_idle_screen(); self.status.showMessage("Emulator quit (core unloaded)")

    def is_running(self) -> bool: return self.btn_startstop.text().startswith("Pause")

    # ---------------- Keyboard input ----------------
    def keyPressEvent(self, e: QtGui.QKeyEvent):
        if e.isAutoRepeat() or not self.is_running(): return
        act = self._action_for_key_event(e)
        if act: self.emuThread.cmd_input_press(EVENTS_PRESS[act]); self.status.showMessage(f"Pressed {act}"); return
        super().keyPressEvent(e)
    def keyReleaseEvent(self, e: QtGui.QKeyEvent):
        if e.isAutoRepeat() or not self.is_running(): return
        act = self._action_for_key_event(e)
        if act:
            self.emuThread.cmd_input_release(EVENTS_RELEASE[act]); self.status.showMessage(f"Released {act}")
            if self.prefs.get("learn_from_user_inputs", True) and self.agent_worker:
                self.agent_worker.user_teach(act)
            return
        super().keyReleaseEvent(e)
    def _action_for_key_event(self, e: QtGui.QKeyEvent) -> Optional[str]:
        key = int(e.key()); is_keypad = bool(e.modifiers() & QC.Qt.KeyboardModifier.KeypadModifier)
        for act, cfg in self.keybinds.items():
            if key == int(cfg.get("key", 0)) and ((not bool(cfg.get("keypad", False))) or is_keypad): return act
        return None
    def _press(self, evt, name=""):
        if not self.is_running(): return
        self.emuThread.cmd_input_press(evt); self.status.showMessage(f"Pressed {name}")
    def _release(self, evt, name=""):
        if not self.is_running(): return
        self.emuThread.cmd_input_release(evt); self.status.showMessage(f"Released {name}")
        if self.prefs.get("learn_from_user_inputs", True) and self.agent_worker:
            self.agent_worker.user_teach(name)

    # ---------------- RAW ingestion ----------------
    def _ingest_raw_info(self):
        ing = RawInfoIngestor(self.prefs)
        self.status.showMessage("Ingesting RAW Info…")
        def _run():
            ing.progress.connect(self._append_agent_log)
            ing.ingest()
            self.status.showMessage("RAW Info ingestion finished.")
        th.Thread(target=_run, daemon=True).start()

    def _sync_pokemon_corpus(self):
        if not self.prefs.get("pokemon_sync_enabled", False):
            QtWidgets.QMessageBox.information(
                self,
                "Pokémon Corpus",
                "Corpus syncing is disabled in preferences. Enable `pokemon_sync_enabled` to proceed.",
            )
            return
        self.status.showMessage("Syncing Pokémon corpus…")

        def _run():
            try:
                ingestor = PokemonCorpusIngestor(cache_dir=POKEMON_CACHE, knowledge_dir=KNOWLEDGE)
                result = ingestor.sync()
                refreshed = 0
                if self.agent_worker and getattr(self.agent_worker, "ks", None):
                    try:
                        refreshed = int(self.agent_worker.ks.refresh_pokemon_lexicon())
                    except Exception:
                        refreshed = 0
                summary = (
                    f"Pokémon corpus synced — {result.entry_count} entries "
                    f"({len(result.fetched)} fetched, {len(result.from_cache)} cached)."
                )
                if refreshed:
                    summary = f"{summary} KnowledgeStore entries: {refreshed}."
                log_lines = [summary]
                if result.errors:
                    log_lines.append("Errors: " + ", ".join(result.errors))

                def _finish():
                    self.status.showMessage(summary)
                    for line in log_lines:
                        self._append_agent_log(line)

                QtCore.QTimer.singleShot(0, _finish)
            except Exception as exc:
                message = f"Pokémon corpus sync failed: {exc}"

                def _fail():
                    self.status.showMessage(message)
                    self._append_agent_log(message)

                QtCore.QTimer.singleShot(0, _fail)

        th.Thread(target=_run, daemon=True).start()

    # ---------------- Frame/audio/speed helpers ----------------
    def _on_frame_bytes(self, rgb: bytes, w: int, h: int):
        self.frame_deque.append((rgb, w, h))
        try: self._last_frame_png = png_bytes_from_rgb(rgb, w, h)
        except Exception: self._last_frame_png = None
        if self.prefs.get("lcd_tint_enabled", False):
            col = QtGui.QColor(self.prefs.get("lcd_tint_color","#ff3b3b"))
            strength = float(self.prefs.get("lcd_tint_strength", 0.12))
            arr = np.frombuffer(rgb, dtype=np.uint8).reshape((h,w,3)).copy()
            arr = srgb_tint(arr, (col.red(), col.green(), col.blue()), strength)
            rgb_disp = arr.tobytes()
        else:
            rgb_disp = rgb
        self.lcd.set_frame_bytes(rgb_disp, w, h)

    def _save_profile_state(self):
        name = self.prefs.get("profile", "Player1"); path = profile_state_path(name)
        self.emuThread.cmd_save(path)
    def _load_profile_state(self):
        name = self.prefs.get("profile", "Player1"); path = profile_state_path(name)
        self.emuThread.cmd_load_state(path)
    def action_save_state(self):
        self._save_profile_state(); self.status.showMessage(f"Saved state → {self.prefs.get('profile')}/slot.state")
    def action_load_state(self):
        self._load_profile_state(); self.status.showMessage(f"Loaded state ← {self.prefs.get('profile')}/slot.state")
    def action_screenshot(self):
        pm = self.lcd.pixmap(); 
        if not pm: return
        out = ASSETS / f"screenshot_{time.strftime('%Y%m%d-%H%M%S')}.png"; pm.save(str(out), "PNG")
        self.status.showMessage(f"Screenshot → {out.name}")
    def adjust_speed(self, delta: float):
        self._speed = max(0.5, min(3.0, getattr(self, "_speed", 1.0) + delta))
        self.emuThread.cmd_speed(self._speed); self.status.showMessage(f"Speed ×{self._speed:.2f}")

    # ---------------- File / audio / fullscreen ----------------
    def action_open_rom(self):
        start_dir = str(ROMS_DIR.resolve())
        dlg = QtWidgets.QFileDialog(self, "Open Game Boy ROM", start_dir, "Game Boy ROM (*.gb)")
        dlg.setDirectory(start_dir); dlg.setFileMode(QtWidgets.QFileDialog.FileMode.ExistingFile)
        if dlg.exec():
            file = dlg.selectedFiles()[0]
            if file:
                p = Path(file); self._load_rom_and_remember(p)
                if p.parent.resolve() == ROMS_DIR.resolve(): self._current_rom_name = p.name

    def _select_audio_device(self, device_index: Optional[int]):
        self.prefs["audio_device"] = device_index; save_prefs(self.prefs)
        if self.audio.enabled:
            self.audio.set_device(device_index); self.status.showMessage(f"Audio device: {'Default' if device_index is None else device_index}")
    def _toggle_mute(self, v: bool):
        self.prefs["audio_muted"] = bool(v); save_prefs(self.prefs); self.audio.set_muted(bool(v))
        self.status.showMessage("Audio muted" if v else "Audio unmuted")
    def _set_volume(self, gain: float):
        self.prefs["audio_gain"] = float(gain); save_prefs(self.prefs); self.audio.set_gain(float(gain))
        self.status.showMessage(f"Volume: {gain:.2f}×")
    def _set_idle_screen(self):
        pm = QtGui.QPixmap(self.lcd.size()); pm.fill(QtGui.QColor(11,11,11)); self.lcd.setPixmap(pm)
        img = Image.new("RGB", (160, 144), (0,0,0)); bio = io.BytesIO(); img.save(bio,"PNG"); self._last_frame_png = bio.getvalue()
    def _toggle_start_stop(self): self.start_emulation()
    def toggle_fullscreen(self):
        if self.isFullScreen(): self.showNormal()
        else: self.showFullScreen()
    def changeEvent(self, e: QtCore.QEvent):
        super().changeEvent(e)
        if e.type() == QtCore.QEvent.Type.WindowStateChange:
            self.addDockWidget(QtCore.Qt.DockWidgetArea.LeftDockWidgetArea, self.controls_dock)
            self.controls_dock.setFloating(False)

    # ---------------- Visual key highlight for agent presses -------------------
    @QtCore.pyqtSlot(str, int)
    def _highlight_button(self, act: str, dur_ms: int):
        btn_map = {
            "UP": self.btn_up, "DOWN": self.btn_down, "LEFT": self.btn_left, "RIGHT": self.btn_right,
            "A": self.btn_a, "B": self.btn_b, "START": self.btn_start, "SELECT": self.btn_select
        }
        btn = btn_map.get(act.upper())
        if not btn: return
        btn.setDown(True)
        QtCore.QTimer.singleShot(max(60, int(dur_ms)), lambda: btn.setDown(False))

    # ---------------- HTTP bridge lifecycle ----------------
    def _start_http_bridge(self, port: int = 8787):
        if getattr(self, "_bridge", None): return
        try:
            self._bridge = BridgeServer(("127.0.0.1", port), BridgeHandler, self)
        except OSError as e:
            for p in range(port+1, port+10):
                try:
                    self._bridge = BridgeServer(("127.0.0.1", p), BridgeHandler, self)
                    self.prefs["bridge_port"] = p; save_prefs(self.prefs); port = p; break
                except OSError: continue
            if not getattr(self, "_bridge", None):
                self.status.showMessage(f"HTTP bridge failed: {e}"); return
        t = th.Thread(target=self._bridge.serve_forever, daemon=True); t.start(); self._bridge_thread = t
        self.status.showMessage(f"HTTP bridge at http://127.0.0.1:{port}")

    def _stop_http_bridge(self):
        srv = getattr(self, "_bridge", None)
        if not srv: return
        try: srv.shutdown(); srv.server_close()
        finally: self._bridge = None; self._bridge_thread = None

    # ---------------- Agent controls ----------------
    def _refresh_models(self):
        models = self._preferred_models()
        for combo in (self.vision_model_combo, self.reasoning_model_combo):
            current = combo.currentText()
            combo.blockSignals(True)
            combo.clear()
            combo.addItems(models)
            if current:
                idx = combo.findText(current)
                if idx >= 0:
                    combo.setCurrentIndex(idx)
                else:
                    combo.setEditText(current)
            combo.blockSignals(False)
        self.status.showMessage("Models refreshed", 3000)

    def _start_agent(self):
        if self.agent_worker: return
        vision_model = self.vision_model_combo.currentText().strip()
        reasoning_model = self.reasoning_model_combo.currentText().strip()
        if vision_model:
            self.prefs["vision_model"] = vision_model
            self.prefs["agent_model"] = vision_model
        if reasoning_model:
            self.prefs["reasoning_model"] = reasoning_model
        self.prefs["agent_interval_ms"] = int(self.spin_interval.value())
        self.prefs["agent_allow_saveload"] = bool(self.chk_cheats.isChecked())
        self.prefs["agent_enable_ocr"] = bool(self.chk_ocr.isChecked())
        self.prefs["ocr_model"] = self.ocr_model.text().strip()
        sensitivity_data = self.directive_sensitivity_combo.currentData()
        if sensitivity_data is None:
            sensitivity_value = self.directive_sensitivity_combo.currentText().strip().lower()
        else:
            sensitivity_value = str(sensitivity_data)
        if sensitivity_value not in {"low", "normal", "high"}:
            sensitivity_value = "normal"
        self.prefs["directive_sensitivity"] = sensitivity_value
        self.prefs["prompts"]["decision"] = self.prompt_edit.toPlainText().strip() or DEFAULT_PROMPTS["decision"]
        self.prefs["embed_model"] = self.embed_model.text().strip() or self.prefs["embed_model"]
        self.prefs["summary_model"] = self.summary_model.text().strip() or self.prefs["summary_model"]
        save_prefs(self.prefs)

        self.agent_worker = AgentWorker(self)
        self.agent_worker.log.connect(self._append_agent_log)
        self.agent_worker.status.connect(self.status.showMessage)
        self.agent_worker.uiFlash.connect(self._highlight_button)
        self.agent_worker.tasksUpdated.connect(self._refresh_task_panel)
        self.agent_worker.narrativeReady.connect(self._update_narrative_panel)
        self.agent_worker.memorySnapshot.connect(self._on_memory_snapshot)
        self._refresh_task_panel(self.agent_worker.task_manager.to_serializable())
        self.agent_worker.start()

    def _stop_agent(self):
        if not self.agent_worker: return
        self.agent_worker.stop(); self.agent_worker.wait(3000)
        self.agent_worker = None
        self._latest_memory_snapshot = {}
        self.status.showMessage("Agent stopped")

    def _append_agent_log(self, s: str):
        self.agent_logs.appendPlainText(s)
        self.agent_logs.verticalScrollBar().setValue(self.agent_logs.verticalScrollBar().maximum())

    @QtCore.pyqtSlot(list)
    def _refresh_task_panel(self, tasks: List[Dict[str, Any]]):
        if not hasattr(self, "task_tree"):
            return
        self.task_tree.setUpdatesEnabled(False)
        self.task_tree.clear()
        for task in tasks:
            goal = str(task.get("goal", ""))
            status = str(task.get("status", ""))
            needs_list = task.get("needs") or []
            if isinstance(needs_list, str):
                needs = needs_list
            else:
                needs = ", ".join(str(n) for n in needs_list)
            source = str(task.get("source", "llm") or "llm")
            status_text = status if not source else f"{status} [{source}]"
            item = QtWidgets.QTreeWidgetItem([goal, status_text, needs])
            evidence = task.get("evidence") or []
            if isinstance(evidence, (list, tuple)):
                tooltip = "\n".join(str(ev) for ev in evidence if str(ev).strip())
            else:
                tooltip = str(evidence)
            provenance = task.get("provenance") if isinstance(task.get("provenance"), dict) else {}
            prov_lines: List[str] = []
            if source:
                prov_lines.append(f"source: {source}")
            if isinstance(provenance, dict) and provenance:
                tags = provenance.get("tags")
                if isinstance(tags, list) and tags:
                    prov_lines.append("tags: " + ", ".join(str(t) for t in tags))
                score = provenance.get("score")
                if isinstance(score, (int, float)):
                    prov_lines.append(f"score: {score:.2f}")
                sources = provenance.get("sources")
                if isinstance(sources, list) and sources:
                    prov_lines.append("detected via: " + ", ".join(str(s) for s in sources))
            if prov_lines:
                prov_text = "\n".join(prov_lines)
                tooltip = f"{tooltip}\n{prov_text}".strip() if tooltip else prov_text
            if tooltip:
                item.setToolTip(0, tooltip)
                item.setToolTip(1, tooltip)
                item.setToolTip(2, tooltip)
            self.task_tree.addTopLevelItem(item)
        self.task_tree.header().setStretchLastSection(True)
        self.task_tree.resizeColumnToContents(0)
        self.task_tree.setUpdatesEnabled(True)

    @QtCore.pyqtSlot(str)
    def _update_narrative_panel(self, narrative: str):
        if not hasattr(self, "narrative_view"):
            return
        text = narrative.strip()
        if not text:
            return
        self.narrative_view.setPlainText(text)
        idx = self.agent_tabs.indexOf(self.narrative_tab)
        if idx != -1:
            self.agent_tabs.setTabText(idx, "Narrative")

    @QtCore.pyqtSlot(dict)
    def _on_memory_snapshot(self, snapshot: Dict[str, Any]):
        self._latest_memory_snapshot = dict(snapshot or {})
        visual = self._latest_memory_snapshot.get("visual") or {}
        if hasattr(self, "memory_list") and isinstance(self.memory_list, QtWidgets.QListWidget):
            self.memory_list.clear()
            regions = []
            decomposition = visual.get("decomposition") if isinstance(visual, dict) else {}
            if isinstance(decomposition, dict):
                regions = decomposition.get("regions") or []
            for region in regions[:24]:
                if not isinstance(region, dict):
                    continue
                label = str(region.get("label") or "region")
                confidence = region.get("confidence")
                if isinstance(confidence, (int, float)):
                    text = f"{label} ({confidence*100:.0f}%)"
                else:
                    text = label
                item = QtWidgets.QListWidgetItem(text)
                thumb_b64 = region.get("thumbnail_b64") or region.get("crop_b64")
                tooltip_parts = [f"bbox={region.get('bbox')}"]
                if confidence is not None:
                    tooltip_parts.append(f"confidence={confidence}")
                facing = region.get("facing")
                if facing:
                    tooltip_parts.append(f"facing={facing}")
                if region.get("details"):
                    tooltip_parts.append(json.dumps(region.get("details"), indent=2))
                item.setToolTip("\n".join(tooltip_parts))
                if isinstance(thumb_b64, str):
                    try:
                        data = base64.b64decode(thumb_b64)
                        pixmap = QtGui.QPixmap()
                        pixmap.loadFromData(data, "PNG")
                        item.setIcon(QtGui.QIcon(pixmap))
                    except Exception:
                        pass
                self.memory_list.addItem(item)
        if hasattr(self, "memory_matches") and isinstance(self.memory_matches, QtWidgets.QPlainTextEdit):
            matches = visual.get("matches") if isinstance(visual, dict) else []
            lines: List[str] = []
            if isinstance(matches, list):
                for pack in matches:
                    if not isinstance(pack, dict):
                        continue
                    query = pack.get("query") or {}
                    label = query.get("label") or "region"
                    lines.append(f"Query: {label} {query.get('bbox')}")
                    results = pack.get("results") or []
                    for result in results:
                        if not isinstance(result, dict):
                            continue
                        score = result.get("score")
                        score_txt = f"{score:.3f}" if isinstance(score, (int, float)) else str(score)
                        lines.append(
                            f"  • {result.get('label')} @ {result.get('bbox')} score={score_txt} ts={result.get('ts')}"
                        )
                    lines.append("")
            if not lines:
                lines = ["No region matches recorded yet."]
            self.memory_matches.setPlainText("\n".join(lines))
        if hasattr(self, "timeline_view") and isinstance(self.timeline_view, QtWidgets.QPlainTextEdit):
            timeline_section = self._latest_memory_snapshot.get("timeline") or {}
            timeline_lines: List[str] = []
            summary = timeline_section.get("summary")
            if isinstance(summary, str) and summary.strip():
                timeline_lines.append(summary.strip())
            prediction = timeline_section.get("prediction") or {}
            if isinstance(prediction, dict) and prediction:
                message = prediction.get("message")
                action = prediction.get("action")
                confidence = prediction.get("confidence")
                if message:
                    if timeline_lines:
                        timeline_lines.append("")
                    timeline_lines.append(f"Hint: {message}")
                elif action:
                    hint_line = f"Hint: try {action}"
                    if isinstance(confidence, (int, float)):
                        hint_line += f" (confidence {confidence:.2f})"
                    if timeline_lines:
                        timeline_lines.append("")
                    timeline_lines.append(hint_line)
                elif timeline_lines:
                    timeline_lines.append("")
            history = timeline_section.get("history") or []
            if isinstance(history, list) and history:
                if timeline_lines:
                    timeline_lines.append("")
                timeline_lines.append("Recent transitions:")
                for item in history[:6]:
                    if not isinstance(item, dict):
                        continue
                    action = item.get("action") or "?"
                    mode = item.get("mode") or item.get("primary_mode")
                    changed = item.get("changed")
                    marker = "✓" if changed else "…"
                    score = item.get("score")
                    ts_val = item.get("ts")
                    parts = [f" • {action} {marker}"]
                    if mode:
                        parts.append(f"[{mode}]")
                    if isinstance(score, (int, float)):
                        parts.append(f"score={score:.3f}")
                    if ts_val:
                        parts.append(f"ts={ts_val}")
                    timeline_lines.append(" ".join(parts))
            if not timeline_lines:
                timeline_lines = ["No timeline data captured yet."]
            self.timeline_view.setPlainText("\n".join(timeline_lines))

    def _inspect_memories(self):
        snap = self._latest_memory_snapshot or {}
        if not snap:
            QtWidgets.QMessageBox.information(self, "Retrieved memories", "No memory retrievals recorded yet.")
            return
        lines: List[str] = []
        lines.append(f"State key: {snap.get('state_key') or 'n/a'}")
        lines.append(f"pHash query: {snap.get('phash_query') or 'n/a'}")
        vector_ready = "yes" if snap.get("vector_ready") else "no"
        text_status = snap.get("text_status") or "idle"
        lines.append(f"Vector store ready: {vector_ready} (text status: {text_status})")
        phash_matches = snap.get("phash_matches") or []
        if phash_matches:
            lines.append("")
            lines.append("Screen matches:")
            for item in phash_matches:
                ts_val = item.get("ts") or "?"
                action = item.get("action") or "?"
                changed_flag = item.get("changed")
                if changed_flag is None:
                    changed_txt = "?"
                else:
                    changed_txt = "✓" if bool(changed_flag) else "×"
                caption = str(item.get("caption") or "").strip()
                if len(caption) > 120:
                    caption = caption[:117] + "…"
                lines.append(f" • [{ts_val}] {action} ({changed_txt}) {caption}")
                ocr = str(item.get("ocr") or "").strip()
                if ocr:
                    if len(ocr) > 120:
                        ocr = ocr[:117] + "…"
                    lines.append(f"    OCR: {ocr}")
        else:
            lines.append("No screen matches were recalled.")
        text_matches = snap.get("text_matches") or []
        if text_matches:
            lines.append("")
            lines.append("Vector matches:")
            for item in text_matches[:5]:
                kind = item.get("kind") or "entry"
                path = item.get("path") or item.get("id") or item.get("title") or "?"
                score = item.get("score")
                if isinstance(score, (int, float)):
                    score_txt = f"{score:.3f}"
                else:
                    score_txt = str(score)
                lines.append(f" • ({kind}) {path} — score {score_txt}")
        text_payload = "\n".join(lines)
        dlg = QtWidgets.QDialog(self)
        dlg.setWindowTitle("Retrieved memories")
        dlg.setModal(True)
        layout = QtWidgets.QVBoxLayout(dlg)
        view = QtWidgets.QPlainTextEdit(text_payload)
        view.setReadOnly(True)
        view.setMinimumHeight(260)
        layout.addWidget(view)
        btn_box = QtWidgets.QHBoxLayout()
        btn_box.addStretch(1)
        close_btn = QtWidgets.QPushButton("Close")
        close_btn.clicked.connect(dlg.accept)
        btn_box.addWidget(close_btn)
        layout.addLayout(btn_box)
        dlg.resize(520, 360)
        dlg.exec()

    def closeEvent(self, ev: QtGui.QCloseEvent):
        try:
            self._stop_http_bridge()
            if self.agent_worker:
                self.agent_worker.stop(); self.agent_worker.wait(2000)
            if self.prefs.get("save_on_quit", True): self._save_profile_state()
        finally:
            try: self.emuThread.stop_thread()
            finally:
                if self.audio.enabled: self.audio.stop()
                super().closeEvent(ev)

# ---------------------------------- main --------------------------------------
def main(argv: Optional[Sequence[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="Virtual Game Boy launcher and tooling")
    parser.add_argument(
        "--sync-pokemon-corpus",
        action="store_true",
        help="Fetch Pokémon official/Wikipedia vocabulary and update the KnowledgeStore lexicon.",
    )
    parser.add_argument(
        "--force-pokemon-refresh",
        action="store_true",
        help="Ignore cache rate limits when syncing the Pokémon corpus.",
    )
    parser.add_argument("rom", nargs="?", help="Optional Game Boy ROM to launch immediately.")
    args = parser.parse_args(argv if argv is not None else sys.argv[1:])

    prefs = load_prefs()
    if args.sync_pokemon_corpus:
        if not prefs.get("pokemon_sync_enabled", False):
            print(
                "Pokémon corpus syncing is disabled. Set `pokemon_sync_enabled` in prefs to true to enable.",
                file=sys.stderr,
            )
            return 2
        ingestor = PokemonCorpusIngestor(cache_dir=POKEMON_CACHE, knowledge_dir=KNOWLEDGE)
        result = ingestor.sync(force=bool(args.force_pokemon_refresh))
        store = KnowledgeStore(prefs)
        refreshed = store.refresh_pokemon_lexicon()
        status_line = (
            f"Pokémon corpus synced — {result.entry_count} entries "
            f"({len(result.fetched)} fetched, {len(result.from_cache)} cached)."
        )
        print(status_line)
        print(f"KnowledgeStore now tracks {refreshed} Pokémon-specific entries.")
        if result.errors:
            print("Errors: " + ", ".join(result.errors), file=sys.stderr)
            return 1 if result.entry_count else 3
        return 0

    try:
        QtWidgets.QApplication.setAttribute(QtCore.Qt.ApplicationAttribute.AA_UseHighDpiPixmaps, True)
    except Exception:
        pass
    app = QtWidgets.QApplication(sys.argv)
    app.setApplicationName("Virtual Game Boy")
    rom_cli = Path(args.rom).expanduser() if args.rom else None
    win = VirtualGameBoy(rom_cli)
    win.show()
    return app.exec()

if __name__ == "__main__":
    sys.exit(main())
```

Virtual Game Boy — PyQt6 + PyBoy with Learning Agent

Adds (highlights):
• On-disk learning brain (ε-greedy per screen cluster using pHash + Hamming)
• Smart probe bursts after parse failures (START→A→B→SELECT→D-pad) with early-stop on change
• Cooldowns/backoff to prevent infinite loops and key spam
• Heuristics for “title/press start” and “dialog box” that are gated by learned failures
• User-teaching: when the user presses a key, the agent records before/after and learns from it
• Knowledge store (large + mini64 frames, OCR, caption), timeline summaries, optional embeddings
• RAW Info ingestion (drop files/images in Agent_Knowledge/Raw_Info → vectorized + OCR’d)
• UI polish: white-on-dark for all agent inputs, key highlight on presses, keybind editor, etc.
• HTTP bridge (/status, /frame.png, /press, /release, /start, /pause, /reset, /save_state, /load_state)
**Classes:** AudioEngine, EmuThread, BridgeHandler, BridgeServer, KnowledgeStore, RawInfoIngestor, PromptsDialog, CognitiveTask, TaskManager, Brain, MenuMappingStore, NamingMacroStore, _ObservationContext, AgentWorker, LCDCanvas, SafeComboBox, KeyCaptureDialog, KeybindsDialog, VirtualGameBoy
**Functions:** _app_dir(), _reset_log(), _excepthook(exc_type, exc, tb), ts(), sanitize(name), png_bytes_from_rgb(rgb, w, h), pHash64(img), hamming_hex(a, b), sha1_bytes(b), srgb_tint(rgb, color, strength), log_similarity_event(payload), ollama_list(), ollama_generate(model, prompt, b64_image, system), ollama_embed(model, text), load_prompts(), save_prompts(d), _kb(key, keypad), _upgrade_keybinds(raw), load_prefs(), save_prefs(p), sanitize_name(name), list_profiles(), profile_dir(name), profile_state_path(name), _normalize_directive_text(text), _iter_directive_segments(text), _score_directive(text, origin), extract_screen_directives(ocr_text, ocr_fallback), _key_to_text(keycode, keypad), main(argv)


## Module `bootstrap_launcher.py`

```python
#!/usr/bin/env python3
# bootstrap_launcher.py
# Solid source+frozen entry:
#  • If frozen: run app.
#  • If source: if deps already present, RUN APP DIRECTLY (no relaunch).
#               Otherwise, create venv, install deps, relaunch inside venv.
#  • Robust venv detection & logging; Windows-safe relaunch with PATH/VIRTUAL_ENV.

from __future__ import annotations
import sys, os, subprocess, venv, traceback
from pathlib import Path

APP_ROOT = Path(__file__).resolve().parent
ASSETS   = APP_ROOT / "Assets"; ASSETS.mkdir(exist_ok=True)
LOG      = ASSETS / "bootstrap.log"
VENV_DIR = APP_ROOT / "venv"
REQS     = APP_ROOT / "requirements.txt"

def log(msg: str):
    try:
        with LOG.open("a", encoding="utf-8") as f:
            f.write(msg.rstrip() + "\n")
    except Exception:
        pass
    try:
        print(msg, flush=True)
    except Exception:
        pass

def msgbox(title: str, text: str):
    try:
        if os.name == "nt":
            import ctypes
            MB_ICONERROR = 0x00000010
            ctypes.windll.user32.MessageBoxW(0, text, title, MB_ICONERROR)
    except Exception:
        pass

def chdir_app_root():
    try:
        os.chdir(str(APP_ROOT))
    except Exception:
        pass

def venv_python() -> Path:
    return VENV_DIR / ("Scripts/python.exe" if os.name == "nt" else "bin/python")

def _is_relative_to(p: Path, base: Path) -> bool:
    try:
        p.resolve().relative_to(base.resolve())
        return True
    except Exception:
        return False

def running_in_venv_strict() -> bool:
    exe   = Path(sys.executable).resolve()
    pref  = Path(sys.prefix).resolve()
    vroot = VENV_DIR.resolve()
    ok = _is_relative_to(exe, vroot) or _is_relative_to(pref, vroot)
    log(f"[probe] exe={exe}")
    log(f"[probe] prefix={pref}")
    log(f"[probe] venv={vroot}")
    log(f"[probe] in_venv={ok}")
    return ok

def ensure_venv() -> Path:
    if not VENV_DIR.exists():
        log(">> Creating virtual environment …")
        venv.EnvBuilder(with_pip=True, clear=False, upgrade=False).create(VENV_DIR)
    py = venv_python()
    if not py.exists():
        raise RuntimeError(f"venv python not found at {py}")
    return py

def install_requirements(py: Path):
    log(">> Upgrading pip/setuptools/wheel …")
    subprocess.check_call([str(py), "-m", "pip", "install", "--upgrade", "pip", "setuptools", "wheel"])
    if REQS.exists():
        log(">> Installing requirements.txt …")
        subprocess.check_call([str(py), "-m", "pip", "install", "-r", str(REQS)])
    else:
        log(">> Installing default runtime deps …")
        subprocess.check_call([str(py), "-m", "pip", "install",
                               "pyboy", "PyQt6", "pillow", "numpy", "pysdl2-dll", "sounddevice"])

def have_runtime_deps() -> bool:
    try:
        import PyQt6  # noqa: F401
        import pyboy  # noqa: F401
        import PIL    # noqa: F401
        import numpy  # noqa: F401
        return True
    except Exception as e:
        log("Dependency probe failed: " + repr(e))
        return False

def relaunch_inside(py: Path, stage: str):
    env = os.environ.copy()
    env["VIRTUAL_ENV"] = str(VENV_DIR.resolve())
    env["VGB_BOOTSTRAP_STAGE"] = stage
    if os.name == "nt":
        scripts = str((VENV_DIR / "Scripts").resolve())
        env["PATH"] = scripts + os.pathsep + env.get("PATH", "")
    log(f">> Re-launching inside venv: {py} (stage={stage})")
    os.execve(str(py), [str(py), str(APP_ROOT / Path(__file__).name)], env)

# Hidden-import hint so PyInstaller bundles the main module.
try:
    import VirtualGameBoy as _HINT  # noqa: F401
except Exception:
    _HINT = None

def run_app():
    try:
        if str(APP_ROOT) not in sys.path:
            sys.path.insert(0, str(APP_ROOT))
        from VirtualGameBoy import main as app_main
        app_main()
    except Exception:
        err = traceback.format_exc()
        log(err)
        msgbox("Virtual Game Boy — launcher",
               f"Failed to start VirtualGameBoy.\n\nSee log:\n{LOG}")

def main():
    chdir_app_root()
    log("=== VirtualGameBoy bootstrap ===")
    log(f"python={sys.executable}")
    log(f"cwd={Path.cwd()}")

    # If frozen EXE, just run the app.
    if getattr(sys, "frozen", False):
        run_app()
        return

    # --- SOURCE MODE ---
    # 1) If deps are already available in current interpreter → run app directly.
    #    (No relaunch → avoids any external tool messing up quoting of spaced paths.)
    if have_runtime_deps():
        log(">> Deps already available. Running app directly (no venv relaunch).")
        run_app()
        return

    # 2) Otherwise, create venv, install deps, relaunch inside venv.
    try:
        py = ensure_venv()
        install_requirements(py)
        relaunch_inside(py, stage="installed")  # never returns
        return
    except Exception:
        err = traceback.format_exc()
        log(err)
        msgbox("Virtual Game Boy — launcher",
               f"Failed to prepare venv/deps.\n\nSee log:\n{LOG}")

if __name__ == "__main__":
    main()
```

**Functions:** log(msg), msgbox(title, text), chdir_app_root(), venv_python(), _is_relative_to(p, base), running_in_venv_strict(), ensure_venv(), install_requirements(py), have_runtime_deps(), relaunch_inside(py, stage), run_app(), main()


## Module `visual_decomposition.py`

```python
"""Utility functions that break a Game Boy frame into semantic regions.

The VirtualGameBoy agent relies on a coarse yet reliable understanding of the
screen layout so downstream cognition and memory tooling can reason about the
state without decoding the entire framebuffer.  The routines in this module are
lightweight, deterministic, and require only Pillow and NumPy which are already
bundled with the project.

The main entry point :func:`decompose_frame` accepts either a ``PIL.Image`` or
an ``np.ndarray`` representing an RGB frame.  The function returns a dictionary
containing:

``frame_size``
    ``(width, height)`` tuple for the analysed frame.

``regions``
    A list of dictionaries describing the detected panes (dialogue box,
    top-level UI), cursor arrows, and the player sprite.  Each region includes a
    bounding box, detection confidence, embeddings, and base64 encoded crops so
    the agent can attach them to observations or persist them to the knowledge
    store without re-deriving thumbnails.

``stats``
    Lightweight telemetry that helps callers gauge detection confidence and is
    primarily useful for debugging/regression tests.

The heuristics are intentionally conservative: they favour precision over
recall and avoid expensive image processing so they can execute every frame
within the agent loop.
"""

from __future__ import annotations

import base64
import io
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple

import numpy as np
from PIL import Image, ImageFilter


# ---------------------------------------------------------------------------
# Dataclasses & helpers
# ---------------------------------------------------------------------------


@dataclass
class Region:
    """Representation of a detected semantic region."""

    label: str
    bbox: Tuple[int, int, int, int]
    confidence: float
    facing: Optional[str] = None
    priority: float = 0.0
    details: Dict[str, float] = field(default_factory=dict)

    def to_payload(self, frame: np.ndarray) -> Dict[str, object]:
        """Convert the region into a serialisable dictionary."""

        x, y, w, h = self.bbox
        x = int(max(0, x))
        y = int(max(0, y))
        w = int(max(1, w))
        h = int(max(1, h))
        h_frame, w_frame = frame.shape[:2]
        x2 = min(w_frame, x + w)
        y2 = min(h_frame, y + h)
        crop = frame[y:y2, x:x2]
        if crop.size == 0:
            raise ValueError("Region crop is empty")
        embedding, stats = _region_embedding(crop, (h_frame, w_frame))
        thumb = _thumbnail(Image.fromarray(crop))
        payload: Dict[str, object] = {
            "label": self.label,
            "bbox": [x, y, x2 - x, y2 - y],
            "confidence": float(max(0.0, min(1.0, self.confidence))),
            "score": float(self.priority),
            "details": {**stats, **self.details},
            "embedding": embedding,
            "crop_b64": _to_base64(Image.fromarray(crop)),
            "thumbnail_b64": _to_base64(thumb),
        }
        if self.facing:
            payload["facing"] = self.facing
        return payload


def _ensure_image(frame: Image.Image | np.ndarray) -> Image.Image:
    if isinstance(frame, Image.Image):
        return frame.convert("RGB")
    if isinstance(frame, np.ndarray):
        if frame.ndim == 2:
            arr = np.repeat(frame[:, :, None], 3, axis=2)
        elif frame.ndim == 3:
            arr = frame[:, :, :3]
        else:
            raise ValueError("Unsupported ndarray shape for frame")
        return Image.fromarray(arr.astype(np.uint8), mode="RGB")
    raise TypeError("Unsupported frame type: %r" % (type(frame),))


def _to_base64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode("ascii")


def _thumbnail(img: Image.Image, size: int = 48) -> Image.Image:
    thumb = img.copy()
    thumb.thumbnail((size, size), Image.Resampling.BILINEAR)
    return thumb


def _region_embedding(region: np.ndarray, frame_shape: Tuple[int, int]) -> Tuple[List[float], Dict[str, float]]:
    h, w = region.shape[:2]
    mean_rgb = region.mean(axis=(0, 1)) / 255.0
    std_rgb = region.std(axis=(0, 1)) / 255.0
    area_ratio = (h * w) / float(frame_shape[0] * frame_shape[1])
    embedding = [
        float(mean_rgb[0]),
        float(mean_rgb[1]),
        float(mean_rgb[2]),
        float(std_rgb.mean()),
        float(area_ratio),
    ]
    stats = {
        "mean_r": float(mean_rgb[0]),
        "mean_g": float(mean_rgb[1]),
        "mean_b": float(mean_rgb[2]),
        "std_rgb": float(std_rgb.mean()),
        "area": float(area_ratio),
    }
    return embedding, stats


def _estimate_facing(region: np.ndarray) -> Optional[str]:
    if region.size == 0:
        return None
    h, w = region.shape[:2]
    if h < 4 or w < 4:
        return None
    left = float(region[:, : w // 2].mean())
    right = float(region[:, w // 2 :].mean())
    top = float(region[: h // 2, :].mean())
    bottom = float(region[h // 2 :, :].mean())
    horiz_ratio = left / (right + 1e-3)
    vert_ratio = top / (bottom + 1e-3)
    if abs(horiz_ratio - 1.0) > 0.12:
        return "left" if horiz_ratio < 1.0 else "right"
    if abs(vert_ratio - 1.0) > 0.12:
        return "up" if vert_ratio < 1.0 else "down"
    return None


def _connected_components(
    mask: np.ndarray,
    *,
    min_area: int = 8,
    max_components: int = 8,
) -> List[Tuple[slice, slice, np.ndarray]]:
    """Return connected components for a boolean mask using 8-connectivity."""

    visited = np.zeros_like(mask, dtype=bool)
    h, w = mask.shape
    components: List[Tuple[slice, slice, np.ndarray]] = []
    for y in range(h):
        for x in range(w):
            if not mask[y, x] or visited[y, x]:
                continue
            stack = [(y, x)]
            coords: List[Tuple[int, int]] = []
            visited[y, x] = True
            while stack:
                cy, cx = stack.pop()
                coords.append((cy, cx))
                for ny in (cy - 1, cy, cy + 1):
                    if ny < 0 or ny >= h:
                        continue
                    for nx in (cx - 1, cx, cx + 1):
                        if nx < 0 or nx >= w:
                            continue
                        if visited[ny, nx] or not mask[ny, nx]:
                            continue
                        visited[ny, nx] = True
                        stack.append((ny, nx))
            if len(coords) < min_area:
                continue
            ys, xs = zip(*coords)
            y0, y1 = min(ys), max(ys) + 1
            x0, x1 = min(xs), max(xs) + 1
            region_mask = np.zeros((y1 - y0, x1 - x0), dtype=bool)
            for cy, cx in coords:
                region_mask[cy - y0, cx - x0] = True
            components.append((slice(y0, y1), slice(x0, x1), region_mask))
            if len(components) >= max_components:
                return components
    return components


# ---------------------------------------------------------------------------
# Detection heuristics
# ---------------------------------------------------------------------------


def _detect_dialogue_box(gray: np.ndarray) -> Optional[Tuple[int, int, int, int, Dict[str, float]]]:
    h, w = gray.shape
    if h == 0 or w == 0:
        return None
    bottom_band = gray[int(h * 0.45) :, :]
    if bottom_band.size == 0:
        return None
    brightness_threshold = float(np.clip(np.percentile(bottom_band, 80), 140, 255))
    binary = bottom_band >= brightness_threshold
    row_density = binary.mean(axis=1)
    if not np.any(row_density > 0.4):
        return None
    indices = np.where(row_density > 0.4)[0]
    # Select longest contiguous band near the bottom of the image.
    longest_run: Tuple[int, int] = (indices[0], indices[0])
    run_start = indices[0]
    for idx, current in enumerate(indices[1:], start=1):
        if current == indices[idx - 1] + 1:
            continue
        run = (run_start, indices[idx - 1])
        if (run[1] - run[0]) > (longest_run[1] - longest_run[0]):
            longest_run = run
        run_start = current
    final_run = (run_start, indices[-1])
    if (final_run[1] - final_run[0]) > (longest_run[1] - longest_run[0]):
        longest_run = final_run
    start_row, end_row = longest_run
    box_height = end_row - start_row + 1
    top = int(h * 0.45) + max(0, start_row - 1)
    bottom = int(h * 0.45) + min(bottom_band.shape[0], end_row + 2)
    # Expand horizontally by requiring at least 40% bright coverage per column.
    band = binary[start_row : end_row + 1, :]
    col_density = band.mean(axis=0)
    cols = np.where(col_density > 0.35)[0]
    if cols.size == 0:
        return None
    left = max(0, cols.min() - 2)
    right = min(w, cols.max() + 3)
    confidence = float(
        min(
            1.0,
            0.3 + 0.3 * (box_height / max(1, int(h * 0.3))) + 0.4 * (row_density[indices].mean()),
        )
    )
    details = {
        "row_density_mean": float(row_density.mean()),
        "row_density_max": float(row_density.max()),
        "col_density_mean": float(col_density.mean()),
        "brightness_threshold": brightness_threshold / 255.0,
    }
    return left, top, right - left, bottom - top, details | {"confidence_hint": confidence}


def _detect_ui_pane(gray: np.ndarray) -> Optional[Tuple[int, int, int, int, Dict[str, float]]]:
    h, w = gray.shape
    if h == 0 or w == 0:
        return None
    top_band = gray[: int(h * 0.35), :]
    if top_band.size == 0:
        return None
    threshold = float(np.clip(np.percentile(top_band, 65), 120, 255))
    binary = top_band >= threshold
    row_density = binary.mean(axis=1)
    indices = np.where(row_density > 0.35)[0]
    if indices.size == 0:
        return None
    # Choose band that starts near the top.
    start = indices[0]
    for idx in indices:
        if idx > start + 1:
            break
        start = idx
    end = indices[-1]
    height = end - indices[0] + 1
    top = max(0, indices[0] - 1)
    bottom = min(top_band.shape[0], end + 2)
    col_density = binary[indices[0] : end + 1, :].mean(axis=0)
    cols = np.where(col_density > 0.35)[0]
    if cols.size == 0:
        return None
    left = max(0, cols.min() - 2)
    right = min(w, cols.max() + 2)
    coverage = float(row_density[indices].mean())
    confidence = float(min(1.0, 0.25 + coverage * 0.6 + min(0.15, height / max(1, int(h * 0.25)))))
    details = {
        "row_density_mean": float(row_density.mean()),
        "row_density_max": float(row_density.max()),
        "brightness_threshold": threshold / 255.0,
    }
    return left, top, right - left, bottom - top, details | {"confidence_hint": confidence}


def _detect_player_sprite(
    frame: np.ndarray,
    edge_mask: np.ndarray,
    *,
    max_components: int = 12,
) -> Optional[Tuple[int, int, int, int, float, Optional[str], Dict[str, float]]]:
    h, w = frame.shape[:2]
    components = _connected_components(edge_mask, min_area=18, max_components=max_components)
    if not components:
        return None
    center_x, center_y = w / 2.0, h / 2.0
    best: Optional[Tuple[int, int, int, int, float, Optional[str], Dict[str, float]]] = None
    best_score: Optional[float] = None
    for ys, xs, comp_mask in components:
        x0, x1 = xs.start, xs.stop
        y0, y1 = ys.start, ys.stop
        width = x1 - x0
        height = y1 - y0
        area = width * height
        if area < 60 or area > (w * h * 0.3):
            continue
        cx = (x0 + x1) / 2.0
        cy = (y0 + y1) / 2.0
        distance = np.hypot(cx - center_x, cy - center_y)
        density = float(comp_mask.mean())
        score = distance + (1.4 - density) * 20.0
        crop = frame[y0:y1, x0:x1]
        facing = _estimate_facing(crop)
        details = {
            "edge_density": density,
            "component_area": float(area) / float(w * h),
        }
        if best_score is None or score < best_score:
            best_score = score
            best = (x0, y0, width, height, density, facing, details)
    if best is None:
        return None
    x0, y0, width, height, density, facing, details = best
    confidence = float(min(1.0, 0.45 + density * 0.8))
    details = {**details, "confidence_hint": confidence}
    return x0, y0, width, height, confidence, facing, details


def _detect_cursor_arrow(
    dialogue_bbox: Tuple[int, int, int, int],
    edge_mask: np.ndarray,
) -> Optional[Tuple[int, int, int, int, float, Dict[str, float]]]:
    x, y, w, h = dialogue_bbox
    region = edge_mask[y : y + h, x : x + w]
    if region.size == 0:
        return None
    components = _connected_components(region, min_area=6, max_components=6)
    if not components:
        return None
    for ys, xs, comp_mask in components:
        x0 = x + xs.start
        x1 = x + xs.stop
        y0 = y + ys.start
        y1 = y + ys.stop
        width = x1 - x0
        height = y1 - y0
        if width < 4 or height < 4:
            continue
        if width > 24 or height > 20:
            continue
        density = float(comp_mask.mean())
        if density < 0.18:
            continue
        confidence = float(min(1.0, 0.4 + density * 1.2))
        details = {
            "edge_density": density,
            "relative_position": float((y1 - y) / max(1, h)),
            "confidence_hint": confidence,
        }
        return x0, y0, width, height, confidence, details
    return None


# ---------------------------------------------------------------------------
# Public API
# ---------------------------------------------------------------------------


def decompose_frame(frame: Image.Image | np.ndarray) -> Dict[str, object]:
    """Break a frame into semantic regions with metadata ready for the agent."""

    image = _ensure_image(frame)
    width, height = image.size
    arr = np.asarray(image, dtype=np.uint8)
    gray = np.dot(arr[..., :3], [0.299, 0.587, 0.114]).astype(np.float32)

    regions: List[Region] = []
    stats: Dict[str, float] = {}

    dialogue = _detect_dialogue_box(gray)
    if dialogue is not None:
        x, y, w_box, h_box, details = dialogue
        confidence = details.pop("confidence_hint", 0.6)
        regions.append(
            Region(
                label="dialogue_box",
                bbox=(x, y, w_box, h_box),
                confidence=confidence,
                priority=float(w_box * h_box),
                details=details,
            )
        )
        stats["dialogue_density"] = float(details.get("row_density_mean", 0.0))

    ui_pane = _detect_ui_pane(gray)
    if ui_pane is not None:
        x, y, w_box, h_box, details = ui_pane
        confidence = details.pop("confidence_hint", 0.6)
        regions.append(
            Region(
                label="ui_pane",
                bbox=(x, y, w_box, h_box),
                confidence=confidence,
                priority=float(w_box * h_box),
                details=details,
            )
        )
        stats["ui_density"] = float(details.get("row_density_mean", 0.0))

    edges = image.convert("L").filter(ImageFilter.FIND_EDGES)
    edge_arr = np.asarray(edges, dtype=np.float32)
    edge_threshold = float(np.clip(np.percentile(edge_arr, 75), 20.0, 255.0))
    edge_mask = edge_arr >= edge_threshold
    stats["edge_density"] = float(edge_mask.mean())

    sprite = _detect_player_sprite(arr, edge_mask)
    if sprite is not None:
        x, y, w_box, h_box, confidence, facing, details = sprite
        regions.append(
            Region(
                label="player_sprite",
                bbox=(x, y, w_box, h_box),
                confidence=confidence,
                facing=facing,
                priority=1.0 - details.get("component_area", 0.0),
                details=details,
            )
        )

    if dialogue is not None:
        arrow = _detect_cursor_arrow((dialogue[0], dialogue[1], dialogue[2], dialogue[3]), edge_mask)
        if arrow is not None:
            x, y, w_box, h_box, confidence, details = arrow
            regions.append(
                Region(
                    label="cursor_arrow",
                    bbox=(x, y, w_box, h_box),
                    confidence=confidence,
                    priority=details.get("edge_density", 0.0),
                    details=details,
                )
            )

    regions.sort(key=lambda r: r.priority, reverse=True)

    payload_regions: List[Dict[str, object]] = []
    for region in regions:
        try:
            payload_regions.append(region.to_payload(arr))
        except Exception:
            continue

    stats["component_count"] = float(len(payload_regions))
    stats["frame_mean"] = float(gray.mean() / 255.0)
    stats["frame_std"] = float(gray.std() / 255.0)

    return {
        "frame_size": (width, height),
        "regions": payload_regions,
        "stats": stats,
    }


__all__ = ["decompose_frame"]
```

Utility functions that break a Game Boy frame into semantic regions.

The VirtualGameBoy agent relies on a coarse yet reliable understanding of the
screen layout so downstream cognition and memory tooling can reason about the
state without decoding the entire framebuffer.  The routines in this module are
lightweight, deterministic, and require only Pillow and NumPy which are already
bundled with the project.

The main entry point :func:`decompose_frame` accepts either a ``PIL.Image`` or
an ``np.ndarray`` representing an RGB frame.  The function returns a dictionary
containing:

``frame_size``
    ``(width, height)`` tuple for the analysed frame.

``regions``
    A list of dictionaries describing the detected panes (dialogue box,
    top-level UI), cursor arrows, and the player sprite.  Each region includes a
    bounding box, detection confidence, embeddings, and base64 encoded crops so
    the agent can attach them to observations or persist them to the knowledge
    store without re-deriving thumbnails.

``stats``
    Lightweight telemetry that helps callers gauge detection confidence and is
    primarily useful for debugging/regression tests.

The heuristics are intentionally conservative: they favour precision over
recall and avoid expensive image processing so they can execute every frame
within the agent loop.
**Classes:** Region
**Functions:** _ensure_image(frame), _to_base64(img), _thumbnail(img, size), _region_embedding(region, frame_shape), _estimate_facing(region), _connected_components(mask), _detect_dialogue_box(gray), _detect_ui_pane(gray), _detect_player_sprite(frame, edge_mask), _detect_cursor_arrow(dialogue_bbox, edge_mask), decompose_frame(frame)


## Module `tests\test_action_verification.py`

```python
import types
import unittest
import tempfile
from pathlib import Path
from unittest import mock

import numpy as np

from tests import test_brain_confidence as brain_confidence

agent_module = brain_confidence.agent_module
Brain = brain_confidence.Brain
AgentWorker = agent_module.AgentWorker


class ActionVerificationTests(unittest.TestCase):
    def _make_worker_stub(self) -> AgentWorker:
        worker = object.__new__(AgentWorker)
        worker.timeline_buf = []
        worker.status = types.SimpleNamespace(emit=lambda *args, **kwargs: None)
        worker.log = types.SimpleNamespace(emit=lambda *args, **kwargs: None)
        worker._last_sprite_payload = {}
        worker._pending_mismatch_escalation = None
        worker._compute_expected_deltas = AgentWorker._compute_expected_deltas.__get__(worker, AgentWorker)
        worker._verify_action_outcome = AgentWorker._verify_action_outcome.__get__(worker, AgentWorker)
        worker._classify_screen = lambda **_kwargs: {
            "mode": "menu",
            "cursor_index": 0,
            "line_count": 2,
            "options": ["YES", "NO"],
        }
        return worker

    def test_mismatch_penalizes_confidence(self) -> None:
        worker = self._make_worker_stub()
        before_screen = {"mode": "menu", "cursor_index": 0, "options": ["YES", "NO"], "line_count": 2}
        expectation = worker._compute_expected_deltas(
            "DOWN",
            screen_state=before_screen,
            mapping_summary=None,
            sprite_payload=None,
        )
        after_frame = (np.zeros((4, 4, 3), dtype=np.uint8).tobytes(), 4, 4)
        with mock.patch.object(agent_module, "decompose_frame", return_value={"regions": []}):
            verification = worker._verify_action_outcome(
                action="DOWN",
                expectation=expectation,
                before_screen=before_screen,
                after_frame=after_frame,
                movement={"dx": 0.0, "dy": 0.0, "magnitude": 0.0},
                changed=True,
                elapsed=0.2,
            )
        self.assertEqual("mismatch", verification.get("classification"))

        with tempfile.TemporaryDirectory() as tmp:
            brain_path = Path(tmp) / "brain.json"
            brain = Brain(brain_path)
            state = brain.get_state("ffffffffffffffff")
            for _ in range(3):
                brain.record_result(
                    state,
                    "DOWN",
                    changed=True,
                    movement={"magnitude": 2.0},
                    elapsed=0.2,
                    verification={"classification": "match"},
                )
            baseline = brain.confidence_profile(state, "DOWN")
            brain.record_result(
                state,
                "DOWN",
                changed=True,
                movement={"magnitude": 2.0},
                elapsed=0.2,
                verification=verification,
            )
            updated = brain.confidence_profile(state, "DOWN")
            self.assertLess(updated["confidence"], baseline["confidence"])
            self.assertGreaterEqual(updated["failures"], baseline["failures"])


if __name__ == "__main__":
    unittest.main()
```

**Classes:** ActionVerificationTests


## Module `tests\test_brain_confidence.py`

```python
import importlib.util
import json
import sys
import tempfile
import types
import unittest
from pathlib import Path

MODULE_PATH = Path(__file__).resolve().parents[1] / "Agent-VirtualGameBoy.py"
sys.path.insert(0, str(MODULE_PATH.parent))

# Provide a lightweight PyQt6 stub so the agent module can load in headless test environments.
pyqt_stub = types.ModuleType("PyQt6")
class _DynamicNamespace(types.SimpleNamespace):
    def __getattr__(self, name):  # type: ignore[override]
        value = type(name, (), {})
        setattr(self, name, value)
        return value


class _StubSignal:
    def __init__(self, *_args, **_kwargs):
        pass

    def connect(self, *_args, **_kwargs):
        return None

    def emit(self, *_args, **_kwargs):
        return None


def _pyqt_signal(*_args, **_kwargs):
    return _StubSignal()


qt_keys = types.SimpleNamespace(
    Key_W=0,
    Key_S=1,
    Key_A=2,
    Key_D=3,
    Key_Left=4,
    Key_Right=5,
    Key_Backspace=6,
    Key_Return=7,
    Key_Up=8,
    Key_Down=9,
    Key_PageUp=10,
    Key_PageDown=11,
    Key_Home=12,
    Key_End=13,
    Key_Escape=14,
)
pyqt_stub.QtCore = types.SimpleNamespace(
    QThread=object,
    QObject=object,
    Qt=types.SimpleNamespace(Key=qt_keys),
    pyqtSignal=_pyqt_signal,
    pyqtSlot=lambda *_args, **_kwargs: (lambda func: func),
)
pyqt_stub.QtGui = _DynamicNamespace()
pyqt_stub.QtWidgets = _DynamicNamespace()
sys.modules.setdefault("PyQt6", pyqt_stub)
sys.modules.setdefault("PyQt6.QtCore", pyqt_stub.QtCore)
sys.modules.setdefault("PyQt6.QtGui", pyqt_stub.QtGui)
sys.modules.setdefault("PyQt6.QtWidgets", pyqt_stub.QtWidgets)


class _StubResponse:
    def __init__(self, data=None):
        self._data = data or {}
        self.status_code = 200

    def raise_for_status(self) -> None:
        return None

    def json(self) -> dict:
        return dict(self._data)


def _stub_get(*_args, **_kwargs):
    return _StubResponse()


def _stub_post(*_args, **_kwargs):
    return _StubResponse()


requests_stub = types.ModuleType("requests")
requests_stub.get = _stub_get
requests_stub.post = _stub_post
sys.modules.setdefault("requests", requests_stub)

spec = importlib.util.spec_from_file_location("agent_virtualgameboy", MODULE_PATH)
assert spec and spec.loader
agent_module = types.ModuleType(spec.name)
agent_module.__file__ = str(MODULE_PATH)
sys.modules[spec.name] = agent_module
spec.loader.exec_module(agent_module)  # type: ignore[arg-type]
Brain = agent_module.Brain
LEARNABLE = agent_module.LEARNABLE


class BrainConfidenceTests(unittest.TestCase):
    def test_confidence_profile_adjusts_cadence(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            brain_path = Path(tmp) / "brain.json"
            brain = Brain(brain_path)
            state = brain.get_state("ffffffffffffffff")
            self.assertIn("A", LEARNABLE)

            # Initial profile should default to neutral cadence
            initial = brain.confidence_profile(state, "A")
            self.assertGreaterEqual(initial["hold_scale"], 1.0)
            self.assertGreaterEqual(initial["repeat_delay_s"], 0.65)

            # Simulate repeated successes with fast elapsed times
            for _ in range(6):
                brain.record_result(state, "A", changed=True, movement={"magnitude": 2.0}, elapsed=0.2)

            success_profile = brain.confidence_profile(state, "A")
            self.assertGreaterEqual(success_profile["confidence"], 0.7)
            self.assertLess(success_profile["hold_scale"], 1.0)
            self.assertLess(success_profile["repeat_delay_s"], 0.6)
            self.assertLessEqual(success_profile["avg_elapsed"], 0.21)

            # Simulate repeated failures with slower elapsed times
            for _ in range(7):
                brain.record_result(state, "B", changed=False, movement={}, elapsed=0.8)

            failure_profile = brain.confidence_profile(state, "B")
            self.assertLessEqual(failure_profile["confidence"], 0.5)
            self.assertGreater(failure_profile["hold_scale"], 1.1)
            self.assertGreater(failure_profile["repeat_delay_s"], 1.0)

            # Ensure metadata persisted to disk includes new keys
            saved = json.loads(brain_path.read_text("utf-8"))
            state_data = saved[state]
            self.assertIn("recent", state_data["stats"]["A"])
            self.assertIn("recent", state_data["stats"]["B"])
            self.assertIn("screen_modes", state_data["stats"]["A"])
            self.assertIsInstance(state_data["stats"]["A"]["screen_modes"], dict)
            self.assertIn("alternate_success", state_data["stats"]["A"])
            self.assertIsInstance(state_data["stats"]["A"]["alternate_success"], dict)


if __name__ == "__main__":
    unittest.main()
```

**Classes:** _DynamicNamespace, _StubSignal, _StubResponse, BrainConfidenceTests
**Functions:** _pyqt_signal(), _stub_get(), _stub_post()


## Module `tests\test_directive_extractor.py`

```python
from tests import test_brain_confidence as brain_confidence

extract_screen_directives = brain_confidence.agent_module.extract_screen_directives


def _goals(payload):
    return [entry["goal"] for entry in payload]


def test_tutorial_prompt_detected():
    directives = extract_screen_directives(
        "Press START to begin your adventure!",
        None,
        sensitivity="normal",
    )
    assert directives, "Expected at least one directive for tutorial prompt"
    goals = _goals(directives)
    assert any("Press START" in goal for goal in goals)
    directive = directives[0]
    assert directive["source"] == "screen"
    assert directive["provenance"]["tags"], "Expected provenance tags"


def test_quest_marker_detected_low_sensitivity():
    text = "Objective: Find Professor Oak before leaving town."
    directives = extract_screen_directives(text, None, sensitivity="low")
    goals = _goals(directives)
    assert any("Objective" in goal for goal in goals)
    quest = directives[0]
    assert "quest" in quest.get("needs", []) or "quest" in quest.get("provenance", {}).get("tags", [])


def test_optional_hint_respects_sensitivity():
    fallback = {"lines": [{"hint": "Hint: Press B to open the menu."}]}
    low = extract_screen_directives(None, fallback, sensitivity="low")
    high = extract_screen_directives(None, fallback, sensitivity="high")
    assert not low, "Low sensitivity should ignore optional hints"
    assert any("Press B" in goal for goal in _goals(high)), "High sensitivity should capture hint"
```

**Functions:** _goals(payload), test_tutorial_prompt_detected(), test_quest_marker_detected_low_sensitivity(), test_optional_hint_respects_sensitivity()


## Module `tests\test_menu_mappings.py`

```python
import json
import tempfile
import unittest
from collections import deque
from pathlib import Path

from tests.test_brain_confidence import agent_module


class DummyEmuThread:
    def cmd_input_press(self, *_args, **_kwargs):
        return None

    def cmd_input_release(self, *_args, **_kwargs):
        return None


class DummyApp:
    def __init__(self):
        self.frame_deque = deque()
        self.prefs = {}
        self.emuThread = DummyEmuThread()

    def is_running(self) -> bool:
        return False


class MenuMappingPersistenceTests(unittest.TestCase):
    def test_menu_mapping_persists_and_guides_actions(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            mapping_path = Path(tmp) / "menu_mappings.json"
            original_path = agent_module.MENU_MAPPINGS_PATH
            agent_module.MENU_MAPPINGS_PATH = mapping_path
            try:
                worker = agent_module.AgentWorker(DummyApp())
                worker.menu_mappings = agent_module.MenuMappingStore(mapping_path)
                state_key = "cluster-demo"
                screen_state = {
                    "mode": "menu",
                    "options": ["New Game", "Continue", "Options"],
                    "cursor_index": 1,
                }
                for _ in range(3):
                    worker.menu_mappings.record_interaction(state_key, screen_state, "A", True)
                for _ in range(2):
                    worker.menu_mappings.record_interaction(state_key, screen_state, "START", True)
                reloaded = agent_module.MenuMappingStore(mapping_path)
                actions = reloaded.best_actions(state_key, screen_state)
                self.assertGreaterEqual(len(actions), 2)
                self.assertEqual(actions[0]["action"], "A")
                self.assertEqual(actions[0]["success"], 3)
                self.assertEqual(actions[1]["action"], "START")
                summary = reloaded.summary_for(state_key, screen_state)
                self.assertIsNotNone(summary)
                assert summary is not None
                self.assertEqual(summary["primary"]["action"], "A")
                self.assertEqual(summary["primary"]["success"], 3)
                self.assertTrue(any(alt["action"] == "START" for alt in summary.get("alternates", [])))
                worker.menu_mappings = reloaded
                global_cool = {act: 0.0 for act in agent_module.LEARNABLE}
                choice = worker._resolve_mapping_choice(state_key, screen_state, global_cool)
                self.assertIsNotNone(choice)
                assert choice is not None
                self.assertEqual(choice["choice"]["action"], "A")
                self.assertTrue(any(alt.get("action") == "START" for alt in choice.get("alternates", [])))
                next_choice = worker._resolve_mapping_choice(state_key, screen_state, global_cool)
                self.assertIsNotNone(next_choice)
                assert next_choice is not None
                self.assertEqual(next_choice["choice"]["action"], "START")
                data = json.loads(mapping_path.read_text("utf-8"))
                self.assertIn(state_key, data)
            finally:
                agent_module.MENU_MAPPINGS_PATH = original_path


if __name__ == "__main__":
    unittest.main()
```

**Classes:** DummyEmuThread, DummyApp, MenuMappingPersistenceTests


## Module `tests\test_naming_macros.py`

```python
import types
from collections import deque

import pytest
from PIL import Image, ImageDraw

from tests.test_brain_confidence import agent_module

AgentWorker = agent_module.AgentWorker
NamingMacroStore = agent_module.NamingMacroStore


def _synth_naming_image(cursor=(0, 0)) -> Image.Image:
    """Generate a lightweight naming layout without relying on binary fixtures."""

    width, height = 160, 144
    base_color = 220
    cell_width, cell_height = 11, 9
    gap_x, gap_y = 5, 8
    margin_x, margin_y = 12, 18

    rows = 4
    cols = 8

    image = Image.new("L", (width, height), color=base_color)
    draw = ImageDraw.Draw(image)

    for row in range(rows):
        for col in range(cols):
            x0 = margin_x + col * (cell_width + gap_x)
            y0 = margin_y + row * (cell_height + gap_y)
            x1 = x0 + cell_width
            y1 = y0 + cell_height
            fill = 80

            if (row, col) == cursor:
                fill = 25
            elif col == cols - 1 and row == 0:
                fill = 60  # backspace button analogue
            elif col == cols - 1 and row == rows - 1:
                fill = 70  # confirm button analogue

            draw.rectangle([x0, y0, x1, y1], fill=fill)

    return image.convert("RGB")


def _make_worker() -> AgentWorker:
    worker = agent_module.AgentWorker.__new__(agent_module.AgentWorker)
    worker.pending_actions = deque()
    worker._current_plan_meta = None
    worker.timeline_buf = []
    worker._naming_action_buffer = []
    worker._naming_active_state = None
    worker._reasoning_tag = "test"
    return worker


def test_classify_screen_detects_naming_grid():
    worker = _make_worker()
    img = _synth_naming_image(cursor=(1, 3))
    state = worker._classify_screen(image=img, ocr_text=None, caption=None, ocr_fallback=None)
    assert state["mode"] == "naming"
    grid = state["grid"]
    assert grid["row_count"] >= 3
    assert any(cell["mean"] < 140 for cell in grid["cells"])
    buttons = state.get("buttons", {})
    assert "backspace" in buttons


def test_naming_macro_store_prefers_fast_variant(tmp_path):
    worker = _make_worker()
    img = _synth_naming_image(cursor=(0, 2))
    state = worker._classify_screen(image=img, ocr_text=None, caption=None, ocr_fallback=None)
    store = NamingMacroStore(tmp_path / "macros.json")
    store.update_layout("stateA", state)
    slow = [{"name": "RIGHT", "duration_ms": 200}, {"name": "A", "duration_ms": 180}]
    fast = [{"name": "RIGHT", "duration_ms": 120}, {"name": "A", "duration_ms": 100}]
    sig = state.get("grid_signature")
    store.record_macro(
        state_key="stateA",
        target_name="Ash",
        actions=slow,
        total_ms=380,
        layout_signature=sig,
        success=True,
    )
    store.record_macro(
        state_key="stateA",
        target_name="Ash",
        actions=fast,
        total_ms=220,
        layout_signature=sig,
        success=True,
    )
    preferred = store.preferred_macro("stateA", target_name="Ash", layout_signature=sig)
    assert preferred is not None
    assert pytest.approx(preferred["total_ms"]) == 220
    assert preferred["actions"][0]["duration_ms"] <= 120


def test_try_queue_naming_macro(tmp_path):
    worker = _make_worker()
    img = _synth_naming_image(cursor=(3, 7))
    screen_state = worker._classify_screen(image=img, ocr_text=None, caption=None, ocr_fallback=None)
    store = NamingMacroStore(tmp_path / "macros.json")
    store.update_layout("cluster1", screen_state)
    actions = [
        {"name": "RIGHT", "duration_ms": 120},
        {"name": "DOWN", "duration_ms": 120},
        {"name": "A", "duration_ms": 150},
    ]
    store.record_macro(
        state_key="cluster1",
        target_name="Red",
        actions=actions,
        total_ms=390,
        layout_signature=screen_state.get("grid_signature"),
        success=True,
    )
    plan_holder = {}

    def fake_set_pending_plan(self, steps, reason, source):
        plan_holder["steps"] = steps
        plan_holder["reason"] = reason
        plan_holder["source"] = source
        return True

    worker.naming_macros = store
    worker.log = types.SimpleNamespace(emit=lambda _msg: None)
    worker._set_pending_plan = types.MethodType(fake_set_pending_plan, worker)
    worker._queue_exploration_plan = lambda *args, **kwargs: True
    queued = worker._try_queue_naming_macro("cluster1", screen_state, target="Red")
    assert queued is True
    assert plan_holder["source"] == "naming_macro"
    durations = [step["duration_ms"] for step in plan_holder["steps"]]
    assert all(40 <= dur <= 4000 for dur in durations)
    assert plan_holder["steps"][0]["name"] == "RIGHT"

    # layout mismatch triggers exploration fallback
    worker.pending_actions.clear()
    plan_holder.clear()
    mismatch_state = dict(screen_state)
    mismatch_state["grid_signature"] = "different"
    queued = worker._try_queue_naming_macro("cluster1", mismatch_state, target="Red")
    assert queued is False
```

**Functions:** _synth_naming_image(cursor), _make_worker(), test_classify_screen_detects_naming_grid(), test_naming_macro_store_prefers_fast_variant(tmp_path), test_try_queue_naming_macro(tmp_path)


## Module `tests\test_operator_pipeline.py`

```python
import time

from tools.operator_pipeline import ObservationOperator, OperatorAggregator, OperatorResult


def test_operator_aggregator_concurrent_merge():
    aggregator = OperatorAggregator()

    def fast_operator() -> OperatorResult:
        time.sleep(0.05)
        return OperatorResult(
            name="fast",
            summary="fast-path",
            confidence=0.6,
            payload={"proposal": {"action": "A", "confidence": 0.6, "reason": "fast"}},
        )

    def slow_operator() -> OperatorResult:
        time.sleep(0.2)
        return OperatorResult(
            name="slow",
            summary="slow-path",
            confidence=0.8,
            payload={"proposal": {"action": "B", "confidence": 0.9, "reason": "slow"}},
        )

    def failing_operator() -> OperatorResult:
        time.sleep(0.1)
        raise RuntimeError("boom")

    operators = [
        ObservationOperator(name="fast", func=fast_operator),
        ObservationOperator(name="slow", func=slow_operator),
        ObservationOperator(name="failing", func=failing_operator),
    ]

    start = time.perf_counter()
    results = aggregator.run_group(operators, timeout=2.0)
    elapsed = time.perf_counter() - start

    assert elapsed < 0.5, f"operators did not execute concurrently (elapsed={elapsed:.3f}s)"
    assert set(results) == {"fast", "slow", "failing"}
    assert results["failing"].error is not None
    assert results["fast"].payload["proposal"]["action"] == "A"
    assert results["slow"].payload["proposal"]["action"] == "B"

    bundle = aggregator.assemble(results)
    assert bundle.health["total"] == 3
    assert bundle.health["failed"] == 1
    assert bundle.health["succeeded"] == 2
    assert bundle.action_proposal["action"] == "B"
    assert bundle.confidence < 0.7  # failure penalty applied

    bundle_dict = bundle.to_dict()
    assert "slow" in bundle_dict["results"]
    assert bundle_dict["results"]["slow"]["summary"] == "slow-path"
```

**Functions:** test_operator_aggregator_concurrent_merge()


## Module `tests\test_pokemon_ingest.py`

```python
import tempfile
import unittest
from pathlib import Path

from tools.pokemon_ingest import PokemonCorpusIngestor


class PokemonIngestScopeTests(unittest.TestCase):
    def test_off_topic_domains_are_rejected(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            cache_dir = Path(tmp) / "cache"
            knowledge_dir = Path(tmp) / "knowledge"
            ingestor = PokemonCorpusIngestor(cache_dir=cache_dir, knowledge_dir=knowledge_dir)

            self.assertFalse(ingestor.is_allowed_url("https://example.com/pokemon"))
            self.assertFalse(ingestor.is_allowed_url("ftp://pokemon.com/resource"))
            self.assertTrue(
                ingestor.is_allowed_url(
                    "https://www.pokemon.com/us/pokemon-video-games/pokemon-red-version-blue-version/"
                )
            )
            self.assertTrue(
                ingestor.is_allowed_url("https://en.wikipedia.org/wiki/Pok%C3%A9mon_Red_and_Blue")
            )


if __name__ == "__main__":
    unittest.main()
```

**Classes:** PokemonIngestScopeTests


## Module `tests\test_similarity_thresholds.py`

```python
import importlib
import tempfile
from collections import defaultdict
from pathlib import Path
import unittest

try:
    brain_confidence_module = importlib.import_module("tests.test_brain_confidence")
except ModuleNotFoundError:
    brain_confidence_module = importlib.import_module("test_brain_confidence")
agent_module = brain_confidence_module.agent_module

Brain = agent_module.Brain
KnowledgeStore = agent_module.KnowledgeStore


def _mutate_phash(base: str, mask: int) -> str:
    value = (int(base, 16) ^ mask) & ((1 << 64) - 1)
    return f"{value:016x}"


class SimilarityThresholdTests(unittest.TestCase):
    def test_brain_threshold_reacts_to_feedback(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            brain_path = Path(tmp) / "brain.json"
            prefs = {
                "brain_phash_threshold_min": 3,
                "brain_phash_threshold_max": 10,
                "brain_phash_threshold_default": 4,
            }
            brain = Brain(brain_path, prefs=prefs)
            base_state = brain.get_state("0000000000000000")

            close_hash = _mutate_phash("0000000000000000", 0b1111)
            for _ in range(4):
                brain.note_similarity_feedback(base_state, close_hash, True)

            snapshot = brain.threshold_snapshot(base_state)
            self.assertGreaterEqual(snapshot["current"], 5)
            self.assertLessEqual(snapshot["current"], prefs["brain_phash_threshold_max"])

            far_hash = _mutate_phash("0000000000000000", 0xFFFF)
            for _ in range(4):
                brain.note_similarity_feedback(base_state, far_hash, False)

            updated = brain.threshold_snapshot(base_state)
            self.assertLessEqual(updated["current"], snapshot["current"])
            self.assertGreaterEqual(updated["current"], prefs["brain_phash_threshold_min"])

            events = brain.drain_threshold_events()
            self.assertIsInstance(events, list)

    def test_knowledge_threshold_tracks_cluster_errors(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            state_path = Path(tmp) / "cluster_state.json"
            prefs = {
                "knowledge_phash_threshold_min": 4,
                "knowledge_phash_threshold_max": 12,
                "knowledge_phash_threshold_default": 6,
            }
            store = KnowledgeStore(prefs, state_path=state_path)
            store.phash_clusters = defaultdict(list)
            store._cluster_thresholds.clear()
            store._cluster_errors.clear()
            store._cluster_last_distance.clear()
            store._cluster_clean_streaks.clear()

            base = "0000000000000000"
            store.phash_clusters[base] = []
            store._ensure_cluster_defaults(base)

            close_hash = _mutate_phash(base, 0b1111)
            for _ in range(4):
                assigned = store._assign_cluster_key(close_hash, changed=True)
                self.assertEqual(assigned, base)

            snapshot = store.cluster_threshold_snapshot(base)
            self.assertGreaterEqual(snapshot["current"], prefs["knowledge_phash_threshold_default"] + 1)

            far_hash = _mutate_phash(base, 0xFFFF)
            for _ in range(4):
                assigned = store._assign_cluster_key(far_hash, changed=False)
                self.assertEqual(assigned, far_hash)

            snapshot2 = store.cluster_threshold_snapshot(base)
            self.assertLessEqual(snapshot2["current"], snapshot["current"])
            self.assertGreaterEqual(snapshot2["current"], prefs["knowledge_phash_threshold_min"])

            events = store.drain_threshold_events()
            self.assertIsInstance(events, list)


if __name__ == "__main__":
    unittest.main()
```

**Classes:** SimilarityThresholdTests
**Functions:** _mutate_phash(base, mask)


## Module `tests\test_timeline_manager.py`

```python
from pathlib import Path
from typing import Any, Dict, List

import sys

import pytest

sys.path.append(str(Path(__file__).resolve().parents[1]))

from tools.timeline_manager import TimelineManager


class DummyKnowledgeStore:
    def __init__(self) -> None:
        self.windows: List[Dict[str, Any]] = []

    def record_timeline_window(self, payload: Dict[str, Any]) -> None:
        self.windows.append(dict(payload))


def make_event_kwargs(ts: str, action: str, mode: str, changed: bool = True) -> Dict[str, Any]:
    return {
        "ts": ts,
        "action": action,
        "duration_ms": 120,
        "changed": changed,
        "source": "test",
        "before_digest": f"before-{ts}",
        "after_digest": f"after-{ts}",
        "movement": {},
        "state_key": f"state-{ts}",
        "before_screen": {"mode": mode},
        "after_screen": {"mode": mode},
    }


def test_scored_history_respects_decay():
    ks = DummyKnowledgeStore()
    manager = TimelineManager(knowledge_store=ks, horizon=5, decay=0.5, window_size=3)
    manager.record_transition(**make_event_kwargs("1", "A", "dialogue"))
    manager.record_transition(**make_event_kwargs("2", "B", "menu"))
    manager.record_transition(**make_event_kwargs("3", "UP", "overworld", changed=False))

    history = manager.scored_history()
    assert pytest.approx(history[0]["score"], rel=1e-6) == 1.0
    assert pytest.approx(history[1]["score"], rel=1e-6) == 0.5
    assert pytest.approx(history[2]["score"], rel=1e-6) == 0.25


def test_predictive_hint_prefers_recent_dialogue_success():
    manager = TimelineManager(horizon=6, decay=0.6, window_size=3)
    manager.record_transition(**make_event_kwargs("1", "A", "dialogue"))
    manager.record_transition(**make_event_kwargs("2", "A", "dialogue"))

    summary = manager.recent_summary()
    assert summary == "last dialogue advanced after 2×A"

    hint = manager.predictive_hint()
    assert hint["action"] == "A"
    assert hint["mode"] == "dialogue"
    assert "Dialogue" in hint.get("message", "")
    assert hint["confidence"] > 0


def test_pruning_archives_windows():
    ks = DummyKnowledgeStore()
    manager = TimelineManager(knowledge_store=ks, horizon=2, decay=0.8, window_size=1)
    manager.record_transition(**make_event_kwargs("1", "A", "dialogue"))
    manager.record_transition(**make_event_kwargs("2", "B", "menu"))
    manager.record_transition(**make_event_kwargs("3", "A", "dialogue", changed=False))

    assert len(manager.scored_history()) == 2
    assert ks.windows, "Expected timeline windows to be recorded on prune"
    recorded = ks.windows[0]
    assert recorded["start_ts"] == "1"
    assert recorded["end_ts"] == "1"
    assert any("A×1" in entry for entry in recorded["actions"])


def test_annotation_updates_after_screen():
    manager = TimelineManager(horizon=3, decay=0.7, window_size=2)
    manager.record_transition(**make_event_kwargs("1", "A", "dialogue"))
    manager.annotate_screen_state(digest="after-1", screen_state={"mode": "menu", "options": ["Start"]})
    history = manager.scored_history(limit=1)
    assert history[0]["after_screen"]["mode"] == "menu"
    assert "options" in history[0]["after_screen"]
```

**Classes:** DummyKnowledgeStore
**Functions:** make_event_kwargs(ts, action, mode, changed), test_scored_history_respects_decay(), test_predictive_hint_prefers_recent_dialogue_success(), test_pruning_archives_windows(), test_annotation_updates_after_screen()


## Module `tests\test_visual_decomposition.py`

```python
import base64
import json
import sys
from pathlib import Path

import pytest
from PIL import Image, ImageDraw

sys.path.insert(0, str(Path(__file__).resolve().parents[1]))
from visual_decomposition import decompose_frame
from tests.test_brain_confidence import agent_module


def build_synthetic_frame(width: int = 160, height: int = 144) -> Image.Image:
    """Create a procedurally-generated frame with canonical UI regions."""

    frame = Image.new("RGB", (width, height), (32, 64, 96))
    draw = ImageDraw.Draw(frame)

    # Top HUD / UI pane
    hud_bottom = int(height * 0.27)
    draw.rectangle((0, 0, width - 1, hud_bottom), fill=(208, 210, 218))

    # Dialogue box region near the bottom
    dialogue_top = int(height * 0.65)
    draw.rectangle((0, dialogue_top, width - 1, height - 1), fill=(232, 232, 240))

    # Add border lines to boost edge detection
    draw.line((0, dialogue_top, width - 1, dialogue_top), fill=(64, 64, 96), width=2)
    draw.line((0, hud_bottom, width - 1, hud_bottom), fill=(64, 64, 96), width=2)

    # Player sprite (Ash) roughly centered
    sprite_box = (70, 58, 94, 88)
    draw.rectangle(sprite_box, fill=(240, 200, 120), outline=(30, 30, 30), width=2)

    # Cursor arrow inside dialogue box
    arrow_y = dialogue_top + int((height - dialogue_top) * 0.4)
    arrow = [
        (width - 46, arrow_y - 6),
        (width - 28, arrow_y),
        (width - 46, arrow_y + 6),
    ]
    draw.polygon(arrow, fill=(255, 255, 255), outline=(30, 30, 30))

    # Dialogue text hint rectangles
    draw.rectangle((8, dialogue_top + 8, width - 60, dialogue_top + 24), fill=(64, 64, 96))
    draw.rectangle((8, dialogue_top + 26, width - 90, dialogue_top + 38), fill=(64, 64, 96))

    return frame


def test_decompose_frame_detects_key_regions():
    frame = build_synthetic_frame()
    result = decompose_frame(frame)
    labels = {region["label"] for region in result["regions"]}
    expected = {"dialogue_box", "ui_pane", "player_sprite", "cursor_arrow"}
    assert expected.issubset(labels)
    dialogue = next(r for r in result["regions"] if r["label"] == "dialogue_box")
    assert dialogue["bbox"][1] >= 80
    assert dialogue["bbox"][3] >= 24
    sprite = next(r for r in result["regions"] if r["label"] == "player_sprite")
    assert sprite["bbox"][2] <= 30
    assert sprite["bbox"][3] <= 30
    assert isinstance(sprite.get("embedding"), list) and len(sprite["embedding"]) == 5
    for region in result["regions"]:
        assert region.get("bbox")
        thumb = region.get("thumbnail_b64")
        assert isinstance(thumb, str) and thumb
        data = base64.b64decode(thumb)
        assert data.startswith(b"\x89PNG")


@pytest.fixture()
def isolated_knowledge_store(tmp_path, monkeypatch):
    mod = agent_module
    base = tmp_path / "knowledge"
    base.mkdir(parents=True, exist_ok=True)

    dirs = {
        "KN_IMG_DIR": base / "images",
        "KN_MINI_DIR": base / "mini64",
        "KN_REGION_DIR": base / "regions",
        "KN_REGION_THUMBS": base / "region_thumbs",
        "VEC_DIR": base / "vectors",
    }
    files = {
        "KN_META": base / "metadata.jsonl",
        "TIMELINE": base / "timeline.jsonl",
        "KN_REGION_META": base / "regions.jsonl",
        "KN_STATE": base / "cluster_state.json",
        "VEC_NPY": base / "vectors" / "text_vectors.npy",
        "VEC_IDX": base / "vectors" / "text_index.json",
    }
    for key, path in dirs.items():
        path.mkdir(parents=True, exist_ok=True)
        monkeypatch.setattr(mod, key, path, raising=False)
    for key, path in files.items():
        path.parent.mkdir(parents=True, exist_ok=True)
        monkeypatch.setattr(mod, key, path, raising=False)
    monkeypatch.setattr(mod, "KNOWLEDGE", base, raising=False)
    ks = mod.KnowledgeStore({}, state_path=files["KN_STATE"])
    return ks, files["KN_REGION_META"]


def test_knowledge_store_region_pack(isolated_knowledge_store):
    ks, region_meta_path = isolated_knowledge_store
    frame = build_synthetic_frame()
    regions = decompose_frame(frame)["regions"]
    ks.add(frame, {"rom": "TestROM", "profile": "Unit"}, regions=regions)
    assert region_meta_path.exists()
    rows = [json.loads(line) for line in region_meta_path.read_text("utf-8").splitlines() if line.strip()]
    assert any(row.get("label") == "player_sprite" for row in rows)
    assert all("crop" in row for row in rows)
    matches = ks.find_region_matches(regions)
    assert matches, "Expected region matches after storing pack"
    assert matches[0]["results"], "Each match should include results"
```

**Functions:** build_synthetic_frame(width, height), test_decompose_frame_detects_key_regions(), isolated_knowledge_store(tmp_path, monkeypatch), test_knowledge_store_region_pack(isolated_knowledge_store)


## Module `tests\__init__.py`

```python

```



## Module `tools\codex_pr_sentinel.py`

```python
"""Lightweight governance checks executed in CI to guard Codex workflows."""
from __future__ import annotations

import argparse
import sys
from pathlib import Path

import yaml

from logic_inbox import load_entries, validate_entries


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Run Codex governance sentinel checks")
    parser.add_argument(
        "--config",
        type=Path,
        default=Path(".github/codex_sentinel.yml"),
        help="Path to sentinel configuration file",
    )
    parser.add_argument(
        "--inbox",
        type=Path,
        default=Path("memory/logic_inbox.jsonl"),
        help="Path to logic inbox JSONL file",
    )
    return parser.parse_args()


def ensure_required_assets(required: list[str]) -> list[str]:
    missing: list[str] = []
    for target in required:
        path = Path(target)
        if not path.exists():
            missing.append(target)
    return missing


def load_config(path: Path) -> dict:
    if not path.exists():
        raise FileNotFoundError(f"Sentinel configuration missing: {path}")
    with path.open("r", encoding="utf-8") as handle:
        data = yaml.safe_load(handle) or {}
    if not isinstance(data, dict):
        raise ValueError("Sentinel configuration must define a mapping at top level.")
    return data


def main(argv: list[str] | None = None) -> int:
    args = parse_args()
    try:
        config = load_config(args.config)
    except (FileNotFoundError, ValueError) as exc:
        print(str(exc), file=sys.stderr)
        return 1

    required_files = config.get("required_files", [])
    if not isinstance(required_files, list):
        print("`required_files` must be a list", file=sys.stderr)
        return 1

    missing = ensure_required_assets(required_files)
    if missing:
        print("Missing required governance assets:", file=sys.stderr)
        for item in missing:
            print(f" - {item}", file=sys.stderr)
        return 1

    inbox_requirements = config.get("inbox_requirements", {})
    if inbox_requirements and not isinstance(inbox_requirements, dict):
        print("`inbox_requirements` must be a mapping", file=sys.stderr)
        return 1

    required_fields = inbox_requirements.get("mandatory_fields", [])
    if required_fields and not isinstance(required_fields, list):
        print("`mandatory_fields` must be a list", file=sys.stderr)
        return 1

    try:
        entries = load_entries(args.inbox)
    except ValueError as exc:
        print(str(exc), file=sys.stderr)
        return 1

    issues = validate_entries(entries, required_fields)
    if issues:
        print("logic inbox validation failed:", file=sys.stderr)
        for issue in issues:
            print(f" - {issue}", file=sys.stderr)
        return 1

    print("Codex sentinel checks passed.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
```

Lightweight governance checks executed in CI to guard Codex workflows.
**Functions:** parse_args(), ensure_required_assets(required), load_config(path), main(argv)


## Module `tools\logic_inbox.py`

```python
"""Utility helpers for managing the Codex logic inbox.

The logic inbox stores actionable TODO items as newline-delimited JSON objects.
This module exposes a small CLI for validating, listing, and updating entries
without introducing external dependencies.
"""
from __future__ import annotations

import argparse
import json
import sys
import uuid
from dataclasses import dataclass, field
from pathlib import Path
from typing import Iterable, List, Sequence


@dataclass
class InboxEntry:
    """Represents a single actionable item stored in the inbox."""

    data: dict
    source_line: int = 0

    def missing_fields(self, required_fields: Sequence[str]) -> List[str]:
        return [field for field in required_fields if field not in self.data]


def load_entries(path: Path) -> List[InboxEntry]:
    entries: List[InboxEntry] = []
    if not path.exists():
        return entries

    for idx, raw_line in enumerate(path.read_text().splitlines(), start=1):
        line = raw_line.strip()
        if not line:
            continue
        try:
            payload = json.loads(line)
        except json.JSONDecodeError as exc:
            raise ValueError(f"Invalid JSON on line {idx}: {exc.msg}") from exc
        if not isinstance(payload, dict):
            raise ValueError(f"Inbox entries must be JSON objects (line {idx}).")
        entries.append(InboxEntry(data=payload, source_line=idx))
    return entries


def dump_entries(path: Path, entries: Iterable[InboxEntry]) -> None:
    lines = [json.dumps(entry.data, sort_keys=True) for entry in entries]
    path.write_text("\n".join(lines) + ("\n" if lines else ""))


def validate_entries(entries: Sequence[InboxEntry], required_fields: Sequence[str]) -> List[str]:
    issues: List[str] = []
    for entry in entries:
        missing = entry.missing_fields(required_fields)
        if missing:
            issues.append(
                f"Entry on line {entry.source_line} missing fields: {', '.join(missing)}"
            )
    return issues


def list_entries(entries: Sequence[InboxEntry]) -> str:
    if not entries:
        return "(logic inbox empty)"
    lines = []
    for entry in entries:
        display = json.dumps(entry.data, sort_keys=True)
        lines.append(f"- line {entry.source_line}: {display}")
    return "\n".join(lines)


def add_entry(entries: List[InboxEntry], description: str, status: str, entry_id: str | None = None) -> InboxEntry:
    payload = {
        "id": entry_id or str(uuid.uuid4()),
        "description": description,
        "status": status,
    }
    entry = InboxEntry(data=payload, source_line=len(entries) + 1)
    entries.append(entry)
    return entry


def update_status(entries: List[InboxEntry], entry_id: str, status: str) -> bool:
    for entry in entries:
        if entry.data.get("id") == entry_id:
            entry.data["status"] = status
            return True
    return False


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Manage the Codex logic inbox.")
    subparsers = parser.add_subparsers(dest="command", required=True)

    validate_parser = subparsers.add_parser("validate", help="Validate inbox integrity")
    validate_parser.add_argument("path", type=Path, help="Path to logic_inbox.jsonl")
    validate_parser.add_argument(
        "--require-field",
        action="append",
        default=[],
        help="Field that must be present on each inbox entry (may repeat).",
    )

    list_parser = subparsers.add_parser("list", help="List inbox entries")
    list_parser.add_argument("path", type=Path, help="Path to logic_inbox.jsonl")

    add_parser = subparsers.add_parser("add", help="Add a new inbox entry")
    add_parser.add_argument("path", type=Path, help="Path to logic_inbox.jsonl")
    add_parser.add_argument("description", help="Description of the task to add")
    add_parser.add_argument(
        "--status",
        default="pending",
        help="Initial status for the new task (default: pending)",
    )
    add_parser.add_argument("--id", help="Optional explicit ID for the task")

    update_parser = subparsers.add_parser(
        "update", help="Update the status of an existing inbox entry"
    )
    update_parser.add_argument("path", type=Path, help="Path to logic_inbox.jsonl")
    update_parser.add_argument("id", help="ID of the entry to update")
    update_parser.add_argument(
        "--status", required=True, help="New status value (e.g., done, pending)"
    )

    return parser


def main(argv: Sequence[str] | None = None) -> int:
    parser = build_parser()
    args = parser.parse_args(argv)

    try:
        entries = load_entries(args.path)
    except ValueError as exc:
        parser.error(str(exc))

    if args.command == "validate":
        issues = validate_entries(entries, args.require_field)
        if issues:
            for issue in issues:
                print(issue, file=sys.stderr)
            return 1
        print("logic inbox validation passed")
        return 0

    if args.command == "list":
        print(list_entries(entries))
        return 0

    if args.command == "add":
        new_entry = add_entry(entries, args.description, args.status, args.id)
        dump_entries(args.path, entries)
        print(json.dumps(new_entry.data, sort_keys=True))
        return 0

    if args.command == "update":
        updated = update_status(entries, args.id, args.status)
        if not updated:
            parser.error(f"No entry found with id '{args.id}'")
        dump_entries(args.path, entries)
        print(f"Updated {args.id} to status {args.status}")
        return 0

    parser.error("Unknown command")
    return 1


if __name__ == "__main__":
    sys.exit(main())
```

Utility helpers for managing the Codex logic inbox.

The logic inbox stores actionable TODO items as newline-delimited JSON objects.
This module exposes a small CLI for validating, listing, and updating entries
without introducing external dependencies.
**Classes:** InboxEntry
**Functions:** load_entries(path), dump_entries(path, entries), validate_entries(entries, required_fields), list_entries(entries), add_entry(entries, description, status, entry_id), update_status(entries, entry_id, status), build_parser(), main(argv)


## Module `tools\operator_pipeline.py`

```python
from __future__ import annotations

import concurrent.futures as _cf
import threading as _th
import time as _time
from dataclasses import dataclass, field
from typing import Callable, Dict, Any, Optional, List

from PyQt6 import QtCore


_HAS_QT = hasattr(QtCore, "QRunnable") and hasattr(QtCore, "QThreadPool")


@dataclass
class OperatorResult:
    """Structured payload emitted by a single observation operator."""

    name: str
    summary: str
    confidence: float
    payload: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "summary": self.summary,
            "confidence": float(self.confidence),
            "payload": self.payload,
            "error": self.error,
        }


@dataclass
class OperatorBundle:
    """Aggregated view of all operator outputs for a single frame."""

    results: Dict[str, OperatorResult] = field(default_factory=dict)
    summary: str = ""
    confidence: float = 0.0
    health: Dict[str, int] = field(default_factory=dict)
    action_proposal: Optional[Dict[str, Any]] = None
    advisories: List[Dict[str, Any]] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "summary": self.summary,
            "confidence": float(self.confidence),
            "health": dict(self.health),
            "results": {name: result.to_dict() for name, result in self.results.items()},
            "action_proposal": self.action_proposal,
            "advisories": list(self.advisories),
        }


@dataclass
class ObservationOperator:
    """Descriptor for a callable that produces an :class:`OperatorResult`."""

    name: str
    func: Callable[[], OperatorResult]


def _execute_operator(operator: ObservationOperator) -> OperatorResult:
    try:
        result = operator.func()
        if not isinstance(result, OperatorResult):
            raise TypeError("Operator must return OperatorResult")
    except Exception as exc:  # pragma: no cover - defensive
        result = OperatorResult(
            name=operator.name,
            summary="error",
            confidence=0.0,
            payload={},
            error=str(exc),
        )
    return result


if _HAS_QT:
    class _OperatorRunnable(QtCore.QRunnable):
        def __init__(self, operator: ObservationOperator, callback: Callable[[OperatorResult], None]):
            super().__init__()
            self._operator = operator
            self._callback = callback

        @QtCore.pyqtSlot()
        def run(self) -> None:  # pragma: no cover - executed in worker threads
            result = _execute_operator(self._operator)
            self._callback(result)


else:  # pragma: no cover - fallback for tests without Qt bindings
    class _OperatorRunnable:
        def __init__(self, operator: ObservationOperator, callback: Callable[[OperatorResult], None]):
            self._operator = operator
            self._callback = callback

        def run(self) -> None:
            result = _execute_operator(self._operator)
            self._callback(result)


class OperatorAggregator:
    """Coordinates operator execution across a :class:`QThreadPool`."""

    def __init__(self, *, thread_pool: Optional[QtCore.QThreadPool] = None):
        if _HAS_QT:
            self._pool: Optional[QtCore.QThreadPool] = thread_pool or QtCore.QThreadPool()
            self._executor: Optional[_cf.ThreadPoolExecutor] = None
        else:
            if thread_pool is not None and not isinstance(thread_pool, _cf.ThreadPoolExecutor):
                raise TypeError("thread_pool must be a ThreadPoolExecutor when Qt is unavailable")
            self._pool = None
            self._executor = thread_pool if isinstance(thread_pool, _cf.ThreadPoolExecutor) else _cf.ThreadPoolExecutor(max_workers=8)

    @property
    def pool(self):
        return self._pool if _HAS_QT else self._executor

    def run_group(
        self,
        operators: List[ObservationOperator],
        *,
        timeout: float = 8.0,
    ) -> Dict[str, OperatorResult]:
        if not operators:
            return {}
        results: Dict[str, OperatorResult] = {}
        if _HAS_QT:
            lock = _th.Lock()
            event = _th.Event()
            total = len(operators)

            def _handle(result: OperatorResult) -> None:
                with lock:
                    results[result.name] = result
                    if len(results) >= total:
                        event.set()

            for op in operators:
                runnable = _OperatorRunnable(op, _handle)
                assert self._pool is not None
                self._pool.start(runnable)
            finished = event.wait(timeout)
            if not finished:
                with lock:
                    completed = set(results)
                for op in operators:
                    if op.name in completed:
                        continue
                    results[op.name] = OperatorResult(
                        name=op.name,
                        summary="timeout",
                        confidence=0.0,
                        payload={},
                        error="timeout",
                    )
            return results

        futures = {
            self._executor.submit(_execute_operator, op): op for op in operators  # type: ignore[union-attr]
        }
        deadline = _time.perf_counter() + timeout
        for future, op in futures.items():
            remaining = max(0.0, deadline - _time.perf_counter())
            try:
                result = future.result(timeout=remaining or 0.01)
            except _cf.TimeoutError:
                future.cancel()
                result = OperatorResult(
                    name=op.name,
                    summary="timeout",
                    confidence=0.0,
                    payload={},
                    error="timeout",
                )
            except Exception as exc:  # pragma: no cover - defensive
                result = OperatorResult(
                    name=op.name,
                    summary="error",
                    confidence=0.0,
                    payload={},
                    error=str(exc),
                )
            results[result.name] = result
        return results

    def assemble(self, results: Dict[str, OperatorResult]) -> OperatorBundle:
        health = {
            "total": len(results),
            "failed": 0,
            "timeouts": 0,
            "succeeded": 0,
        }
        summary_parts: List[str] = []
        combined_conf = 0.0
        best_proposal: Optional[Dict[str, Any]] = None
        best_score = -1.0
        for name, result in results.items():
            if result.error:
                health["failed"] += 1
                if result.error == "timeout":
                    health["timeouts"] += 1
            else:
                health["succeeded"] += 1
            combined_conf += max(0.0, float(result.confidence))
            summary_parts.append(f"{name}:{result.summary} ({result.confidence:.2f})")
            proposal = result.payload.get("proposal") if isinstance(result.payload, dict) else None
            if isinstance(proposal, dict):
                try:
                    score = float(proposal.get("confidence", 0.0))
                except Exception:
                    score = 0.0
                if score > best_score:
                    best_score = score
                    best_proposal = proposal
        avg_conf = combined_conf / len(results) if results else 0.0
        penalty = min(0.5, 0.1 * health["failed"])
        overall = max(0.0, min(1.0, avg_conf - penalty))
        bundle = OperatorBundle(
            results=dict(results),
            summary=" | ".join(summary_parts),
            confidence=overall,
            health=health,
            action_proposal=best_proposal,
        )
        return bundle

__all__ = [
    "ObservationOperator",
    "OperatorAggregator",
    "OperatorBundle",
    "OperatorResult",
]
```

**Classes:** OperatorResult, OperatorBundle, ObservationOperator, OperatorAggregator
**Functions:** _execute_operator(operator)


## Module `tools\pokemon_ingest.py`

```python
"""Utility for fetching and parsing canonical Pokémon vocabulary."""
from __future__ import annotations

import json
import re
import unicodedata
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from html.parser import HTMLParser
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence, Tuple
from urllib.parse import urlparse
from urllib.request import Request, urlopen


@dataclass
class IngestResult:
    """Summary of an ingestion run."""

    fetched: List[str]
    from_cache: List[str]
    errors: List[str]
    entry_count: int
    structured_vocab: Dict[str, List[Dict[str, object]]]


class _TextExtractor(HTMLParser):
    __slots__ = ("_parts", "_skip_stack")

    def __init__(self) -> None:
        super().__init__(convert_charrefs=True)
        self._parts: List[str] = []
        self._skip_stack: List[str] = []

    def handle_starttag(self, tag: str, attrs: List[Tuple[str, Optional[str]]]):
        if tag in {"script", "style", "noscript"}:
            self._skip_stack.append(tag)

    def handle_endtag(self, tag: str):
        if self._skip_stack and self._skip_stack[-1] == tag:
            self._skip_stack.pop()

    def handle_data(self, data: str):
        if self._skip_stack:
            return
        cleaned = data.strip()
        if cleaned:
            self._parts.append(cleaned)

    def get_text(self) -> str:
        return "\n".join(self._parts)


class PokemonCorpusIngestor:
    """Fetches Pokémon canonical text fragments and exports structured vocab."""
    ALLOWED_SOURCES: Tuple[str, ...] = (
        "https://www.pokemon.com/us/pokemon-video-games/pokemon-red-version-blue-version/",
        "https://www.pokemon.com/us/pokemon-video-games/pokemon-yellow-version-special-pikachu-edition/",
        "https://en.wikipedia.org/wiki/Pok%C3%A9mon_Red_and_Blue",
        "https://en.wikipedia.org/wiki/Pok%C3%A9mon_Yellow",
        "https://en.wikipedia.org/wiki/Pok%C3%A9mon_Green",
    )
    MIN_REFRESH_INTERVAL = timedelta(hours=12)
    MAX_CACHE_BYTES = 600_000

    def __init__(
        self,
        *,
        cache_dir: Path,
        knowledge_dir: Path,
        allowed_sources: Optional[Sequence[str]] = None,
    ) -> None:
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.knowledge_dir = knowledge_dir
        self.knowledge_dir.mkdir(parents=True, exist_ok=True)
        self.allowed_sources: Tuple[str, ...] = (
            tuple(allowed_sources) if allowed_sources else self.ALLOWED_SOURCES
        )
        self.manifest_path = self.cache_dir / "manifest.json"
        self.vocab_cache = self.cache_dir / "vocab.json"
        self.lexicon_path = self.knowledge_dir / "pokemon_lexicon.json"

    # ---------------------- Public helpers ----------------------
    def is_allowed_url(self, url: str) -> bool:
        parsed = urlparse(url)
        if parsed.scheme not in {"http", "https"}:
            return False
        domain = parsed.netloc.lower()
        if domain.endswith("pokemon.com"):
            return True
        if domain == "en.wikipedia.org" and any(url.startswith(prefix) for prefix in (
            "https://en.wikipedia.org/wiki/Pok%C3%A9mon_",
        )):
            return True
        return False

    def sync(self, *, force: bool = False) -> IngestResult:
        manifest = self._load_manifest()
        now = datetime.now(timezone.utc)
        aggregated: List[Tuple[str, str]] = []
        fetched: List[str] = []
        from_cache: List[str] = []
        errors: List[str] = []

        for url in self.allowed_sources:
            if not self.is_allowed_url(url):
                errors.append(url)
                continue
            cached_html = self._read_cached_source(manifest, url)
            if cached_html and not force:
                last_fetch = self._last_fetch(manifest, url)
                if last_fetch and now - last_fetch < self.MIN_REFRESH_INTERVAL:
                    aggregated.append((url, cached_html))
                    from_cache.append(url)
                    continue
            try:
                html_text = self._fetch(url)
            except Exception:
                if cached_html:
                    aggregated.append((url, cached_html))
                    from_cache.append(url)
                    continue
                errors.append(url)
                continue
            aggregated.append((url, html_text))
            fetched.append(url)
            self._write_cache_entry(manifest, url, html_text, now)

        if not aggregated:
            structured = {"ui_labels": [], "item_names": [], "glyph_variants": []}
            return IngestResult(fetched, from_cache, errors, 0, structured)

        structured = self._build_vocab(aggregated)
        entries = self._compile_entries(structured)
        manifest["updated_at"] = now.isoformat()
        self._save_manifest(manifest)
        self._enforce_cache_quota()
        self._write_structured(structured, manifest, entries, now)
        return IngestResult(fetched, from_cache, errors, len(entries), structured)

    # ---------------------- Internal helpers ----------------------
    def _load_manifest(self) -> Dict[str, Dict[str, object]]:
        if self.manifest_path.exists():
            try:
                return json.loads(self.manifest_path.read_text("utf-8"))
            except Exception:
                return {"sources": {}}
        return {"sources": {}}

    def _save_manifest(self, manifest: Dict[str, object]) -> None:
        tmp = self.manifest_path.with_suffix(".tmp")
        tmp.write_text(json.dumps(manifest, indent=2), encoding="utf-8")
        tmp.replace(self.manifest_path)

    def _read_cached_source(self, manifest: Dict[str, object], url: str) -> Optional[str]:
        info = manifest.get("sources", {}).get(url)
        if not isinstance(info, dict):
            return None
        rel = info.get("path")
        if not rel:
            return None
        path = self.cache_dir / str(rel)
        if not path.exists():
            return None
        try:
            return path.read_text("utf-8")
        except Exception:
            return None

    def _last_fetch(self, manifest: Dict[str, object], url: str) -> Optional[datetime]:
        info = manifest.get("sources", {}).get(url)
        if not isinstance(info, dict):
            return None
        ts = info.get("fetched_at")
        if not isinstance(ts, str):
            return None
        try:
            return datetime.fromisoformat(ts)
        except Exception:
            return None

    def _fetch(self, url: str) -> str:
        req = Request(url, headers={"User-Agent": "Agent-VirtualGameBoy/1.0"})
        with urlopen(req, timeout=20) as resp:
            data = resp.read()
        return data.decode("utf-8", errors="ignore")

    def _cache_filename(self, url: str, now: datetime) -> Path:
        parsed = urlparse(url)
        parts = [parsed.netloc.replace(".", "_")]
        if parsed.path:
            cleaned = re.sub(r"[^a-zA-Z0-9]+", "_", parsed.path).strip("_")
            if cleaned:
                parts.append(cleaned)
        name = "_".join(parts) or "pokemon"
        stamp = now.strftime("%Y%m%d%H%M%S")
        return self.cache_dir / f"{name}_{stamp}.html"

    def _write_cache_entry(self, manifest: Dict[str, object], url: str, html_text: str, now: datetime) -> None:
        path = self._cache_filename(url, now)
        path.write_text(html_text, encoding="utf-8")
        manifest.setdefault("sources", {})[url] = {
            "path": path.name,
            "fetched_at": now.isoformat(),
            "size": len(html_text.encode("utf-8")),
        }

    def _enforce_cache_quota(self) -> None:
        html_files = sorted(
            [p for p in self.cache_dir.glob("*.html")],
            key=lambda p: p.stat().st_mtime,
        )
        total = sum(p.stat().st_size for p in html_files)
        while total > self.MAX_CACHE_BYTES and html_files:
            victim = html_files.pop(0)
            size = victim.stat().st_size
            victim.unlink(missing_ok=True)
            total -= size

    def _strip_html(self, html_text: str) -> str:
        parser = _TextExtractor()
        parser.feed(html_text)
        return parser.get_text()

    def _build_vocab(self, payloads: Iterable[Tuple[str, str]]) -> Dict[str, List[Dict[str, object]]]:
        ui_labels: Dict[str, Dict[str, object]] = {}
        item_names: Dict[str, Dict[str, object]] = {}
        glyph_variants: Dict[str, Dict[str, object]] = {}

        for source, html_text in payloads:
            raw_text = self._strip_html(html_text)
            lines = [line.strip() for line in raw_text.splitlines() if line.strip()]
            for line in lines:
                self._collect_ui_labels(line, source, ui_labels)
                self._collect_item_names(line, source, item_names)
                self._collect_glyph_variants(line, source, glyph_variants)

        def _finalize(bucket: Dict[str, Dict[str, object]]) -> List[Dict[str, object]]:
            finalized: List[Dict[str, object]] = []
            for entry in bucket.values():
                sources = entry.get("sources")
                if isinstance(sources, set):
                    entry["sources"] = sorted(sources)
                raw_forms = entry.get("raw_forms")
                if isinstance(raw_forms, set):
                    entry["raw_forms"] = sorted(raw_forms)
                finalized.append(entry)
            return finalized

        return {
            "ui_labels": _finalize(ui_labels),
            "item_names": _finalize(item_names),
            "glyph_variants": _finalize(glyph_variants),
        }

    def _collect_ui_labels(self, line: str, source: str, bucket: Dict[str, Dict[str, object]]) -> None:
        for match in re.findall(r"\b[A-Z][A-Z0-9&'\-/ ]{2,}\b", line):
            token = match.strip()
            if len(token) > 28:
                continue
            key = self._normalize(token)
            entry = bucket.setdefault(
                key,
                {
                    "text": token,
                    "normalized": key,
                    "category": "ui_label",
                    "sources": set(),
                    "glyph_estimate": self._glyph_estimate(key),
                },
            )
            entry["sources"].add(source)

    def _collect_item_names(self, line: str, source: str, bucket: Dict[str, Dict[str, object]]) -> None:
        patterns = [
            r"\b(?:TM|HM)\d{2}\b",
            r"\b[A-Z][a-z]+(?:\s[A-Z][a-z]+){0,2}\b",
        ]
        stopwords = {"the", "and", "with", "this", "game", "video", "version"}
        for pattern in patterns:
            for match in re.findall(pattern, line):
                if match.lower() in stopwords:
                    continue
                if len(match) < 3:
                    continue
                key = self._normalize(match)
                if len(key) < 3:
                    continue
                entry = bucket.setdefault(
                    key,
                    {
                        "text": match,
                        "normalized": key,
                        "category": "item_name",
                        "sources": set(),
                        "glyph_estimate": self._glyph_estimate(key),
                    },
                )
                entry["sources"].add(source)

    def _collect_glyph_variants(self, line: str, source: str, bucket: Dict[str, Dict[str, object]]) -> None:
        for token in re.findall(r"[\w\-\'\s]*[Éé♀♂★☆♪™℠éÉ·]+[\w\-\'\s]*", line):
            cleaned = token.strip()
            if len(cleaned) < 2:
                continue
            key = self._normalize(cleaned)
            entry = bucket.setdefault(
                key,
                {
                    "text": cleaned,
                    "normalized": key,
                    "category": "glyph_variant",
                    "sources": set(),
                    "glyph_estimate": self._glyph_estimate(key),
                    "raw_forms": set(),
                },
            )
            entry.setdefault("raw_forms", set()).add(cleaned)
            entry["sources"].add(source)

    def _compile_entries(self, structured: Dict[str, List[Dict[str, object]]]) -> Dict[str, Dict[str, object]]:
        combined: Dict[str, Dict[str, object]] = {}
        for category, entries in structured.items():
            for entry in entries:
                key = str(entry.get("normalized") or "").strip()
                if not key:
                    continue
                merged = combined.setdefault(
                    key,
                    {
                        "normalized": key,
                        "category": category,
                        "sources": set(),
                        "glyph_estimate": int(entry.get("glyph_estimate", len(key))),
                        "raw_variants": set(),
                    },
                )
                sources = entry.get("sources", [])
                if isinstance(sources, set):
                    sources_iter: Iterable[str] = sources
                elif isinstance(sources, list):
                    sources_iter = sources
                else:
                    sources_iter = []
                merged["sources"].update(sources_iter)
                raw = entry.get("text")
                if isinstance(raw, str) and raw.strip():
                    merged["raw_variants"].add(raw.strip())
                extras = entry.get("raw_forms", [])
                if isinstance(extras, set):
                    extras_iter: Iterable[str] = extras
                elif isinstance(extras, list):
                    extras_iter = extras
                else:
                    extras_iter = []
                for extra in extras_iter:
                    if isinstance(extra, str) and extra.strip():
                        merged["raw_variants"].add(extra.strip())
        for value in combined.values():
            value["sources"] = sorted(value["sources"])
            value["raw_variants"] = sorted(value["raw_variants"]) or [value["normalized"]]
        return combined

    def _write_structured(
        self,
        structured: Dict[str, List[Dict[str, object]]],
        manifest: Dict[str, object],
        entries: Dict[str, Dict[str, object]],
        now: datetime,
    ) -> None:
        payload = {
            "generated_at": now.isoformat(),
            "structured": structured,
            "manifest": manifest,
        }
        tmp_vocab = self.vocab_cache.with_suffix(".tmp")
        tmp_vocab.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        tmp_vocab.replace(self.vocab_cache)
        lex_payload = {
            "refreshed_at": now.isoformat(),
            "entries": entries,
            "sources": manifest.get("sources", {}),
        }
        tmp_lex = self.lexicon_path.with_suffix(".tmp")
        tmp_lex.write_text(json.dumps(lex_payload, indent=2), encoding="utf-8")
        tmp_lex.replace(self.lexicon_path)

    @staticmethod
    def _normalize(text: str) -> str:
        normalized = unicodedata.normalize("NFKD", text)
        ascii_only = "".join(ch for ch in normalized if ch.isascii())
        return re.sub(r"\s+", " ", ascii_only).strip().upper()

    @staticmethod
    def _glyph_estimate(text: str) -> int:
        return len(re.sub(r"[^A-Z0-9]", "", text))


__all__ = ["PokemonCorpusIngestor", "IngestResult"]
```

Utility for fetching and parsing canonical Pokémon vocabulary.
**Classes:** IngestResult, _TextExtractor, PokemonCorpusIngestor


## Module `tools\timeline_manager.py`

```python
from __future__ import annotations

from collections import Counter, deque
from dataclasses import dataclass, field
from typing import Any, Deque, Dict, Iterable, List, Optional, Sequence, Tuple


def _safe_round(value: float, digits: int = 3) -> float:
    try:
        return round(float(value), digits)
    except Exception:
        return 0.0


@dataclass
class TimelineEvent:
    ts: str
    action: str
    duration_ms: int
    changed: bool
    source: str
    before_digest: Optional[str] = None
    after_digest: Optional[str] = None
    movement: Dict[str, Any] = field(default_factory=dict)
    state_key: Optional[str] = None
    before_screen: Optional[Dict[str, Any]] = None
    after_screen: Optional[Dict[str, Any]] = None

    def primary_mode(self) -> Optional[str]:
        for payload in (self.after_screen, self.before_screen):
            if isinstance(payload, dict):
                mode = payload.get("mode")
                if isinstance(mode, str) and mode:
                    return mode
        return None

    def to_dict(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {
            "ts": self.ts,
            "action": self.action,
            "duration_ms": self.duration_ms,
            "changed": bool(self.changed),
            "source": self.source,
            "before_digest": self.before_digest,
            "after_digest": self.after_digest,
            "movement": dict(self.movement or {}),
            "state_key": self.state_key,
        }
        if self.before_screen:
            data["before_screen"] = dict(self.before_screen)
        if self.after_screen:
            data["after_screen"] = dict(self.after_screen)
        mode = self.primary_mode()
        if mode:
            data["mode"] = mode
        return data


class TimelineManager:
    def __init__(
        self,
        *,
        knowledge_store: Optional[Any] = None,
        horizon: int = 40,
        decay: float = 0.65,
        window_size: int = 6,
    ) -> None:
        self.knowledge_store = knowledge_store
        self.horizon = max(1, int(horizon))
        self.decay = float(decay) if 0.0 < float(decay) < 1.0 else 0.65
        self.window_size = max(1, int(window_size))
        self._events: Deque[TimelineEvent] = deque()
        self._archive_buffer: List[TimelineEvent] = []

    # ------------------------------------------------------------------
    # Recording + annotation helpers
    # ------------------------------------------------------------------
    def record_transition(
        self,
        *,
        ts: str,
        action: str,
        duration_ms: int,
        changed: bool,
        source: str,
        before_digest: Optional[str],
        after_digest: Optional[str],
        movement: Dict[str, Any],
        state_key: Optional[str],
        before_screen: Optional[Dict[str, Any]] = None,
        after_screen: Optional[Dict[str, Any]] = None,
    ) -> TimelineEvent:
        event = TimelineEvent(
            ts=ts,
            action=str(action),
            duration_ms=int(duration_ms),
            changed=bool(changed),
            source=str(source),
            before_digest=before_digest,
            after_digest=after_digest,
            movement=dict(movement or {}),
            state_key=state_key,
            before_screen=self._compact_screen_state(before_screen),
            after_screen=self._compact_screen_state(after_screen),
        )
        self._events.append(event)
        self._prune_if_needed()
        return event

    def annotate_screen_state(
        self,
        *,
        digest: Optional[str],
        screen_state: Optional[Dict[str, Any]],
        state_key: Optional[str] = None,
    ) -> None:
        if not self._events:
            return
        compact = self._compact_screen_state(screen_state)
        digest_str = str(digest) if digest else None
        for event in reversed(self._events):
            matches_digest = digest_str and event.after_digest and event.after_digest == digest_str
            if matches_digest or (digest_str is None and event.after_digest is None and event.after_screen is None):
                if compact:
                    event.after_screen = compact
                if state_key and not event.state_key:
                    event.state_key = state_key
                break
        else:
            if state_key and self._events:
                self._events[-1].state_key = self._events[-1].state_key or state_key

    # ------------------------------------------------------------------
    # Reporting helpers
    # ------------------------------------------------------------------
    def scored_history(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        if not self._events:
            return []
        scored: List[Dict[str, Any]] = []
        for idx, event in enumerate(reversed(self._events)):
            score = self.decay ** idx
            payload = event.to_dict()
            payload["score"] = _safe_round(score)
            scored.append(payload)
            if limit is not None and len(scored) >= limit:
                break
        return scored

    def recent_summary(self) -> Optional[str]:
        if not self._events:
            return None
        last = self._events[-1]
        mode = last.primary_mode()
        if not mode:
            mode = "state"
        streak = 1
        if self._events:
            for event in list(self._events)[:-1][::-1]:
                if event.action != last.action:
                    break
                if event.changed is False:
                    break
                if event.primary_mode() != last.primary_mode():
                    break
                streak += 1
        action_label = f"{streak}×{last.action}" if streak > 1 else last.action
        verb = "advanced" if last.changed else "stalled"
        return f"last {mode} {verb} after {action_label}"

    def predictive_hint(self) -> Dict[str, Any]:
        history = list(reversed(self._events))
        if not history:
            return {}
        weights: Dict[Tuple[str, str], float] = {}
        for idx, event in enumerate(history):
            mode = event.primary_mode()
            if not mode:
                continue
            score = self.decay ** idx
            weight = score * (1.5 if event.changed else 0.6)
            key = (mode, event.action)
            weights[key] = weights.get(key, 0.0) + weight
        if not weights:
            return {}
        (mode, action), best_score = max(weights.items(), key=lambda item: item[1])
        total = sum(weights.values()) or 1.0
        confidence = min(0.99, max(0.0, best_score / total))
        message = self._build_hint_message(mode, action)
        return {
            "mode": mode,
            "action": action,
            "confidence": _safe_round(confidence, 3),
            "message": message,
            "summary": self.recent_summary(),
        }

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _compact_screen_state(self, screen: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        if not isinstance(screen, dict):
            return None
        compact: Dict[str, Any] = {}
        for key in ("mode", "confidence", "cursor_index", "caret_row", "line_count"):
            if key in screen and screen[key] is not None:
                compact[key] = screen[key]
        options = screen.get("options")
        if isinstance(options, Sequence):
            trimmed = []
            for opt in list(options)[:5]:
                if opt is None:
                    continue
                text = str(opt)
                if len(text) > 32:
                    text = text[:29] + "…"
                trimmed.append(text)
            if trimmed:
                compact["options"] = trimmed
        fallback = screen.get("fallback")
        if isinstance(fallback, dict):
            cursor_idx = fallback.get("cursor_index")
            if cursor_idx is not None and "cursor_index" not in compact:
                compact["cursor_index"] = cursor_idx
        if not compact:
            mode = screen.get("mode")
            if isinstance(mode, str) and mode:
                compact["mode"] = mode
        return compact or None

    def _build_hint_message(self, mode: str, action: str) -> str:
        action = action.upper()
        mode = mode.lower()
        if mode == "dialogue":
            return f"Dialogue likely continues; prepare to press {action}."
        if mode == "menu":
            return f"Menu interaction favors {action}; expect cursor prompt."
        if mode == "overworld":
            return f"Overworld movement trend points to {action}."
        return f"Recent trend suggests {action}."

    def _prune_if_needed(self) -> None:
        while len(self._events) > self.horizon:
            dropped = self._events.popleft()
            self._archive_buffer.append(dropped)
            if len(self._archive_buffer) >= self.window_size:
                self._flush_archive_buffer()
        # If we trimmed but still have leftovers that won't reach window_size soon,
        # keep at least the most recent drop archived when buffer gets large.
        if len(self._archive_buffer) >= self.window_size:
            self._flush_archive_buffer()

    def _flush_archive_buffer(self) -> None:
        if not self._archive_buffer:
            return
        window = list(self._archive_buffer)
        self._archive_buffer.clear()
        payload = self._summarize_window(window)
        if not payload:
            return
        sink = getattr(self.knowledge_store, "record_timeline_window", None)
        if callable(sink):
            try:
                sink(payload)
            except Exception:
                pass

    def _summarize_window(self, window: Sequence[TimelineEvent]) -> Optional[Dict[str, Any]]:
        if not window:
            return None
        start_ts = window[0].ts
        end_ts = window[-1].ts
        mode_counts: Counter[str] = Counter()
        action_counts: Counter[str] = Counter()
        success_counts: Counter[str] = Counter()
        for event in window:
            mode = event.primary_mode()
            if mode:
                mode_counts[mode] += 1
            action_counts[event.action] += 1
            if event.changed:
                success_counts[event.action] += 1
        primary_mode = None
        if mode_counts:
            primary_mode = max(mode_counts.items(), key=lambda item: item[1])[0]
        segments: List[str] = []
        for action, count in action_counts.most_common():
            successes = success_counts.get(action, 0)
            marker = "✓" if successes else "…"
            segments.append(f"{action}×{count}{marker}")
        summary_text = ", ".join(segments)
        if primary_mode:
            summary = f"{primary_mode} window: {summary_text}" if summary_text else f"{primary_mode} window"
        else:
            summary = summary_text or "timeline window"
        return {
            "start_ts": start_ts,
            "end_ts": end_ts,
            "primary_mode": primary_mode,
            "actions": segments,
            "summary": summary,
        }


__all__ = ["TimelineManager", "TimelineEvent"]
```

**Classes:** TimelineEvent, TimelineManager
**Functions:** _safe_round(value, digits)


## Module `tools\__init__.py`

```python

```




---
**Generation Parameters**


```text

You are an expert software engineer.  Carefully read every
file under the target directory (skipping any virtual environment
folders) and produce a comprehensive, well‑structured README in
Markdown.  Focus most of your attention on Python (.py) files: parse
their module‑level docstrings, enumerate classes and functions, and
describe what each does.  Summarise the purpose of non‑Python files
(such as JSON, YAML, text, images) briefly.  Provide an overview of
the project architecture and any dependencies you can infer from the
code.  Include usage notes or examples where appropriate.  Do not
invent information – base your summary solely on the source content.
Use headings, subheadings and lists to organise the README.

```