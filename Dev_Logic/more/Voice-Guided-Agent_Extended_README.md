# Project Documentation

## Table of Contents
- [Overview](#overview)
- [Python Modules](#python-modules)
- [Other Files](#other-files)

## Overview
This README was generated automatically by analyzing the project contents. Python modules are parsed for docstrings, classes, and functions. Image files are embedded as previews. Executable files (.exe) are listed by name; their contents are intentionally skipped.

## Python Modules

- `ant_api\__init__.py`
- `ant_api\mesh.py`
- `ant_api\schema.py`
- `cells\__init__.py`
- `cells\lineage.py`
- `dataset_manager.py`
- `Dev_Logic\Implemented_logic\agent_terminal.py`
- `Dev_Logic\Implemented_logic\Chatbot_Agent.py`
- `Dev_Logic\Implemented_logic\codex_local2.py`
- `Dev_Logic\Implemented_logic\Codex_Terminal.py`
- `Dev_Logic\Implemented_logic\image_pipeline.py`
- `Dev_Logic\Implemented_logic\Ollama_Chat_Terminal.py`
- `Dev_Logic\Implemented_logic\Simple_Codex_Terminal.py`
- `Dev_Logic\Implemented_logic\Simple_Ollama_Terminal.py`
- `Dev_Logic\Implemented_logic\simple_terminal.py`
- `Dev_Logic\Implemented_logic\Virtual_Desktop.py`
- `lexicon_manager.py`
- `Loader\__init__.py`
- `Loader\ant_launcher.py`
- `Loader\immune_system.py`
- `ollama_helper.py`
- `planner_service.py`
- `tests\conftest.py`
- `tests\test_ant_loader.py`
- `tests\test_ant_mesh_schema.py`
- `tests\test_cell_self_edit.py`
- `tests\test_clarification_flow.py`
- `tests\test_codex_terminal_panel.py`
- `tests\test_command_panel.py`
- `tests\test_dataset_manager.py`
- `tests\test_directive_buckets.py`
- `tests\test_directive_history.py`
- `tests\test_directive_history_cards.py`
- `tests\test_dispatch_errors.py`
- `tests\test_expressionary.py`
- `tests\test_keyboard_typing.py`
- `tests\test_magic_learn.py`
- `tests\test_ollama_helper.py`
- `tests\test_plan_execution.py`
- `tests\test_planner_service.py`
- `tests\test_script_metadata.py`
- `tests\test_speech_buffer.py`
- `tests\test_tts_barge_in.py`
- `tests\test_virtual_desktop_shell.py`
- `tools\codex_pr_sentinel.py`
- `tools\logic_inbox.py`
- `tools\manage_tests.py`
- `Virtual_Desktop.py`
- `vision_context.py`
- `Voice_Guided_Tools.py`
- `VoiceGuidedCodexTerminal.py`

## Other Files

- `.git\config`
- `.git\description`
- `.git\FETCH_HEAD`
- `.git\HEAD`
- `.git\hooks\applypatch-msg.sample`
- `.git\hooks\commit-msg.sample`
- `.git\hooks\fsmonitor-watchman.sample`
- `.git\hooks\post-update.sample`
- `.git\hooks\pre-applypatch.sample`
- `.git\hooks\pre-commit.sample`
- `.git\hooks\pre-merge-commit.sample`
- `.git\hooks\pre-push.sample`
- `.git\hooks\pre-rebase.sample`
- `.git\hooks\pre-receive.sample`
- `.git\hooks\prepare-commit-msg.sample`
- `.git\hooks\push-to-checkout.sample`
- `.git\hooks\sendemail-validate.sample`
- `.git\hooks\update.sample`
- `.git\index`
- `.git\info\exclude`
- `.git\logs\HEAD`
- `.git\logs\refs\heads\main`
- `.git\logs\refs\remotes\origin\HEAD`
- `.git\objects\pack\pack-046c25877b15ae2e324f735f9e704c9846ad5a49.idx`
- `.git\objects\pack\pack-046c25877b15ae2e324f735f9e704c9846ad5a49.pack`
- `.git\objects\pack\pack-046c25877b15ae2e324f735f9e704c9846ad5a49.rev`
- `.git\packed-refs`
- `.git\refs\heads\main`
- `.git\refs\remotes\origin\HEAD`
- `.github\codex_sentinel.yml`
- `.github\labeler.yml`
- `.github\workflows\automerge.yml`
- `.github\workflows\codex-pr-sentinel.yml`
- `.github\workflows\copilot-pr-watcher.yml`
- `.github\workflows\label.yml`
- `.github\workflows\manual.yml`
- `.github\workflows\python-package.yml`
- `.github\workflows\stale.yml`
- `.github\workflows\summary.yml`
- `.gitignore`
- `__pycache__\dataset_manager.cpython-313.pyc`
- `__pycache__\lexicon_manager.cpython-313.pyc`
- `__pycache__\ollama_helper.cpython-313.pyc`
- `__pycache__\planner_service.cpython-313.pyc`
- `__pycache__\vision_context.cpython-313.pyc`
- `__pycache__\VoiceGuidedCodexTerminal.cpython-313.pyc`
- `Agent.md`
- `Archived Conversations\.gitkeep`
- `codex_terminal_config.json`
- `data\.gitkeep`
- `data\chat_history.jsonl`
- `data\chat_index.json`
- `data\planner_log.jsonl`
- `data\planner_log.md`
- `Dev_Logic\Implemented_logic\index.jsonl`
- `Dev_Logic\Implemented_logic\ollama_chat_helper.md`
- `docs\design_ant_runtime.md`
- `docs\design_buffer_summary_review.md`
- `docs\design_ci_streamlining.md`
- `docs\design_clarification_escalation.md`
- `docs\design_codex_terminal_audio_panel.md`
- `docs\design_cursor_overlay_bubble.md`
- `docs\design_directive_buckets.md`
- `docs\design_directive_history_cards.md`
- `docs\design_directive_history_metadata.md`
- `docs\design_directive_metadata.md`
- `docs\design_expressionary_navigation_guards.md`
- `docs\design_interactive_command_panel.md`
- `docs\design_keyboard_cursor_typing.md`
- `docs\design_magic_learn_pending.md`
- `docs\design_magic_learn_segments.md`
- `docs\design_magic_learn_ui_review.md`
- `docs\design_plan_execution_typing.md`
- `docs\design_script_creation_intent.md`
- `docs\design_script_metadata_normalization.md`
- `docs\design_speech_buffer_confirmation.md`
- `docs\design_tts_barge_in.md`
- `docs\design_type_intent_polite_prefixes.md`
- `docs\design_virtual_desktop_refactor.md`
- `docs\design_voice_guided_codex_terminal.md`
- `docs\ollama_integration_design.md`
- `docs\ollama_validation_tests_design.md`
- `docs\planner_service_design.md`
- `memory\codex_memory.json`
- `memory\logic_inbox.jsonl`
- `README.md`
- `vgtools_config.json`
- `vgtools_logs\session_20250924_235051.jsonl`


## Detailed Module Analyses


## Module `dataset_manager.py`

```python
#!/usr/bin/env python3
"""Dataset persistence for chat transcripts and embeddings."""

from __future__ import annotations

import json
import math
import threading
import time
import uuid
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

_Collection = (list, tuple, set, frozenset)

from ollama_helper import OllamaHelper

DATA_DIR = Path(__file__).resolve().parent / "data"
DATASET_FILE = DATA_DIR / "chat_history.jsonl"
INDEX_FILE = DATA_DIR / "chat_index.json"
MAX_CONTEXT = 50


def cosine_similarity(a: Iterable[float], b: Iterable[float]) -> float:
    vec_a = list(a)
    vec_b = list(b)
    if not vec_a or not vec_b or len(vec_a) != len(vec_b):
        return 0.0
    dot = sum(x * y for x, y in zip(vec_a, vec_b))
    norm_a = math.sqrt(sum(x * x for x in vec_a))
    norm_b = math.sqrt(sum(y * y for y in vec_b))
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return dot / (norm_a * norm_b)


@dataclass
class DatasetEntry:
    id: str
    role: str
    text: str
    ts: float = field(default_factory=lambda: time.time())
    embedding: List[float] = field(default_factory=list)
    metadata: Dict[str, str] = field(default_factory=dict)

    def to_json(self) -> str:
        return json.dumps({
            "id": self.id,
            "role": self.role,
            "text": self.text,
            "ts": self.ts,
            "embedding": self.embedding,
            "metadata": self.metadata,
        }, ensure_ascii=False)


class DatasetManager:
    """Append-only dataset for chat history with semantic retrieval."""

    def __init__(
        self,
        helper: OllamaHelper,
        data_dir: Path = DATA_DIR,
        enable_embeddings: bool = True,
    ):
        self.helper = helper
        self.data_dir = data_dir
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.dataset_path = self.data_dir / DATASET_FILE.name
        self.index_path = self.data_dir / INDEX_FILE.name
        self._lock = threading.Lock()
        self._index: List[Dict[str, object]] = []
        self.enable_embeddings = enable_embeddings
        self._load_index()

    def set_embeddings_enabled(self, enabled: bool) -> None:
        self.enable_embeddings = enabled

    # ------------------------------------------------------------------
    def append(
        self,
        role: str,
        text: str,
        metadata: Optional[Dict[str, str]] = None,
    ) -> DatasetEntry:
        entry_metadata = self._normalize_metadata(metadata)
        entry = DatasetEntry(
            id=uuid.uuid4().hex,
            role=role,
            text=text,
            metadata=entry_metadata,
        )
        if self.enable_embeddings and text.strip():
            ok, vector, _ = self.helper.embed(text)
            if ok:
                entry.embedding = vector
        payload = entry.to_json()
        with self._lock:
            with self.dataset_path.open("a", encoding="utf-8") as handle:
                handle.write(payload + "\n")
            self._index.append({
                "id": entry.id,
                "role": entry.role,
                "embedding": entry.embedding,
                "ts": entry.ts,
            })
            self._persist_index()
        return entry

    # ------------------------------------------------------------------
    def filter_by_metadata(
        self,
        filters: Dict[str, object],
    ) -> List[DatasetEntry]:
        """Return entries whose metadata contains all requested filters."""

        normalized = self._normalize_metadata_filters(filters)
        if not normalized:
            return self.recent_history(limit=MAX_CONTEXT)

        results: List[DatasetEntry] = []
        try:
            with self.dataset_path.open("r", encoding="utf-8") as handle:
                for line in handle:
                    try:
                        data = json.loads(line)
                    except json.JSONDecodeError:
                        continue
                    metadata = data.get("metadata") or {}
                    if not isinstance(metadata, dict):
                        continue
                    metadata_dict = {str(k): str(v) for k, v in metadata.items()}
                    if not self._metadata_matches(metadata_dict, normalized):
                        continue
                    results.append(
                        DatasetEntry(
                            id=str(data.get("id", "")),
                            role=str(data.get("role", "")),
                            text=str(data.get("text", "")),
                            ts=float(data.get("ts", 0.0)),
                            embedding=data.get("embedding") or [],
                            metadata=metadata_dict,
                        )
                    )
        except FileNotFoundError:
            return []

        results.sort(key=lambda item: item.ts)
        return results

    # ------------------------------------------------------------------
    def semantic_directive_search(
        self,
        query: str,
        *,
        statuses: Optional[Iterable[str]] = None,
        bucket_id: Optional[str] = None,
        top_k: int = 5,
    ) -> List[DatasetEntry]:
        """Semantic search constrained by directive metadata filters."""

        base_results = self.semantic_search(query, top_k=top_k)
        filters: Dict[str, object] = {}
        if statuses:
            filters["directive_status"] = list(statuses)
        if bucket_id:
            filters["directive_bucket_id"] = bucket_id
        normalized = self._normalize_metadata_filters(filters)
        if not normalized:
            return base_results
        return [
            entry
            for entry in base_results
            if self._metadata_matches(entry.metadata, normalized)
        ]

    # ------------------------------------------------------------------
    def semantic_search(
        self,
        query: str,
        top_k: int = 5,
    ) -> List[DatasetEntry]:
        if not query.strip():
            return []
        if not self.enable_embeddings:
            return []
        ok, query_vec, _ = self.helper.embed(query)
        if not ok or not query_vec:
            return []
        with self._lock:
            candidates = list(self._index)
        scored: List[Tuple[float, Dict[str, object]]] = []
        for row in candidates:
            embedding = row.get("embedding") or []
            if not embedding:
                continue
            score = cosine_similarity(query_vec, embedding)
            if score <= 0:
                continue
            scored.append((score, row))
        scored.sort(key=lambda item: item[0], reverse=True)
        top_rows = [row for _, row in scored[:top_k]]
        return self._load_entries(top_rows)

    # ------------------------------------------------------------------
    def recent_history(self, limit: int = 6) -> List[DatasetEntry]:
        with self._lock:
            rows = list(self._index)[-limit:]
        return self._load_entries(rows)

    # ------------------------------------------------------------------
    def _load_index(self) -> None:
        if not self.index_path.exists():
            return
        try:
            data = json.loads(self.index_path.read_text(encoding="utf-8"))
            if isinstance(data, list):
                self._index = data[-MAX_CONTEXT:]
        except Exception:
            self._index = []

    def _persist_index(self) -> None:
        data = self._index[-MAX_CONTEXT:]
        self.index_path.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )

    def _load_entries(
        self,
        rows: Iterable[Dict[str, object]],
    ) -> List[DatasetEntry]:
        lookup = {row.get("id"): row for row in rows}
        if not lookup:
            return []
        results: List[DatasetEntry] = []
        try:
            with self.dataset_path.open("r", encoding="utf-8") as handle:
                for line in handle:
                    data = json.loads(line)
                    entry_id = data.get("id")
                    if entry_id in lookup:
                        results.append(DatasetEntry(
                            id=entry_id,
                            role=data.get("role", ""),
                            text=data.get("text", ""),
                            ts=data.get("ts", 0.0),
                            embedding=data.get("embedding") or [],
                            metadata=data.get("metadata") or {},
                        ))
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []
        results.sort(key=lambda item: item.ts)
        return results

    # ------------------------------------------------------------------
    def _normalize_metadata(
        self,
        metadata: Optional[Dict[str, str]],
    ) -> Dict[str, str]:
        normalized: Dict[str, str] = {}
        if not metadata:
            return normalized
        for key, value in metadata.items():
            if value is None:
                continue
            key_str = str(key)
            value_str = str(value)
            if not key_str:
                continue
            normalized[key_str] = value_str
        return normalized

    def _normalize_metadata_filters(
        self,
        filters: Dict[str, object],
    ) -> Dict[str, set]:
        normalized: Dict[str, set] = {}
        for key, raw in filters.items():
            if raw is None:
                continue
            values: set = set()
            if isinstance(raw, str):
                cleaned = raw.strip().lower()
                if cleaned:
                    values.add(cleaned)
            elif isinstance(raw, _Collection):
                for item in raw:
                    if item is None:
                        continue
                    cleaned = str(item).strip().lower()
                    if cleaned:
                        values.add(cleaned)
            else:
                cleaned = str(raw).strip().lower()
                if cleaned:
                    values.add(cleaned)
            if values:
                normalized[str(key)] = values
        return normalized

    def _metadata_matches(
        self,
        metadata: Dict[str, str],
        filters: Dict[str, set],
    ) -> bool:
        for key, expected in filters.items():
            actual = metadata.get(key)
            if actual is None:
                return False
            actual_values = {
                part.strip().lower()
                for part in str(actual).split(",")
                if part.strip()
            }
            if not actual_values:
                actual_values = {str(actual).strip().lower()}
            if actual_values.isdisjoint(expected):
                return False
        return True


__all__ = [
    "DatasetManager",
    "DatasetEntry",
    "cosine_similarity",
    "DATASET_FILE",
    "INDEX_FILE",
]
```

Dataset persistence for chat transcripts and embeddings.
**Classes:** DatasetEntry, DatasetManager
**Functions:** cosine_similarity(a, b)


## Module `lexicon_manager.py`

```python
"""Lexicon manager for learned voice phrases.

This module stores user-defined phrases that map to downstream intents
understood by :func:`parse_expressionary`.  The data is persisted on disk so
that learned phrases survive application restarts.
"""

from __future__ import annotations

import json
import threading
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, Optional, Tuple


class LexiconConflictError(RuntimeError):
    """Raised when attempting to overwrite an existing phrase mapping."""


@dataclass
class LexiconEntry:
    phrase: str
    intent: str
    params: Dict[str, Any]


class LexiconManager:
    """Thread-safe persistence helper for learned lexicon entries."""

    def __init__(
        self,
        storage_path: Optional[Path] = None,
        normalizer: Optional[Callable[[str], str]] = None,
    ) -> None:
        self._path = storage_path or Path(__file__).with_name("learned_lexicon.json")
        self._normalize = normalizer or (lambda s: s.strip().lower())
        self._lock = threading.Lock()
        self._entries: Dict[str, LexiconEntry] = {}
        self._load_from_disk()

    # ------------------------------------------------------------------
    # internal helpers
    def _load_from_disk(self) -> None:
        if not self._path.exists():
            self._entries.clear()
            return

        try:
            data = json.loads(self._path.read_text(encoding="utf-8"))
        except Exception:
            # Corrupted lexicon — start fresh but keep file for inspection.
            self._entries.clear()
            return

        if not isinstance(data, dict):
            self._entries.clear()
            return

        entries = {}
        for key, value in data.get("entries", {}).items():
            if not isinstance(value, dict):
                continue
            phrase = value.get("phrase") or key
            intent = value.get("intent")
            params = value.get("params")
            if not isinstance(intent, str) or not isinstance(params, dict):
                continue
            entries[key] = LexiconEntry(phrase=phrase, intent=intent, params=params)

        self._entries = entries

    def _serialize(self) -> Dict[str, Any]:
        with self._lock:
            return {
                "entries": {
                    key: {
                        "phrase": entry.phrase,
                        "intent": entry.intent,
                        "params": entry.params,
                    }
                    for key, entry in self._entries.items()
                }
            }

    # ------------------------------------------------------------------
    # public API
    def load(self) -> Dict[str, Dict[str, Any]]:
        """Return a copy of the currently loaded lexicon entries."""

        with self._lock:
            return {
                key: {
                    "phrase": entry.phrase,
                    "intent": entry.intent,
                    "params": dict(entry.params),
                }
                for key, entry in self._entries.items()
            }

    def save(self) -> None:
        data = self._serialize()
        self._path.parent.mkdir(parents=True, exist_ok=True)
        self._path.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding="utf-8")

    def match(self, phrase: str) -> Optional[Tuple[str, Dict[str, Any]]]:
        key = self._normalize(phrase)
        with self._lock:
            entry = self._entries.get(key)
            if not entry:
                return None
            return entry.intent, dict(entry.params)

    def update(self, phrase: str, intent: str, params: Dict[str, Any]) -> bool:
        """Insert or validate a phrase mapping.

        Returns ``True`` when a new mapping was stored.  Raises
        :class:`LexiconConflictError` if attempting to overwrite an existing
        mapping with a different intent/params payload.  Re-applying the exact
        same mapping returns ``False`` to signal that no change was necessary.
        """

        key = self._normalize(phrase)
        if not key:
            raise ValueError("Phrase must not be empty")

        with self._lock:
            existing = self._entries.get(key)
            if existing:
                if existing.intent != intent or existing.params != params:
                    raise LexiconConflictError(
                        f"Phrase '{phrase}' already maps to a different action"
                    )
                return False

            self._entries[key] = LexiconEntry(
                phrase=phrase,
                intent=intent,
                params=dict(params),
            )

        self.save()
        return True


__all__ = ["LexiconManager", "LexiconConflictError", "LexiconEntry"]
```

Lexicon manager for learned voice phrases.

This module stores user-defined phrases that map to downstream intents
understood by :func:`parse_expressionary`.  The data is persisted on disk so
that learned phrases survive application restarts.
**Classes:** LexiconConflictError, LexiconEntry, LexiconManager


## Module `ollama_helper.py`

```python
#!/usr/bin/env python3
"""Utilities for interacting with a local Ollama instance."""

from __future__ import annotations

import json
import os
import subprocess
from dataclasses import dataclass
from typing import Dict, Generator, Iterable, List, Optional, Tuple

try:  # optional dependency
    import requests
except Exception:  # pragma: no cover - requests may be absent in CI
    requests = None  # type: ignore

OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://127.0.0.1:11434")
CHAT_MODEL = "qwen3:8b"
EMBED_MODEL = "snowflake-arctic-embed2:latest"
DEFAULT_TIMEOUT = 60


@dataclass
class OllamaResult:
    ok: bool
    content: str
    error: str = ""
    diagnostics: Optional[Dict[str, str]] = None


class OllamaHelper:
    """Wrapper around Ollama HTTP/CLI interfaces with graceful fallbacks."""

    def __init__(self, host: str = OLLAMA_HOST):
        self.host = host.rstrip("/")

    # ------------------------------------------------------------------
    # Discovery & health
    # ------------------------------------------------------------------
    def check_health(self, timeout: float = 3.0) -> Tuple[bool, str]:
        if requests is None:
            return False, "Python requests module unavailable"
        try:
            resp = requests.get(self.host, timeout=timeout)
            if resp.ok:
                return True, "OK"
            return False, f"HTTP {resp.status_code}"
        except Exception as exc:  # pragma: no cover - network issues
            return False, str(exc)

    def list_models(self) -> List[str]:
        models: List[str] = []
        if requests is not None:
            try:
                resp = requests.get(f"{self.host}/api/tags", timeout=5)
                if resp.ok:
                    payload = resp.json()
                    models.extend(
                        m.get("name") or m.get("model")
                        for m in payload.get("models", [])
                        if m.get("name") or m.get("model")
                    )
            except Exception:
                pass
        if not models:
            models.extend(self._list_models_cli())
        return sorted({m for m in models if m})

    def ensure_model(self, model: str) -> bool:
        return model in self.list_models()

    # ------------------------------------------------------------------
    # Chat completion
    # ------------------------------------------------------------------
    def chat(
        self,
        messages: List[Dict[str, str]],
        model: str = CHAT_MODEL,
        timeout: float = DEFAULT_TIMEOUT,
        stream: bool = False,
    ) -> OllamaResult:
        if requests is not None:
            try:
                body = {"model": model, "messages": messages, "stream": stream}
                resp = requests.post(
                    f"{self.host}/api/chat",
                    json=body,
                    timeout=timeout,
                    stream=stream,
                    headers={"Content-Type": "application/json"},
                )
                if not resp.ok:
                    error_msg = f"HTTP {resp.status_code}: {resp.text[:200]}"
                    return OllamaResult(False, "", error_msg)
                if stream:
                    content = "".join(self._consume_stream(resp.iter_lines()))
                else:
                    payload = resp.json()
                    msg = payload.get("message") or {}
                    content = msg.get("content") or payload.get("response", "")
                return OllamaResult(True, content)
            except Exception as exc:  # pragma: no cover - network issues
                last_error = str(exc)
            else:
                last_error = "unknown"
        else:
            last_error = "requests unavailable"
        # CLI fallback
        cli_ok, cli_text, cli_err = self._chat_via_cli(
            messages,
            model,
            timeout,
        )
        cli_diag = {"transport": "cli"}
        if cli_ok:
            return OllamaResult(True, cli_text, diagnostics=cli_diag)
        error_text = cli_err or last_error
        return OllamaResult(False, "", error_text, diagnostics=cli_diag)

    def stream_chat(
        self,
        messages: List[Dict[str, str]],
        model: str = CHAT_MODEL,
        timeout: float = DEFAULT_TIMEOUT,
    ) -> Generator[str, None, OllamaResult]:
        if requests is None:
            yield from ()
            offline_diag = {"transport": "none"}
            return OllamaResult(
                False,
                "",
                "requests unavailable",
                diagnostics=offline_diag,
            )
        try:
            body = {"model": model, "messages": messages, "stream": True}
            resp = requests.post(
                f"{self.host}/api/chat",
                json=body,
                timeout=timeout,
                stream=True,
                headers={"Content-Type": "application/json"},
            )
            if not resp.ok:
                error_msg = f"HTTP {resp.status_code}: {resp.text[:200]}"
                return OllamaResult(False, "", error_msg)
            buffer: List[str] = []
            for chunk in resp.iter_lines():
                if not chunk:
                    continue
                try:
                    payload = json.loads(chunk.decode("utf-8"))
                except Exception:
                    continue
                piece = (
                    (payload.get("message") or {}).get("content")
                    or payload.get("response", "")
                )
                if piece:
                    buffer.append(piece)
                    yield piece
            return OllamaResult(True, "".join(buffer))
        except Exception as exc:  # pragma: no cover - network issues
            return OllamaResult(False, "", str(exc))

    # ------------------------------------------------------------------
    # Embeddings
    # ------------------------------------------------------------------
    def embed(
        self,
        text: str,
        model: str = EMBED_MODEL,
        timeout: float = 120.0,
    ) -> Tuple[bool, List[float], str]:
        if requests is not None:
            try:
                payload = {"model": model, "input": text}
                resp = requests.post(
                    f"{self.host}/api/embeddings",
                    json=payload,
                    timeout=timeout,
                )
                if not resp.ok:
                    msg = f"HTTP {resp.status_code}: {resp.text[:200]}"
                    return False, [], msg
                data = resp.json()
                vector = data.get("embedding")
                if vector is None and isinstance(data.get("data"), list):
                    vector = (data["data"] or [{}])[0].get("embedding")
                if isinstance(vector, list):
                    return True, [float(x) for x in vector], ""
                return False, [], "Malformed embedding payload"
            except Exception as exc:  # pragma: no cover - network issues
                last_error = str(exc)
        else:
            last_error = "requests unavailable"
        return False, [], last_error

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _consume_stream(
        self,
        lines: Iterable[bytes],
    ) -> List[str]:
        pieces: List[str] = []
        for line in lines:
            if not line:
                continue
            try:
                payload = json.loads(line.decode("utf-8"))
            except Exception:
                continue
            piece = (
                (payload.get("message") or {}).get("content")
                or payload.get("response", "")
            )
            if piece:
                pieces.append(piece)
        return pieces

    def _list_models_cli(self) -> List[str]:
        try:
            proc = subprocess.run(
                [
                    "ollama",
                    "list",
                ],
                check=False,
                capture_output=True,
                text=True,
                timeout=5,
            )
        except Exception:
            return []
        if proc.returncode != 0:
            return []
        models: List[str] = []
        for line in proc.stdout.splitlines()[1:]:
            parts = line.strip().split()
            if parts:
                models.append(parts[0])
        return models

    def _chat_via_cli(
        self,
        messages: List[Dict[str, str]],
        model: str,
        timeout: float,
    ) -> Tuple[bool, str, str]:
        prompt_lines = [
            f"{m['role']}: {m.get('content', '')}"
            for m in messages
        ]
        prompt = "\n".join(prompt_lines)
        try:
            proc = subprocess.run(
                ["ollama", "run", model, prompt],
                check=False,
                capture_output=True,
                text=True,
                timeout=timeout,
            )
        except Exception as exc:
            return False, "", str(exc)
        if proc.returncode != 0:
            return False, "", proc.stderr.strip() or proc.stdout.strip()
        return True, proc.stdout.strip(), ""


__all__ = [
    "OllamaHelper",
    "OllamaResult",
    "CHAT_MODEL",
    "EMBED_MODEL",
]
```

Utilities for interacting with a local Ollama instance.
**Classes:** OllamaResult, OllamaHelper


## Module `planner_service.py`

```python
"""Reasoning-driven planner service for ambiguous directives."""

from __future__ import annotations

import json
import os
import re
import time
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

from ollama_helper import CHAT_MODEL, OllamaHelper, OllamaResult

PLANNER_MODEL = os.getenv("PLANNER_MODEL", CHAT_MODEL)
DATA_DIR = Path(__file__).resolve().parent / "data"
JSON_LOG_NAME = "planner_log.jsonl"
MD_LOG_NAME = "planner_log.md"


@dataclass
class PlannerStep:
    """Single actionable step emitted by the planner."""

    action: str
    summary: str
    arguments: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        payload = {
            "action": self.action,
            "summary": self.summary,
        }
        if self.arguments:
            payload["arguments"] = self.arguments
        return payload


@dataclass
class PlannerPlan:
    """Structured plan describing the proposed action sequence."""

    title: str
    steps: List[PlannerStep] = field(default_factory=list)
    confidence: float = 0.0
    notes: str = ""
    next_action: str = ""
    raw: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_payload(self) -> Dict[str, Any]:
        payload = {
            "title": self.title,
            "steps": [step.to_dict() for step in self.steps],
            "confidence": self.confidence,
            "notes": self.notes,
            "next_action": self.next_action,
            "raw": self.raw,
        }
        if self.metadata:
            payload["metadata"] = self.metadata
        return payload


@dataclass
class PlannerDecision:
    """Planner interpretation of an utterance."""

    intent: str
    needs_clarification: bool
    question: Optional[str]
    plan: Optional[PlannerPlan]
    confidence: float
    raw: Dict[str, Any]
    raw_response: str
    error: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        data = {
            "intent": self.intent,
            "needs_clarification": self.needs_clarification,
            "question": self.question,
            "confidence": self.confidence,
            "raw": self.raw,
            "raw_response": self.raw_response,
            "error": self.error,
        }
        if self.plan:
            data["plan"] = self.plan.to_payload()
        return data


class PlannerService:
    """Call the preferred reasoning model to derive structured plans."""

    def __init__(
        self,
        helper: Optional[OllamaHelper] = None,
        *,
        model: str = PLANNER_MODEL,
        data_dir: Path | None = None,
    ) -> None:
        self.helper = helper or OllamaHelper()
        self.model = model
        self.data_dir = data_dir or DATA_DIR
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.json_log = self.data_dir / JSON_LOG_NAME
        self.md_log = self.data_dir / MD_LOG_NAME
        if not self.json_log.exists():
            self.json_log.touch()
        if not self.md_log.exists():
            self.md_log.write_text("# Planner Decisions\n\n", encoding="utf-8")

    # ------------------------------------------------------------------
    def plan(
        self,
        utterance: str,
        *,
        context: Optional[Dict[str, Any]] = None,
    ) -> PlannerDecision:
        """Interpret ``utterance`` and emit a :class:`PlannerDecision`."""

        context = context or {}
        messages = self._build_messages(utterance, context)
        result = self.helper.chat(messages, model=self.model, timeout=60.0)
        decision = self._parse_result(utterance, result, context)
        self._log_event(
            {
                "event": "decision",
                "utterance": utterance,
                "context": context,
                "decision": decision.to_dict(),
            }
        )
        return decision

    # ------------------------------------------------------------------
    def record_execution(
        self,
        plan: PlannerPlan | Dict[str, Any],
        *,
        stage: str,
        status: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Persist execution metadata for replay."""

        context = context or {}
        if isinstance(plan, PlannerPlan):
            payload = plan.to_payload()
        else:
            payload = plan
        self._log_event(
            {
                "event": "execution",
                "stage": stage,
                "status": status,
                "plan": payload,
                "context": context,
            }
        )

    # ------------------------------------------------------------------
    def _build_messages(
        self,
        utterance: str,
        context: Dict[str, Any],
    ) -> List[Dict[str, str]]:
        context_json = json.dumps(context, ensure_ascii=False, indent=2)
        return [
            {
                "role": "system",
                "content": (
                    "You are a planning assistant that routes natural language "
                    "to GUI automation primitives. Respond ONLY with JSON using "
                    "the schema {intent, clarification_needed, clarification_question, "
                    "title, confidence, steps, notes, next_action}. Steps must be an "
                    "array of objects containing action, summary, and optional arguments."
                ),
            },
            {
                "role": "user",
                "content": (
                    "Utterance: "
                    + utterance
                    + "\nContext: "
                    + context_json
                    + "\nRespond with JSON only."
                ),
            },
        ]

    # ------------------------------------------------------------------
    def _parse_result(
        self,
        utterance: str,
        result: OllamaResult,
        context: Dict[str, Any],
    ) -> PlannerDecision:
        fallback_question = "Do you want to design the idea or open the editor?"
        if not result.ok:
            return PlannerDecision(
                intent="clarify",
                needs_clarification=True,
                question=fallback_question,
                plan=None,
                confidence=0.0,
                raw={"error": result.error or "planner-error", "utterance": utterance},
                raw_response=result.error or "",
                error=result.error or "planner-error",
            )

        data = self._extract_json(result.content)
        if not data:
            return PlannerDecision(
                intent="clarify",
                needs_clarification=True,
                question=fallback_question,
                plan=None,
                confidence=0.0,
                raw={"raw_text": result.content, "utterance": utterance},
                raw_response=result.content,
                error="invalid-json",
            )

        intent = str(data.get("intent") or "clarify").lower()
        clarification_needed = bool(
            data.get("clarification_needed")
            or intent in {"clarify", "clarification", "question"}
        )
        question = data.get("clarification_question") or data.get("question")
        confidence = 0.0
        try:
            confidence = float(data.get("confidence") or 0.0)
        except Exception:
            confidence = 0.0

        plan_obj: Optional[PlannerPlan] = None
        if data.get("steps"):
            plan_obj = self._build_plan(data)

        return PlannerDecision(
            intent=intent,
            needs_clarification=clarification_needed,
            question=str(question) if question else None,
            plan=plan_obj,
            confidence=confidence,
            raw={"data": data, "context": context},
            raw_response=result.content,
        )

    # ------------------------------------------------------------------
    def _build_plan(self, data: Dict[str, Any]) -> PlannerPlan:
        title = str(data.get("title") or data.get("plan") or "Plan")
        steps_data = data.get("steps") or []
        steps: List[PlannerStep] = []
        if isinstance(steps_data, list):
            for item in steps_data:
                if not isinstance(item, dict):
                    continue
                action = str(item.get("action") or item.get("act") or "unknown")
                summary = str(
                    item.get("summary")
                    or item.get("description")
                    or item.get("detail")
                    or action
                )
                arguments = item.get("arguments") or item.get("args") or {}
                if not isinstance(arguments, dict):
                    arguments = {}
                steps.append(PlannerStep(action=action, summary=summary, arguments=arguments))
        notes = str(data.get("notes") or "")
        next_action = str(data.get("next_action") or data.get("next") or "")
        confidence = 0.0
        try:
            confidence = float(data.get("confidence") or 0.0)
        except Exception:
            confidence = 0.0
        metadata = data.get("metadata")
        if not isinstance(metadata, dict):
            metadata = {}
        return PlannerPlan(
            title=title,
            steps=steps,
            confidence=confidence,
            notes=notes,
            next_action=next_action,
            raw=data,
            metadata=metadata,
        )

    # ------------------------------------------------------------------
    def _extract_json(self, text: str) -> Dict[str, Any]:
        if not text:
            return {}
        snippet = text.strip()
        fence_match = re.search(r"```json(.*?)```", snippet, re.DOTALL | re.IGNORECASE)
        if fence_match:
            snippet = fence_match.group(1)
        brace_match = re.search(r"\{.*\}", snippet, re.DOTALL)
        if brace_match:
            snippet = brace_match.group(0)
        snippet = snippet.strip()
        if not snippet:
            return {}
        try:
            return json.loads(snippet)
        except json.JSONDecodeError:
            return {}

    # ------------------------------------------------------------------
    def _log_event(self, payload: Dict[str, Any]) -> None:
        ts = time.time()
        iso = datetime.fromtimestamp(ts, tz=timezone.utc).isoformat()
        record = {"ts": ts, "iso": iso, **payload}
        with self.json_log.open("a", encoding="utf-8") as handle:
            handle.write(json.dumps(record, ensure_ascii=False) + "\n")

        lines = [f"### {iso}", f"- Event: {payload.get('event', 'unknown')}" ]
        utterance = payload.get("utterance")
        if utterance:
            lines.append(f"- Utterance: `{utterance}`")
        if payload.get("event") == "decision":
            decision = payload.get("decision") or {}
            intent = decision.get("intent")
            lines.append(f"- Intent: {intent}")
            if decision.get("needs_clarification"):
                question = decision.get("question") or "(none)"
                lines.append(f"- Clarification: {question}")
            plan = decision.get("plan")
            if plan:
                lines.append(f"- Plan: {plan.get('title')} ({len(plan.get('steps', []))} steps)")
        elif payload.get("event") == "execution":
            status = payload.get("status")
            stage = payload.get("stage")
            lines.append(f"- Stage: {stage}")
            lines.append(f"- Status: {status}")
        lines.append("")
        with self.md_log.open("a", encoding="utf-8") as md:
            md.write("\n".join(lines) + "\n")


__all__ = [
    "PlannerService",
    "PlannerDecision",
    "PlannerPlan",
    "PlannerStep",
]
```

Reasoning-driven planner service for ambiguous directives.
**Classes:** PlannerStep, PlannerPlan, PlannerDecision, PlannerService


## Module `Virtual_Desktop.py`

```python
"""Minimal virtual desktop shell with Start panel integration.

This module promotes the Dev Logic desktop prototype into a repository-level
component. It keeps the containment/allowlist guards while trimming dependencies
that only existed in the sandbox build. The desktop exposes a Start ▸ Apps entry
for launching the voice-enabled Codex terminal inside a card window.
"""

from __future__ import annotations

import os
import shutil
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Callable, Dict, Iterable, List, Optional, Tuple

from PySide6.QtCore import QEvent, QFileInfo, QMimeData, QPoint, QRect, QSize, Qt, Signal
from PySide6.QtGui import QColor, QCloseEvent, QDrag, QIcon, QPainter, QPixmap, QResizeEvent
from PySide6.QtWidgets import (
    QApplication,
    QFrame,
    QHBoxLayout,
    QLabel,
    QMainWindow,
    QMessageBox,
    QPushButton,
    QScrollArea,
    QSizePolicy,
    QStyle,
    QToolButton,
    QVBoxLayout,
    QWidget,
)

try:  # Import lazily so the desktop still loads even if the terminal fails.
    from VoiceGuidedCodexTerminal import create_card as create_voice_codex_card
except Exception:  # pragma: no cover - optional dependency
    create_voice_codex_card = None  # type: ignore

SCRIPT_DIR = Path(__file__).resolve().parent
_ENV_WORKSPACE = os.environ.get("CODEX_WORKSPACE")
try:
    WORKSPACE_ROOT = (
        Path(_ENV_WORKSPACE).expanduser().resolve() if _ENV_WORKSPACE else SCRIPT_DIR
    )
except Exception:
    WORKSPACE_ROOT = SCRIPT_DIR


def workspace_root() -> str:
    """Return the active workspace path for the virtual desktop."""

    return str(WORKSPACE_ROOT)


def _safe_resolve(path_str: Optional[str]) -> Optional[str]:
    if not path_str:
        return None
    try:
        resolved = Path(path_str).expanduser().resolve()
    except Exception:
        return None
    return str(resolved)


def _is_contained(path: str) -> bool:
    try:
        resolved = Path(path).resolve()
        root = WORKSPACE_ROOT
        return resolved == root or root in resolved.parents
    except Exception:
        return False


_defensive_candidates: Iterable[Optional[str]] = (
    sys.executable,
    os.environ.get("COMSPEC"),
    os.environ.get("SHELL"),
    shutil.which("python"),
    shutil.which("python3"),
    shutil.which("cmd"),
    shutil.which("cmd.exe"),
    shutil.which("powershell"),
    shutil.which("powershell.exe"),
    shutil.which("pwsh"),
    shutil.which("bash"),
    shutil.which("sh"),
)


def _build_allowlist() -> set[str]:
    entries: set[str] = set()
    for candidate in _defensive_candidates:
        resolved = _safe_resolve(candidate)
        if resolved:
            entries.add(resolved)
    return entries


ALLOWLIST: set[str] = _build_allowlist()


def _resolve_executable_path(cmd: List[str], cwd: Optional[str]) -> Optional[str]:
    if not cmd:
        return None
    first = cmd[0]
    if os.path.isabs(first):
        resolved = _safe_resolve(first)
        if resolved:
            return resolved
    search_path = None
    if cwd:
        try:
            candidate = Path(cwd).joinpath(first).resolve()
            if candidate.exists():
                return str(candidate)
        except Exception:
            pass
        try:
            resolved_cwd = Path(cwd).resolve()
            if resolved_cwd.exists():
                search_path = str(resolved_cwd)
        except Exception:
            search_path = None
    if search_path:
        located = shutil.which(first, path=search_path)
        if located:
            resolved = _safe_resolve(located)
            if resolved:
                return resolved
    located = shutil.which(first)
    if located:
        resolved = _safe_resolve(located)
        if resolved:
            return resolved
    return None


def _validate_process_request(cmd: List[str], cwd: Optional[str]) -> Tuple[bool, str]:
    if not cmd:
        return False, "Blocked: no command specified."
    resolved_cwd = os.path.abspath(cwd or workspace_root())
    if not os.path.isdir(resolved_cwd):
        return False, f"Blocked: working directory does not exist ({resolved_cwd})."
    if not _is_contained(resolved_cwd):
        return False, "Blocked: working directory is outside the Virtual Desktop workspace."
    exec_path = _resolve_executable_path(cmd, resolved_cwd)
    if not exec_path:
        return False, "Blocked: executable could not be resolved inside the workspace."
    if not (_is_contained(exec_path) or exec_path in ALLOWLIST):
        name = os.path.basename(exec_path) or exec_path
        return False, f"Blocked: {name} is outside the Virtual Desktop workspace."
    return True, exec_path


def validate_process_request(cmd: List[str], cwd: Optional[str] = None) -> Tuple[bool, str]:
    """Public wrapper for the containment guard used by tests."""

    return _validate_process_request(cmd, cwd)


_ICON_DRAG_MIME = "application/x-virtual-desktop-icon"


class DesktopIcon(QToolButton):
    """Interactive desktop icon with hover highlight and drag support."""

    moved = Signal(str, QPoint)
    selection_changed = Signal(bool)

    def __init__(
        self,
        path: str,
        parent: Optional[QWidget] = None,
        grid_size: Tuple[int, int] | QSize = (96, 96),
    ) -> None:
        super().__init__(parent)
        self._path = path
        self._hovered = False
        self._selected = False
        self._dragging = False
        self._press_pos = QPoint()
        self._drag_offset = QPoint()
        self._stored_pos = QPoint()
        self._grid_size = self._coerce_grid_size(grid_size)
        self._drop_target = parent
        if self._drop_target is not None:
            self._drop_target.setAcceptDrops(True)
            self._drop_target.installEventFilter(self)
        self.setAutoRaise(True)
        self.setToolButtonStyle(Qt.ToolButtonTextUnderIcon)
        self.setCursor(Qt.PointingHandCursor)
        self.setIconSize(QSize(48, 48))
        self._apply_path_metadata()
        self._update_tooltip()

    # ------------------------------------------------------------------ properties
    def path(self) -> str:
        return self._path

    def isSelected(self) -> bool:
        return self._selected

    def setSelected(self, value: bool) -> None:
        if self._selected == value:
            return
        self._selected = value
        self.selection_changed.emit(value)
        self.update()

    # ------------------------------------------------------------------ Qt handlers
    def enterEvent(self, event: QEvent) -> None:  # pragma: no cover - Qt lifecycle
        self._hovered = True
        self.update()
        super().enterEvent(event)

    def leaveEvent(self, event: QEvent) -> None:  # pragma: no cover - Qt lifecycle
        self._hovered = False
        self.update()
        super().leaveEvent(event)

    def mousePressEvent(self, event) -> None:  # pragma: no cover - Qt lifecycle
        if event.button() == Qt.LeftButton:
            self._press_pos = event.position().toPoint()
            self._stored_pos = self.pos()
            self.setSelected(True)
        super().mousePressEvent(event)

    def mouseMoveEvent(self, event) -> None:  # pragma: no cover - Qt lifecycle
        if (event.buttons() & Qt.LeftButton) and not self._dragging:
            delta = event.position().toPoint() - self._press_pos
            if delta.manhattanLength() >= QApplication.startDragDistance():
                self._start_drag()
                return
        super().mouseMoveEvent(event)

    def mouseReleaseEvent(self, event) -> None:  # pragma: no cover - Qt lifecycle
        if event.button() == Qt.LeftButton:
            # Keep selection independent from activation.
            self.setSelected(True)
        super().mouseReleaseEvent(event)

    def paintEvent(self, event) -> None:  # pragma: no cover - Qt lifecycle
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        rect = self.rect().adjusted(4, 4, -4, -4)
        if self._selected:
            fill = QColor(62, 102, 181, 150)
            stroke = QColor(62, 102, 181, 220)
        elif self._hovered:
            fill = QColor(62, 102, 181, 70)
            stroke = QColor(62, 102, 181, 160)
        else:
            fill = None
            stroke = None
        if fill is not None and stroke is not None:
            painter.setBrush(fill)
            painter.setPen(stroke)
            painter.drawRoundedRect(rect, 8, 8)
        painter.end()
        super().paintEvent(event)

    def eventFilter(self, obj, event):  # pragma: no cover - Qt lifecycle
        if obj is self._drop_target and event and self._dragging:
            if event.type() in {QEvent.DragEnter, QEvent.DragMove}:
                source = getattr(event, "source", lambda: None)()
                if source is self and event.mimeData().hasFormat(_ICON_DRAG_MIME):
                    event.acceptProposedAction()
                    return True
            elif event.type() == QEvent.Drop:
                source = getattr(event, "source", lambda: None)()
                if source is self and event.mimeData().hasFormat(_ICON_DRAG_MIME):
                    self._handle_drop(event)
                    return True
        return super().eventFilter(obj, event)

    # ------------------------------------------------------------------ helpers
    def _coerce_grid_size(self, grid: Tuple[int, int] | QSize) -> QSize:
        if isinstance(grid, QSize):
            return QSize(max(1, grid.width()), max(1, grid.height()))
        gx, gy = grid
        return QSize(max(1, int(gx)), max(1, int(gy)))

    def _apply_path_metadata(self) -> None:
        info = QFileInfo(self._path)
        base_name = info.completeBaseName() or info.fileName()
        if not base_name:
            base_name = os.path.basename(self._path)
        icon = QApplication.style().standardIcon(
            QStyle.SP_DirIcon if info.isDir() else QStyle.SP_FileIcon
        )
        self.setIcon(icon)
        self.setText(base_name)

    def _update_tooltip(self) -> None:
        info = QFileInfo(self._path)
        name = info.fileName() or os.path.basename(self._path)
        if info.isDir():
            type_name = "File folder"
        else:
            suffix = info.completeSuffix()
            type_name = f"{suffix.upper()} File" if suffix else "File"
        created = info.birthTime()
        if not created.isValid():
            created = info.created()
        created_text = created.toLocalTime().toString("dddd, MMMM d, yyyy h:mm AP")
        if not created_text:
            created_text = "Unknown"
        tooltip = f"{name}\nType: {type_name}\nCreated: {created_text}"
        self.setToolTip(tooltip)

    def _start_drag(self) -> None:
        if self._drop_target is None:
            return
        drag = QDrag(self)
        mime = QMimeData()
        mime.setData(_ICON_DRAG_MIME, self._path.encode("utf-8", "ignore"))
        drag.setMimeData(mime)
        pixmap = self.grab()
        if not pixmap.isNull():
            translucent = QPixmap(pixmap.size())
            translucent.fill(Qt.transparent)
            painter = QPainter(translucent)
            painter.setOpacity(0.7)
            painter.drawPixmap(0, 0, pixmap)
            painter.end()
            drag.setPixmap(translucent)
            drag.setHotSpot(self._press_pos)
        self._dragging = True
        self._drag_offset = QPoint(self._press_pos)
        result = drag.exec(Qt.MoveAction)
        if result != Qt.MoveAction:
            # Drag cancelled – restore prior selection highlight.
            self.move(self._stored_pos)
        self._dragging = False
        self._drag_offset = QPoint()
        self.update()

    def _handle_drop(self, event) -> None:
        if self._drop_target is None:
            return
        drop_point = event.position().toPoint() - self._drag_offset
        target = self._snap_to_grid(drop_point)
        rect = self._drop_target.rect()
        target.setX(max(0, min(target.x(), rect.width() - self.width())))
        target.setY(max(0, min(target.y(), rect.height() - self.height())))
        self.move(target)
        self._stored_pos = QPoint(target)
        self.setSelected(True)
        self.moved.emit(self._path, target)
        self.update()
        event.acceptProposedAction()

    def _snap_to_grid(self, point: QPoint) -> QPoint:
        gx = self._grid_size.width()
        gy = self._grid_size.height()
        snapped_x = int(round(point.x() / gx) * gx)
        snapped_y = int(round(point.y() / gy) * gy)
        return QPoint(snapped_x, snapped_y)

@dataclass
class CardDescriptor:
    identifier: str
    title: str
    icon: Optional[QIcon]
    callback: Callable[[], None]


class CardWindow(QFrame):
    """Simple card shell with header and close control."""

    closed = Signal(object)

    def __init__(self, title: str, widget: QWidget, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.setObjectName("CardWindow")
        self._content = widget
        self._title_label = QLabel(title)
        self._title_label.setObjectName("CardTitle")
        self._title_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)

        self._btn_close = QPushButton("✕")
        self._btn_close.setFixedSize(QSize(28, 24))
        self._btn_close.clicked.connect(self._on_close_clicked)

        header = QHBoxLayout()
        header.setContentsMargins(12, 8, 12, 4)
        header.addWidget(self._title_label)
        header.addWidget(self._btn_close, alignment=Qt.AlignRight)

        body = QVBoxLayout(self)
        body.setContentsMargins(0, 0, 0, 0)
        body.setSpacing(0)
        body.addLayout(header)
        body.addWidget(widget)

        self.setFrameShape(QFrame.StyledPanel)
        self.setStyleSheet(
            """
            QFrame#CardWindow {
                background: #0c1320;
                border: 1px solid #1f2a3b;
                border-radius: 12px;
            }
            QLabel#CardTitle {
                font-weight: 600;
                color: #eaf2ff;
            }
            QPushButton {
                border: none;
                color: #eaf2ff;
                background: transparent;
            }
            QPushButton:hover {
                background: rgba(255, 255, 255, 0.1);
            }
            """
        )

    def title(self) -> str:
        return self._title_label.text()

    def set_title(self, title: str) -> None:
        self._title_label.setText(title)

    def _on_close_clicked(self) -> None:
        self.closed.emit(self)
        self.setParent(None)
        self.deleteLater()


class StartPanel(QFrame):
    """Docked Start panel listing applications."""

    entry_invoked = Signal(str)

    def __init__(self, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.setObjectName("StartPanel")
        self.setVisible(False)
        self._entries: List[CardDescriptor] = []
        self._buttons: Dict[str, QPushButton] = {}

        layout = QVBoxLayout(self)
        layout.setContentsMargins(16, 16, 16, 16)
        layout.setSpacing(8)

        self._header = QLabel("Apps")
        self._header.setStyleSheet("QLabel{font-weight:600;color:#eaf2ff;}")
        layout.addWidget(self._header)

        self._apps_container = QVBoxLayout()
        self._apps_container.setSpacing(6)
        layout.addLayout(self._apps_container)

        self.setFrameShape(QFrame.StyledPanel)
        self.setStyleSheet(
            """
            QFrame#StartPanel {
                background: rgba(12, 19, 32, 0.94);
                border: 1px solid #1f2a3b;
                border-radius: 16px;
                min-width: 280px;
            }
            QPushButton {
                text-align: left;
                padding: 10px 12px;
                border-radius: 8px;
                background: transparent;
                color: #eaf2ff;
            }
            QPushButton:hover {
                background: rgba(62, 102, 181, 0.6);
            }
            """
        )

    def set_entries(self, entries: Iterable[CardDescriptor]) -> None:
        self._entries = list(entries)
        self._clear_buttons()
        for entry in self._entries:
            button = QPushButton(entry.title, self)
            button.setIcon(entry.icon or QIcon())
            button.clicked.connect(self._build_handler(entry))
            button.setProperty("startId", entry.identifier)
            self._apps_container.addWidget(button)
            self._buttons[entry.identifier] = button

    def entries(self) -> List[CardDescriptor]:
        return list(self._entries)

    def _clear_buttons(self) -> None:
        for button in self._buttons.values():
            button.setParent(None)
            button.deleteLater()
        self._buttons.clear()

    def _build_handler(self, entry: CardDescriptor) -> Callable[[], None]:
        def handler() -> None:
            entry.callback()
            self.entry_invoked.emit(entry.identifier)
            self.setVisible(False)

        return handler


class VirtualDesktopWindow(QMainWindow):
    """Contained desktop window with Start panel and card stack."""

    def __init__(self, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.setWindowTitle("Virtual Desktop")
        self.resize(1280, 840)

        central = QWidget(self)
        self.setCentralWidget(central)
        central_layout = QVBoxLayout(central)
        central_layout.setContentsMargins(0, 0, 0, 0)
        central_layout.setSpacing(0)

        self._cards_area = QScrollArea(self)
        self._cards_area.setWidgetResizable(True)
        self._cards_widget = QWidget()
        self._cards_layout = QVBoxLayout(self._cards_widget)
        self._cards_layout.setContentsMargins(32, 24, 32, 24)
        self._cards_layout.setSpacing(16)
        self._cards_layout.addStretch(1)
        self._cards_area.setWidget(self._cards_widget)

        central_layout.addWidget(self._cards_area, 1)

        self._taskbar = QFrame(self)
        self._taskbar.setObjectName("Taskbar")
        self._taskbar.setFixedHeight(48)
        taskbar_layout = QHBoxLayout(self._taskbar)
        taskbar_layout.setContentsMargins(16, 4, 16, 4)
        taskbar_layout.setSpacing(8)

        self._start_button = QPushButton(" ⊞ Start", self._taskbar)
        self._start_button.clicked.connect(self._toggle_start_panel)
        taskbar_layout.addWidget(self._start_button, alignment=Qt.AlignLeft)

        self._task_buttons: Dict[CardWindow, QPushButton] = {}
        self._taskbar_container = QHBoxLayout()
        self._taskbar_container.setSpacing(6)
        taskbar_layout.addLayout(self._taskbar_container, stretch=1)
        taskbar_layout.addStretch(1)

        central_layout.addWidget(self._taskbar)

        self._start_panel = StartPanel(central)
        self._start_panel.entry_invoked.connect(lambda _=None: self._start_button.setChecked(False))
        self._start_panel.hide()

        self._cards: Dict[str, CardWindow] = {}
        self._start_button.setCheckable(True)

        self._refresh_start_panel()
        self._position_start_panel()

        self.setStyleSheet(
            """
            QFrame#Taskbar {
                background: rgba(10, 17, 30, 0.94);
                border-top: 1px solid #1f2a3b;
            }
            QPushButton {
                font: 11pt 'Segoe UI';
            }
            """
        )

    # ------------------------------------------------------------------ cards
    def add_card(self, widget: QWidget, title: str, card_id: Optional[str] = None) -> CardWindow:
        if card_id and card_id in self._cards:
            card = self._cards[card_id]
            card.set_title(title)
            self._focus_card(card)
            return card

        card = CardWindow(title, widget, parent=self._cards_widget)
        if self._cards_layout.count() > 0:
            self._cards_layout.insertWidget(self._cards_layout.count() - 1, card)
        else:
            self._cards_layout.addWidget(card)
        card.closed.connect(lambda _: self._remove_card(card, card_id))
        self._register_task_button(card, title, card_id)
        self._focus_card(card)
        if card_id:
            self._cards[card_id] = card
        return card

    def _register_task_button(
        self, card: CardWindow, title: str, card_id: Optional[str]
    ) -> None:
        button = QPushButton(title, self._taskbar)
        button.setCheckable(True)
        button.clicked.connect(lambda _: self._focus_card(card))
        self._taskbar_container.addWidget(button)
        self._task_buttons[card] = button
        for other in self._task_buttons.values():
            other.setChecked(False)
        button.setChecked(True)

    def _focus_card(self, card: CardWindow) -> None:
        card.raise_()
        self._cards_area.ensureWidgetVisible(card)
        for other, button in self._task_buttons.items():
            button.setChecked(other is card)

    def _remove_card(self, card: CardWindow, card_id: Optional[str]) -> None:
        button = self._task_buttons.pop(card, None)
        if button:
            button.setParent(None)
            button.deleteLater()
        if card_id and card_id in self._cards:
            self._cards.pop(card_id, None)
        card.setParent(None)
        card.deleteLater()

    # ---------------------------------------------------------------- Start panel
    def _refresh_start_panel(self) -> None:
        entries = self._build_start_entries()
        self._start_panel.set_entries(entries)

    def _build_start_entries(self) -> List[CardDescriptor]:
        style = QApplication.style()
        entries: List[CardDescriptor] = []

        if create_voice_codex_card is not None:
            entries.append(
                CardDescriptor(
                    identifier="voice-codex-terminal",
                    title="Voice Codex Terminal",
                    icon=style.standardIcon(QStyle.SP_DesktopIcon),
                    callback=self.open_voice_codex_terminal,
                )
            )
        else:
            entries.append(
                CardDescriptor(
                    identifier="voice-codex-terminal",
                    title="Voice Codex Terminal (unavailable)",
                    icon=style.standardIcon(QStyle.SP_MessageBoxWarning),
                    callback=self._voice_terminal_unavailable,
                )
            )

        return entries

    def _toggle_start_panel(self) -> None:
        if self._start_panel.isVisible():
            self._start_panel.hide()
            self._start_button.setChecked(False)
        else:
            self._start_panel.show()
            self._start_panel.raise_()
            self._position_start_panel()
            self._start_button.setChecked(True)

    def _position_start_panel(self) -> None:
        panel = self._start_panel
        if not panel:
            return
        parent = panel.parentWidget()
        if not parent:
            return
        panel.adjustSize()
        start_point = QPoint(16, parent.height() - panel.height() - self._taskbar.height() - 16)
        if start_point.y() < 0:
            start_point.setY(0)
        panel.move(start_point)

    def resizeEvent(self, event: QResizeEvent) -> None:  # pragma: no cover - Qt lifecycle
        super().resizeEvent(event)
        self._position_start_panel()

    # ---------------------------------------------------------------- launchers
    def open_voice_codex_terminal(self) -> None:
        if create_voice_codex_card is None:
            self._voice_terminal_unavailable()
            return
        try:
            widget = create_voice_codex_card(embedded=True)
        except Exception as exc:  # pragma: no cover - defensive
            QMessageBox.critical(
                self,
                "Voice Codex Terminal",
                f"Unable to create Codex card: {exc}",
            )
            return
        self.add_card(widget, "Voice Codex Terminal", card_id="voice-codex-terminal")
        self._start_panel.hide()
        self._start_button.setChecked(False)

    def _voice_terminal_unavailable(self) -> None:
        QMessageBox.information(
            self,
            "Voice Codex Terminal",
            "The VoiceGuidedCodexTerminal module is unavailable in this environment.",
        )

    # ---------------------------------------------------------------- window close
    def closeEvent(self, event: QCloseEvent) -> None:  # pragma: no cover - Qt lifecycle
        self._start_panel.hide()
        super().closeEvent(event)


def main() -> None:  # pragma: no cover - CLI helper
    app = QApplication.instance()
    owns_app = False
    if app is None:
        app = QApplication(sys.argv)
        owns_app = True
        try:
            app.setStyle("Fusion")
        except Exception:
            pass
    window = VirtualDesktopWindow()
    window.show()
    if owns_app:
        sys.exit(app.exec())


__all__ = [
    "ALLOWLIST",
    "CardDescriptor",
    "CardWindow",
    "DesktopIcon",
    "VirtualDesktopWindow",
    "main",
    "validate_process_request",
    "workspace_root",
]


if __name__ == "__main__":  # pragma: no cover - CLI entry
    main()
```

Minimal virtual desktop shell with Start panel integration.

This module promotes the Dev Logic desktop prototype into a repository-level
component. It keeps the containment/allowlist guards while trimming dependencies
that only existed in the sandbox build. The desktop exposes a Start ▸ Apps entry
for launching the voice-enabled Codex terminal inside a card window.
**Classes:** DesktopIcon, CardDescriptor, CardWindow, StartPanel, VirtualDesktopWindow
**Functions:** workspace_root(), _safe_resolve(path_str), _is_contained(path), _build_allowlist(), _resolve_executable_path(cmd, cwd), _validate_process_request(cmd, cwd), validate_process_request(cmd, cwd), main()


## Module `vision_context.py`

```python
"""Vision/OCR context capture helpers bridging Dev_Logic implementations."""

from __future__ import annotations

import importlib.util
import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional

from PySide6.QtWidgets import QWidget

from ollama_helper import OllamaHelper

VISION_MODEL = os.getenv("VISION_MODEL", "")
PIPELINE_PATH = Path("Dev_Logic/Implemented_logic/image_pipeline.py")


@dataclass
class VisionArtifacts:
    image_path: Optional[Path]
    ocr_markdown: Optional[str]
    ocr_error: Optional[str]
    summary: Optional[str]
    summary_error: Optional[str]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "image_path": self.image_path.as_posix() if self.image_path else None,
            "ocr_markdown": self.ocr_markdown,
            "ocr_error": self.ocr_error,
            "summary": self.summary,
            "summary_error": self.summary_error,
        }


class VisionContextRecorder:
    """Capture before/after UI context using ledger-provided helpers."""

    def __init__(self, *, data_dir: Path, helper: Optional[OllamaHelper] = None) -> None:
        self.data_dir = data_dir
        self.helper = helper
        self.context_dir = self.data_dir / "planner_context"
        self.context_dir.mkdir(parents=True, exist_ok=True)
        self._pipeline = None

    # ------------------------------------------------------------------
    def capture(
        self,
        widget: QWidget,
        tag: str,
        *,
        utterance: str,
    ) -> VisionArtifacts:
        """Capture screenshot + OCR summary for ``widget``."""

        image_path = self._save_screenshot(widget, tag)
        ocr_markdown: Optional[str] = None
        ocr_error: Optional[str] = None
        summary: Optional[str] = None
        summary_error: Optional[str] = None

        pipeline = self._load_pipeline()
        if pipeline and image_path:
            try:
                ocr_result = pipeline.perform_ocr(image_path)
            except Exception as exc:  # pragma: no cover - ledger import failures
                ocr_markdown = None
                ocr_error = str(exc)
            else:
                if getattr(ocr_result, "ok", False):
                    ocr_markdown = getattr(ocr_result, "markdown", None)
                else:
                    ocr_error = getattr(ocr_result, "error", "unknown")

            vision_client = self._vision_client()
            if vision_client and ocr_markdown is not None:
                try:
                    vision_result = pipeline.analyze_image(
                        image_path,
                        ocr_markdown,
                        client=vision_client,
                        model=VISION_MODEL,
                        user_text=utterance,
                    )
                except Exception as exc:  # pragma: no cover - ledger import failures
                    summary_error = str(exc)
                else:
                    if getattr(vision_result, "ok", False):
                        summary = getattr(vision_result, "summary", None)
                    else:
                        summary_error = getattr(vision_result, "error", "vision-error")
            elif vision_client is None and VISION_MODEL:
                summary_error = "vision-client-unavailable"
        elif not pipeline:
            ocr_error = "image-pipeline-not-loaded"
            summary_error = "image-pipeline-not-loaded"

        return VisionArtifacts(
            image_path=image_path,
            ocr_markdown=ocr_markdown,
            ocr_error=ocr_error,
            summary=summary,
            summary_error=summary_error,
        )

    # ------------------------------------------------------------------
    def _save_screenshot(self, widget: QWidget, tag: str) -> Optional[Path]:
        try:
            pixmap = widget.grab()
        except Exception:
            return None
        if not hasattr(pixmap, "save"):
            return None
        timestamp = int(time.time() * 1000)
        filename = f"{timestamp}_{tag}.png"
        path = self.context_dir / filename
        try:
            pixmap.save(str(path), "PNG")
        except Exception:
            return None
        return path

    # ------------------------------------------------------------------
    def _load_pipeline(self):
        if self._pipeline is not None:
            return self._pipeline
        if not PIPELINE_PATH.exists():
            self._pipeline = None
            return None
        spec = importlib.util.spec_from_file_location(
            "dev_logic_image_pipeline",
            PIPELINE_PATH,
        )
        if spec is None or spec.loader is None:
            self._pipeline = None
            return None
        module = importlib.util.module_from_spec(spec)
        try:
            spec.loader.exec_module(module)  # type: ignore[union-attr]
        except Exception:
            self._pipeline = None
            return None
        self._pipeline = module
        return module

    # ------------------------------------------------------------------
    def _vision_client(self):
        if not VISION_MODEL:
            return None
        if self.helper is None:
            return None

        class _Client:
            def __init__(self, helper: OllamaHelper):
                self._helper = helper

            def chat(
                self,
                model: str,
                messages: Any,
                images: Optional[list[str]] = None,
            ) -> tuple[bool, str, str]:
                # OllamaHelper does not currently support passing images; return an error.
                return False, "", "vision-transport-unavailable"

        return _Client(self.helper)


__all__ = ["VisionContextRecorder", "VisionArtifacts"]
```

Vision/OCR context capture helpers bridging Dev_Logic implementations.
**Classes:** VisionArtifacts, VisionContextRecorder


## Module `VoiceGuidedCodexTerminal.py`

```python
"""Voice-guided Codex terminal widget and standalone entry point."""
from __future__ import annotations

import json
import queue
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

from PySide6.QtCore import QEasingCurve, QEvent, QPropertyAnimation, QThread, Qt, Signal
from PySide6.QtGui import QColor, QFont, QKeySequence, QLinearGradient, QPainter, QPalette
from PySide6.QtWidgets import (
    QApplication,
    QCheckBox,
    QComboBox,
    QDialog,
    QDialogButtonBox,
    QFrame,
    QGridLayout,
    QHBoxLayout,
    QLabel,
    QLineEdit,
    QPushButton,
    QPlainTextEdit,
    QSlider,
    QStyle,
    QShortcut,
    QVBoxLayout,
    QWidget,
    QKeySequenceEdit,
)

from Voice_Guided_Tools import (
    AppConfig,
    ChatResponder,
    ChatReply,
    Pyttsx3TTS,
    SapiTTS,
    SpeechThread,
    TTSEngine,
)


@dataclass
class Theme:
    """Color palette for the Codex card and desktop."""

    desktop_top: str = "#0f3b8e"
    desktop_mid: str = "#1c54cc"
    edge_glow: str = "#4aa8ff"

    card_bg: str = "#0c1320"
    card_border: str = "#213040"
    card_radius: int = 14
    header_bg: str = "#0a111e"
    header_fg: str = "#eaf2ff"
    term_bg: str = "#0b1828"
    term_fg: str = "#e9f3ff"
    accent: str = "#1E5AFF"
    accent_hover: str = "#2f72ff"
    ok: str = "#00d17a"
    warn: str = "#ffd76b"
    err: str = "#ff6b6b"
    info: str = "#9bb7ff"


CONFIG_PATH = Path(__file__).with_name("codex_terminal_config.json")


DEFAULT_CONFIG: Dict[str, Any] = {
    "ollama_host": "http://127.0.0.1:11434",
    "prompt_influence": True,
    "stream": False,
    "models": {
        "chat": "gpt-oss:20b",
        "vision": "llava-llama3:latest",
        "embed": "snowflake-arctic-embed2:latest",
    },
    "prompts": {
        "system": "You are Codex Terminal. Answer succinctly and correctly.",
        "system_min": "Answer appropriately.",
        "vision": "Analyze this image and explain succinctly.",
        "user_prefix": "",
    },
    "audio": {
        "mic_device_name": None,
        "asr_backend": "google",
        "phrase_time_limit": 3.0,
        "energy_threshold": 300,
        "dynamic_energy": True,
        "sample_rate": 16000,
        "tts_engine": "sapi",
        "tts_voice_hint": "Zira",
        "tts_rate": 0,
        "tts_volume": 100,
        "tts_full_duplex": True,
    },
    "ui": {
        "audio_panel": {
            "visible": False,
            "pinned": False,
        }
    },
}


def _deep_update(target: Dict[str, Any], defaults: Dict[str, Any]) -> Dict[str, Any]:
    for key, value in defaults.items():
        if isinstance(value, dict):
            target[key] = _deep_update(target.get(key, {}) if isinstance(target.get(key), dict) else {}, value)
        else:
            target.setdefault(key, value)
    return target


def load_config() -> Dict[str, Any]:
    data: Dict[str, Any] = {}
    if CONFIG_PATH.exists():
        try:
            data = json.loads(CONFIG_PATH.read_text(encoding="utf-8"))
        except Exception:
            data = {}
    data = _deep_update(data, DEFAULT_CONFIG)
    save_config(data)
    return data


def save_config(data: Dict[str, Any]) -> None:
    CONFIG_PATH.write_text(json.dumps(data, indent=2), encoding="utf-8")


class ChatWorker(QThread):
    """Background thread that routes prompts to the chat responder."""

    reply_ready = Signal(str, list)
    error = Signal(str)
    busy = Signal(bool)

    def __init__(self, responder: ChatResponder, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.responder = responder
        self._queue: "queue.Queue[Optional[str]]" = queue.Queue()
        self._stop = threading.Event()

    def enqueue(self, text: str) -> None:
        self._queue.put(text)

    def stop(self) -> None:
        self._queue.put(None)
        self._stop.set()

    def run(self) -> None:  # pragma: no cover - background worker
        while not self._stop.is_set():
            try:
                item = self._queue.get(timeout=0.1)
            except queue.Empty:
                continue
            if item is None:
                break
            self.busy.emit(True)
            try:
                reply: ChatReply = self.responder.reply(item)
                text = reply.text if reply.text.strip() else "(no response)"
                self.reply_ready.emit(text, reply.diagnostics)
            except Exception as exc:  # pragma: no cover - defensive
                self.error.emit(str(exc))
            finally:
                self.busy.emit(False)


class AudioSettingsDialog(QDialog):
    """Simple dialog for adjusting microphone/ASR/TTS options."""

    def __init__(
        self,
        parent: QWidget,
        config: Dict[str, Any],
        app_config: AppConfig,
        available_mics: List[str],
    ) -> None:
        super().__init__(parent)
        self.setWindowTitle("Audio Settings")
        self.config = config
        self.app_config = app_config
        audio = config.get("audio", {})

        layout = QVBoxLayout(self)
        grid = QGridLayout()
        row = 0

        grid.addWidget(QLabel("Microphone"), row, 0)
        self.cmb_mic = QComboBox()
        self.cmb_mic.addItem("(System Default)", userData="")
        for name in available_mics:
            self.cmb_mic.addItem(name, userData=name)
        if audio.get("mic_device_name"):
            idx = self.cmb_mic.findData(audio.get("mic_device_name"))
            if idx >= 0:
                self.cmb_mic.setCurrentIndex(idx)
        grid.addWidget(self.cmb_mic, row, 1)
        row += 1

        grid.addWidget(QLabel("ASR Backend"), row, 0)
        self.cmb_asr = QComboBox()
        self.cmb_asr.addItems(["google", "vosk"])
        current_backend = str(audio.get("asr_backend") or "google")
        idx = self.cmb_asr.findText(current_backend)
        if idx >= 0:
            self.cmb_asr.setCurrentIndex(idx)
        grid.addWidget(self.cmb_asr, row, 1)
        row += 1

        grid.addWidget(QLabel("TTS Engine"), row, 0)
        self.cmb_tts = QComboBox()
        self.cmb_tts.addItems(["sapi", "pyttsx3"])
        idx = self.cmb_tts.findText(str(audio.get("tts_engine") or "sapi"))
        if idx >= 0:
            self.cmb_tts.setCurrentIndex(idx)
        grid.addWidget(self.cmb_tts, row, 1)
        row += 1

        grid.addWidget(QLabel("Voice hint"), row, 0)
        self.txt_voice = QLineEdit(str(audio.get("tts_voice_hint") or ""))
        grid.addWidget(self.txt_voice, row, 1)
        row += 1

        grid.addWidget(QLabel("Speech rate"), row, 0)
        self.slide_rate = QSlider(Qt.Horizontal)
        self.slide_rate.setRange(-10, 10)
        self.slide_rate.setValue(int(audio.get("tts_rate") or 0))
        grid.addWidget(self.slide_rate, row, 1)
        row += 1

        grid.addWidget(QLabel("Volume"), row, 0)
        self.slide_volume = QSlider(Qt.Horizontal)
        self.slide_volume.setRange(0, 100)
        self.slide_volume.setValue(int(audio.get("tts_volume") or 100))
        grid.addWidget(self.slide_volume, row, 1)
        row += 1

        grid.addWidget(QLabel("Full duplex"), row, 0)
        self.chk_duplex = QCheckBox("Allow speaking while listening")
        self.chk_duplex.setChecked(bool(audio.get("tts_full_duplex", True)))
        grid.addWidget(self.chk_duplex, row, 1)
        row += 1

        layout.addLayout(grid)

        buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)

    def apply_changes(self) -> None:
        audio = self.config.setdefault("audio", {})
        selected_mic = self.cmb_mic.currentData() or None
        audio["mic_device_name"] = selected_mic
        audio["asr_backend"] = self.cmb_asr.currentText()
        audio["tts_engine"] = self.cmb_tts.currentText()
        audio["tts_voice_hint"] = self.txt_voice.text().strip()
        audio["tts_rate"] = int(self.slide_rate.value())
        audio["tts_volume"] = int(self.slide_volume.value())
        audio["tts_full_duplex"] = bool(self.chk_duplex.isChecked())

        self.app_config.mic_device_name = selected_mic
        self.app_config.asr_backend = audio["asr_backend"]
        self.app_config.tts_engine = audio["tts_engine"]
        self.app_config.tts_voice_hint = audio["tts_voice_hint"]
        self.app_config.tts_rate = audio["tts_rate"]
        self.app_config.tts_volume = audio["tts_volume"]
        self.app_config.tts_full_duplex = audio["tts_full_duplex"]
        self.app_config.save()


class AudioControlPanel(QFrame):
    """Slide-out panel exposing live audio and hotkey controls."""

    def __init__(self, card: "CodexTerminalCard") -> None:
        super().__init__(card)
        self.card = card
        self.setObjectName("audio-panel")
        self.setFrameShape(QFrame.StyledPanel)
        self.setStyleSheet(
            f"#audio-panel {{ background: {card.theme.header_bg}; border-left: 1px solid {card.theme.card_border}; }}"
            "QLabel.section { font-weight: 600; margin-top: 8px; }"
        )

        self._devices: List[str] = []
        self._hotkey_editors: Dict[str, QKeySequenceEdit] = {}

        layout = QVBoxLayout(self)
        layout.setContentsMargins(18, 18, 18, 18)
        layout.setSpacing(12)

        header_row = QHBoxLayout()
        header_label = QLabel("Voice Controls")
        header_label.setStyleSheet("font-size: 13pt; font-weight: 600;")
        header_row.addWidget(header_label)
        header_row.addStretch(1)
        self.chk_pin = QCheckBox("Pin open")
        self.chk_pin.toggled.connect(self.card._on_panel_pin_changed)
        header_row.addWidget(self.chk_pin)
        layout.addLayout(header_row)

        self.cmb_device = QComboBox()
        self.cmb_device.currentIndexChanged.connect(self._device_changed)
        layout.addWidget(self._section_label("Microphone"))
        layout.addWidget(self.cmb_device)

        self.cmb_backend = QComboBox()
        self.cmb_backend.addItems(["google", "vosk"])
        self.cmb_backend.currentIndexChanged.connect(self._backend_changed)
        layout.addWidget(self._section_label("ASR backend"))
        layout.addWidget(self.cmb_backend)

        layout.addWidget(self._section_label("TTS rate"))
        self.slide_rate = QSlider(Qt.Horizontal)
        self.slide_rate.setRange(-10, 10)
        self.slide_rate.valueChanged.connect(self._rate_changed)
        rate_row = QHBoxLayout()
        rate_row.addWidget(self.slide_rate, 1)
        self.lbl_rate_value = QLabel("0")
        rate_row.addWidget(self.lbl_rate_value)
        layout.addLayout(rate_row)

        layout.addWidget(self._section_label("TTS volume"))
        self.slide_volume = QSlider(Qt.Horizontal)
        self.slide_volume.setRange(0, 100)
        self.slide_volume.valueChanged.connect(self._volume_changed)
        volume_row = QHBoxLayout()
        volume_row.addWidget(self.slide_volume, 1)
        self.lbl_volume_value = QLabel("100")
        volume_row.addWidget(self.lbl_volume_value)
        layout.addLayout(volume_row)

        self.chk_duplex = QCheckBox("Allow speaking while listening")
        self.chk_duplex.toggled.connect(self._duplex_toggled)
        layout.addWidget(self.chk_duplex)

        layout.addWidget(self._section_label("Hotkeys"))
        self._add_hotkey_editor(layout, "Toggle microphone", "hotkey_toggle_mic")
        self._add_hotkey_editor(layout, "Stop TTS playback", "hotkey_stop_motion")
        self._add_hotkey_editor(layout, "Toggle duplex", "hotkey_pause_resume")
        self._add_hotkey_editor(layout, "Push-to-talk", "hotkey_push_to_talk")

        layout.addStretch(1)

    def _section_label(self, text: str) -> QLabel:
        label = QLabel(text)
        label.setObjectName("section-label")
        label.setProperty("class", "section")
        return label

    # ------------------------------------------------------------------ sync helpers
    def sync_from_state(self) -> None:
        audio = self.card.config.get("audio", {})
        self._populate_devices(self.card._available_mics, audio.get("mic_device_name"))
        self._set_combo_value(self.cmb_backend, str(audio.get("asr_backend") or "google"))
        self._set_slider_value(self.slide_rate, int(audio.get("tts_rate", 0)))
        self._set_slider_value(self.slide_volume, int(audio.get("tts_volume", 100)))
        self.lbl_rate_value.setText(str(self.slide_rate.value()))
        self.lbl_volume_value.setText(str(self.slide_volume.value()))
        self._set_checkbox(self.chk_duplex, bool(audio.get("tts_full_duplex", True)))
        self._set_checkbox(self.chk_pin, self.card._panel_pinned)

        for attr, editor in self._hotkey_editors.items():
            seq = getattr(self.card.app_config, attr, "") or ""
            editor.blockSignals(True)
            editor.setKeySequence(QKeySequence(seq))
            editor.blockSignals(False)

    def update_devices(self, devices: List[str]) -> None:
        audio = self.card.config.get("audio", {})
        self._populate_devices(devices, audio.get("mic_device_name"))

    # ------------------------------------------------------------------ control bindings
    def _device_changed(self, index: int) -> None:
        name = self.cmb_device.itemData(index) or None
        self.card.update_mic_device(name)

    def _backend_changed(self, index: int) -> None:
        backend = self.cmb_backend.itemText(index)
        self.card.update_asr_backend(backend)

    def _rate_changed(self, value: int) -> None:
        self.lbl_rate_value.setText(str(value))
        self.card.update_tts_rate(int(value))

    def _volume_changed(self, value: int) -> None:
        self.lbl_volume_value.setText(str(value))
        self.card.update_tts_volume(int(value))

    def _duplex_toggled(self, checked: bool) -> None:
        self.card.update_full_duplex(bool(checked))

    def _hotkey_changed(self, attr: str) -> None:
        editor = self._hotkey_editors[attr]
        sequence = editor.keySequence()
        text = sequence.toString(QKeySequence.PortableText)
        self.card.update_hotkey(attr, text)

    # ------------------------------------------------------------------ widget wiring
    def _add_hotkey_editor(self, layout: QVBoxLayout, label: str, attr: str) -> None:
        row = QHBoxLayout()
        lbl = QLabel(label)
        row.addWidget(lbl)
        editor = QKeySequenceEdit()
        editor.setMaximumWidth(160)
        editor.editingFinished.connect(lambda attr=attr: self._hotkey_changed(attr))
        row.addWidget(editor)
        layout.addLayout(row)
        self._hotkey_editors[attr] = editor

    def _populate_devices(self, devices: List[str], selected: Optional[str]) -> None:
        self._devices = devices
        self.cmb_device.blockSignals(True)
        self.cmb_device.clear()
        self.cmb_device.addItem("(System Default)", userData="")
        for name in devices:
            self.cmb_device.addItem(name, userData=name)
        index = self.cmb_device.findData(selected or "")
        self.cmb_device.setCurrentIndex(index if index >= 0 else 0)
        self.cmb_device.blockSignals(False)

    def _set_combo_value(self, combo: QComboBox, value: str) -> None:
        combo.blockSignals(True)
        idx = combo.findText(value)
        combo.setCurrentIndex(idx if idx >= 0 else 0)
        combo.blockSignals(False)

    def _set_slider_value(self, slider: QSlider, value: int) -> None:
        slider.blockSignals(True)
        slider.setValue(value)
        slider.blockSignals(False)

    def _set_checkbox(self, checkbox: QCheckBox, checked: bool) -> None:
        checkbox.blockSignals(True)
        checkbox.setChecked(checked)
        checkbox.blockSignals(False)

class GradientDesktop(QWidget):
    """Simple gradient background used when running standalone."""

    def __init__(self, theme: Theme, parent: Optional[QWidget] = None) -> None:
        super().__init__(parent)
        self.theme = theme
        self.setMinimumSize(900, 600)
        pal = self.palette()
        pal.setColor(QPalette.Window, QColor(theme.desktop_mid))
        self.setPalette(pal)
        self.setAutoFillBackground(True)

    def paintEvent(self, event):  # pragma: no cover - Qt painting
        painter = QPainter(self)
        rect = self.rect()
        gradient = QLinearGradient(rect.topLeft(), rect.bottomLeft())
        gradient.setColorAt(0.0, QColor(self.theme.desktop_top))
        gradient.setColorAt(0.6, QColor(self.theme.desktop_mid))
        gradient.setColorAt(1.0, QColor(self.theme.desktop_top))
        painter.fillRect(rect, gradient)

        glow = QColor(self.theme.edge_glow)
        glow.setAlpha(45)
        painter.setPen(glow)
        painter.drawRoundedRect(rect.adjusted(6, 6, -6, -6), 32, 32)


class CodexTerminalCard(QFrame):
    """Card containing the chat transcript and controls."""

    def __init__(self, embedded: bool, parent: Optional[QWidget] = None) -> None:
        super().__init__(parent)
        self.embedded = embedded
        self.theme = Theme()
        self.config = load_config()
        self.app_config = AppConfig.load()
        self._apply_audio_config()

        self.chat_responder = ChatResponder()
        self.chat_worker = ChatWorker(self.chat_responder, self)
        self.chat_worker.reply_ready.connect(self._on_reply_ready)
        self.chat_worker.error.connect(self._on_chat_error)
        self.chat_worker.busy.connect(self._on_chat_busy)
        self.chat_worker.start()

        self.tts: Optional[TTSEngine] = self._create_tts_engine()

        self._mic_thread: Optional[SpeechThread] = None
        self._mic_running = False
        self._push_to_talk_active = False
        self._available_mics: List[str] = []
        self._hotkey_shortcuts: List[QShortcut] = []
        self._panel_visible = False
        self._panel_pinned = False
        self._panel_target_width = 320
        self._panel_animation: Optional[QPropertyAnimation] = None

        self._build_ui()
        self._update_device_cache(self._list_microphones())
        self._load_panel_state()
        self._install_hotkeys()
        self._update_status("Ready.")

    # ------------------------------------------------------------------ UI
    def _build_ui(self) -> None:
        self.setObjectName("codex-card")
        self.setStyleSheet(
            f"#codex-card {{ background: {self.theme.card_bg}; border: 1px solid {self.theme.card_border};"
            f" border-radius: {self.theme.card_radius}px; color: {self.theme.header_fg}; }}"
        )
        outer = QHBoxLayout(self)
        outer.setContentsMargins(20, 20, 20, 20)
        outer.setSpacing(16)

        main_column = QVBoxLayout()
        main_column.setSpacing(16)

        header = QHBoxLayout()
        title = QLabel("Codex Terminal")
        title_font = QFont()
        title_font.setPointSize(16)
        title_font.setBold(True)
        title.setFont(title_font)
        header.addWidget(title)
        header.addStretch(1)

        self.btn_panel = QPushButton("Audio Panel")
        self.btn_panel.setCheckable(True)
        self.btn_panel.setCursor(Qt.PointingHandCursor)
        self.btn_panel.toggled.connect(self._on_panel_toggled)
        header.addWidget(self.btn_panel)
        main_column.addLayout(header)

        self.transcript = QPlainTextEdit()
        self.transcript.setReadOnly(True)
        self.transcript.setStyleSheet(
            f"background: {self.theme.term_bg}; color: {self.theme.term_fg};"
            "font-family: Consolas, 'Cascadia Code', monospace;"
            "font-size: 12.5pt; border-radius: 12px; padding: 12px;"
        )
        main_column.addWidget(self.transcript, 1)

        input_row = QHBoxLayout()
        self.input = QPlainTextEdit()
        self.input.setFixedHeight(70)
        self.input.installEventFilter(self)
        self.input.setPlaceholderText("Type your prompt…")
        input_row.addWidget(self.input, 1)

        self.btn_send = QPushButton("Send")
        self.btn_send.clicked.connect(self._send_clicked)
        self.btn_send.setCursor(Qt.PointingHandCursor)
        self.btn_send.setFixedWidth(120)
        input_row.addWidget(self.btn_send)
        main_column.addLayout(input_row)

        footer = QHBoxLayout()
        self.btn_mic = QPushButton("Start Mic")
        self.btn_mic.clicked.connect(self._toggle_mic)
        self.btn_mic.setCursor(Qt.PointingHandCursor)
        footer.addWidget(self.btn_mic)

        footer.addStretch(1)

        self.status = QLabel("Idle")
        footer.addWidget(self.status)
        main_column.addLayout(footer)

        outer.addLayout(main_column, 1)

        self.audio_panel = AudioControlPanel(self)
        self.audio_panel.setMinimumWidth(0)
        self.audio_panel.setMaximumWidth(0)
        self.audio_panel.hide()
        outer.addWidget(self.audio_panel)

        self._panel_animation = QPropertyAnimation(self.audio_panel, b"maximumWidth", self)
        self._panel_animation.setDuration(220)
        self._panel_animation.setEasingCurve(QEasingCurve.InOutCubic)
        self._panel_animation.finished.connect(self._on_panel_animation_finished)

    def eventFilter(self, obj, event):  # pragma: no cover - Qt integration
        if obj is self.input and event.type() == QEvent.KeyPress:
            if event.key() in (Qt.Key_Return, Qt.Key_Enter) and event.modifiers() in (Qt.NoModifier, Qt.KeypadModifier):
                self._send_clicked()
                return True
        return super().eventFilter(obj, event)

    # ---------------------------------------------------------------- audio config
    def _apply_audio_config(self) -> None:
        audio = self.config.get("audio", {})
        self.app_config.mic_device_name = audio.get("mic_device_name") or None
        self.app_config.asr_backend = str(audio.get("asr_backend") or "google")
        self.app_config.phrase_time_limit = float(audio.get("phrase_time_limit", self.app_config.phrase_time_limit))
        self.app_config.energy_threshold = int(audio.get("energy_threshold", self.app_config.energy_threshold))
        self.app_config.dynamic_energy = bool(audio.get("dynamic_energy", self.app_config.dynamic_energy))
        self.app_config.sample_rate = int(audio.get("sample_rate", self.app_config.sample_rate))
        self.app_config.tts_engine = str(audio.get("tts_engine") or "sapi")
        self.app_config.tts_voice_hint = str(audio.get("tts_voice_hint") or "")
        self.app_config.tts_rate = int(audio.get("tts_rate", 0))
        self.app_config.tts_volume = int(audio.get("tts_volume", 100))
        self.app_config.tts_full_duplex = bool(audio.get("tts_full_duplex", True))
        self.app_config.save()

    def _update_audio_config(self) -> None:
        save_config(self.config)
        self._apply_audio_config()
        self._recreate_tts_engine()

    # ---------------------------------------------------------------- settings
    def _open_settings(self) -> None:
        dialog = AudioSettingsDialog(
            self,
            self.config,
            self.app_config,
            self._list_microphones(),
        )
        if dialog.exec() == QDialog.Accepted:
            dialog.apply_changes()
            self._update_audio_config()

    def _list_microphones(self) -> List[str]:
        temp_thread = SpeechThread(self.app_config)
        devices: List[str] = []
        temp_thread.devices.connect(lambda names: devices.extend(names))
        temp_thread.list_devices()
        temp_thread.deleteLater()
        self._update_device_cache(devices)
        return list(self._available_mics)

    def _update_device_cache(self, names: List[str]) -> None:
        unique: List[str] = []
        seen: set[str] = set()
        for name in names:
            if not name:
                continue
            if name not in seen:
                seen.add(name)
                unique.append(name)
        self._available_mics = unique
        if hasattr(self, "audio_panel"):
            self.audio_panel.update_devices(unique)

    # ---------------------------------------------------------------- panel controls
    def _load_panel_state(self) -> None:
        ui_state = self.config.setdefault("ui", {}).setdefault("audio_panel", {})
        visible = bool(ui_state.get("visible", False))
        self._panel_pinned = bool(ui_state.get("pinned", False))
        checked = visible or self._panel_pinned
        if hasattr(self, "btn_panel"):
            self.btn_panel.blockSignals(True)
            self.btn_panel.setChecked(checked)
            self.btn_panel.blockSignals(False)
        if hasattr(self, "audio_panel"):
            self.audio_panel.chk_pin.blockSignals(True)
            self.audio_panel.chk_pin.setChecked(self._panel_pinned)
            self.audio_panel.chk_pin.blockSignals(False)
            self.audio_panel.sync_from_state()
        self._set_panel_visible(checked, animate=False)
        self._panel_visible = checked
        self._persist_panel_state()

    def _on_panel_toggled(self, checked: bool) -> None:
        if not checked and self._panel_pinned:
            if hasattr(self, "btn_panel"):
                self.btn_panel.blockSignals(True)
                self.btn_panel.setChecked(True)
                self.btn_panel.blockSignals(False)
            return
        self._panel_visible = checked
        self._set_panel_visible(checked)
        self._persist_panel_state()

    def _on_panel_pin_changed(self, pinned: bool) -> None:
        self._panel_pinned = bool(pinned)
        if self._panel_pinned and hasattr(self, "btn_panel") and not self.btn_panel.isChecked():
            self.btn_panel.blockSignals(True)
            self.btn_panel.setChecked(True)
            self.btn_panel.blockSignals(False)
            self._panel_visible = True
            self._set_panel_visible(True)
        self._persist_panel_state()

    def _set_panel_visible(self, visible: bool, *, animate: bool = True) -> None:
        if not hasattr(self, "audio_panel") or self.audio_panel is None:
            return
        target = self._panel_target_width if visible else 0
        if not animate:
            self.audio_panel.setMaximumWidth(target)
            if visible:
                self.audio_panel.show()
            else:
                self.audio_panel.hide()
            return
        if visible:
            self.audio_panel.show()
        if self._panel_animation:
            self._panel_animation.stop()
            self._panel_animation.setStartValue(self.audio_panel.maximumWidth())
            self._panel_animation.setEndValue(target)
            self._panel_animation.start()

    def _on_panel_animation_finished(self) -> None:
        if not hasattr(self, "audio_panel") or self.audio_panel is None:
            return
        if self._panel_visible:
            self.audio_panel.setMaximumWidth(self._panel_target_width)
        else:
            self.audio_panel.setMaximumWidth(0)
            self.audio_panel.hide()

    def _persist_panel_state(self) -> None:
        ui_state = self.config.setdefault("ui", {}).setdefault("audio_panel", {})
        ui_state["visible"] = bool(getattr(self, "btn_panel", None) and self.btn_panel.isChecked())
        ui_state["pinned"] = bool(self._panel_pinned)
        save_config(self.config)

    # ---------------------------------------------------------------- audio setting mutations
    def update_mic_device(self, name: Optional[str]) -> None:
        changed = self._set_audio_setting("mic_device_name", name)
        if changed:
            self._restart_mic_if_running()

    def update_asr_backend(self, backend: str) -> None:
        backend = backend or "google"
        changed = self._set_audio_setting("asr_backend", backend)
        if changed:
            self._restart_mic_if_running()

    def update_tts_rate(self, rate: int) -> None:
        rate = int(rate)
        changed = self._set_audio_setting("tts_rate", rate)
        if changed and self.tts:
            try:
                self.tts.set_rate(rate)
            except Exception:
                pass

    def update_tts_volume(self, volume: int) -> None:
        volume = int(volume)
        changed = self._set_audio_setting("tts_volume", volume)
        if changed and self.tts:
            try:
                self.tts.set_volume(volume)
            except Exception:
                pass

    def update_full_duplex(self, enabled: bool) -> None:
        changed = self._set_audio_setting("tts_full_duplex", bool(enabled))
        if changed:
            if hasattr(self, "audio_panel"):
                self.audio_panel.sync_from_state()
            state = "enabled" if enabled else "disabled"
            self._update_status(f"Full duplex {state}.")

    def update_hotkey(self, attr: str, sequence: str) -> None:
        if not hasattr(self.app_config, attr):
            return
        current = getattr(self.app_config, attr)
        if current == sequence:
            return
        setattr(self.app_config, attr, sequence)
        self.app_config.save()
        self._install_hotkeys()
        if hasattr(self, "audio_panel"):
            self.audio_panel.sync_from_state()

    def _set_audio_setting(self, key: str, value: Any) -> bool:
        audio = self.config.setdefault("audio", {})
        existing = audio.get(key)
        if existing == value:
            # ensure AppConfig mirrors persisted value
            setattr(self.app_config, key, value)
            return False
        audio[key] = value
        setattr(self.app_config, key, value)
        save_config(self.config)
        self.app_config.save()
        return True

    def _restart_mic_if_running(self) -> None:
        if not self._mic_running:
            return
        self._stop_mic()
        self._start_mic()

    # ---------------------------------------------------------------- hotkeys
    def _install_hotkeys(self) -> None:
        for shortcut in self._hotkey_shortcuts:
            shortcut.setParent(None)
            shortcut.deleteLater()
        self._hotkey_shortcuts = []
        mappings = [
            (self.app_config.hotkey_toggle_mic, self._toggle_mic),
            (self.app_config.hotkey_stop_motion, self._stop_tts_hotkey),
            (self.app_config.hotkey_pause_resume, self._toggle_duplex_hotkey),
            (self.app_config.hotkey_push_to_talk, self._push_to_talk_trigger),
        ]
        for sequence, handler in mappings:
            shortcut = self._create_hotkey(sequence, handler)
            if shortcut:
                self._hotkey_shortcuts.append(shortcut)

    def _create_hotkey(self, sequence: str, handler) -> Optional[QShortcut]:
        if not sequence:
            return None
        shortcut = QShortcut(QKeySequence(sequence), self)
        shortcut.setContext(Qt.WidgetWithChildrenShortcut)
        shortcut.setAutoRepeat(False)
        shortcut.activated.connect(handler)
        return shortcut

    def _stop_tts_hotkey(self) -> None:
        if self.tts:
            self.tts.stop()
            self._update_status("Speech stopped.")

    def _toggle_duplex_hotkey(self) -> None:
        new_value = not bool(self.app_config.tts_full_duplex)
        self.update_full_duplex(new_value)

    def _push_to_talk_trigger(self) -> None:
        if not self.app_config.hotkey_push_to_talk:
            return
        if not self._mic_running:
            self._push_to_talk_active = True
            self._start_mic()
        elif self._push_to_talk_active:
            self._push_to_talk_active = False
            self._stop_mic()



    # ---------------------------------------------------------------- mic controls
    def _toggle_mic(self) -> None:
        if self._mic_running:
            self._stop_mic()
        else:
            self._start_mic()

    def _start_mic(self) -> None:
        if self._mic_running:
            return
        self._mic_thread = SpeechThread(self.app_config)
        self._mic_thread.text_ready.connect(self._on_mic_text)
        self._mic_thread.status.connect(self._on_mic_status)
        self._mic_thread.error.connect(self._on_mic_error)
        self._mic_thread.devices.connect(self._on_mic_devices)
        self._mic_thread.speech_start.connect(lambda: self._update_status("Listening…"))
        self._mic_thread.speech_end.connect(lambda: self._update_status("Processing…"))
        self._mic_thread.start()
        self._mic_thread.list_devices()
        self._mic_running = True
        self.btn_mic.setText("Stop Mic")
        self._update_status("Mic running.")

    def _stop_mic(self) -> None:
        if not self._mic_running:
            return
        if self._mic_thread:
            self._mic_thread.stop()
            self._mic_thread.wait(2000)
            self._mic_thread.deleteLater()
            self._mic_thread = None
        self._mic_running = False
        self._push_to_talk_active = False
        self.btn_mic.setText("Start Mic")
        self._update_status("Mic stopped.")

    def _on_mic_text(self, text: str) -> None:
        if not text.strip():
            return
        self._append_user(text.strip())
        if not self.app_config.tts_full_duplex and self.tts:
            self.tts.stop()
        self._submit_chat(text.strip())

    def _on_mic_status(self, status: str) -> None:
        self._update_status(status)

    def _on_mic_error(self, message: str) -> None:
        self._update_status(f"Mic error: {message}")

    def _on_mic_devices(self, names: List[str]) -> None:
        self._update_device_cache(names)
        if hasattr(self, "audio_panel"):
            self.audio_panel.sync_from_state()

    # ---------------------------------------------------------------- chat helpers
    def _send_clicked(self) -> None:
        text = self.input.toPlainText().strip()
        if not text:
            return
        self.input.clear()
        self._append_user(text)
        self._submit_chat(text)

    def _submit_chat(self, text: str) -> None:
        self.chat_worker.enqueue(text)

    def _append_user(self, text: str) -> None:
        self._append_line("You", text)

    def _append_bot(self, text: str) -> None:
        self._append_line("Codex", text)
        if self.tts:
            self.tts.say(text)

    def _append_line(self, speaker: str, text: str) -> None:
        timestamp = time.strftime("%H:%M:%S")
        self.transcript.appendPlainText(f"[{timestamp}] {speaker}: {text}")
        self.transcript.verticalScrollBar().setValue(self.transcript.verticalScrollBar().maximum())

    def _on_reply_ready(self, text: str, diagnostics: List[str]) -> None:
        self._append_bot(text)
        if diagnostics:
            self._append_line("diagnostics", " | ".join(diagnostics))

    def _on_chat_error(self, message: str) -> None:
        self._append_line("error", message)

    def _on_chat_busy(self, busy: bool) -> None:
        self.btn_send.setEnabled(not busy)
        if busy:
            self._update_status("Thinking…")
        else:
            self._update_status("Ready.")

    # ---------------------------------------------------------------- status
    def _update_status(self, text: str) -> None:
        self.status.setText(text)

    # ---------------------------------------------------------------- TTS
    def _create_tts_engine(self) -> Optional[TTSEngine]:
        engine: Optional[TTSEngine] = None
        if self.app_config.tts_engine == "pyttsx3":
            engine = Pyttsx3TTS(self.app_config)
        else:
            engine = SapiTTS(self.app_config)
        if engine:
            try:
                engine.set_voice_hint(self.app_config.tts_voice_hint or "")
                engine.set_rate(self.app_config.tts_rate)
                engine.set_volume(self.app_config.tts_volume)
            except Exception:  # pragma: no cover - guard
                pass
        return engine

    def _recreate_tts_engine(self) -> None:
        if self.tts:
            self.tts.stop()
        self.tts = self._create_tts_engine()

    # ---------------------------------------------------------------- lifecycle
    def closeEvent(self, event):  # pragma: no cover - Qt lifecycle
        self.chat_worker.stop()
        self.chat_worker.wait(2000)
        if self.tts:
            self.tts.stop()
        self._stop_mic()
        super().closeEvent(event)


def create_card(embedded: bool = False) -> QWidget:
    """Create the Codex terminal card.

    When ``embedded`` is False, returns a desktop widget containing the card.
    Otherwise the bare card is returned for integration with the virtual desktop.
    """

    card = CodexTerminalCard(embedded=embedded)
    if embedded:
        return card
    desktop = GradientDesktop(card.theme)
    layout = QVBoxLayout(desktop)
    layout.setContentsMargins(80, 60, 80, 60)
    layout.addStretch(1)
    layout.addWidget(card, alignment=Qt.AlignCenter)
    layout.addStretch(1)
    return desktop


def main() -> None:
    import sys

    app = QApplication.instance()
    owns_app = False
    if app is None:
        app = QApplication(sys.argv)
        owns_app = True
        try:
            app.setStyle("Fusion")
        except Exception:
            pass

    widget = create_card(embedded=False)
    widget.setWindowTitle("Voice-Guided Codex Terminal")
    icon = QApplication.style().standardIcon(QStyle.SP_DesktopIcon)
    widget.setWindowIcon(icon)
    widget.resize(960, 640)
    widget.show()

    if owns_app:
        sys.exit(app.exec())


if __name__ == "__main__":  # pragma: no cover - CLI entry
    main()
```

Voice-guided Codex terminal widget and standalone entry point.
**Classes:** Theme, ChatWorker, AudioSettingsDialog, AudioControlPanel, GradientDesktop, CodexTerminalCard
**Functions:** _deep_update(target, defaults), load_config(), save_config(data), create_card(embedded), main()


## Module `Voice_Guided_Tools.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Voice-Guided Tools — Trainer (Full-Duplex, Everything Concurrent)
=================================================================

This single file implements a *terminal-in-desktop* trainer with:
- Full-duplex audio: Zira speaks while the mic listens (no barge-in cancel).
- Dedicated threads for **everything**: ASR, TTS, Planner, Executor/Motion,
  Logger, and UI timers — all non-blocking.
- Device selection (microphone) + deep audio/ASR/TTS settings.
- Control-Magic only (global control); expressionary Language→Plan parsing
  (shapes, navigation, directives) with clarifying questions.
- Dual chat lanes (User ↑ / Zira ↓) with a lime-green read cursor sweep.
- Virtual Desktop: cursor animation, ghost “ten fingers” on keyboard,
  vertical bubble tooltip, code editor, security panel, agent controls.
- Session logging (JSONL), snapshots, retry/revert, hotkeys.

Optional deps:
    pip install PySide6 speechrecognition sounddevice pywin32 pyttsx3
Vosk (offline ASR) optional:
    pip install vosk
and download a model, then point Settings→ASR→Vosk Model Path.
"""

from __future__ import annotations

import json
import math
import os
import queue
import re
import sys
import time
import threading
import traceback
import uuid
from dataclasses import dataclass, asdict, field
from functools import partial
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Set, Tuple, Union

from PySide6.QtCore import (
    Qt, QEvent, QEventLoop, QObject, QPoint, QPointF, QRect, QRectF, QSize,
    QRegularExpression, QThread, QTimer, Signal, Slot
)
from PySide6.QtGui import (
    QAction, QColor, QFont, QImage, QKeyEvent, QKeySequence, QMouseEvent,
    QPainter, QPalette, QPaintEvent, QPixmap, QResizeEvent, QTextCursor,
    QTextFormat, QPen
)
from PySide6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QGroupBox, QLabel, QGridLayout, QVBoxLayout,
    QHBoxLayout, QLineEdit, QPushButton, QPlainTextEdit, QTextEdit, QComboBox,
    QCheckBox, QSlider, QFileDialog, QMessageBox, QDoubleSpinBox, QSpinBox, QTabWidget, QSizePolicy,
    QScrollArea
)

from dataset_manager import DatasetManager
from lexicon_manager import LexiconManager, LexiconConflictError
from ollama_helper import CHAT_MODEL, EMBED_MODEL, OllamaHelper
from planner_service import PlannerPlan, PlannerDecision, PlannerService
from vision_context import VisionContextRecorder

CanvasContent = Union[QWidget, QPixmap, Callable[[QPainter, QRectF], None]]

# ----- Command suggestion data -----

@dataclass
class CommandSuggestion:
    """Structured metadata for a desktop command suggestion."""

    label: str
    action: Optional[str]
    payload_prompt: Optional[str] = None
    deny_action: Optional[str] = "ctrl:deny"
    confirm_label: str = "Confirm"
    deny_label: str = "Deny"
    initial_payload: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class DirectiveHistoryAction:
    """Button metadata exposed on a directive history card."""

    label: str
    command: str
    enabled: bool = True
    tooltip: Optional[str] = None


@dataclass
class DirectiveHistoryCard:
    """Structured representation of a directive bucket for UI history cards."""

    bucket_id: str
    title: str
    status: str
    summary: str
    alias: str
    actions: List[DirectiveHistoryAction] = field(default_factory=list)
    is_active: bool = False


@dataclass
class PendingMagicLearn:
    """State container for a pending magic learn capture."""

    requested_at: float
    last_heard_at: float
    prompt: str
    segments: List[str] = field(default_factory=list)
    state: str = "collecting"
    draft: str = ""

    def combined_payload(self) -> str:
        return " ".join(seg.strip() for seg in self.segments if seg.strip()).strip()

    def current_payload(self) -> str:
        text = self.draft.strip()
        return text or self.combined_payload()

    def segment_summary(self) -> str:
        if not self.segments:
            return "No segments captured yet."
        lines = [f"{idx}. {seg}" for idx, seg in enumerate(self.segments, start=1)]
        return "\n".join(lines)

    def refresh_draft(self) -> None:
        combined = self.combined_payload()
        if combined:
            self.draft = combined

# ---------- Optional libraries ----------
_has_sr = False
try:
    import speech_recognition as sr  # type: ignore
    _has_sr = True
except Exception:
    _has_sr = False

_has_sd = False
try:
    import sounddevice as sd  # type: ignore
    _has_sd = True
except Exception:
    _has_sd = False

_has_sapi = False
try:
    import pythoncom  # type: ignore
    from win32com.client import Dispatch, constants  # type: ignore
    _has_sapi = True
except Exception:
    _has_sapi = False

_has_pyttsx3 = False
try:
    import pyttsx3  # type: ignore
    _has_pyttsx3 = True
except Exception:
    _has_pyttsx3 = False

_has_vosk = False
try:
    from vosk import Model, KaldiRecognizer  # type: ignore
    _has_vosk = True
except Exception:
    _has_vosk = False

# ---------- Theme ----------
class Theme:
    BG = QColor("#7f8791")
    DESK = QColor("#516076")
    CARD = QColor("#5e6670")
    CARD_DARK = QColor("#4c5561")
    BORDER = QColor("#b8c0cc")
    BORDER_DARK = QColor("#3b4250")
    TEXT = QColor("#e8eef7")
    ACCENT = QColor("#1967ff")
    ACCENT_DARK = QColor("#124dcc")
    SUCCESS = QColor("#1fce6d")
    INPUT_BG = QColor("#131b28")
    INPUT_SOFT = QColor("#1c2636")
    LIME = QColor("#54ff76")
    RADIUS = 12

def apply_palette(app: QApplication):
    pal = QPalette()
    pal.setColor(QPalette.Window, Theme.BG)
    pal.setColor(QPalette.Base, Theme.INPUT_SOFT)
    pal.setColor(QPalette.Text, Theme.TEXT)
    pal.setColor(QPalette.WindowText, Theme.TEXT)
    pal.setColor(QPalette.Button, Theme.CARD)
    pal.setColor(QPalette.ButtonText, Theme.TEXT)
    pal.setColor(QPalette.Highlight, Theme.ACCENT)
    pal.setColor(QPalette.HighlightedText, QColor("#ffffff"))
    app.setPalette(pal)
    app.setStyleSheet(f"""
        QMainWindow {{ background: {Theme.BG.name()}; }}
        QGroupBox {{
            background: {Theme.CARD.name()};
            border: 1px solid {Theme.BORDER.name()};
            border-radius: {Theme.RADIUS}px;
            margin-top: 18px; color: {Theme.TEXT.name()};
        }}
        QGroupBox::title {{ left: 10px; padding: 2px 6px; }}
        QLabel {{ color: {Theme.TEXT.name()}; }}
        QLineEdit, QTextEdit, QPlainTextEdit {{
            background: {Theme.INPUT_BG.name()};
            border: 1px solid {Theme.BORDER_DARK.name()};
            border-radius: 10px; padding: 6px 8px; color: {Theme.TEXT.name()};
        }}
        QPushButton {{
            background: {Theme.CARD_DARK.name()};
            border: 1px solid {Theme.BORDER.name()};
            border-radius: 10px; padding: 6px 12px; color: {Theme.TEXT.name()};
        }}
        QPushButton.primary {{ background: {Theme.ACCENT.name()}; color:#fff; border:none; }}
        QPushButton.success {{ background:{Theme.SUCCESS.name()}; color:#0b2f19; border:none; }}
        QPlainTextEdit#Log {{
            background: qlineargradient(x1:0,y1:0,x2:0,y2:1, stop:0 #0e1b2d, stop:1 #0a1320);
            border:1px solid {Theme.BORDER_DARK.name()}; border-radius:10px; color:{Theme.TEXT.name()}; padding:10px;
        }}
    """)

# ---------- Config ----------
@dataclass
class AppConfig:
    # mic & ASR
    mic_device_name: Optional[str] = None
    asr_backend: str = "google"  # google | vosk
    phrase_time_limit: float = 3.0
    energy_threshold: int = 300
    dynamic_energy: bool = True
    sample_rate: int = 16000
    vad_aggressiveness: int = 2
    vosk_model_path: str = ""
    speech_buffer_silence: float = 1.2

    # tts
    tts_engine: str = "sapi"      # sapi | pyttsx3
    tts_voice_hint: str = "Zira"
    tts_rate: int = 0             # relative rate offset (SAPI) or abs pyttsx3 rate
    tts_volume: int = 100         # 0..100
    tts_full_duplex: bool = True  # speak while listening (no barge-in)

    # hotkeys
    hotkey_toggle_mic: str = "F9"
    hotkey_stop_motion: str = "F8"
    hotkey_pause_resume: str = "F7"
    hotkey_push_to_talk: str = ""  # optional (e.g., F4)

    # security
    security_level: str = "workspace-write"  # read-only | workspace-write | full-auto

    # cursor/desktop
    cursor_speed: int = 540
    theme_accent: str = "#1967ff"
    typing_travel_time: float = 0.22
    typing_hold_time: float = 0.06

    @staticmethod
    def path() -> Path:
        return Path(__file__).with_name("vgtools_config.json")

    @classmethod
    def load(cls) -> "AppConfig":
        p = cls.path()
        if p.exists():
            try:
                data = json.loads(p.read_text(encoding="utf-8"))
                return cls(**{**asdict(cls()), **data})
            except Exception:
                pass
        cfg = cls()
        cfg.save()
        return cfg

    def save(self):
        AppConfig.path().write_text(json.dumps(asdict(self), indent=2), encoding="utf-8")

# ---------- Logger ----------
class SessionLogger:
    def __init__(self):
        root = Path(__file__).with_name("vgtools_logs")
        root.mkdir(exist_ok=True)
        self.path = root / f"session_{time.strftime('%Y%m%d_%H%M%S')}.jsonl"
        self._lock = threading.Lock()

    def write(self, obj: dict):
        try:
            with self._lock:
                with self.path.open("a", encoding="utf-8") as f:
                    f.write(json.dumps(obj, ensure_ascii=False) + "\n")
        except Exception:
            pass

# ---------- Chat Responder ----------
@dataclass
class ChatReply:
    text: str
    diagnostics: List[str]
    used_local_model: bool


class ChatResponder:
    """Generate conversational replies using a local Ollama model with fallback."""

    _MODEL_CACHE_TTL = 300.0

    def __init__(self):
        self.helper = OllamaHelper()
        self.dataset = DatasetManager(self.helper, enable_embeddings=False)
        self._model_cache: Dict[str, Tuple[bool, float]] = {}

    # ------------------------------------------------------------------
    def reply(
        self,
        text: str,
        *,
        metadata: Optional[Dict[str, str]] = None,
    ) -> ChatReply:
        prompt = text.strip()
        diagnostics: List[str] = []
        if not prompt:
            diagnostics.append("[ollama] Empty prompt received; using standby reply.")
            return ChatReply("I'm here.", diagnostics, False)

        context_metadata = self._normalize_metadata(metadata)

        def with_context(extra: Dict[str, str]) -> Dict[str, str]:
            merged = dict(context_metadata)
            for key, value in extra.items():
                merged[str(key)] = str(value)
            return merged

        health_ok, health_msg = self.helper.check_health()
        diagnostics.append(f"[ollama] health: {health_msg}")
        embeddings_ready = False
        if health_ok:
            embeddings_ready = self._model_available(EMBED_MODEL)
            self.dataset.set_embeddings_enabled(embeddings_ready)
            if not embeddings_ready:
                diagnostics.append(f"[ollama] embedding model '{EMBED_MODEL}' unavailable; skipping semantic memory.")
        else:
            self.dataset.set_embeddings_enabled(False)

        if not health_ok:
            user_entry = self.dataset.append("user", prompt, with_context({"source": "live"}))
            if prompt and not user_entry.embedding:
                diagnostics.append("[ollama] stored user prompt without embeddings.")
            reply_text = self._fallback_response(prompt)
            self.dataset.append(
                "assistant",
                reply_text,
                with_context({"source": "fallback"}),
            )
            diagnostics.append("[ollama] service unreachable; fallback engaged.")
            return ChatReply(reply_text, diagnostics, False)

        if not self._model_available(CHAT_MODEL):
            diagnostics.append(f"[ollama] chat model '{CHAT_MODEL}' unavailable; fallback engaged.")
            user_entry = self.dataset.append("user", prompt, with_context({"source": "live"}))
            if prompt and not user_entry.embedding and embeddings_ready:
                diagnostics.append("[ollama] embedding request failed for user prompt.")
            reply_text = self._fallback_response(prompt)
            self.dataset.append(
                "assistant",
                reply_text,
                with_context({"source": "fallback"}),
            )
            return ChatReply(reply_text, diagnostics, False)

        history_entries = self.dataset.recent_history(limit=6)
        semantic_entries = self.dataset.semantic_search(prompt, top_k=3) if embeddings_ready else []
        context: List[Dict[str, str]] = []
        seen: Set[str] = set()
        for entry in history_entries + semantic_entries:
            if entry.id in seen:
                continue
            seen.add(entry.id)
            role = entry.role if entry.role in {"user", "assistant", "system"} else "system"
            context.append({"role": role, "content": entry.text})

        user_entry = self.dataset.append("user", prompt, with_context({"source": "live"}))
        if prompt and embeddings_ready and not user_entry.embedding:
            diagnostics.append("[ollama] embedding request failed for user prompt.")

        messages: List[Dict[str, str]] = [
            {"role": "system", "content": "You are Zira, a helpful assistant running locally via Ollama."},
        ]
        messages.extend(context)
        messages.append({"role": "user", "content": prompt})

        result = self.helper.chat(messages, model=CHAT_MODEL, timeout=45.0, stream=True)
        if result.ok and result.content.strip():
            reply_text = result.content.strip()
            diagnostics.append(f"[ollama] reply generated via {CHAT_MODEL}.")
            self.dataset.append(
                "assistant",
                reply_text,
                with_context({"source": "ollama", "model": CHAT_MODEL}),
            )
            return ChatReply(reply_text, diagnostics, True)

        diagnostics.append(f"[ollama] generation failed: {result.error or 'empty response'}")
        if result.diagnostics:
            for key, value in result.diagnostics.items():
                diagnostics.append(f"[ollama] {key}: {value}")
        reply_text = self._fallback_response(prompt)
        self.dataset.append(
            "assistant",
            reply_text,
            with_context({"source": "fallback"}),
        )
        diagnostics.append("[ollama] fallback response delivered.")
        return ChatReply(reply_text, diagnostics, False)

    def _normalize_metadata(
        self,
        metadata: Optional[Dict[str, str]],
    ) -> Dict[str, str]:
        if not metadata:
            return {}
        normalized: Dict[str, str] = {}
        for key, value in metadata.items():
            if value is None:
                continue
            key_str = str(key)
            value_str = str(value)
            if not key_str:
                continue
            normalized[key_str] = value_str
        return normalized

    # ------------------------------------------------------------------
    def _model_available(self, model: str) -> bool:
        now = time.time()
        cached = self._model_cache.get(model)
        if cached and now - cached[1] < self._MODEL_CACHE_TTL:
            return cached[0]
        available = self.helper.ensure_model(model)
        self._model_cache[model] = (available, now)
        return available

    def _fallback_response(self, text: str) -> str:
        t = text.strip().lower()
        if not t:
            return "I'm here."
        if "hello" in t or "hi" in t:
            return "Hello! How can I help?"
        if "time" in t:
            return time.strftime("It's %I:%M %p.")
        if "name" in t:
            return "I'm Zira, your voice-guided assistant."
        return "I'm thinking about that..."

# ---------- TTS Engines (async, full-duplex) ----------
class TTSEngine(QObject):
    speaking = Signal(str)
    finished = Signal()
    voices_loaded = Signal(list)  # [(id, name)]
    def list_voices(self) -> List[Tuple[str,str]]: return []
    def say(self, text: str): ...
    def stop(self): ...
    def set_rate(self, v: int): ...
    def set_volume(self, v: int): ...
    def set_voice_hint(self, hint: str): ...

class SapiTTS(TTSEngine):
    def __init__(self, cfg: AppConfig):
        super().__init__()
        self.enabled = _has_sapi
        self.cfg = cfg
        self._queue: "queue.Queue[str]" = queue.Queue()
        self._stop = threading.Event()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def list_voices(self):
        if not self.enabled: return []
        pythoncom.CoInitialize()
        v = Dispatch("SAPI.SpVoice")
        lst = []
        for t in v.GetVoices():
            lst.append((t.Id, t.GetDescription()))
        self.voices_loaded.emit(lst)
        return lst

    def set_voice_hint(self, hint: str):
        self.cfg.tts_voice_hint = hint

    def set_rate(self, v: int):
        self.cfg.tts_rate = int(v)

    def set_volume(self, v: int):
        self.cfg.tts_volume = int(v)

    def say(self, text: str):
        self._queue.put(text)

    def stop(self):
        # to stop current speech: we enqueue a special token
        self._queue.put("__STOP__")

    def _run(self):
        voice = None
        if self.enabled:
            pythoncom.CoInitialize()
            voice = Dispatch("SAPI.SpVoice")
            try:
                # select voice by hint
                for t in voice.GetVoices():
                    if self.cfg.tts_voice_hint and self.cfg.tts_voice_hint.lower() in t.GetDescription().lower():
                        voice.Voice = t
                        break
            except Exception:
                pass
            try:
                voice.Rate = self.cfg.tts_rate
                voice.Volume = max(0, min(100, self.cfg.tts_volume))
            except Exception:
                pass
        while not self._stop.is_set():
            try:
                text = self._queue.get(timeout=0.1)
            except queue.Empty:
                continue
            if text == "__STOP__":
                if voice:
                    try: voice.Speak("", 2)  # purge
                    except Exception: pass
                self.finished.emit()
                continue
            self.speaking.emit(text)
            if voice:
                try:
                    # SVSFlagsAsync allows us to keep listening while speaking (full-duplex)
                    voice.Speak(text, 1)
                except Exception:
                    pass
            else:
                # simulate timing
                time.sleep(max(0.3, min(2.5, len(text)/40.0)))
            self.finished.emit()

class Pyttsx3TTS(TTSEngine):
    def __init__(self, cfg: AppConfig):
        super().__init__()
        self.engine = None
        if _has_pyttsx3:
            self.engine = pyttsx3.init()
        self.cfg = cfg
        self._queue: "queue.Queue[str]" = queue.Queue()
        self._stop = threading.Event()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def list_voices(self):
        lst = []
        if self.engine:
            for v in self.engine.getProperty("voices"):
                lst.append((v.id, v.name))
        self.voices_loaded.emit(lst)
        return lst

    def set_voice_hint(self, hint: str):
        if self.engine:
            for v in self.engine.getProperty("voices"):
                if hint.lower() in v.name.lower():
                    self.engine.setProperty("voice", v.id)
                    break
        self.cfg.tts_voice_hint = hint

    def set_rate(self, v: int):
        if self.engine:
            self.engine.setProperty("rate", v)
        self.cfg.tts_rate = v

    def set_volume(self, v: int):
        if self.engine:
            self.engine.setProperty("volume", max(0, min(1.0, v/100)))
        self.cfg.tts_volume = v

    def say(self, text: str):
        self._queue.put(text)

    def stop(self):
        self._queue.put("__STOP__")

    def _run(self):
        while not self._stop.is_set():
            try:
                text = self._queue.get(timeout=0.1)
            except queue.Empty:
                continue
            if text == "__STOP__":
                if self.engine:
                    self.engine.stop()
                self.finished.emit()
                continue
            self.speaking.emit(text)
            if self.engine:
                self.engine.say(text)
                self.engine.runAndWait()  # pyttsx3 blocks internally but runs in this dedicated thread
            else:
                time.sleep(max(0.3, min(2.5, len(text)/40.0)))
            self.finished.emit()

# ---------- ASR workers (full-duplex safe) ----------
class SpeechThread(QThread):
    """ASR/VAD thread that continuously listens for user speech."""

    text_ready = Signal(str)
    status = Signal(str)
    devices = Signal(list)
    error = Signal(str)
    speech_start = Signal()
    speech_end = Signal()

    def __init__(self, cfg: AppConfig):
        super().__init__()
        self.cfg = cfg
        self._stop = threading.Event()
        self._backend = cfg.asr_backend
        self._recognizer = sr.Recognizer() if _has_sr else None
        self._vosk: Optional[Tuple[Model, KaldiRecognizer]] = None

    def list_devices(self):
        names: List[str] = []
        if _has_sr:
            try:
                names = list(sr.Microphone.list_microphone_names())
            except Exception:
                names = []
        self.devices.emit(names)

    def stop(self):
        self._stop.set()

    def run(self):
        if self._backend == "vosk" and _has_vosk and self.cfg.vosk_model_path and Path(self.cfg.vosk_model_path).exists():
            try:
                model = Model(self.cfg.vosk_model_path)
                self._vosk = (model, None)  # recognizer constructed per stream in listen()
                self.status.emit("ASR: Vosk model ready.")
            except Exception as e:
                self.error.emit(f"Vosk load failed: {e}")
                self._backend = "google"

        if not _has_sr:
            self.error.emit("SpeechRecognition not installed.")
            return

        mic_index = None
        try:
            names = list(sr.Microphone.list_microphone_names())
            if self.cfg.mic_device_name and self.cfg.mic_device_name in names:
                mic_index = names.index(self.cfg.mic_device_name)
        except Exception:
            mic_index = None

        try:
            self.status.emit("Mic opening…")
            with sr.Microphone(device_index=mic_index, sample_rate=self.cfg.sample_rate) as source:
                self.status.emit("Mic opened.")
                if self._recognizer:
                    self._recognizer.dynamic_energy_threshold = bool(self.cfg.dynamic_energy)
                    self._recognizer.energy_threshold = int(self.cfg.energy_threshold)
                while not self._stop.is_set():
                    if self._recognizer:
                        try:
                            gen = self._recognizer.listen(
                                source,
                                phrase_time_limit=self.cfg.phrase_time_limit,
                                stream=True,
                            )
                            chunks: List[bytes] = []
                            had_chunks = False
                            for i, chunk in enumerate(gen):
                                if i == 0:
                                    self.speech_start.emit()
                                had_chunks = True
                                chunks.append(chunk.get_raw_data())
                            if not chunks:
                                continue
                            audio = sr.AudioData(
                                b"".join(chunks),
                                source.SAMPLE_RATE,
                                source.SAMPLE_WIDTH,
                            )
                        except Exception as e:
                            self.error.emit(f"listen error: {e}")
                            continue

                        text = ""
                        if self._backend == "google":
                            try:
                                text = self._recognizer.recognize_google(audio, show_all=False)
                            except Exception:
                                text = ""
                        elif self._backend == "vosk" and _has_vosk:
                            try:
                                import json as _json
                                if self._vosk:
                                    rec = KaldiRecognizer(self._vosk[0], self.cfg.sample_rate)
                                    rec.AcceptWaveform(
                                        audio.get_raw_data(
                                            convert_rate=self.cfg.sample_rate,
                                            convert_width=2,
                                        )
                                    )
                                    res = _json.loads(rec.Result() or "{}").get("text", "")
                                    text = res
                            except Exception:
                                text = ""

                        if text:
                            self.text_ready.emit(text)
                        if had_chunks:
                            self.speech_end.emit()
                    else:
                        time.sleep(0.05)
        except Exception as e:
            self.error.emit(f"Mic error: {e}")

# ---------- Expressionary NLU ----------
MISHEAR = {
    "laughter": "left", "left her": "left", "lafta": "left",
    "write": "right", "wright": "right", "rite": "right",
    "upwards": "up", "downwards": "down",
    "double click": "double-click", "right click": "right-click",
    "centre": "center"
}

SCRIPT_CREATION_PHRASES = (
    "create a python",
    "make a script",
    "write a python script",
    "python script",
    "create a script",
    "build a script",
    "build python code",
    "create python code",
    "make python code",
    "write python code",
    "start a new code",
    "start new code",
    "start a script",
    "start script",
    "start coding a script",
    "start coding some python",
    "start coding python",
    "spin up a python script",
    "spin up a script",
    "generate a python script",
    "generate python code",
    "generate some python code",
    "draft a python script",
    "draft python script",
)

SCRIPT_CREATION_KEYWORD_GROUPS: Tuple[Tuple[str, ...], ...] = (
    ("create", "script"),
    ("create", "python", "script"),
    ("create", "python", "code"),
    ("make", "script"),
    ("make", "python", "code"),
    ("write", "python", "script"),
    ("build", "script"),
    ("build", "python", "code"),
    ("generate", "script"),
    ("generate", "python", "code"),
    ("draft", "script"),
    ("draft", "python", "script"),
    ("start", "script"),
    ("start", "python", "script"),
    ("start", "python", "code"),
    ("start", "coding", "python"),
    ("start", "coding", "script"),
    ("spin up", "script"),
    ("spin up", "python", "script"),
)

_MAGIC_LEARN_RE = re.compile(r"^\s*magic\s+learn\s*(.*)$", re.IGNORECASE)


def _keyword_in_text(text: str, keyword: str) -> bool:
    """Return True when ``keyword`` is present in ``text`` respecting word boundaries."""

    if " " in keyword:
        return keyword in text
    return bool(re.search(rf"\b{re.escape(keyword)}\b", text))


def _is_script_creation_request(normalized: str) -> bool:
    for phrase in SCRIPT_CREATION_PHRASES:
        if phrase in normalized:
            return True

    for keywords in SCRIPT_CREATION_KEYWORD_GROUPS:
        if all(_keyword_in_text(normalized, keyword) for keyword in keywords):
            return True
    return False

_LEXICON_MANAGER: Optional[LexiconManager] = None


_TYPE_POLITE_PREFIX_RE = re.compile(
    r"""
    ^
    (
        (?:please|kindly)(?:[\s,]+(?:can|could|would|will|may)\s+you)?
        |
        (?:can|could|would|will|may)\s+you(?:[\s,]+(?:please|kindly))?
        |
        i\s+(?:want|need)\s+you\s+to
        |
        i(?:'d)?\s+(?:like|love)\s+you\s+to
        |
        i\s+would\s+(?:like|love)\s+you\s+to
    )
    [\s,]+
    """,
    re.IGNORECASE | re.VERBOSE,
)

_TYPE_VERB_RE = re.compile(
    r"""
    ^
    (
        type\s+out
        |
        type\s+up
        |
        type
        |
        write\s+about
        |
        write\s+out
        |
        write\s+up
        |
        write
    )
    \s+(?P<text>.+)
    $
    """,
    re.IGNORECASE | re.VERBOSE,
)


def _strip_polite_prefixes(utterance: str) -> str:
    stripped = utterance.lstrip()
    while True:
        match = _TYPE_POLITE_PREFIX_RE.match(stripped)
        if not match:
            break
        stripped = stripped[match.end():].lstrip()
    return stripped


def set_lexicon_manager(manager: Optional[LexiconManager]) -> None:
    global _LEXICON_MANAGER
    _LEXICON_MANAGER = manager

def normalize(s: str) -> str:
    t = s.strip().lower()
    for bad, good in MISHEAR.items():
        t = t.replace(bad, good)
    return t

def parse_expressionary(text: str) -> Tuple[str, dict]:
    normalized = normalize(text)
    if not normalized:
        return ("none", {})

    if normalized.startswith("magic "):
        remainder = normalized[6:].strip()
        if remainder.startswith("send"):
            if remainder == "send" or "buffer" in remainder:
                return ("ctrl_magic", {"cmd": "flush_buffer"})
        if remainder.startswith("flush"):
            return ("ctrl_magic", {"cmd": "flush_buffer"})
        if remainder.startswith("cancel") and "buffer" in remainder:
            return ("ctrl_magic", {"cmd": "cancel_buffer"})
        if remainder.startswith("discard") and "buffer" in remainder:
            return ("ctrl_magic", {"cmd": "cancel_buffer"})
        if (
            remainder.startswith("need more time")
            or remainder.startswith("more time")
            or remainder.startswith("give me more time")
            or remainder.startswith("i need more time")
        ):
            return ("ctrl_magic", {"cmd": "need_more_time"})
        if remainder.startswith("summarize now") or remainder == "summarize":
            return ("ctrl_magic", {"cmd": "summarize_now"})

        bucket_match = re.match(r"^(reinstate|review|rollback)\s+bucket\s+(.+)$", remainder)
        if bucket_match:
            op = bucket_match.group(1)
            token = bucket_match.group(2).strip()
            if token:
                cmd_map = {
                    "reinstate": "reinstate_bucket",
                    "review": "review_bucket",
                    "rollback": "rollback_bucket",
                }
                return (
                    "ctrl_magic",
                    {
                        "cmd": cmd_map[op],
                        "metadata": {"bucket_token": token},
                    },
                )
        cmd_parts = remainder.split()
        cmd = cmd_parts[0] if cmd_parts else ""
        command_map = {
            "start": "start",
            "continue": "start",
            "stop": "stop",
            "pause": "pause",
            "confirm": "confirm",
            "proceed": "confirm",
            "deny": "deny",
            "cancel": "cancel_directives",
            "idea": "idea",
            "deploy": "deploy",
            "revert": "revert",
            "retry": "retry",
            "listen": "listen",
            "up": "up",
            "down": "down",
            "teach": "learn",
            "learn": "learn",
            "done": "done",
            "add": "add_directives",
            "reinstate": "reinstate_directives",
            "restore": "reinstate_directives",
            "flush": "flush_buffer",
            "send": "flush_buffer",
        }
        canonical_cmd = command_map.get(cmd)
        if canonical_cmd == "learn":
            if cmd == "learn":
                m = _MAGIC_LEARN_RE.match(text)
            else:
                alias_re = re.compile(rf"^\s*magic\s+{re.escape(cmd)}\s*(.*)$", re.IGNORECASE)
                m = alias_re.match(text)
            payload = m.group(1).strip() if m else ""
            return ("magic_learn", {"payload": payload})
        if canonical_cmd == "done":
            return ("magic_learn", {"control": "done"})
        ctrl_commands = {
            "start",
            "stop",
            "pause",
            "confirm",
            "deny",
            "cancel_directives",
            "idea",
            "deploy",
            "revert",
            "retry",
            "listen",
            "up",
            "down",
            "add_directives",
            "reinstate_directives",
            "flush_buffer",
            "cancel_buffer",
            "need_more_time",
            "summarize_now",
        }
        if canonical_cmd in ctrl_commands:
            return ("ctrl_magic", {"cmd": canonical_cmd})
        return ("chat", {"text": text})

    if _LEXICON_MANAGER:
        match = _LEXICON_MANAGER.match(normalized)
        if match:
            intent, params = match
            return intent, params

    return _parse_builtin_expressionary(normalized, text)


def _parse_builtin_expressionary(normalized: str, original: str) -> Tuple[str, dict]:
    t = normalized
    text = original

    if t in ("stop", "cancel", "stop moving"):
        return ("stop_motion", {})

    if "double-click" in t or t == "double":
        return ("click", {"kind": "double"})
    if "right-click" in t:
        return ("click", {"kind": "right"})
    if t.startswith("click") or t == "left click":
        return ("click", {"kind": "single"})

    m = QRegularExpression(r"scroll\s+(up|down)(?:\s+(\d+))?").match(t)
    if m.hasMatch():
        return ("scroll", {"dir": m.captured(1), "amount": int(m.captured(2) or "120")})

    m = QRegularExpression(r"(?:go|move)\s+(left|right|up|down)(?:\s+(a\s+little|a\s+bit|a\s+lot|halfway|[\d.]+)\s*(?:units?)?)?").match(t)
    if m.hasMatch():
        dir_ = m.captured(1)
        amt = m.captured(2)
        quant = None
        if amt:
            amt = amt.strip()
            if amt in ("a little", "a bit"):
                quant = 18.0
            elif amt == "a lot":
                quant = 120.0
            elif amt == "halfway":
                quant = "halfway"
            else:
                try:
                    quant = float(amt)
                except Exception:
                    quant = None
        return ("move", {"dir": dir_, "units": quant})

    goto_patterns = [
        QRegularExpression(r"^(?:go|move|cursor)\s+to\s+([a-z0-9 _\-]+)"),
        QRegularExpression(r"^(?:focus|navigate)\s+(?:on|to)\s+([a-z0-9 _\-]+)"),
        QRegularExpression(r"^focus\s+the\s+([a-z0-9 _\-]+)"),
    ]
    for pattern in goto_patterns:
        m = pattern.match(t)
        if m.hasMatch():
            name = m.captured(1).strip()
            if name:
                return ("goto", {"name": name})

    shapes = ["circle", "zigzag", "spiral", "figure eight", "figure-8", "square", "box", "snake", "wave"]
    for sh in shapes:
        if sh in t:
            shape = ("figure-8" if "figure" in sh else ("square" if sh in ("square", "box") else ("snake" if sh in ("snake", "wave") else sh)))
            laps = 1
            m = QRegularExpression(r"(\d+)\s*(?:times?|laps?)").match(t)
            if m.hasMatch():
                laps = int(m.captured(1))
            radius = None
            r = QRegularExpression(r"radius\s+(\d+)").match(t)
            if r.hasMatch():
                radius = float(r.captured(1))
            speed = "normal"
            if "fast" in t:
                speed = "fast"
            if "slow" in t:
                speed = "slow"
            return ("shape", {"shape": shape, "laps": laps, "radius": radius, "speed": speed})

    stripped_for_type = _strip_polite_prefixes(text.strip())
    type_match = _TYPE_VERB_RE.match(stripped_for_type)
    if type_match:
        payload = type_match.group("text").strip()
        if payload:
            return ("type", {"text": payload})

    if _is_script_creation_request(t):
        return ("directive", {"plan": "create_python_script", "text": text})
    return ("chat", {"text": text})

# ---------- Desktop & Panels ----------
class Panel(QGroupBox):
    def __init__(self, title: str, parent: QWidget):
        super().__init__(title, parent)
        self.setAttribute(Qt.WA_StyledBackground, True)
        # Allow panels to act like floating windows inside the virtual desktop.
        # Users (and the agent cursor) can drag panels around to new locations.
        self._drag_offset: Optional[QPoint] = None

    def mousePressEvent(self, e: QMouseEvent) -> None:  # type: ignore[override]
        if e.button() == Qt.LeftButton:
            self._drag_offset = e.position().toPoint()
        super().mousePressEvent(e)

    def mouseMoveEvent(self, e: QMouseEvent) -> None:  # type: ignore[override]
        if self._drag_offset is not None:
            new_pos = self.mapToParent(e.position().toPoint() - self._drag_offset)
            self.move(new_pos)
        super().mouseMoveEvent(e)

    def mouseReleaseEvent(self, e: QMouseEvent) -> None:  # type: ignore[override]
        self._drag_offset = None
        super().mouseReleaseEvent(e)


class LineNumberArea(QWidget):
    """Side widget used by CodeEditor to paint line numbers."""

    def __init__(self, editor: "CodeEditor"):
        super().__init__(editor)
        self._editor = editor

    def sizeHint(self) -> QSize:  # pragma: no cover - GUI only
        return QSize(self._editor.line_number_area_width(), 0)

    def paintEvent(self, event: QPaintEvent) -> None:  # pragma: no cover - GUI only
        self._editor.line_number_area_paint_event(event)


class CodeEditor(QPlainTextEdit):
    """Minimal code editor with line numbers, used inside the Code Editor panel."""

    def __init__(self, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self._line_number_area = LineNumberArea(self)
        self.blockCountChanged.connect(self.update_line_number_area_width)
        self.updateRequest.connect(self.update_line_number_area)
        self.cursorPositionChanged.connect(self.highlight_current_line)
        self.update_line_number_area_width(0)
        self.setLineWrapMode(QPlainTextEdit.NoWrap)
        self.setTabStopDistance(4 * self.fontMetrics().horizontalAdvance(" "))

    # ----- line number helpers -----
    def line_number_area_width(self) -> int:
        digits = len(str(max(1, self.blockCount())))
        space = 3 + self.fontMetrics().horizontalAdvance("9") * digits
        return space

    def update_line_number_area_width(self, _=0):
        self.setViewportMargins(self.line_number_area_width(), 0, 0, 0)

    def update_line_number_area(self, rect: QRect, dy: int):  # pragma: no cover - GUI only
        if dy:
            self._line_number_area.scroll(0, dy)
        else:
            self._line_number_area.update(0, rect.y(), self._line_number_area.width(), rect.height())
        if rect.contains(self.viewport().rect()):
            self.update_line_number_area_width()

    def resizeEvent(self, event: QResizeEvent) -> None:  # pragma: no cover - GUI only
        super().resizeEvent(event)
        cr = self.contentsRect()
        self._line_number_area.setGeometry(
            QRect(cr.left(), cr.top(), self.line_number_area_width(), cr.height())
        )

    def line_number_area_paint_event(self, event: QPaintEvent) -> None:  # pragma: no cover - GUI only
        painter = QPainter(self._line_number_area)
        painter.fillRect(event.rect(), Theme.CARD_DARK)

        block = self.firstVisibleBlock()
        block_number = block.blockNumber()
        top = int(self.blockBoundingGeometry(block).translated(self.contentOffset()).top())
        bottom = top + int(self.blockBoundingRect(block).height())

        while block.isValid() and top <= event.rect().bottom():
            if block.isVisible() and bottom >= event.rect().top():
                number = str(block_number + 1)
                painter.setPen(Theme.BORDER)
                painter.drawText(
                    0,
                    top,
                    self._line_number_area.width() - 4,
                    self.fontMetrics().height(),
                    Qt.AlignRight,
                    number,
                )
            block = block.next()
            top = bottom
            bottom = top + int(self.blockBoundingRect(block).height())
            block_number += 1

    def highlight_current_line(self) -> None:  # pragma: no cover - GUI only
        extra_selections: List[QTextEdit.ExtraSelection] = []
        if not self.isReadOnly():
            selection = QTextEdit.ExtraSelection()
            line_color = Theme.CARD.lighter(110)
            selection.format.setBackground(line_color)
            selection.format.setProperty(QTextFormat.FullWidthSelection, True)
            selection.cursor = self.textCursor()
            selection.cursor.clearSelection()
            extra_selections.append(selection)
        self.setExtraSelections(extra_selections)


class CodeEditorPanel(Panel):
    """Floating panel with a tabbed code editor (Notepad++ style)."""

    def __init__(self, parent: QWidget):
        super().__init__("Code Editor", parent)
        lay = QVBoxLayout(self); lay.setContentsMargins(10, 26, 10, 10)
        self.tabs = QTabWidget()
        self.tabs.setTabsClosable(True)
        self.tabs.tabCloseRequested.connect(self.tabs.removeTab)
        lay.addWidget(self.tabs)

        bar = QHBoxLayout()
        btn_new = QPushButton("New Tab")
        btn_new.clicked.connect(self.new_tab)
        bar.addWidget(btn_new)
        bar.addStretch(1)
        lay.addLayout(bar)

        self.new_tab()

    def new_tab(self, name: str = "untitled") -> None:
        editor = CodeEditor()
        idx = self.tabs.addTab(editor, name)
        self.tabs.setCurrentIndex(idx)

    def current_editor(self) -> CodeEditor:
        return self.tabs.currentWidget()  # type: ignore[return-value]

@dataclass
class KeyStroke:
    label: str
    output: Optional[str] = None
    is_modifier: bool = False


class OnScreenKeyboard(QWidget):
    KEY_ROWS = [
        ["`", "1", "2", "3", "4", "5", "6", "7", "8", "9", "0", "-", "=", "Backspace"],
        ["Tab", "Q", "W", "E", "R", "T", "Y", "U", "I", "O", "P", "[", "]", "\\"],
        ["Caps", "A", "S", "D", "F", "G", "H", "J", "K", "L", ";", "'", "Enter"],
        ["Shift", "Z", "X", "C", "V", "B", "N", "M", ",", ".", "/", "Shift"],
        ["Space"],
    ]

    SHIFT_OUTPUTS: Dict[str, str] = {
        "`": "~",
        "1": "!",
        "2": "@",
        "3": "#",
        "4": "$",
        "5": "%",
        "6": "^",
        "7": "&",
        "8": "*",
        "9": "(",
        "0": ")",
        "-": "_",
        "=": "+",
        "[": "{",
        "]": "}",
        "\\": "|",
        ";": ":",
        "'": '"',
        ",": "<",
        ".": ">",
        "/": "?",
    }

    def __init__(self, parent: QWidget):
        super().__init__(parent)
        self._buttons: Dict[str, List[QPushButton]] = {}
        self._shift_latched = False
        self._caps_locked = False
        self._programmatic_override: Optional[str] = None

        lay = QGridLayout(self)
        lay.setContentsMargins(8, 8, 8, 8)
        lay.setHorizontalSpacing(6)
        lay.setVerticalSpacing(6)
        row = 0
        for r in self.KEY_ROWS:
            col = 0
            for key in r:
                btn = QPushButton(key)
                btn.setMinimumHeight(28)
                btn.setStyleSheet("QPushButton{border-radius:12px;}")
                btn.clicked.connect(lambda _, k=key: self.emit_key(k))
                self._buttons.setdefault(key, []).append(btn)
                span = 1
                if key == "Space":
                    span = 6
                elif key in ("Backspace", "Enter", "Shift", "Caps", "Tab"):
                    span = 2
                lay.addWidget(btn, row, col, 1, span)
                col += span
            row += 1

    def button_for_label(self, label: str) -> Optional[QPushButton]:
        btns = self._buttons.get(label)
        if not btns:
            return None
        return btns[0]

    def button_center(self, label: str, desktop: QWidget) -> Optional[QPointF]:
        btn = self.button_for_label(label)
        if btn is None:
            return None
        center = btn.rect().center()
        pos = btn.mapTo(desktop, center)
        return QPointF(float(pos.x()), float(pos.y()))

    def character_plan(self, ch: str) -> Optional[List[KeyStroke]]:
        if ch == "\n":
            return [KeyStroke("Enter", "\n")]
        if ch == "\t":
            return [KeyStroke("Tab", "\t")]
        if ch == " ":
            return [KeyStroke("Space", " ")]
        if ch in self.SHIFT_OUTPUTS.values():
            for base, shifted in self.SHIFT_OUTPUTS.items():
                if shifted == ch:
                    return [KeyStroke("Shift", is_modifier=True), KeyStroke(base, ch)]
        if ch.isalpha():
            key = ch.upper()
            if ch.isupper():
                return [KeyStroke("Shift", is_modifier=True), KeyStroke(key, ch)]
            return [KeyStroke(key, ch.lower())]
        if ch in self.SHIFT_OUTPUTS:
            return [KeyStroke(ch, ch)]
        if ch in {"-", "=", "[", "]", "\\", ";", "'", ",", ".", "/", "`", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9"}:
            return [KeyStroke(ch, ch)]
        return None

    def press_character(
        self,
        ch: str,
        desktop: "VirtualDesktop",
        travel_time: float,
        hold_time: float,
        *,
        fallback: Optional[QWidget] = None,
    ) -> bool:
        strokes = self.character_plan(ch)
        if not strokes:
            if fallback is not None:
                if isinstance(fallback, (QPlainTextEdit, QTextEdit)):
                    fallback.insertPlainText(ch)
                elif isinstance(fallback, QLineEdit):
                    fallback.insert(ch)
            return False

        for stroke in strokes:
            self._press_stroke(stroke, desktop, travel_time, hold_time)
        return True

    def _press_stroke(
        self,
        stroke: KeyStroke,
        desktop: "VirtualDesktop",
        travel_time: float,
        hold_time: float,
    ) -> None:
        btn = self.button_for_label(stroke.label)
        if btn is None:
            # Nothing to press – rely on fallback via emit_key override
            self._programmatic_override = stroke.output
            self.emit_key(stroke.label)
            return

        target = self.button_center(stroke.label, desktop)
        start = desktop.cursor_position()
        if target is not None:
            desktop.begin_typing_motion(start, target, travel_time, hold_time)
            desktop.move_to(float(target.x()), float(target.y()))
            self._drain_events(max(travel_time, 0.01))
        desktop.click_flash()
        self._programmatic_override = stroke.output
        btn.animateClick(0)
        self._drain_events(max(hold_time, 0.01))

    def _drain_events(self, duration: float) -> None:
        end = time.time() + max(0.0, duration)
        while time.time() < end:
            QApplication.processEvents(QEventLoop.AllEvents, 16)

    def emit_key(self, key: str):
        fw = QApplication.focusWidget()
        if fw is None:
            self._shift_latched = False
            return
        if key == "Shift":
            self._shift_latched = not self._shift_latched
            return
        if key == "Caps":
            self._caps_locked = not self._caps_locked
            return
        if isinstance(fw, (QLineEdit, QTextEdit, QPlainTextEdit)):
            if key == "Backspace":
                self._programmatic_override = None
                if isinstance(fw, QLineEdit):
                    fw.backspace()
                else:
                    fw.textCursor().deletePreviousChar()
                self._shift_latched = False
                return
            if key == "Enter":
                self._programmatic_override = None
                ev = QKeyEvent(QEvent.KeyPress, Qt.Key_Return, Qt.NoModifier, "\n")
                QApplication.postEvent(fw, ev)
                self._shift_latched = False
                return
            if key == "Tab":
                self._programmatic_override = None
                fw.focusNextChild()
                self._shift_latched = False
                return
            if key == "Space":
                self._programmatic_override = None
                if isinstance(fw, (QTextEdit, QPlainTextEdit)):
                    fw.insertPlainText(" ")
                else:
                    fw.insert(" ")
                self._shift_latched = False
                return

            text = self._resolve_output(key)
            if text is not None:
                if isinstance(fw, (QPlainTextEdit, QTextEdit)):
                    fw.insertPlainText(text)
                else:
                    fw.insert(text)
        self._shift_latched = False

    def _resolve_output(self, key: str) -> Optional[str]:
        if self._programmatic_override is not None:
            text = self._programmatic_override
            self._programmatic_override = None
            return text

        if len(key) == 1:
            if key.isalpha():
                upper = self._caps_locked ^ self._shift_latched
                return key.upper() if upper else key.lower()
            if self._shift_latched and key in self.SHIFT_OUTPUTS:
                return self.SHIFT_OUTPUTS[key]
            return key
        return None


class DesktopCanvas(QWidget):
    """Square workspace canvas that can host custom drawings or child widgets."""

    def __init__(self, parent: Optional[QWidget] = None) -> None:
        super().__init__(parent)
        sp = QSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        sp.setHeightForWidth(True)
        self.setSizePolicy(sp)
        self.setMinimumSize(320, 320)
        self.setObjectName("DesktopCanvas")
        self._content_widget: Optional[QWidget] = None
        self._pixmap: Optional[QPixmap] = None
        self._drawer: Optional[Callable[[QPainter, QRectF], None]] = None
        self._frame_margin = 24

    def hasHeightForWidth(self) -> bool:  # type: ignore[override]
        return True

    def heightForWidth(self, width: int) -> int:  # type: ignore[override]
        return width

    def sizeHint(self) -> QSize:  # type: ignore[override]
        return QSize(640, 640)

    def set_content(self, content: Optional[CanvasContent]) -> None:
        """Accepts a QWidget, QPixmap, or painter callback."""
        if isinstance(content, QWidget):
            self._set_widget(content)
            self._pixmap = None
            self._drawer = None
        else:
            if self._content_widget is not None:
                self._content_widget.hide()
                self._content_widget.setParent(None)
                self._content_widget = None
            if isinstance(content, QPixmap):
                self._pixmap = content
                self._drawer = None
            else:
                self._pixmap = None
                self._drawer = content
        self.update()

    def clear_content(self) -> None:
        self.set_content(None)

    def content_widget(self) -> Optional[QWidget]:
        return self._content_widget

    def _set_widget(self, widget: QWidget) -> None:
        if widget is self._content_widget:
            return
        if self._content_widget is not None:
            self._content_widget.hide()
            self._content_widget.setParent(None)
        self._content_widget = widget
        widget.setParent(self)
        widget.show()
        self._update_widget_geometry()

    def _update_widget_geometry(self) -> None:
        if self._content_widget is None:
            return
        rect = self._frame_rect().toRect()
        self._content_widget.setGeometry(rect)

    def paintEvent(self, event: QPaintEvent) -> None:  # type: ignore[override]
        p = QPainter(self)
        p.setRenderHint(QPainter.Antialiasing, True)
        p.fillRect(event.rect(), QColor(Theme.CARD_DARK))

        frame = self._frame_rect()
        frame_brush = QColor(Theme.DESK)
        frame_pen = QPen(QColor(Theme.BORDER_DARK))
        frame_pen.setWidth(2)
        p.setPen(frame_pen)
        p.setBrush(frame_brush)
        p.drawRoundedRect(frame, 20, 20)

        if self._pixmap is not None:
            scaled = self._pixmap.scaled(frame.size().toSize(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
            top_left = frame.center() - QPointF(scaled.width() / 2, scaled.height() / 2)
            p.drawPixmap(int(top_left.x()), int(top_left.y()), scaled)
        elif self._drawer is not None:
            self._drawer(p, frame)
        elif self._content_widget is None:
            grid_pen = QPen(QColor("#2a3645"))
            grid_pen.setWidth(1)
            p.setPen(grid_pen)
            step = frame.width() / 6 if frame.width() > 0 else 0
            x = frame.left() + step
            while x < frame.right() - 1e-3 and step > 0:
                p.drawLine(QPointF(x, frame.top() + 12), QPointF(x, frame.bottom() - 12))
                x += step
            y = frame.top() + step
            while y < frame.bottom() - 1e-3 and step > 0:
                p.drawLine(QPointF(frame.left() + 12, y), QPointF(frame.right() - 12, y))
                y += step
            p.setPen(QColor(Theme.TEXT))
            title_font = QFont("Segoe UI", 18, QFont.Bold)
            p.setFont(title_font)
            p.drawText(frame, Qt.AlignCenter, "Workspace")
            note_font = QFont("Segoe UI", 10)
            p.setFont(note_font)
            note_rect = frame.adjusted(0, frame.height() * 0.55, 0, -frame.height() * 0.2)
            p.drawText(note_rect, Qt.AlignHCenter | Qt.AlignTop,
                       "Use set_canvas_content() to embed previews or widgets")

    def resizeEvent(self, event: QResizeEvent) -> None:  # type: ignore[override]
        super().resizeEvent(event)
        self._update_widget_geometry()

    def _frame_rect(self) -> QRectF:
        side = min(self.width(), self.height()) - 2 * self._frame_margin
        side = max(0.0, float(side))
        left = (self.width() - side) / 2.0
        top = (self.height() - side) / 2.0
        return QRectF(left, top, side, side)

class CursorOverlay(QWidget):
    """Transparent overlay that draws the virtual cursor, flash ring,
    speech bubble, and ghost fingertips without intercepting mouse input."""

    def __init__(self, desktop: "VirtualDesktop") -> None:
        super().__init__(desktop)
        self._desktop = desktop
        self.setAttribute(Qt.WA_TransparentForMouseEvents, True)
        self.setAttribute(Qt.WA_TranslucentBackground, True)
        self.setAttribute(Qt.WA_NoSystemBackground, True)
        self.setAutoFillBackground(False)

    def paintEvent(self, event: QPaintEvent) -> None:  # type: ignore[override]
        if self.width() <= 0 or self.height() <= 0:
            return

        buffer = QImage(self.size(), QImage.Format_ARGB32_Premultiplied)
        buffer.fill(Qt.transparent)

        offscreen = QPainter(buffer)
        offscreen.setRenderHint(QPainter.Antialiasing, True)
        offscreen.setCompositionMode(QPainter.CompositionMode_SourceOver)

        for g in self._desktop._ghosts:
            base = QColor("#d6e5ff")
            base.setAlpha(180)
            offscreen.setBrush(base)
            offscreen.setPen(QColor("#213040"))
            offscreen.drawEllipse(QRectF(g.x() - 5, g.y() - 5, 10, 10))

        c = self._desktop._cursor
        base = QColor("#ffffff")
        base.setAlpha(230)
        offscreen.setBrush(base)
        offscreen.setPen(QColor("#0a0d12"))
        offscreen.drawEllipse(QRectF(c.x() - 8, c.y() - 8, 16, 16))
        if self._desktop._flash > 0:
            ring = QColor(Theme.ACCENT)
            ring.setAlpha(int(180 * self._desktop._flash))
            offscreen.setBrush(Qt.NoBrush)
            offscreen.setPen(ring)
            offscreen.drawEllipse(QRectF(c.x() - 18, c.y() - 18, 36, 36))

        width = 300
        lines = self._desktop._bubble_lines
        height = 8 + 18 * len(lines)

        padding = 14.0
        vertical_gap = 12.0
        desktop_rect = QRectF(0.0, 0.0, float(self.width()), float(self.height()))
        margin = 8.0
        interior = QRectF(
            desktop_rect.left() + margin,
            desktop_rect.top() + margin,
            max(0.0, desktop_rect.width() - 2 * margin),
            max(0.0, desktop_rect.height() - 2 * margin),
        )

        def make_rect(orientation: str) -> QRectF:
            if orientation == "left":
                return QRectF(c.x() - padding - width, c.y() - vertical_gap - height / 2, width, height)
            if orientation == "right":
                return QRectF(c.x() + padding, c.y() - vertical_gap - height / 2, width, height)
            if orientation == "up":
                return QRectF(c.x() - width / 2, c.y() - vertical_gap - height, width, height)
            # default to down
            return QRectF(c.x() - width / 2, c.y() + vertical_gap, width, height)

        centers = self._desktop.named_centers()
        nearest = None
        best_dist = float("inf")
        for point in centers.values():
            dx = float(point.x() - c.x())
            dy = float(point.y() - c.y())
            dist = dx * dx + dy * dy
            if dist < best_dist:
                best_dist = dist
                nearest = (dx, dy)

        horizontal_pref = "right"
        vertical_pref = "down"
        if nearest is not None:
            dx, dy = nearest
            horizontal_pref = "right" if dx <= 0 else "left"
            vertical_pref = "down" if dy <= 0 else "up"
        horizontal_alt = "left" if horizontal_pref == "right" else "right"
        vertical_alt = "up" if vertical_pref == "down" else "down"

        if nearest is not None and abs(nearest[0]) < abs(nearest[1]):
            candidates = [vertical_pref, vertical_alt, horizontal_pref, horizontal_alt]
        else:
            candidates = [horizontal_pref, horizontal_alt, vertical_pref, vertical_alt]

        for orientation in ("right", "left", "down", "up"):
            if orientation not in candidates:
                candidates.append(orientation)

        bubble = None
        for orientation in candidates:
            candidate = make_rect(orientation)
            if interior.width() <= 0 or interior.height() <= 0:
                bubble = candidate
                break
            if QRectF(interior).contains(candidate):
                bubble = candidate
                break

        if bubble is None:
            bubble = make_rect(candidates[0]) if candidates else make_rect("right")
            if interior.width() > 0 and interior.height() > 0:
                max_left = interior.right() - bubble.width()
                if max_left < interior.left():
                    max_left = interior.left()
                max_top = interior.bottom() - bubble.height()
                if max_top < interior.top():
                    max_top = interior.top()
                bubble.moveLeft(min(max(bubble.left(), interior.left()), max_left))
                bubble.moveTop(min(max(bubble.top(), interior.top()), max_top))

        offscreen.setBrush(Theme.CARD_DARK)
        offscreen.setPen(QColor("#2f3847"))
        offscreen.drawRoundedRect(bubble, 8, 8)
        offscreen.setPen(Theme.TEXT)
        offscreen.setFont(QFont("Segoe UI", 9))
        for i, line in enumerate(lines):
            offscreen.drawText(
                bubble.adjusted(8, 4 + i * 18, -8, 0),
                Qt.AlignLeft | Qt.AlignTop,
                line,
            )

        offscreen.end()

        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing, True)
        painter.setCompositionMode(QPainter.CompositionMode_SourceOver)
        painter.drawImage(0, 0, buffer)

class VirtualDesktop(QWidget):
    suggestion_confirmed = Signal(object, str)
    suggestion_denied = Signal(object)
    history_action_requested = Signal(str, str)

    @dataclass
    class _GhostAnimation:
        start: QPointF
        end: QPointF
        start_time: float
        travel_time: float
        hold_time: float

    @dataclass
    class _SuggestionRow:
        widget: QWidget
        label: QLabel
        confirm: QPushButton
        deny: QPushButton
        input: Optional[QLineEdit]
        suggestion: CommandSuggestion

    @dataclass
    class _HistoryCardRow:
        widget: QWidget
        title: QLabel
        status: QLabel
        summary: QLabel
        buttons: Dict[str, QPushButton]
        card: DirectiveHistoryCard

    def __init__(self, cfg: AppConfig):
        super().__init__()
        self.cfg = cfg
        self.setMinimumSize(1280, 860)
        self._cursor = QPointF(420, 260)
        self._target = QPointF(420, 260)
        self._speed = float(cfg.cursor_speed)
        self._flash = 0.0
        self._last = time.time()
        self._bubble_lines: List[str] = ["Ready"]
        self._autopilot: Optional[Tuple[float, float]] = None
        self._shape_seq: Optional[List[QPointF]] = None
        self._shape_idx = 0
        self._recording_id: Optional[str] = None
        self._recording_path: List[Tuple[float,float,float]] = []
        self._ghosts: List[QPointF] = []
        self._ghost_anim: Optional[VirtualDesktop._GhostAnimation] = None
        self._typing_travel_time = float(cfg.typing_travel_time)
        self._typing_hold_time = float(cfg.typing_hold_time)
        self._suggestion_rows: List[VirtualDesktop._SuggestionRow] = []
        self._current_suggestions: List[CommandSuggestion] = []
        self._history_card_rows: List[VirtualDesktop._HistoryCardRow] = []
        self._current_history_cards: List[DirectiveHistoryCard] = []

        self._anim = QTimer(self); self._anim.timeout.connect(self._tick); self._anim.start(16)

        self._build_panels()

        self._overlay = CursorOverlay(self)
        self._overlay.setGeometry(self.rect())
        self._overlay.raise_()
        self._overlay.show()

    def _build_panels(self):
        main = QHBoxLayout(self)
        main.setContentsMargins(20, 20, 20, 20)
        main.setSpacing(20)

        # ----- Left column: conversation, input, response -----
        left = QVBoxLayout()
        left.setSpacing(20)

        self.panel_chats = Panel("Conversation", self)
        v = QVBoxLayout(self.panel_chats)
        v.setContentsMargins(10, 26, 10, 10)
        labU = QLabel("User")
        labU.setStyleSheet("QLabel{font-weight:600;color:#d6e5ff;}")
        self.user_chat = QPlainTextEdit()
        self.user_chat.setReadOnly(True)
        self.user_chat.setMaximumBlockCount(800)
        self.user_chat.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        labZ = QLabel("Zira")
        labZ.setStyleSheet("QLabel{font-weight:600;color:#b3ffc4;}")
        self.zira_chat = QPlainTextEdit()
        self.zira_chat.setReadOnly(True)
        self.zira_chat.setMaximumBlockCount(800)
        self.zira_chat.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        v.addWidget(labU)
        v.addWidget(self.user_chat, 1)
        v.addWidget(labZ)
        v.addWidget(self.zira_chat, 1)
        self.panel_chats.setMinimumSize(480, 520)
        self.panel_chats.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        left.addWidget(self.panel_chats, 3)

        self.panel_input = Panel("Message", self)
        g = QGridLayout(self.panel_input)
        g.setContentsMargins(10, 26, 10, 10)
        self.txt_input = QLineEdit()
        self.txt_input.setPlaceholderText("Say or type…")
        self.btn_send = QPushButton("Send")
        self.btn_send.setProperty("class", "primary")
        self.cmb_mic = QComboBox()
        self.cmb_mic.setEditable(False)
        self.btn_mic = QPushButton("Start Mic")
        g.addWidget(self.txt_input, 0, 0, 1, 2)
        g.addWidget(self.btn_send, 0, 2)
        g.addWidget(QLabel("Microphone:"), 1, 0)
        g.addWidget(self.cmb_mic, 1, 1)
        g.addWidget(self.btn_mic, 1, 2)
        self.lbl_listening = QLabel("Listening…")
        self.lbl_listening.setVisible(False)
        self.lbl_listening.setStyleSheet("QLabel{color:#b6cfff;font-style:italic;}")
        g.addWidget(self.lbl_listening, 2, 0, 1, 3)

        self._buffer_control_widget = QWidget()
        buffer_row = QHBoxLayout(self._buffer_control_widget)
        buffer_row.setContentsMargins(0, 0, 0, 0)
        buffer_row.setSpacing(6)
        self.btn_flush_buffer = QPushButton("Send Buffer")
        self.btn_flush_buffer.setProperty("class", "success")
        self.btn_cancel_buffer = QPushButton("Cancel Buffer")
        buffer_row.addWidget(self.btn_flush_buffer)
        buffer_row.addWidget(self.btn_cancel_buffer)
        buffer_row.addStretch(1)
        self._buffer_control_widget.setVisible(False)
        g.addWidget(self._buffer_control_widget, 3, 0, 1, 3)
        left.addWidget(self.panel_input, 1)

        self.panel_log = Panel("Response Window", self)
        lv = QVBoxLayout(self.panel_log)
        self.log = QPlainTextEdit()
        self.log.setObjectName("Log")
        self.log.setReadOnly(True)
        self.log.setMaximumBlockCount(1600)
        self.log.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        lv.addWidget(self.log)
        self.panel_log.setMinimumWidth(480)
        self.panel_log.setMinimumHeight(240)
        self.panel_log.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        left.addWidget(self.panel_log, 2)

        left.setStretch(0, 3)
        left.setStretch(1, 1)
        left.setStretch(2, 2)
        main.addLayout(left, 2)

        # ----- Desktop canvas -----
        self.canvas = DesktopCanvas(self)
        main.addWidget(self.canvas, 4)

        # ----- Middle column: editor, keyboard, controls -----
        mid = QVBoxLayout()
        mid.setSpacing(20)

        self.panel_editor = CodeEditorPanel(self)
        self.code_edit = self.panel_editor.current_editor()
        self.panel_editor.tabs.currentChanged.connect(
            lambda _: setattr(self, "code_edit", self.panel_editor.current_editor())
        )
        mid.addWidget(self.panel_editor, 3)

        self.panel_kb = Panel("On-Screen Keyboard", self)
        kv = QVBoxLayout(self.panel_kb)
        self.keyboard = OnScreenKeyboard(self.panel_kb)
        kv.addWidget(self.keyboard)
        mid.addWidget(self.panel_kb, 1)

        self.panel_ctrl = Panel("Agent Controls", self)
        cg = QGridLayout(self.panel_ctrl)
        self.btn_pause = QPushButton("Pause (F7)")
        self.btn_resume = QPushButton("Resume")
        self.btn_stop = QPushButton("Stop (F8)")
        self.btn_click = QPushButton("Click")
        self.btn_rclk = QPushButton("Right-Click")
        self.btn_dbl = QPushButton("Double-Click")
        self.btn_left = QPushButton("← Left 50")
        self.btn_right = QPushButton("Right 50 →")
        self.btn_up = QPushButton("↑ Up 50")
        self.btn_down = QPushButton("Down 50 ↓")
        for i, b in enumerate([self.btn_pause, self.btn_resume, self.btn_stop, self.btn_click, self.btn_rclk, self.btn_dbl]):
            cg.addWidget(b, 0, i)
        for i, b in enumerate([self.btn_left, self.btn_right, self.btn_up, self.btn_down]):
            cg.addWidget(b, 1, i)
        mid.addWidget(self.panel_ctrl)

        mid.setStretch(0, 3)
        mid.setStretch(1, 1)
        mid.setStretch(2, 1)
        main.addLayout(mid, 3)

        # ----- Right column: security and settings -----
        right = QVBoxLayout()
        right.setSpacing(20)

        self.panel_sec = Panel("Security Manager", self)
        sv = QVBoxLayout(self.panel_sec)
        self.lbl_sec = QLabel("Sandbox Level: workspace-write\nApproval Policy: on-request\nStatus: idle")
        sv.addWidget(self.lbl_sec)
        right.addWidget(self.panel_sec)

        self.panel_commands = Panel("Available Commands", self)
        cv = QVBoxLayout(self.panel_commands)
        cv.setContentsMargins(10, 26, 10, 10)
        cv.setSpacing(6)
        self.command_scroll = QScrollArea(self.panel_commands)
        self.command_scroll.setWidgetResizable(True)
        self.command_scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.command_scroll.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        self._suggestion_container = QWidget(self.command_scroll)
        self._suggestion_layout = QVBoxLayout(self._suggestion_container)
        self._suggestion_layout.setContentsMargins(0, 0, 0, 0)
        self._suggestion_layout.setSpacing(8)
        self.command_scroll.setWidget(self._suggestion_container)
        cv.addWidget(self.command_scroll)
        right.addWidget(self.panel_commands)

        self.panel_settings = Panel("Settings", self)
        s = QGridLayout(self.panel_settings)
        s.setContentsMargins(10, 26, 10, 10)
        s.setVerticalSpacing(6)
        row = 0
        s.addWidget(QLabel("ASR Backend"), row,0); self.cmb_asr = QComboBox(); self.cmb_asr.addItems(["google","vosk"]); s.addWidget(self.cmb_asr,row,1); row+=1
        s.addWidget(QLabel("Phrase Time Limit (s)"), row,0); self.spin_ptl = QSpinBox(); self.spin_ptl.setRange(1,15); s.addWidget(self.spin_ptl,row,1); row+=1
        s.addWidget(QLabel("Energy Threshold"), row,0); self.spin_energy = QSpinBox(); self.spin_energy.setRange(50,4000); s.addWidget(self.spin_energy,row,1); row+=1
        self.chk_dyn = QCheckBox("Dynamic Energy"); s.addWidget(self.chk_dyn,row,0,1,2); row+=1
        s.addWidget(QLabel("Sample Rate"), row,0); self.spin_sr = QSpinBox(); self.spin_sr.setRange(8000,48000); self.spin_sr.setSingleStep(1000); s.addWidget(self.spin_sr,row,1); row+=1
        s.addWidget(QLabel("Buffer Silence (s)"), row,0); self.spin_buffer_gap = QDoubleSpinBox(); self.spin_buffer_gap.setRange(0.2,10.0); self.spin_buffer_gap.setSingleStep(0.1); self.spin_buffer_gap.setDecimals(1); s.addWidget(self.spin_buffer_gap,row,1); row+=1
        s.addWidget(QLabel("Vosk Model Path"), row,0); self.txt_vosk = QLineEdit(); btn_vm = QPushButton("…");
        def _pick_vosk():
            d = QFileDialog.getExistingDirectory(self, "Select Vosk Model Folder")
            if d: self.txt_vosk.setText(d)
        btn_vm.clicked.connect(_pick_vosk); s.addWidget(self.txt_vosk,row,1); s.addWidget(btn_vm,row,2); row+=1

        s.addWidget(QLabel("TTS Engine"), row,0); self.cmb_tts = QComboBox(); self.cmb_tts.addItems(["sapi","pyttsx3"]); s.addWidget(self.cmb_tts,row,1); row+=1
        s.addWidget(QLabel("Voice Hint"), row,0); self.txt_voice = QLineEdit("Zira"); s.addWidget(self.txt_voice,row,1); row+=1
        s.addWidget(QLabel("Rate"), row,0); self.slide_rate = QSlider(Qt.Horizontal); self.slide_rate.setRange(-10, 300); s.addWidget(self.slide_rate,row,1,1,2); row+=1
        s.addWidget(QLabel("Volume"), row,0); self.slide_vol = QSlider(Qt.Horizontal); self.slide_vol.setRange(0,100); s.addWidget(self.slide_vol,row,1,1,2); row+=1
        self.chk_duplex = QCheckBox("Full-Duplex (speak while listening)"); s.addWidget(self.chk_duplex,row,0,1,3); row+=1

        s.addWidget(QLabel("Cursor Speed"), row,0); self.slide_speed = QSlider(Qt.Horizontal); self.slide_speed.setRange(120,1200); s.addWidget(self.slide_speed,row,1,1,2); row+=1

        self.btn_save_cfg = QPushButton("Save Settings")
        self.btn_save_cfg.setProperty("class", "primary")
        s.addWidget(self.btn_save_cfg, row, 0, 1, 3)
        row += 1

        right.addWidget(self.panel_settings, 1)
        right.setStretch(0, 1)
        right.setStretch(1, 2)
        right.setStretch(2, 3)
        main.addLayout(right, 1)

        main.setStretch(0, 2)
        main.setStretch(1, 4)
        main.setStretch(2, 3)
        main.setStretch(3, 1)

        self.set_command_suggestions([])

    def named_centers(self) -> Dict[str, QPointF]:
        def center(widget: QWidget) -> QPointF:
            gp = widget.mapToGlobal(widget.rect().center())
            dp = self.mapFromGlobal(gp)
            return QPointF(float(dp.x()), float(dp.y()))
        return {
            "message input": center(self.txt_input),
            "on-screen keyboard": center(self.panel_kb),
            "keyboard": center(self.panel_kb),
            "response window": center(self.panel_log),
            "agent controls": center(self.panel_ctrl),
            "code editor": center(self.panel_editor),
            "workspace": center(self.canvas),
            "security manager": center(self.panel_sec),
            "zira chat": center(self.zira_chat),
            "user chat": center(self.user_chat),
            "settings": center(self.panel_settings)
        }

    def set_bubble(self, text: str | List[str]):
        if isinstance(text, str):
            s = text.strip()
            lines = [s[i:i+44] for i in range(0, len(s), 44)] or [""]
            self._bubble_lines = lines[:6]
        else:
            self._bubble_lines = text[:6]
        self._overlay.update()

    def set_listening_indicator(self, active: bool, message: Optional[str] = None) -> None:
        if message:
            self.lbl_listening.setText(message)
        else:
            self.lbl_listening.setText("Listening…")
        self.lbl_listening.setVisible(active)

    def set_buffer_controls_enabled(self, enabled: bool) -> None:
        self._buffer_control_widget.setVisible(enabled)
        self.btn_flush_buffer.setEnabled(enabled)
        self.btn_cancel_buffer.setEnabled(enabled)

    def click_flash(self):
        self._flash = 1.0; self._overlay.update()

    def move_to(self, x: float, y: float):
        self._target = QPointF(x, y); self._clamp_target()

    def nudge(self, dx: float, dy: float):
        self._target = QPointF(self._target.x()+dx, self._target.y()+dy); self._clamp_target()

    def start_autopilot(self, dx: float, dy: float):
        self._autopilot = (dx, dy)

    def stop_autopilot(self):
        self._autopilot = None

    def set_shape_path(self, seq: List[QPointF]):
        self._shape_seq = seq; self._shape_idx = 0

    def begin_record(self, cmd_id: str):
        self._recording_id = cmd_id; self._recording_path = []

    def end_record(self) -> List[Tuple[float,float,float]]:
        self._recording_id = None
        path = self._recording_path
        self._recording_path = []
        return path

    def show_ghosts(self, points: List[QPointF]):
        self._ghosts = points[:10]; self._overlay.update()

    def clear_ghosts(self):
        self._ghosts.clear(); self._overlay.update()

    def cursor_position(self) -> QPointF:
        return QPointF(float(self._cursor.x()), float(self._cursor.y()))

    def begin_typing_motion(self, start: QPointF, target: QPointF, travel_time: float, hold_time: float) -> None:
        travel = max(0.05, float(travel_time))
        hold = max(0.0, float(hold_time))
        self._ghost_anim = VirtualDesktop._GhostAnimation(
            QPointF(start.x(), start.y()),
            QPointF(target.x(), target.y()),
            time.time(),
            travel,
            hold,
        )

    def set_canvas_content(self, content: Optional[CanvasContent]) -> None:
        self.canvas.set_content(content)

    def clear_canvas(self) -> None:
        self.canvas.clear_content()

    def canvas_widget(self) -> Optional[QWidget]:
        return self.canvas.content_widget()

    def set_command_suggestions(
        self,
        suggestions: List[CommandSuggestion],
        history: Optional[List[DirectiveHistoryCard]] = None,
    ) -> None:
        self._current_suggestions = list(suggestions)
        self._current_history_cards = list(history or [])
        for row in self._suggestion_rows:
            row.widget.deleteLater()
        self._suggestion_rows = []
        for card_row in self._history_card_rows:
            card_row.widget.deleteLater()
        self._history_card_rows = []

        while self._suggestion_layout.count():
            item = self._suggestion_layout.takeAt(0)
            widget = item.widget()
            if widget is not None:
                widget.deleteLater()

        if not suggestions and not self._current_history_cards:
            placeholder = QLabel("No active suggestions", self._suggestion_container)
            placeholder.setAlignment(Qt.AlignCenter)
            placeholder.setStyleSheet("color: #b0bacd; font-style: italic;")
            self._suggestion_layout.addWidget(placeholder)
            self._suggestion_layout.addStretch(1)
            return

        for suggestion in suggestions:
            row = self._create_suggestion_row(suggestion)
            self._suggestion_layout.addWidget(row.widget)
            self._suggestion_rows.append(row)

        if self._current_history_cards:
            header = QLabel("Directive History", self._suggestion_container)
            header.setStyleSheet(
                "color: #d6e5ff; font-weight: 600; padding: 6px 4px 0 4px;"
            )
            self._suggestion_layout.addWidget(header)
            for card in self._current_history_cards:
                row = self._create_history_card(card)
                self._history_card_rows.append(row)
                self._suggestion_layout.addWidget(row.widget)

        self._suggestion_layout.addStretch(1)

    def _create_suggestion_row(self, suggestion: CommandSuggestion) -> "VirtualDesktop._SuggestionRow":
        container = QWidget(self._suggestion_container)
        container.setObjectName("CommandSuggestionRow")
        layout = QVBoxLayout(container)
        layout.setContentsMargins(8, 6, 8, 6)
        layout.setSpacing(6)

        label = QLabel(suggestion.label, container)
        label.setWordWrap(True)
        layout.addWidget(label)

        input_field: Optional[QLineEdit] = None
        if suggestion.payload_prompt:
            input_field = QLineEdit(container)
            input_field.setPlaceholderText(suggestion.payload_prompt)
            layout.addWidget(input_field)
            if suggestion.initial_payload is not None:
                input_field.setText(suggestion.initial_payload)

        btn_row = QHBoxLayout()
        btn_row.setSpacing(6)

        confirm_text = suggestion.confirm_label or "Confirm"
        confirm = QPushButton(confirm_text, container)
        confirm.setProperty("class", "primary")
        confirm.setEnabled(bool(suggestion.action))
        confirm.clicked.connect(partial(self._emit_suggestion_confirm, suggestion, input_field))
        btn_row.addWidget(confirm)

        deny_text = suggestion.deny_label or "Deny"
        deny = QPushButton(deny_text, container)
        deny_action = suggestion.deny_action
        if deny_action:
            deny.clicked.connect(partial(self._emit_suggestion_deny, suggestion))
        else:
            deny.setEnabled(False)
        btn_row.addWidget(deny)
        btn_row.addStretch(1)
        layout.addLayout(btn_row)

        return VirtualDesktop._SuggestionRow(
            widget=container,
            label=label,
            confirm=confirm,
            deny=deny,
            input=input_field,
            suggestion=suggestion,
        )

    def _create_history_card(
        self, card: DirectiveHistoryCard
    ) -> "VirtualDesktop._HistoryCardRow":
        container = QWidget(self._suggestion_container)
        container.setObjectName("DirectiveHistoryCard")
        layout = QVBoxLayout(container)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(6)

        state = "active" if card.is_active else "archived"
        container.setProperty("historyState", state)

        archived_bg = Theme.CARD.darker(110).name()
        active_bg = Theme.ACCENT.darker(140).name()
        border = Theme.BORDER.name()
        accent = Theme.ACCENT.name()
        if card.is_active:
            container.setStyleSheet(
                f"background-color: {active_bg}; border: 1px solid {accent}; border-radius: 10px;"
            )
        else:
            container.setStyleSheet(
                f"background-color: {archived_bg}; border: 1px solid {border}; border-radius: 10px;"
            )

        title = QLabel(f"{card.title} — {card.status.replace('_', ' ').title()}", container)
        title.setStyleSheet("font-weight: 600; color: #eef3ff;")
        title.setWordWrap(True)
        layout.addWidget(title)

        alias = QLabel(f"Bucket alias: {card.alias}", container)
        alias.setStyleSheet("color: #b9c8e6; font-size: 11px;")
        layout.addWidget(alias)

        summary_text = card.summary.strip() or "No summary captured yet."
        summary = QLabel(summary_text, container)
        summary.setWordWrap(True)
        summary.setStyleSheet("color: #dde6fb;")
        layout.addWidget(summary)

        button_row = QHBoxLayout()
        button_row.setSpacing(6)
        buttons: Dict[str, QPushButton] = {}
        for action in card.actions:
            btn = QPushButton(action.label, container)
            btn.setEnabled(action.enabled)
            if action.tooltip:
                btn.setToolTip(action.tooltip)
            btn.clicked.connect(partial(self._emit_history_action, card.bucket_id, action.command))
            button_row.addWidget(btn)
            buttons[action.command] = btn

        button_row.addStretch(1)
        layout.addLayout(button_row)

        return VirtualDesktop._HistoryCardRow(
            widget=container,
            title=title,
            status=alias,
            summary=summary,
            buttons=buttons,
            card=card,
        )

    def _emit_suggestion_confirm(
        self,
        suggestion: CommandSuggestion,
        input_field: Optional[QLineEdit],
    ) -> None:
        payload = ""
        if input_field is not None:
            payload = input_field.text().strip()
        self.suggestion_confirmed.emit(suggestion, payload)

    def _emit_suggestion_deny(self, suggestion: CommandSuggestion) -> None:
        self.suggestion_denied.emit(suggestion)

    def _emit_history_action(self, bucket_id: str, command: str) -> None:
        self.history_action_requested.emit(bucket_id, command)

    def _clamp_target(self):
        r = self.rect()
        self._target.setX(min(max(self._target.x(), 0), r.width()-1))
        self._target.setY(min(max(self._target.y(), 0), r.height()-1))

    def _tick(self):
        now = time.time()
        dt = max(0.001, min(0.050, now - self._last))
        self._last = now
        self._speed = float(self._speed)  # keep as float

        if self._autopilot:
            dx, dy = self._autopilot
            self.nudge(dx*dt, dy*dt)

        if self._shape_seq is not None:
            if self._shape_idx < len(self._shape_seq):
                p = self._shape_seq[self._shape_idx]
                self._target = p
                self._shape_idx += 1
            else:
                self._shape_seq = None

        dx = self._target.x() - self._cursor.x()
        dy = self._target.y() - self._cursor.y()
        dist = math.hypot(dx, dy)
        max_step = float(self._speed) * dt
        if dist > 0.1:
            step = min(max_step, dist)
            ratio = step / dist
            self._cursor = QPointF(self._cursor.x()+dx*ratio, self._cursor.y()+dy*ratio)
            self._overlay.update()

        if self._flash > 0:
            self._flash = max(0.0, self._flash - dt*2.0)
            self._overlay.update()

        if self._recording_id is not None:
            self._recording_path.append((now, float(self._cursor.x()), float(self._cursor.y())))

        if self._ghost_anim is not None:
            self._update_ghost_animation(now)

    def _update_ghost_animation(self, now: float) -> None:
        anim = self._ghost_anim
        if anim is None:
            return

        elapsed = max(0.0, now - anim.start_time)
        travel = max(0.001, anim.travel_time)
        progress = min(1.0, elapsed / travel)
        dx = anim.end.x() - anim.start.x()
        dy = anim.end.y() - anim.start.y()

        ghosts: List[QPointF] = []
        spacing = 0.14
        count = 5
        for i in range(count):
            t = progress - i * spacing
            if t <= 0:
                continue
            t = min(t, 1.0)
            ghosts.append(QPointF(anim.start.x() + dx * t, anim.start.y() + dy * t))

        if not ghosts and progress >= 1.0:
            ghosts = [QPointF(anim.end.x(), anim.end.y())]

        self._ghosts = ghosts
        if ghosts:
            self._overlay.update()

        if elapsed >= anim.travel_time + anim.hold_time:
            self._ghost_anim = None
            self.clear_ghosts()

    def _keyboard_area_ghosts(self) -> List[QPointF]:
        kb = self.panel_kb
        r = kb.rect()
        if r.isNull(): return []
        pts: List[QPointF] = []
        grid = 5
        for i in range(10):
            x = (i % grid) / (grid-1 if grid>1 else 1)
            y = (i // grid)/1.0
            gp = kb.mapToGlobal(QPoint(int(r.center().x()+(x-0.5)*r.width()*0.8),
                                       int(r.center().y()+(y-0.5)*r.height()*0.4)))
            dp = self.mapFromGlobal(gp)
            pts.append(QPointF(float(dp.x()), float(dp.y())))
        return pts

    def resizeEvent(self, event: QResizeEvent) -> None:  # type: ignore[override]
        super().resizeEvent(event)
        if hasattr(self, "_overlay"):
            self._overlay.setGeometry(QRect(QPoint(0, 0), event.size()))
            self._overlay.raise_()

    def paintEvent(self, e: QPaintEvent) -> None:  # type: ignore[override]
        p = QPainter(self)
        r = self.rect()
        p.fillRect(r, Theme.DESK)
        p.setPen(Theme.BORDER_DARK)
        p.setRenderHint(QPainter.Antialiasing, True)
        p.drawRoundedRect(r.adjusted(0,0,-1,-1), Theme.RADIUS, Theme.RADIUS)

    def mousePressEvent(self, e: QMouseEvent) -> None:  # type: ignore[override]
        mw = self.window()
        active = not getattr(mw, "_paused", False)
        pos = e.position()
        session = getattr(mw, "_session", None)
        if session is not None:
            session.write({
                "type": "user_click",
                "t": time.time(),
                "x": float(pos.x()),
                "y": float(pos.y()),
                # Qt 6 returns a MouseButton enum which is not directly convertible to int.
                # Use the value attribute when available for cross-version compatibility.
                "button": int(getattr(e.button(), "value", e.button())),
                "agent_active": active,
            })
        if active and e.button() == Qt.LeftButton:
            self._cursor = QPointF(pos.x(), pos.y())
            self.move_to(float(pos.x()), float(pos.y()))
            self._overlay.update()
        super().mousePressEvent(e)

# ---------- Main Window ----------
class MainWindow(QMainWindow):
    MAGIC_LEARN_TIMEOUT = 90.0
    MAX_CLARIFICATION_ATTEMPTS = 2
    _BUFFER_FLUSH_COMMANDS: Set[str] = {
        "magic confirm",
        "magic flush",
        "magic send",
        "magic proceed",
    }
    _BUFFER_CANCEL_COMMANDS: Set[str] = {
        "cancel directives",
        "magic cancel",
        "magic cancel buffer",
        "magic discard buffer",
        "magic cancel directives",
    }
    _BUFFER_CONTINUE_COMMANDS: Set[str] = {
        "continue",
        "please continue",
        "continue please",
        "you can continue",
        "go ahead",
        "keep going",
    }
    _BUFFER_MORE_TIME_COMMANDS: Set[str] = {
        "need more time",
        "more time",
        "i need more time",
        "give me more time",
        "need more time please",
        "more time please",
    }
    _BUFFER_SUMMARIZE_COMMANDS: Set[str] = {
        "summarize now",
        "summarize",
    }
    _BUFFER_PREFLUSH_EXEMPT_COMMANDS: Set[str] = {
        "magic need more time",
        "magic more time",
        "magic i need more time",
        "magic give me more time",
        "magic need more time please",
        "magic more time please",
        "magic summarize now",
        "magic summarize",
    }
    tts_say = Signal(str)
    tts_stop = Signal()

    @dataclass
    class DirectiveBucket:
        bucket_id: str = field(default_factory=lambda: uuid.uuid4().hex)
        utterances: List[str] = field(default_factory=list)
        decisions: List[PlannerDecision] = field(default_factory=list)
        current_decision: Optional[PlannerDecision] = None
        pending_sensitive: Optional[Dict[str, Any]] = None
        last_sensitive: Optional[Dict[str, Any]] = None
        clarification: Optional[Dict[str, Any]] = None
        clarification_attempts: List[Dict[str, Any]] = field(default_factory=list)
        status: str = "idle"
        snapshots: List[Dict[str, Any]] = field(default_factory=list)
        plan_payload: Optional[Dict[str, Any]] = None
        title: str = "Directive"
        buffer_previous_status: Optional[str] = None
        pending_utterance: Optional[str] = None
        pending_summary: Optional[str] = None

        def add_utterance(self, utterance: str) -> None:
            cleaned = utterance.strip()
            if cleaned and cleaned not in self.utterances:
                self.utterances.append(cleaned)

        def add_decision(self, decision: PlannerDecision) -> None:
            self.decisions.append(decision)
            self.current_decision = decision

        def record_snapshot(self, snapshot: Dict[str, Any]) -> None:
            self.snapshots.append(snapshot)

        def summary(self) -> str:
            label = self.title or "Directive"
            human_status = self.status.replace("_", " ")
            return f"{label} — {human_status}"

    def __init__(self, cfg: AppConfig):
        super().__init__()
        self.cfg = cfg
        self.setWindowTitle("Voice-Guided Tools — Trainer (Full-Duplex)")
        self.resize(1620, 920)

        self.desktop = VirtualDesktop(cfg)
        self.setCentralWidget(self.desktop)
        self._session = SessionLogger()
        self.chat_responder = ChatResponder()
        self.planner_service = PlannerService(helper=self.chat_responder.helper)
        self.vision_recorder = VisionContextRecorder(
            data_dir=Path(__file__).resolve().parent / "data",
            helper=self.chat_responder.helper,
        )

        self.lexicon = LexiconManager(normalizer=normalize)
        set_lexicon_manager(self.lexicon)

        # speech
        self._mic_thread: Optional[SpeechThread] = None
        self._mic_running = False

        # TTS engine
        self.tts: TTSEngine
        if cfg.tts_engine == "pyttsx3" and _has_pyttsx3:
            self.tts = Pyttsx3TTS(cfg)
        else:
            self.tts = SapiTTS(cfg)
        self.tts.speaking.connect(self._on_tts_speaking)
        self.tts.finished.connect(self._on_tts_finished)
        self.tts_say.connect(self.tts.say)
        self.tts_stop.connect(self.tts.stop)

        # track current TTS state for barge-in handling
        self._tts_current: Optional[str] = None
        self._tts_pending_resume: Optional[str] = None
        self._tts_speaking = False

        # state
        self._paused = False
        self._last_nonmagic: Optional[str] = None
        self._directive_buckets: List[MainWindow.DirectiveBucket] = []
        self._pending_magic_learn: Optional[PendingMagicLearn] = None
        self._snapshot: Optional[dict] = None
        self._directive_state: Dict[str, Any] = {"metadata": {}}
        self._speech_buffer_initialized = False
        self._speech_buffer_waiting = False
        self._ensure_speech_buffer()

        self._wire_ui()
        self._apply_cfg_to_ui()
        self._install_hotkeys()

        self._log("Ready. Full-duplex voice. F9 toggles mic. F7 pause/resume. F8 stop motion.")
        self._narrate("Ready. I can speak while listening. Choose your microphone and say: magic start.")

        # load microphone list
        self._refresh_mics()
        self._update_command_suggestions()

    # ----- UI wiring -----
    def _wire_ui(self):
        d = self.desktop
        d.btn_send.clicked.connect(self._send_clicked)
        d.txt_input.returnPressed.connect(self._send_clicked)
        d.btn_mic.clicked.connect(self._toggle_mic)
        d.btn_flush_buffer.clicked.connect(lambda: self._flush_speech_buffer(reason="ui-button"))
        d.btn_cancel_buffer.clicked.connect(lambda: self._cancel_speech_buffer(reason="ui-button"))

        d.btn_pause.clicked.connect(lambda: self._handle_ctrl_magic("pause"))
        d.btn_resume.clicked.connect(lambda: self._handle_ctrl_magic("start"))
        d.btn_stop.clicked.connect(lambda: self._handle_ctrl_magic("stop"))
        d.btn_click.clicked.connect(lambda: self._dispatch("click"))
        d.btn_rclk.clicked.connect(lambda: self._dispatch("right-click"))
        d.btn_dbl.clicked.connect(lambda: self._dispatch("double-click"))
        d.btn_left.clicked.connect(lambda: self._dispatch("move left 50"))
        d.btn_right.clicked.connect(lambda: self._dispatch("move right 50"))
        d.btn_up.clicked.connect(lambda: self._dispatch("move up 50"))
        d.btn_down.clicked.connect(lambda: self._dispatch("move down 50"))
        d.suggestion_confirmed.connect(self._on_suggestion_confirmed)
        d.suggestion_denied.connect(self._on_suggestion_denied)
        d.history_action_requested.connect(self._on_history_action_requested)

        # settings live bindings
        d.btn_save_cfg.clicked.connect(self._save_settings_clicked)
        self.desktop.slide_speed.valueChanged.connect(lambda v: setattr(self.cfg, "cursor_speed", int(v)))

    def _on_suggestion_confirmed(self, suggestion: CommandSuggestion, payload: str) -> None:
        action = suggestion.action or ""
        cleaned_payload = (payload or "").strip()
        if not action:
            return

        if action.startswith("ctrl:"):
            self._handle_ctrl_magic(action.split(":", 1)[1], metadata=suggestion.metadata)
            return

        if action == "magic_learn":
            self._handle_magic_learn(cleaned_payload)
            return

        if action == "magic_learn:done":
            if self._pending_magic_learn is not None:
                self._pending_magic_learn.state = "finalizing"
                if cleaned_payload:
                    self._pending_magic_learn.draft = cleaned_payload
            self._handle_magic_learn(cleaned_payload, control="done")
            return

        if action == "magic_learn:stop":
            self._handle_ctrl_magic("stop")
            return

        if action == "clarification":
            if cleaned_payload:
                self._dispatch(cleaned_payload)
            else:
                self.desktop.set_bubble("Clarification needs an answer")
                self._narrate("Please type an answer before confirming.")
            return

        if action == "dispatch" and cleaned_payload:
            self._dispatch(cleaned_payload)
            return

    def _on_suggestion_denied(self, suggestion: CommandSuggestion) -> None:
        action = suggestion.deny_action or ""
        if not action:
            return

        if action.startswith("ctrl:"):
            self._handle_ctrl_magic(action.split(":", 1)[1], metadata=suggestion.metadata)
            return

        if action == "magic_learn:stop":
            self._handle_ctrl_magic("stop")
            return

    def _on_history_action_requested(self, bucket_id: str, action: str) -> None:
        bucket = self._find_bucket_by_id(bucket_id)
        if bucket is None:
            self._narrate("I couldn't find that directive bucket.")
            return

        if action == "reinstate":
            self._reinstate_directive_bucket(bucket)
            return
        if action == "review":
            self._review_directive_bucket(bucket)
            return
        if action == "rollback":
            self._rollback_directive_bucket(bucket)
            return

    def _install_hotkeys(self):
        act_mic = QAction(self); act_mic.setShortcut(QKeySequence(self.cfg.hotkey_toggle_mic))
        act_mic.triggered.connect(self._toggle_mic); self.addAction(act_mic)
        act_stop = QAction(self); act_stop.setShortcut(QKeySequence(self.cfg.hotkey_stop_motion))
        act_stop.triggered.connect(lambda: self._handle_ctrl_magic("stop")); self.addAction(act_stop)
        act_pause = QAction(self); act_pause.setShortcut(QKeySequence(self.cfg.hotkey_pause_resume))
        act_pause.triggered.connect(lambda: self._handle_ctrl_magic("pause") if not self._paused else self._handle_ctrl_magic("start"))
        self.addAction(act_pause)

    def _apply_cfg_to_ui(self):
        c = self.cfg
        self.desktop.cmb_asr.setCurrentText(c.asr_backend)
        self.desktop.spin_ptl.setValue(int(c.phrase_time_limit))
        self.desktop.spin_energy.setValue(int(c.energy_threshold))
        self.desktop.chk_dyn.setChecked(bool(c.dynamic_energy))
        self.desktop.spin_sr.setValue(int(c.sample_rate))
        self.desktop.txt_vosk.setText(c.vosk_model_path)
        if hasattr(self.desktop, "spin_buffer_gap"):
            self.desktop.spin_buffer_gap.setValue(float(c.speech_buffer_silence))
        self.desktop.cmb_tts.setCurrentText(c.tts_engine)
        self.desktop.txt_voice.setText(c.tts_voice_hint or "")
        self.desktop.slide_rate.setValue(int(c.tts_rate))
        self.desktop.slide_vol.setValue(int(c.tts_volume))
        self.desktop.chk_duplex.setChecked(bool(c.tts_full_duplex))
        self.desktop.slide_speed.setValue(int(c.cursor_speed))

        # apply TTS params live
        self.tts.set_voice_hint(c.tts_voice_hint or "")
        self.tts.set_rate(c.tts_rate)
        self.tts.set_volume(c.tts_volume)

    def _save_settings_clicked(self):
        c = self.cfg
        c.asr_backend = self.desktop.cmb_asr.currentText()
        c.phrase_time_limit = float(self.desktop.spin_ptl.value())
        c.energy_threshold = int(self.desktop.spin_energy.value())
        c.dynamic_energy = bool(self.desktop.chk_dyn.isChecked())
        c.sample_rate = int(self.desktop.spin_sr.value())
        if hasattr(self.desktop, "spin_buffer_gap"):
            c.speech_buffer_silence = float(self.desktop.spin_buffer_gap.value())
        c.vosk_model_path = self.desktop.txt_vosk.text().strip()
        c.tts_engine = self.desktop.cmb_tts.currentText()
        c.tts_voice_hint = self.desktop.txt_voice.text().strip() or "Zira"
        c.tts_rate = int(self.desktop.slide_rate.value())
        c.tts_volume = int(self.desktop.slide_vol.value())
        c.tts_full_duplex = bool(self.desktop.chk_duplex.isChecked())
        c.cursor_speed = int(self.desktop.slide_speed.value())
        c.save()
        # reapply to engine
        self.tts.set_voice_hint(c.tts_voice_hint)
        self.tts.set_rate(c.tts_rate)
        self.tts.set_volume(c.tts_volume)
        self.desktop._speed = float(c.cursor_speed)
        self._log("[settings] saved.")

    # ----- mic devices -----
    def _refresh_mics(self):
        if not _has_sr:
            self.desktop.cmb_mic.clear(); self.desktop.cmb_mic.addItem("(SpeechRecognition not installed)")
            return
        try:
            names = list(sr.Microphone.list_microphone_names())
        except Exception:
            names = []
        self.desktop.cmb_mic.clear()
        if not names:
            self.desktop.cmb_mic.addItem("(No devices)")
        else:
            self.desktop.cmb_mic.addItems(names)
            if self.cfg.mic_device_name and self.cfg.mic_device_name in names:
                self.desktop.cmb_mic.setCurrentText(self.cfg.mic_device_name)

    # ----- command suggestions -----
    def _active_directive_bucket(self) -> Optional["MainWindow.DirectiveBucket"]:
        for bucket in reversed(self._directive_buckets):
            if bucket.status in {"awaiting-confirmation", "collecting", "clarifying", "executing"}:
                return bucket
        return None

    def _find_bucket_for_utterance(self, utterance: str) -> Optional["MainWindow.DirectiveBucket"]:
        normalized = utterance.strip()
        if not normalized:
            return None
        for bucket in reversed(self._directive_buckets):
            if normalized in bucket.utterances:
                return bucket
            clar = bucket.clarification
            if isinstance(clar, dict) and clar.get("utterance") == normalized:
                return bucket
        return None

    def _bucket_alias(self, bucket: "MainWindow.DirectiveBucket") -> str:
        token = (bucket.bucket_id or "")[:4].upper()
        if not token:
            token = "????"
        return token

    def _find_bucket_by_id(
        self, bucket_id: Optional[str]
    ) -> Optional["MainWindow.DirectiveBucket"]:
        lookup = (bucket_id or "").strip().lower()
        if not lookup:
            return None
        for bucket in self._directive_buckets:
            if bucket.bucket_id.lower().startswith(lookup):
                return bucket
        return None

    def _resolve_bucket_token(
        self, token: Optional[str]
    ) -> Optional["MainWindow.DirectiveBucket"]:
        if not token:
            return None
        normalized = re.sub(r"[^a-z0-9]", "", token.lower())
        if not normalized:
            return None
        for bucket in reversed(self._directive_buckets):
            if bucket.bucket_id and bucket.bucket_id.lower().startswith(normalized):
                return bucket
            alias = re.sub(r"[^a-z0-9]", "", self._bucket_alias(bucket).lower())
            if alias and alias.startswith(normalized):
                return bucket
            title = re.sub(r"[^a-z0-9]", "", (bucket.title or "").lower())
            if title and title.startswith(normalized):
                return bucket
        return None

    def _bucket_history_cards(self) -> List[DirectiveHistoryCard]:
        cards: List[DirectiveHistoryCard] = []
        active = self._active_directive_bucket()
        for bucket in self._directive_buckets:
            if bucket.status == "idle" and bucket is not active:
                continue

            alias = self._bucket_alias(bucket)
            summary = ""
            for candidate in (
                bucket.pending_summary,
                bucket.pending_utterance,
                *(bucket.utterances[-3:] if bucket.utterances else []),
            ):
                if isinstance(candidate, str) and candidate.strip():
                    summary = candidate.strip()
                    break
            if not summary and isinstance(bucket.plan_payload, dict):
                steps = bucket.plan_payload.get("steps")
                if isinstance(steps, list) and steps:
                    first = steps[0] or {}
                    summary = str(first.get("summary") or first.get("action") or "").strip()
            if not summary:
                summary = bucket.title or "Directive"

            actions: List[DirectiveHistoryAction] = []
            if bucket.status == "canceled":
                actions.append(
                    DirectiveHistoryAction(
                        "Reinstate",
                        "reinstate",
                        tooltip="Restore this directive's pending plan or summary.",
                    )
                )
            actions.append(
                DirectiveHistoryAction(
                    "Review steps",
                    "review",
                    tooltip="Summarize the captured steps or utterances.",
                )
            )
            if bucket.snapshots:
                actions.append(
                    DirectiveHistoryAction(
                        "Rollback to snapshot",
                        "rollback",
                        tooltip="Move back to the last saved snapshot for this directive.",
                    )
                )

            cards.append(
                DirectiveHistoryCard(
                    bucket_id=bucket.bucket_id,
                    title=bucket.title or "Directive",
                    status=bucket.status or "unknown",
                    summary=summary,
                    alias=alias,
                    actions=actions,
                    is_active=(bucket is active and bucket.status != "canceled"),
                )
            )
        return cards

    def _bucket_topics(
        self,
        bucket: Optional["MainWindow.DirectiveBucket"],
        *,
        extra: Optional[Iterable[str]] = None,
    ) -> List[str]:
        if bucket is None:
            return []

        seen: Set[str] = set()
        topics: List[str] = []

        def push(candidate: Optional[str]) -> None:
            if not candidate:
                return
            raw = str(candidate).strip()
            if not raw:
                return
            normalized_phrase = re.sub(r"[^a-z0-9+#/_\-.]+", " ", raw.lower()).strip()
            if normalized_phrase and normalized_phrase not in seen:
                seen.add(normalized_phrase)
                topics.append(normalized_phrase)
            for token in re.findall(r"[a-z0-9][a-z0-9+/_\-]{2,}", normalized_phrase):
                if token not in seen:
                    seen.add(token)
                    topics.append(token)

        plan_payload = bucket.plan_payload if isinstance(bucket.plan_payload, dict) else {}
        plan_metadata = plan_payload.get("metadata") if isinstance(plan_payload, dict) else {}
        if isinstance(plan_metadata, dict):
            push(plan_metadata.get("filename"))
            push(plan_metadata.get("directory"))
            themes = plan_metadata.get("themes")
            if isinstance(themes, list):
                for theme in themes:
                    push(theme)

        push(bucket.title)
        push(bucket.pending_summary)
        push(bucket.pending_utterance)
        for utterance in bucket.utterances[-3:]:
            push(utterance)

        if extra:
            for item in extra:
                push(item)

        return topics[:12]

    def _bucket_metadata(
        self,
        bucket: Optional["MainWindow.DirectiveBucket"],
        *,
        status: Optional[str] = None,
        extra_topics: Optional[Iterable[str]] = None,
        event: Optional[str] = None,
    ) -> Dict[str, str]:
        if bucket is None:
            return {}
        effective_status = (status or bucket.status or "unknown").strip() or "unknown"
        topics = self._bucket_topics(bucket, extra=extra_topics)
        metadata: Dict[str, str] = {
            "directive_bucket_id": bucket.bucket_id,
            "directive_status": effective_status.lower(),
            "directive_title": (bucket.title or "Directive"),
        }
        if topics:
            metadata["directive_topics"] = ",".join(dict.fromkeys(topics))
        if event:
            metadata["directive_event"] = event
        return metadata

    def _record_bucket_transition(
        self,
        bucket: Optional["MainWindow.DirectiveBucket"],
        *,
        status: Optional[str],
        event: str,
        message: str,
        extra_topics: Optional[Iterable[str]] = None,
    ) -> None:
        if bucket is None:
            return
        metadata = self._bucket_metadata(
            bucket,
            status=status,
            extra_topics=extra_topics,
            event=event,
        )
        metadata["source"] = "directive"
        self.chat_responder.dataset.append("system", message, metadata)

    def _get_pending_sensitive(self) -> Optional[Dict[str, Any]]:
        bucket = self._active_directive_bucket()
        if bucket and bucket.status in {"awaiting-confirmation", "collecting"}:
            return bucket.pending_sensitive
        return None

    def _set_pending_sensitive(
        self,
        value: Optional[Dict[str, Any]],
        *,
        bucket: Optional["MainWindow.DirectiveBucket"] = None,
    ) -> None:
        if bucket is None:
            bucket = self._active_directive_bucket()
            if bucket is None and value is not None:
                bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
                self._directive_buckets.append(bucket)
        if bucket is None:
            self._update_command_suggestions()
            return
        bucket.pending_sensitive = value
        if value is not None:
            bucket.last_sensitive = dict(value)
            plan_payload = value.get("plan") if isinstance(value, dict) else None
            if isinstance(plan_payload, dict):
                bucket.plan_payload = plan_payload
                bucket.title = plan_payload.get("title") or bucket.title
            bucket.status = "awaiting-confirmation"
        elif bucket.status == "awaiting-confirmation":
            bucket.status = "idle"
        self._update_command_suggestions()

    def _get_pending_plan_decision(self) -> Optional[PlannerDecision]:
        bucket = self._active_directive_bucket()
        if bucket:
            return bucket.current_decision
        return None

    def _set_pending_plan_decision(
        self,
        value: Optional[PlannerDecision],
        *,
        bucket: Optional["MainWindow.DirectiveBucket"] = None,
        utterance: Optional[str] = None,
    ) -> None:
        if bucket is None:
            bucket = self._active_directive_bucket()
            if bucket is None and value is not None:
                bucket = MainWindow.DirectiveBucket(status="collecting")
                self._directive_buckets.append(bucket)
        if bucket is None:
            self._update_command_suggestions()
            return
        if value is None:
            bucket.current_decision = None
        else:
            bucket.add_decision(value)
            if utterance:
                bucket.add_utterance(utterance)
        self._update_command_suggestions()

    def _get_pending_clarification(self) -> Optional[Dict[str, Any]]:
        bucket = self._active_directive_bucket()
        if bucket and bucket.status == "clarifying":
            return bucket.clarification
        return None

    def _set_pending_clarification(
        self,
        value: Optional[Dict[str, Any]],
        *,
        utterance: Optional[str] = None,
    ) -> Optional["MainWindow.DirectiveBucket"]:
        bucket = self._active_directive_bucket()
        if value is not None:
            if bucket is None or bucket.status not in {"awaiting-confirmation", "clarifying", "collecting"}:
                bucket = MainWindow.DirectiveBucket(status="clarifying")
                self._directive_buckets.append(bucket)
            bucket.clarification = value
            bucket.status = "clarifying"
            raw = value.get("utterance") if isinstance(value, dict) else None
            if isinstance(raw, str):
                bucket.add_utterance(raw)
            if utterance:
                bucket.add_utterance(utterance)
        elif bucket:
            bucket.clarification = None
            if bucket.status == "clarifying":
                bucket.status = "collecting"
        self._update_command_suggestions()
        return bucket

    def _compose_clarification_question(
        self,
        utterance: str,
        bucket: Optional["MainWindow.DirectiveBucket"],
        base_question: str,
    ) -> str:
        prompt = (base_question or "Could you clarify what you need?").strip()
        attempts = bucket.clarification_attempts if bucket else []
        if not attempts:
            return prompt or "Could you clarify what you need?"

        last_answer = ""
        for entry in reversed(attempts):
            answer = (entry.get("answer") or "").strip()
            if answer:
                last_answer = answer
                break

        prefix = f"I'm still not sure how to handle \"{utterance}\"."
        if last_answer:
            prefix = (
                f"I'm still not sure how to handle \"{utterance}\" "
                f"after you said \"{last_answer}\"."
            )

        follow_up = prompt if prompt else "Could you share more specifics so I can help?"
        return f"{prefix} {follow_up}".strip()

    def _clarification_summary_prompt(
        self,
        utterance: str,
        attempts: List[Dict[str, Any]],
    ) -> Tuple[str, str]:
        cleaned_utterance = utterance.strip()
        lines = [f"User request: {cleaned_utterance or utterance}"]
        last_answer = ""
        for attempt in attempts:
            attempt_idx = attempt.get("attempt") or len(lines)
            question = attempt.get("question") or "(no question recorded)"
            lines.append(f"Attempt {attempt_idx} question: {question}")
            answer = attempt.get("answer")
            if answer:
                lines.append(f"Attempt {attempt_idx} answer: {answer}")
                last_answer = answer
        lines.append(
            "The planner could not resolve the directive. Provide actionable guidance or next steps."
        )
        prompt = "\n".join(lines)

        if last_answer:
            message = (
                f"I'm still not sure how to handle \"{utterance}\" after "
                f"your answer \"{last_answer}\". I'll switch to chat for more help."
            )
        else:
            message = (
                f"I'm still not sure how to handle \"{utterance}\" even after our follow-ups. "
                "I'll switch to chat for more help."
            )
        return prompt, message

    def _process_clarification_request(
        self,
        utterance: str,
        base_question: Optional[str],
        *,
        bucket: Optional["MainWindow.DirectiveBucket"] = None,
    ) -> bool:
        working_bucket = bucket or self._find_bucket_for_utterance(utterance)
        attempts = working_bucket.clarification_attempts if working_bucket else []
        attempt_count = len(attempts)

        if attempt_count >= self.MAX_CLARIFICATION_ATTEMPTS:
            prompt, message = self._clarification_summary_prompt(utterance, attempts)
            self.desktop.set_bubble(message[:48])
            self._narrate(message)
            now = time.time()
            self._session.write(
                {
                    "type": "planner-clarification-escalated",
                    "t": now,
                    "utterance": utterance,
                    "attempts": attempt_count,
                    "prompt": prompt,
                }
            )
            self._set_pending_clarification(None)
            if working_bucket:
                working_bucket.clarification = None
                if working_bucket.status == "clarifying":
                    working_bucket.status = "collecting"
                if working_bucket.clarification_attempts:
                    working_bucket.clarification_attempts[-1]["escalated"] = True
                    working_bucket.clarification_attempts[-1]["escalated_at"] = now

            metadata = self._bucket_metadata(
                working_bucket,
                extra_topics=[utterance, prompt],
                event="clarification-escalated",
            )
            reply = self.chat_responder.reply(prompt, metadata=metadata)
            for diag in reply.diagnostics:
                self._log(diag)
            if reply.used_local_model:
                self._log(f"[ollama] response source: {CHAT_MODEL}")
            else:
                self._log("[ollama] response source: fallback")
            if reply.text:
                self._log(f"[zira] {reply.text}")
                self._narrate(reply.text)
            return True

        base = base_question or "Do you want to design the idea or open the editor?"
        question = self._compose_clarification_question(utterance, working_bucket, base)
        self.desktop.set_bubble(question[:48])
        self._narrate(question)
        now = time.time()
        bucket_after = self._set_pending_clarification(
            {"utterance": utterance, "question": question}, utterance=utterance
        )
        target_bucket = bucket_after or working_bucket
        if target_bucket is not None:
            attempt_record = {
                "attempt": attempt_count + 1,
                "retries": attempt_count,
                "utterance": utterance,
                "question": question,
                "asked_at": now,
            }
            target_bucket.clarification_attempts.append(attempt_record)

        self._session.write(
            {
                "type": "planner-clarification",
                "t": now,
                "utterance": utterance,
                "question": question,
                "attempt": attempt_count + 1,
                "retries": attempt_count,
            }
        )
        return True

    def _update_command_suggestions(self) -> None:
        desktop = getattr(self, "desktop", None)
        if desktop is None or not hasattr(desktop, "set_command_suggestions"):
            return

        suggestions: List[CommandSuggestion] = []

        if getattr(self, "_speech_buffer", []):
            suggestions.append(
                CommandSuggestion(
                    "Send Buffered Speech",
                    "ctrl:flush_buffer",
                    confirm_label="Send Buffer",
                    deny_action=None,
                )
            )
            suggestions.append(
                CommandSuggestion(
                    "Cancel Buffered Speech",
                    "ctrl:cancel_buffer",
                    confirm_label="Cancel Buffer",
                    deny_action=None,
                )
            )
            if getattr(self, "_speech_buffer_waiting", False):
                suggestions.append(
                    CommandSuggestion(
                        "Need more time",
                        "ctrl:need_more_time",
                        confirm_label="Need more time",
                        deny_action=None,
                    )
                )
                suggestions.append(
                    CommandSuggestion(
                        "Summarize now",
                        "ctrl:summarize_now",
                        confirm_label="Summarize now",
                        deny_action=None,
                    )
                )

        pending_magic = self._pending_magic_learn
        if pending_magic:
            pending_payload = pending_magic.current_payload()
            if not pending_payload and pending_magic.segments:
                pending_magic.refresh_draft()
                pending_payload = pending_magic.current_payload()

            summary_lines = [
                "Magic Learn Segments",
                pending_magic.segment_summary(),
                "Edit the phrase => action below, then press Magic Done.",
            ]
            label = "\n".join(line for line in summary_lines if line)
            suggestions.append(
                CommandSuggestion(
                    label=label,
                    action="magic_learn:done",
                    payload_prompt="phrase => action",
                    deny_action="magic_learn:stop",
                    confirm_label="Magic Done",
                    deny_label="Magic Stop",
                    initial_payload=pending_payload,
                )
            )

        pending_sensitive = self._get_pending_sensitive()
        pending_plan = self._get_pending_plan_decision()
        active_bucket = self._active_directive_bucket()
        has_summary_pending = bool(
            active_bucket
            and active_bucket.pending_utterance
            and active_bucket.status == "awaiting-confirmation"
        )
        if pending_sensitive or pending_plan or has_summary_pending:
            suggestions.append(CommandSuggestion("Confirm Directives", "ctrl:confirm"))
            suggestions.append(CommandSuggestion("Cancel Directives", "ctrl:deny", deny_action=None))
            suggestions.append(CommandSuggestion("Add Directives", "ctrl:add_directives"))
            suggestions.append(CommandSuggestion("Correct Directive", "ctrl:correct_directive", deny_action=None))

        if self._paused:
            suggestions.append(CommandSuggestion("magic start", "ctrl:start", deny_action=None))
        else:
            suggestions.append(CommandSuggestion("magic pause", "ctrl:pause", deny_action=None))

        if getattr(desktop, "_autopilot", None):
            suggestions.append(CommandSuggestion("magic stop", "ctrl:stop", deny_action=None))

        pending_clarification = self._get_pending_clarification()
        if pending_clarification:
            question = pending_clarification.get("question")
            if question:
                trimmed = question if len(question) <= 64 else f"{question[:61]}…"
                label = f"Clarify: {trimmed}"
            else:
                label = "Clarify pending question"
            suggestions.append(
                CommandSuggestion(
                    label=label,
                    action="clarification",
                    payload_prompt="Type your answer…",
                )
            )

        if self._last_nonmagic:
            suggestions.append(CommandSuggestion("magic retry", "ctrl:retry", deny_action=None))

        if self._snapshot:
            suggestions.append(CommandSuggestion("magic revert", "ctrl:revert", deny_action=None))

        if not self._mic_running:
            suggestions.append(CommandSuggestion("magic listen", "ctrl:listen", deny_action=None))

        if not pending_magic and not (pending_sensitive or pending_plan):
            suggestions.append(CommandSuggestion("magic idea", "ctrl:idea", deny_action=None))

        if any(bucket.status == "canceled" for bucket in self._directive_buckets):
            suggestions.append(CommandSuggestion("Reinstate Directives", "ctrl:reinstate_directives", deny_action=None))

        deduped: List[CommandSuggestion] = []
        seen: Set[str] = set()
        for suggestion in suggestions:
            label = suggestion.label.strip()
            if not label:
                continue
            if label not in seen:
                deduped.append(suggestion)
                seen.add(label)

        history_cards = self._bucket_history_cards()
        desktop.set_command_suggestions(deduped, history_cards)

    def _set_paused(self, value: bool) -> None:
        self._paused = bool(value)
        self._update_command_suggestions()

    def _set_pending_magic_learn(self, value: Optional[Union[dict, PendingMagicLearn]]) -> None:
        pending: Optional[PendingMagicLearn]
        if isinstance(value, dict):
            pending = PendingMagicLearn(
                requested_at=float(value.get("requested_at", time.time())),
                last_heard_at=float(value.get("last_heard_at", value.get("requested_at", time.time()))),
                prompt=str(value.get("prompt", "")),
                segments=list(value.get("segments", [])),
                state=str(value.get("state", "collecting")),
                draft=str(value.get("draft", "")),
            )
            if not pending.draft and pending.segments:
                pending.refresh_draft()
        else:
            pending = value
            if pending is not None and not pending.draft and pending.segments:
                pending.refresh_draft()

        self._pending_magic_learn = pending
        self._update_command_suggestions()

    # ----- simple logs & chat lanes -----
    def _log(self, s: str):
        self.desktop.log.appendPlainText(s)
        self.desktop.log.moveCursor(QTextCursor.End)

    def _user_chat(self, s: str):
        self.desktop.user_chat.appendPlainText(s)
        self.desktop.user_chat.moveCursor(QTextCursor.End)
        self._session.write({"type": "chat", "from": "user", "t": time.time(), "text": s})

    def _zira_chat(self, s: str):
        self.desktop.zira_chat.appendPlainText(s)
        self.desktop.zira_chat.moveCursor(QTextCursor.End)
        self._session.write({"type": "chat", "from": "zira", "t": time.time(), "text": s})

    # ----- TTS events -----
    def _narrate(self, text: str):
        self._zira_chat(text)
        # Full-duplex choice: if disabled, we would stop; else always speak
        if self.cfg.tts_full_duplex:
            self.tts_say.emit(text)
        else:
            # if not duplex, we could stop previous and then speak
            self.tts_stop.emit(); self.tts_say.emit(text)

    def _say_input_unrecognized(
        self,
        *,
        session_entry: Optional[Dict[str, object]] = None,
        log: Optional[str] = None,
    ) -> None:
        """Emit the canonical unrecognized input response and log metadata."""

        self.desktop.set_bubble("Input unrecognized.")
        self._narrate("Input unrecognized.")

        if log:
            self._log(log)

        if session_entry is not None:
            entry: Dict[str, object] = dict(session_entry)
            entry.setdefault("type", "system")
            entry.setdefault("status", "input-unrecognized")
            entry.setdefault("t", time.time())
        else:
            entry = {
                "type": "system",
                "status": "input-unrecognized",
                "t": time.time(),
            }

        self._session.write(entry)

    def _on_tts_speaking(self, text: str):
        # Update bubble for visual feedback and track state
        self._tts_speaking = True
        self._tts_current = text
        self.desktop.set_bubble(text[:96])

    def _on_tts_finished(self):
        self._tts_speaking = False
        self._tts_current = None

    def _on_user_speech_start(self):
        if not self.cfg.tts_full_duplex and self._tts_speaking:
            self._tts_pending_resume = self._tts_current
            self.tts_stop.emit()
            self._tts_speaking = False
        self._ensure_speech_buffer()
        if self._mic_running:
            self.desktop.set_listening_indicator(True, message="Listening…")

    def _on_speech_segment_end(self) -> None:
        if not getattr(self, "_speech_buffer_initialized", False):
            return
        if self._speech_buffer:
            self.desktop.set_listening_indicator(True, message="Listening… (collecting)")
        elif self._mic_running:
            self.desktop.set_listening_indicator(True, message="Listening…")

    def _ensure_speech_buffer(self) -> None:
        if getattr(self, "_speech_buffer_initialized", False):
            return
        self._speech_buffer_initialized = True
        self._speech_buffer: List[str] = []
        self._speech_buffer_last_at: float = 0.0
        self._speech_buffer_timer = QTimer(self)
        self._speech_buffer_timer.setSingleShot(True)
        self._speech_buffer_timer.timeout.connect(self._on_speech_buffer_timeout)
        self._speech_buffer_waiting = False

    def _on_speech_buffer_timeout(self) -> None:
        if not getattr(self, "_speech_buffer", []):
            if getattr(self, "_speech_buffer_waiting", False):
                self._speech_buffer_waiting = False
                self._update_command_suggestions()
            else:
                self._speech_buffer_waiting = False
            return
        if getattr(self, "_speech_buffer_waiting", False):
            self._speech_buffer_waiting = False
            self._narrate("Okay, I'll go ahead and continue.")
            self._flush_speech_buffer(reason="silence-followup")
            return
        self._speech_buffer_waiting = True
        self._narrate("Do you need more time, or should I continue?")
        self._speech_buffer_timer.start(int(self._speech_buffer_gap() * 1000))
        self._update_command_suggestions()

    def _speech_buffer_gap(self) -> float:
        try:
            gap = float(getattr(self.cfg, "speech_buffer_silence", 1.2))
        except (TypeError, ValueError):
            gap = 1.2
        return max(0.2, min(10.0, gap))

    def _append_speech_segment(self, text: str) -> None:
        self._ensure_speech_buffer()
        cleaned = text.strip()
        if not cleaned:
            return
        self._speech_buffer_waiting = False
        self._speech_buffer.append(cleaned)
        self._speech_buffer_last_at = time.time()
        if self._mic_running:
            self.desktop.set_listening_indicator(True, message="Listening… (collecting)")
        self.desktop.set_buffer_controls_enabled(True)
        self._ensure_collecting_bucket()
        self._speech_buffer_timer.start(int(self._speech_buffer_gap() * 1000))
        self._update_command_suggestions()

    def _consume_speech_buffer(self, *, maintain_indicator: bool = True) -> Optional[str]:
        self._ensure_speech_buffer()
        segments = [seg.strip() for seg in self._speech_buffer if seg.strip()]
        combined = " ".join(segments).strip()
        self._speech_buffer.clear()
        self._speech_buffer_last_at = 0.0
        self._speech_buffer_waiting = False
        if hasattr(self, "_speech_buffer_timer"):
            self._speech_buffer_timer.stop()
        if maintain_indicator and self._mic_running:
            self.desktop.set_listening_indicator(True, message="Listening…")
        else:
            self.desktop.set_listening_indicator(False)
        self.desktop.set_buffer_controls_enabled(False)
        return combined or None

    def _summarize_bucket_utterance(
        self,
        utterance: str,
        *,
        bucket: Optional["MainWindow.DirectiveBucket"] = None,
    ) -> Tuple["MainWindow.DirectiveBucket", Optional[str]]:
        cleaned = (utterance or "").strip()
        active = bucket or self._active_directive_bucket()
        if active is None:
            active = MainWindow.DirectiveBucket(status="collecting")
            self._directive_buckets.append(active)

        existing = (active.pending_utterance or "").strip()
        if existing and cleaned and active.status == "collecting":
            combined_text = f"{existing} {cleaned}".strip()
        elif cleaned:
            combined_text = cleaned
        else:
            combined_text = existing

        active.pending_utterance = combined_text or None
        active.pending_summary = None

        summary_text: Optional[str] = None
        if combined_text:
            prompt = (
                "Summarize the following directive request in 25 words or fewer. "
                "Respond with a single neutral sentence describing the work the assistant should perform. "
                f"Request: {combined_text}"
            )
            try:
                metadata = self._bucket_metadata(active, extra_topics=[combined_text])
                reply = self.chat_responder.reply(prompt, metadata=metadata)
                for diag in reply.diagnostics:
                    self._log(diag)
                summary_text = (reply.text or "").strip()
            except Exception as exc:
                self._log(f"[summary] failed: {exc}")
                summary_text = None

            if not summary_text:
                summary_text = combined_text

            active.pending_summary = summary_text
            self._session.write(
                {
                    "type": "speech-buffer-summary",
                    "t": time.time(),
                    "utterance": combined_text,
                    "summary": summary_text,
                }
            )

        return active, summary_text

    def _restore_bucket_after_buffer(self) -> bool:
        bucket = self._active_directive_bucket()
        if bucket and bucket.status == "collecting" and bucket.buffer_previous_status:
            bucket.status = bucket.buffer_previous_status
            bucket.buffer_previous_status = None
            return True
        return False

    def _flush_speech_buffer(
        self,
        *,
        reason: str,
        maintain_indicator: bool = True,
    ) -> Optional[str]:
        self._ensure_speech_buffer()
        combined = self._consume_speech_buffer(maintain_indicator=maintain_indicator)
        self._restore_bucket_after_buffer()
        if not combined:
            self._update_command_suggestions()
            return None

        self._log(f"[mic] buffered utterance ({reason}): {combined}")
        self._user_chat(combined)

        bucket = self._active_directive_bucket()
        bucket, summary = self._summarize_bucket_utterance(combined, bucket=bucket)
        bucket.status = "awaiting-confirmation"

        summary_text = summary or combined
        review_message = f"Summary: {summary_text}" if summary else f"Review: {summary_text}"
        self.desktop.set_bubble(review_message[:48])
        self._narrate(review_message)

        self._resume_pending_tts_if_needed()
        self._update_command_suggestions()
        return combined

    def _handle_buffer_confirmation(self) -> None:
        self._ensure_speech_buffer()
        self._speech_buffer_waiting = False
        self._narrate("Okay, I'll go ahead and continue.")
        self._flush_speech_buffer(reason="magic-done")

    def _cancel_speech_buffer(
        self,
        *,
        reason: str,
        maintain_indicator: bool = True,
    ) -> None:
        self._ensure_speech_buffer()
        had_segments = bool(self._speech_buffer)
        self._speech_buffer_waiting = False
        self._consume_speech_buffer(maintain_indicator=maintain_indicator)
        self._restore_bucket_after_buffer()
        if had_segments:
            self._log(f"[mic] speech buffer canceled ({reason}).")
            self.desktop.set_bubble("Speech buffer canceled.")
        self._update_command_suggestions()

    def _ensure_collecting_bucket(self) -> None:
        bucket = self._active_directive_bucket()
        if bucket and bucket.status not in {"clarifying", "executing"}:
            if bucket.status != "collecting":
                bucket.buffer_previous_status = bucket.status
                bucket.status = "collecting"
                self._update_command_suggestions()

    def _resume_pending_tts_if_needed(self) -> None:
        if self._tts_pending_resume and not self._tts_speaking:
            self.tts_say.emit(self._tts_pending_resume)
            self._tts_pending_resume = None

    # ----- mic -----
    def _toggle_mic(self):
        if self._mic_running: self._stop_mic()
        else: self._start_mic()

    def _start_mic(self):
        if not _has_sr:
            self._log("SpeechRecognition not installed.")
            self._update_command_suggestions()
            return
        if self._mic_thread and self._mic_thread.isRunning():
            return
        sel = self.desktop.cmb_mic.currentText().strip()
        if sel and sel != "(No devices)":
            self.cfg.mic_device_name = sel
        self.cfg.asr_backend = self.desktop.cmb_asr.currentText()
        self.cfg.phrase_time_limit = float(self.desktop.spin_ptl.value())
        self.cfg.energy_threshold = int(self.desktop.spin_energy.value())
        self.cfg.dynamic_energy = bool(self.desktop.chk_dyn.isChecked())
        self.cfg.sample_rate = int(self.desktop.spin_sr.value())
        self.cfg.vosk_model_path = self.desktop.txt_vosk.text().strip()
        if hasattr(self.desktop, "spin_buffer_gap"):
            self.cfg.speech_buffer_silence = float(self.desktop.spin_buffer_gap.value())
        self.cfg.save()

        self._mic_thread = SpeechThread(self.cfg)
        self._mic_thread.text_ready.connect(self._on_mic_text)
        self._mic_thread.status.connect(lambda m: self._log(f"[mic] {m}"))
        self._mic_thread.error.connect(lambda e: self._log(f"[mic error] {e}"))
        self._mic_thread.speech_start.connect(self._on_user_speech_start)
        self._mic_thread.speech_end.connect(self._on_speech_segment_end)
        self._mic_thread.start()
        self._mic_running = True
        self.desktop.btn_mic.setText("Stop Mic")
        self._ensure_speech_buffer()
        self.desktop.set_listening_indicator(True, message="Listening…")
        self.desktop.set_buffer_controls_enabled(bool(self._speech_buffer))
        self._log("Mic started.")
        self._update_command_suggestions()

    def _stop_mic(self):
        if self._mic_thread:
            self._mic_thread.stop()
            self._mic_thread.wait(2000)
        self._mic_thread = None
        self._mic_running = False
        self._cancel_speech_buffer(reason="mic-stop", maintain_indicator=False)
        self.desktop.btn_mic.setText("Start Mic")
        self.desktop.set_bubble("Ready")
        self.desktop.set_listening_indicator(False)
        self._log("Mic stopped.")
        self._update_command_suggestions()

    def _on_mic_text(self, text: str):
        if not text:
            return
        self._ensure_speech_buffer()
        normalized = text.strip().lower()
        if not normalized:
            return

        if getattr(self, "_speech_buffer_waiting", False):
            if normalized in self._BUFFER_CONTINUE_COMMANDS:
                self._speech_buffer_waiting = False
                self._narrate("Continuing now.")
                self._flush_speech_buffer(reason="voice-continue")
                return
            if normalized in self._BUFFER_MORE_TIME_COMMANDS:
                self._speech_buffer_waiting = False
                timer = getattr(self, "_speech_buffer_timer", None)
                if timer is not None:
                    timer.start(int(self._speech_buffer_gap() * 1000))
                if self._mic_running:
                    self.desktop.set_listening_indicator(True, message="Listening… (collecting)")
                self._narrate("Okay, I'll keep listening.")
                self._update_command_suggestions()
                return
            if normalized in self._BUFFER_SUMMARIZE_COMMANDS:
                self._speech_buffer_waiting = False
                self._flush_speech_buffer(reason="user-confirmed")
                return

        if normalized.startswith("magic "):
            if normalized in self._BUFFER_CANCEL_COMMANDS:
                self._cancel_speech_buffer(reason="voice-cancel")
            elif normalized in self._BUFFER_FLUSH_COMMANDS:
                self._flush_speech_buffer(reason="voice-flush")
            elif self._speech_buffer and normalized not in self._BUFFER_PREFLUSH_EXEMPT_COMMANDS:
                self._flush_speech_buffer(reason="pre-magic")
            self._user_chat(text)
            self._dispatch(text)
            self._resume_pending_tts_if_needed()
            return

        if normalized in self._BUFFER_CANCEL_COMMANDS:
            self._cancel_speech_buffer(reason="voice-cancel")
            self._user_chat(text)
            self._dispatch(text)
            self._resume_pending_tts_if_needed()
            return

        self._append_speech_segment(text)

    # ----- input send -----
    def _send_clicked(self):
        txt = self.desktop.txt_input.text().strip()
        if not txt: return
        self._user_chat(txt)
        self._dispatch(txt)
        self.desktop.txt_input.clear()

    # ----- directive helpers -----
    def _nearest_target(self, name: str) -> Optional[QPointF]:
        centers = self.desktop.named_centers()
        q = name.strip().lower()
        for k, pos in centers.items():
            if k.startswith(q) or q in k:
                return pos
        return None

    def _snapshot_state(self, tag: str):
        self._snapshot = {
            "tag": tag,
            "cursor": [float(self.desktop._cursor.x()), float(self.desktop._cursor.y())],
            "focus": self.focusWidget().__class__.__name__ if self.focusWidget() else None,
            "open_file": "draft.py" if self.desktop.code_edit.toPlainText() else None,
            "caret": self.desktop.code_edit.textCursor().position(),
        }
        self._session.write({"type":"snapshot","t":time.time(),"data":self._snapshot})
        bucket = self._active_directive_bucket()
        if bucket:
            bucket.record_snapshot(dict(self._snapshot))
        self._update_command_suggestions()

    def _capture_plan_context(self, tag: str, title: str) -> Optional[Dict[str, Any]]:
        recorder = getattr(self, "vision_recorder", None)
        if not recorder:
            return None
        try:
            artifacts = recorder.capture(self.desktop, tag, utterance=title)
        except Exception as exc:  # pragma: no cover - defensive guard
            self._log(f"[vision] capture error: {exc}")
            return {"error": str(exc)}
        return artifacts.to_dict()

    # ----- directive metadata helpers -----
    def _reset_directive_state(self) -> None:
        self._directive_state = {"metadata": {}}

    def _merge_metadata(
        self,
        primary: Optional[Dict[str, Any]],
        secondary: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        metadata: Dict[str, Any] = {
            "filename": None,
            "directory": None,
            "themes": [],
        }
        for source in (secondary or {}, primary or {}):
            if not isinstance(source, dict):
                continue
            filename = source.get("filename")
            directory = source.get("directory")
            themes = source.get("themes")
            if filename and not metadata["filename"]:
                metadata["filename"] = str(filename)
            if directory and not metadata["directory"]:
                metadata["directory"] = str(directory)
            if themes and not metadata["themes"]:
                if isinstance(themes, list):
                    metadata["themes"] = [str(t) for t in themes if str(t).strip()]
                else:
                    metadata["themes"] = [str(themes)]
        if not metadata["themes"]:
            metadata["themes"] = []
        return metadata

    def _extract_script_metadata(self, text: str) -> Dict[str, Any]:
        metadata = {
            "filename": None,
            "directory": None,
            "themes": [],
        }
        if not text:
            return metadata

        courtesy_suffix = re.compile(r"\b(?:please|thanks|thank you)\b\.?$", re.IGNORECASE)

        def normalize_filename(raw: str) -> Optional[str]:
            cleaned = (raw or "").strip().strip("\"'`")
            if not cleaned:
                return None
            cleaned = courtesy_suffix.sub("", cleaned).strip()
            has_extension = cleaned.lower().endswith(".py")
            if has_extension:
                cleaned = cleaned[:-3]
            cleaned = cleaned.replace("\\", "/")
            cleaned = cleaned.split("/")[-1]
            cleaned = re.sub(r"\s+", " ", cleaned)
            normalized = re.sub(r"[^0-9a-zA-Z_]+", "_", cleaned)
            normalized = re.sub(r"_+", "_", normalized).strip("_")
            if not normalized:
                return None
            if not has_extension:
                normalized = normalized.lower()
            return f"{normalized}.py"

        filename_match = re.search(
            r"([\w\-/]+\.py)",
            text,
        )
        if filename_match:
            normalized = normalize_filename(filename_match.group(1))
            if normalized:
                metadata["filename"] = normalized
        else:
            filename_patterns = (
                r"(?:script\s+name\s+is|file\s+name\s+is|filename\s+is|name\s+the\s+(?:file|script)|call\s+the\s+(?:file|script)|name\s+it|call\s+it)\s+([^,.!?]+?)\s*(?=(?:\s+(?:in|inside|within|into|under|to|folder|directory|path)\b|\bplease\b|\bthanks\b|\bthank you\b|[,.!?]|$))",
            )
            for pattern in filename_patterns:
                match = re.search(pattern, text, flags=re.IGNORECASE)
                if not match:
                    continue
                normalized = normalize_filename(match.group(1))
                if normalized:
                    metadata["filename"] = normalized
                    break

        def normalize_directory(raw: str) -> Optional[str]:
            cleaned = (raw or "").strip().strip("\"'`")
            if not cleaned:
                return None
            cleaned = courtesy_suffix.sub("", cleaned).strip()
            cleaned = re.sub(r"\b(folder|directory|path)\b$", "", cleaned, flags=re.IGNORECASE).strip()
            cleaned = re.sub(r"^(?:the|a|an)\s+", "", cleaned, flags=re.IGNORECASE)
            cleaned = cleaned.replace("\\", "/")
            segments = []
            for segment in cleaned.split("/"):
                piece = segment.strip()
                if not piece:
                    continue
                piece = re.sub(r"\s+", "_", piece.lower())
                piece = re.sub(r"[^0-9a-zA-Z_\-]+", "_", piece)
                piece = re.sub(r"_+", "_", piece).strip("_")
                if piece:
                    segments.append(piece)
            if not segments:
                return None
            normalized = "/".join(segments)
            if ".py" in normalized:
                return None
            if not normalized.endswith("/"):
                normalized = f"{normalized}/"
            return normalized

        directory_patterns = (
            r"(?:in|inside(?:\s+of)?|within|into|to|under)\s+(?:the\s+)?(?:folder|directory|path\s+of\s+)?([^,.!?]+?)\s*(?=(?:\s+(?:folder|directory|path)\b|\bplease\b|\bthanks\b|\bthank you\b|[,.!?]|$))",
            r"(?:folder|directory|path)\s+(?:named|called)\s+([^,.!?]+)",
        )
        for pattern in directory_patterns:
            directory_match = re.search(pattern, text, flags=re.IGNORECASE)
            if not directory_match:
                continue
            normalized_directory = normalize_directory(directory_match.group(1))
            if normalized_directory:
                metadata["directory"] = normalized_directory
                break

        theme_candidates = []
        for pattern in (r"\bthat\s+([^,.!?]+)", r"\bwhich\s+([^,.!?]+)", r"\bfor\s+([^,.!?]+)"):
            theme_candidates.extend(re.findall(pattern, text, flags=re.IGNORECASE))
        cleaned_themes = []
        for theme in theme_candidates:
            cleaned = theme.strip().rstrip(" .")
            if cleaned:
                cleaned_themes.append(cleaned)
        if cleaned_themes:
            metadata["themes"] = cleaned_themes
        return metadata

    def _initialize_directive_plan_state(self, plan: Dict[str, Any], utterance: str) -> None:
        plan_metadata = plan.get("metadata") if isinstance(plan, dict) else {}
        if not isinstance(plan_metadata, dict):
            plan_metadata = {}
        utterance_metadata = self._extract_script_metadata(utterance)
        merged = self._merge_metadata(plan_metadata, utterance_metadata)
        plan["metadata"] = merged
        self._directive_state = {
            "plan": plan,
            "metadata": merged,
            "utterance": utterance,
        }

    def _directive_missing_fields(self) -> List[str]:
        metadata = self._directive_state.get("metadata") if self._directive_state else {}
        if not isinstance(metadata, dict):
            metadata = {}
        missing: List[str] = []
        for field in ("filename", "directory"):
            value = metadata.get(field)
            if not value:
                missing.append(field)
        return missing

    def _prompt_for_directive_metadata(self, field: str) -> None:
        prompts = {
            "filename": "What should the filename be?",
            "directory": "Where should I save the script?",
        }
        question = prompts.get(field, "What details should I note?")
        self._directive_state.setdefault("metadata", {})
        self._directive_state["pending_field"] = field
        self._directive_state["pending_question"] = question
        self.desktop.set_bubble(question[:48])
        self._narrate(question)

    def _handle_directive_metadata_answer(self, answer: str) -> None:
        field = self._directive_state.get("pending_field") if self._directive_state else None
        if not field:
            return
        extracted = self._extract_script_metadata(answer)
        value = answer.strip()
        if field == "filename":
            value = extracted.get("filename") or value
            if value and not value.endswith(".py"):
                value = f"{value}.py"
        if field == "directory":
            value = extracted.get("directory") or value
            if value:
                value = value.rstrip()
                if not value.endswith("/"):
                    value = f"{value}/"
        metadata = self._directive_state.setdefault("metadata", {})
        metadata[field] = value or None
        merged = self._merge_metadata(metadata, extracted)
        self._directive_state["metadata"] = merged
        plan = self._directive_state.get("plan")
        if isinstance(plan, dict):
            plan["metadata"] = merged
        self._directive_state.pop("pending_field", None)
        self._directive_state.pop("pending_question", None)
        ack_templates = {
            "filename": "Filename noted — I'll create {value}.",
            "directory": "Directory noted — I'll work inside {value}.",
        }
        resolved_value = (merged.get(field) if isinstance(merged, dict) else value) or (
            "draft.py" if field == "filename" else "workspace/scripts/"
        )
        ack = ack_templates.get(field, "Noted.").format(value=resolved_value)
        missing = self._directive_missing_fields()
        if not missing:
            ack = f"{ack} Say magic confirm when you're ready for me to build it."
        self.desktop.set_bubble(ack[:48])
        self._narrate(ack)
        if missing:
            self._prompt_for_directive_metadata(missing[0])

    def _directive_metadata_ready(self) -> bool:
        if not self._directive_state:
            return True
        metadata = self._directive_state.get("metadata")
        if not isinstance(metadata, dict):
            return True
        if self._directive_state.get("pending_field"):
            return False
        for field in ("filename", "directory"):
            value = metadata.get(field)
            if not value:
                return False
        return True

    # ----- typing & shapes -----
    def _type_text(self, text: str):
        desktop = self.desktop
        keyboard = getattr(desktop, "keyboard", None)
        target = QApplication.focusWidget() or desktop.code_edit
        target.setFocus()

        travel = float(getattr(self.cfg, "typing_travel_time", getattr(desktop, "_typing_travel_time", 0.2)))
        hold = float(getattr(self.cfg, "typing_hold_time", getattr(desktop, "_typing_hold_time", 0.05)))

        if isinstance(keyboard, OnScreenKeyboard):
            for ch in text:
                keyboard.press_character(ch, desktop, travel, hold, fallback=target)
            return

        # Fallback: insert text directly if the keyboard widget is unavailable.
        for ch in text:
            if ch == "\n":
                ev = QKeyEvent(QEvent.KeyPress, Qt.Key_Return, Qt.NoModifier, "\n")
                QApplication.postEvent(target, ev)
            elif ch == " ":
                if isinstance(target, (QTextEdit, QPlainTextEdit)):
                    target.insertPlainText(" ")
                elif isinstance(target, QLineEdit):
                    target.insert(" ")
            else:
                if isinstance(target, (QTextEdit, QPlainTextEdit)):
                    target.insertPlainText(ch)
                elif isinstance(target, QLineEdit):
                    target.insert(ch)
        desktop.clear_ghosts()

    def _shape_path(self, shape: str, center: QPointF, speed: str, laps: int = 1,
                    radius: Optional[float] = None) -> List[QPointF]:
        seq: List[QPointF] = []
        sp = 1.0
        if speed == "fast": sp = 1.7
        if speed == "slow": sp = 0.6

        if shape == "circle":
            r = radius if radius is not None else 24.0
            steps = max(80, int(2*math.pi*r))
            for _ in range(laps):
                for t in range(steps):
                    a = (t/steps)*2*math.pi
                    seq.append(QPointF(center.x()+r*math.cos(a), center.y()+r*math.sin(a)))
        elif shape == "zigzag":
            amp, length, freq, steps = 16.0, 120.0, 4, 120
            for i in range(steps):
                x = center.x()+ (i/steps-0.5)*length
                y = center.y()+ (1 if (i//(steps/(freq*2)))%2 else -1)*amp
                seq.append(QPointF(x, y))
        elif shape == "spiral":
            r0, r1 = 8.0, 48.0; turns = max(1, laps); steps = 360
            for i in range(turns*steps):
                t = i/(turns*steps)
                r = r0 + (r1-r0)*t
                a = t*2*math.pi*turns
                seq.append(QPointF(center.x()+r*math.cos(a), center.y()+r*math.sin(a)))
        elif shape in ("figure-8","figure eight"):
            r, steps = 18.0, 200
            for _ in range(laps):
                for i in range(steps):
                    t = (i/steps)*2*math.pi
                    x = center.x()+r*math.sin(t)
                    y = center.y()+r*math.sin(t)*math.cos(t)
                    seq.append(QPointF(x,y))
        elif shape == "square":
            side, steps = 40.0, 60
            pts = [
                QPointF(center.x()-side/2, center.y()-side/2),
                QPointF(center.x()+side/2, center.y()-side/2),
                QPointF(center.x()+side/2, center.y()+side/2),
                QPointF(center.x()-side/2, center.y()+side/2),
                QPointF(center.x()-side/2, center.y()-side/2),
            ]
            for _ in range(laps):
                for a,b in zip(pts, pts[1:]):
                    for i in range(steps):
                        t = i/steps
                        seq.append(QPointF(a.x()*(1-t)+b.x()*t, a.y()*(1-t)+b.y()*t))
        elif shape in ("snake","wave"):
            amp, wl, length, steps = 14.0, 60.0, 220.0, 220
            for i in range(steps):
                x = center.x()+ (i/steps-0.5)*length
                y = center.y()+ amp*math.sin(2*math.pi*(x-center.x())/wl)
                seq.append(QPointF(x,y))

        if sp != 1.0:
            thinned: List[QPointF] = []
            step = max(1, int(round(2.0/sp)))
            for i,p in enumerate(seq):
                if i % step == 0: thinned.append(p)
            seq = thinned
        return seq

    # ----- planning -----
    def _directive_plan(self, name: str, text: str) -> dict:
        if name == "create_python_script":
            metadata = self._extract_script_metadata(text)
            return {
                "kind":"directive","title":"Create Python Script","confidence":0.74,
                "steps":[
                    {"act":"focus","tool":"code editor"},
                    {"act":"new_file","name":"draft.py","dir":"workspace/scripts"},
                    {"act":"type_snippet","snippet":"scaffold_main"},
                    {"act":"type_snippet","snippet":"imports_std"},
                    {"act":"save"},
                    {"act":"ask","q":"Add argparse + logging?","key":"add_cli"}
                ],
                "policy":{"sandbox":"write","confirm_before_write":True},
                "raw":text,
                "metadata": metadata,
            }
        return {
            "kind":"directive",
            "title":text,
            "steps":[{"act":"ask","q":"What’s the first step?"}],
            "raw": text,
        }

    def _handle_magic_learn(self, payload: str = "", control: Optional[str] = None) -> None:
        payload = (payload or "").strip()
        pending = self._pending_magic_learn
        was_pending = pending is not None

        if control == "done":
            if not pending:
                self.desktop.set_bubble("No pending magic learn")
                self._narrate("There's no shortcut waiting for magic done.")
                self._log("[lexicon] Ignored magic done without pending request.")
                self._session.write({
                    "type": "lexicon",
                    "t": time.time(),
                    "status": "ignored",
                    "reason": "magic-done-no-pending",
                    "pending": False,
                })
                return

            segment_count = len(pending.segments)
            if payload:
                pending.draft = payload
            combined = pending.current_payload()
            self._log(
                f"[lexicon] Finalizing magic learn payload from {segment_count} captured segment(s)."
            )
            payload = combined
            self._set_pending_magic_learn(None)
            pending = None
            was_pending = True

            if not payload:
                msg = "I didn't hear a phrase before magic done. Say magic learn to try again."
                self.desktop.set_bubble("Need phrase => action")
                self._narrate(msg)
                self._session.write({
                    "type": "lexicon",
                    "t": time.time(),
                    "status": "empty",
                    "reason": "magic-done-empty",
                    "pending": False,
                })
                return

        if not payload:
            wait_msg = "I'm listening. Say the phrase and action, then say 'magic done'."
            now = time.time()
            self._set_pending_magic_learn(
                PendingMagicLearn(
                    requested_at=now,
                    last_heard_at=now,
                    prompt=wait_msg,
                    segments=[],
                    state="collecting",
                )
            )
            self.desktop.set_bubble("Listening for magic learn…")
            self._log("[lexicon] Awaiting magic learn payload until 'magic done'.")
            self._narrate(wait_msg)
            self._session.write({
                "type": "lexicon",
                "t": now,
                "status": "waiting-payload",
                "payload": payload,
                "pending": True,
            })
            return

        self._set_pending_magic_learn(None)
        if was_pending:
            self._log("[lexicon] Received magic learn payload.")

        phrase = action = ""
        for sep in ("=>", "="):
            if sep in payload:
                phrase, action = [part.strip() for part in payload.split(sep, 1)]
                break

        if not phrase or not action:
            msg = "Please provide both phrase and action using 'phrase => action'."
            self.desktop.set_bubble("Need phrase => action")
            self._narrate(msg)
            self._session.write({
                "type": "lexicon",
                "t": time.time(),
                "status": "invalid",
                "payload": payload,
            })
            return

        intent, params = parse_expressionary(action)
        if intent in {"none", "chat", "magic_learn"}:
            self._say_input_unrecognized(
                session_entry={
                    "type": "lexicon",
                    "status": "unrecognized-action",
                    "phrase": phrase,
                    "action": action,
                }
            )
            return

        try:
            created = self.lexicon.update(phrase, intent, params)
        except ValueError:
            msg = "That phrase can't be empty."
            self.desktop.set_bubble("Empty phrase")
            self._narrate(msg)
            self._session.write({
                "type": "lexicon",
                "t": time.time(),
                "status": "invalid-phrase",
                "phrase": phrase,
            })
            return
        except LexiconConflictError as exc:
            msg = str(exc)
            self.desktop.set_bubble("Conflict")
            self._narrate(msg)
            self._session.write({
                "type": "lexicon",
                "t": time.time(),
                "status": "conflict",
                "phrase": phrase,
                "action": action,
            })
            return

        summary = self._format_learned_summary(intent, params)
        if created:
            bubble = f"Learned '{phrase}'"
            narration = f"I'll remember that '{phrase}' means {summary}."
            status = "learned"
        else:
            bubble = f"Already knew '{phrase}'"
            narration = f"'{phrase}' already maps to {summary}."
            status = "unchanged"

        self.desktop.set_bubble(bubble[:48])
        self._narrate(narration)
        self._log(f"[lexicon] Magic learn {status}: '{phrase}' => {summary}.")
        self._session.write({
            "type": "lexicon",
            "t": time.time(),
            "status": status,
            "phrase": phrase,
            "intent": intent,
            "params": params,
            "action": action,
        })

    def _format_learned_summary(self, intent: str, params: dict) -> str:
        if intent == "move":
            units = params.get("units")
            dir_ = params.get("dir", "")
            if units == "halfway":
                return f"move {dir_} halfway"
            if isinstance(units, (int, float)):
                return f"move {dir_} {int(units)} units"
            return f"move {dir_}"
        if intent == "scroll":
            return f"scroll {params.get('dir', '')} {params.get('amount', '')}"
        if intent == "click":
            kind = params.get("kind", "")
            return f"{kind.replace('-', ' ')} click".strip()
        if intent == "goto":
            return f"go to {params.get('name', '')}"
        if intent == "type":
            txt = params.get("text", "")
            preview = (txt[:24] + "…") if len(txt) > 24 else txt
            return f"type '{preview}'"
        if intent == "shape":
            return f"draw a {params.get('shape', '')}"
        if intent == "directive":
            plan = params.get("plan") or params.get("title") or "directive"
            return plan.replace("_", " ")
        if intent == "ctrl_magic":
            return f"magic {params.get('cmd', '')}"
        return intent.replace("_", " ")

    # ----- dispatch -----
    def _dispatch(self, text: str, *, summary: Optional[str] = None):
        stripped = text.strip()
        lowered = stripped.lower()

        if lowered.startswith("magic done"):
            if self._pending_magic_learn:
                pending = self._pending_magic_learn
                pending.state = "finalizing"
                self._handle_magic_learn(control="done")
            elif getattr(self, "_speech_buffer_waiting", False):
                self._handle_buffer_confirmation()
            else:
                self._handle_magic_learn(control="done")
            return

        if self._pending_magic_learn:
            pending = self._pending_magic_learn
            now = time.time()
            last = pending.last_heard_at or pending.requested_at or now
            if pending.state == "collecting" and now - last > self.MAGIC_LEARN_TIMEOUT:
                self.desktop.set_bubble("Magic learn timed out")
                self._log("[lexicon] Magic learn request timed out.")
                self._narrate("The pending shortcut request timed out.")
                self._session.write({
                    "type": "lexicon",
                    "t": now,
                    "status": "timeout",
                    "reason": "magic-timeout",
                    "pending": False,
                })
                self._set_pending_magic_learn(None)
            elif lowered.startswith("magic "):
                if lowered.startswith("magic stop"):
                    self.desktop.set_bubble("Magic learn canceled")
                    self._log("[lexicon] Magic learn canceled.")
                    self._narrate("Canceling the pending shortcut request.")
                    self._session.write({
                        "type": "lexicon",
                        "t": time.time(),
                        "status": "canceled",
                        "reason": "magic-stop",
                        "pending": False,
                    })
                    self._set_pending_magic_learn(None)
                elif lowered.startswith("magic learn"):
                    self._log("[lexicon] Restarting magic learn request.")
                    self._set_pending_magic_learn(None)
                else:
                    self._log("[lexicon] Magic learn interrupted by other magic command.")
                    self._set_pending_magic_learn(None)
            else:
                pending.last_heard_at = now
                pending.state = "collecting"
                if stripped:
                    pending.segments.append(stripped)
                    pending.refresh_draft()
                    bubble = f"Magic segment {len(pending.segments)} captured"
                    self.desktop.set_bubble(bubble[:48])
                    self._log(
                        f"[lexicon] Captured magic learn segment #{len(pending.segments)}: '{stripped}'."
                    )
                else:
                    self._log("[lexicon] Ignored empty magic learn segment.")
                self._update_command_suggestions()
                return

        if (
            self._directive_state.get("pending_field")
            and not text.lower().startswith("magic ")
        ):
            self._handle_directive_metadata_answer(text)
            self._update_command_suggestions()
            return

        if self._paused and not text.lower().startswith("magic "):
            self.desktop.set_bubble("Paused — say 'magic start' or press F7")
            self._narrate("I’m paused. Say start to continue.")
            self._update_command_suggestions()
            return

        pending_clarification = self._get_pending_clarification()
        if pending_clarification and not text.lower().startswith("magic "):
            pending = pending_clarification
            self._set_pending_clarification(None)
            context = {
                "clarification_answer": text,
                "question": pending.get("question") if pending else None,
            }
            utterance = pending.get("utterance") if pending else text
            self._session.write({
                "type": "planner-clarification-answer",
                "t": time.time(),
                "utterance": utterance,
                "answer": text,
            })
            decision = self.planner_service.plan(utterance, context=context)
            if self._handle_planner_decision(decision, utterance, clarification_answer=text):
                return

        intent, params = parse_expressionary(text)
        self.desktop.set_bubble(text[:48])
        if intent == "none": return

        if intent == "ctrl_magic":
            self._handle_ctrl_magic(params["cmd"])
            return

        if intent == "magic_learn":
            self._handle_magic_learn(params.get("payload", ""), control=params.get("control"))
            return

        if intent == "stop_motion":
            self.desktop.stop_autopilot()
            self.desktop.set_bubble("Stopped")
            self._narrate("Motion stopped.")
            self._session.write({"type":"end","t":time.time(),"result":"stop"})
            self._update_command_suggestions()
            return

        if intent == "chat":
            plan_context = {"source": "dispatch"}
            if summary:
                plan_context["summary"] = summary
            decision = self.planner_service.plan(text, context=plan_context)
            if self._handle_planner_decision(decision, text):
                return

        self._last_nonmagic = text
        cmd_id = f"cmd_{int(time.time()*1000)}"
        self.desktop.begin_record(cmd_id)
        entry = {
            "type": "start",
            "cmd_id": cmd_id,
            "t": time.time(),
            "text": text,
            "intent": intent,
            "params": params,
        }
        if summary:
            entry["summary"] = summary
        self._session.write(entry)
        self._update_command_suggestions()

        try:
            if intent == "move":
                dir_, units = params["dir"], params["units"]
                if units == "halfway":
                    if dir_ in ("left","right"):
                        half = self.desktop.rect().width()/2
                        dx = -half if dir_=="left" else +half
                        self.desktop.nudge(dx, 0)
                    else:
                        half = self.desktop.rect().height()/2
                        dy = -half if dir_=="up" else +half
                        self.desktop.nudge(0, dy)
                    self._narrate(f"Moving {dir_} halfway.")
                elif units is None:
                    sp = 260
                    if dir_=="left":  self.desktop.start_autopilot(-sp,0)
                    if dir_=="right": self.desktop.start_autopilot(+sp,0)
                    if dir_=="up":    self.desktop.start_autopilot(0,-sp)
                    if dir_=="down":  self.desktop.start_autopilot(0,+sp)
                    self._narrate(f"Autopilot {dir_}. Say stop to halt.")
                    self._update_command_suggestions()
                else:
                    dx = dy = 0.0
                    if dir_=="left": dx = -units
                    if dir_=="right": dx = +units
                    if dir_=="up": dy = -units
                    if dir_=="down": dy = +units
                    self.desktop.nudge(dx, dy)
                    self._narrate(f"Moved {dir_} {int(units)} units.")
                self._finish_record(cmd_id, "move")
                return

            if intent == "goto":
                target_name = params.get("name", "")
                pos = self._nearest_target(target_name)
                if pos:
                    self.desktop.move_to(pos.x(), pos.y())
                    self._narrate(f"Navigating to {params['name']}.")
                    self._finish_record(cmd_id, "goto")
                else:
                    self._say_input_unrecognized(
                        session_entry={
                            "type": "dispatch",
                            "status": "unknown-target",
                            "intent": "goto",
                            "target": target_name,
                            "cmd_id": cmd_id,
                        },
                        log=f"[goto] Unknown target: {target_name}",
                    )
                    self._finish_record(cmd_id, "unknown-target")
                return

            if intent == "click":
                self.desktop.click_flash()
                self._narrate(f"{params['kind'].title().replace('-',' ')}.")
                self._finish_record(cmd_id, f"click-{params['kind']}")
                return

            if intent == "scroll":
                amt = params["amount"]; direction = params["dir"]
                dy = -amt/6 if direction=="up" else amt/6
                self.desktop.nudge(0, dy)
                self._narrate(f"Scroll {direction} {amt}.")
                self._finish_record(cmd_id, f"scroll-{direction}-{amt}")
                return

            if intent == "type":
                self._narrate(f"Typing {len(params['text'])} characters.")
                self._type_text(params["text"])
                self._finish_record(cmd_id, "typed")
                return

            if intent == "shape":
                shape = params["shape"]; laps = params.get("laps",1) or 1
                radius = params.get("radius"); speed = params.get("speed","normal")
                if shape == "circle" and radius is None:
                    self._narrate("Circle without radius—defaulting to 24 pixels at current cursor. Say another radius to change.")
                if shape == "zigzag":
                    self._narrate("Zigzag: small local oscillations. I’ll keep it short and fast unless you say otherwise.")
                center = self.desktop._cursor
                seq = self._shape_path(shape, center, speed, laps=laps, radius=radius)
                self.desktop.set_shape_path(seq)
                self._finish_record(cmd_id, f"path-{shape}")
                return

            if intent == "directive":
                plan = self._directive_plan(params.get("plan",""), params.get("text",""))
                if plan.get("metadata"):
                    self._initialize_directive_plan_state(plan, text)
                else:
                    self._reset_directive_state()
                metadata = self._directive_state.get("metadata") if plan.get("metadata") else {}
                filename = "draft.py"
                directory = "workspace/scripts"
                if isinstance(metadata, dict):
                    filename = metadata.get("filename") or filename
                    directory = metadata.get("directory") or directory
                summary = (
                    f"Planning → {plan['title']}. I will open the editor, "
                    f"create {filename} in {directory}, scaffold main, then ask about argparse."
                )
                self._narrate(summary)
                if self.cfg.security_level != "read-only":
                    bucket = self._find_bucket_for_utterance(text)
                    if bucket is None:
                        bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
                        bucket.add_utterance(text)
                        self._directive_buckets.append(bucket)
                    self._set_pending_sensitive({"echo_text": "proceed_plan", "plan": plan}, bucket=bucket)
                    self._narrate(
                        f"Security → write access to {directory} requested. Say magic confirm or magic deny."
                    )
                else:
                    self._narrate("Security is read-only; I’ll simulate without writing.")
                self._finish_record(cmd_id, "directive")
                if plan.get("metadata"):
                    missing = self._directive_missing_fields()
                    if missing and not self._directive_state.get("pending_field"):
                        self._prompt_for_directive_metadata(missing[0])
                return

            if intent == "chat":
                text = params.get("text", "")
                self._log(f"[you] {text}")
                bucket = self._find_bucket_for_utterance(text) or self._active_directive_bucket()
                metadata = self._bucket_metadata(bucket, extra_topics=[text]) if bucket else {}
                reply = self.chat_responder.reply(text, metadata=metadata)
                for diag in reply.diagnostics:
                    self._log(diag)
                if reply.used_local_model:
                    self._log(f"[ollama] response source: {CHAT_MODEL}")
                else:
                    self._log("[ollama] response source: fallback")
                if reply.text:
                    self._log(f"[zira] {reply.text}")
                    self._narrate(reply.text)
                self._finish_record(cmd_id, "chat-reply")
                return

        except Exception as e:
            self._finish_record(cmd_id, f"error:{e}")
            self._log(f"[error] {e}")

    def _handle_planner_decision(
        self,
        decision: PlannerDecision,
        utterance: str,
        *,
        clarification_answer: Optional[str] = None,
    ) -> bool:
        """Handle planner output; return True if the event is fully handled."""

        bucket = self._find_bucket_for_utterance(utterance)

        self._log(
            f"[planner] intent={decision.intent} "
            f"clarify={decision.needs_clarification} plan={bool(decision.plan)}"
        )

        if decision.error:
            self._log(f"[planner] error: {decision.error}")

        if clarification_answer is not None and bucket and bucket.clarification_attempts:
            entry = bucket.clarification_attempts[-1]
            entry["answer"] = clarification_answer
            entry["answered_at"] = time.time()

        if decision.needs_clarification:
            base_question = decision.question or "Do you want to design the idea or open the editor?"
            return self._process_clarification_request(
                utterance,
                base_question,
                bucket=bucket,
            )

        if decision.plan:
            plan_payload = decision.plan.to_payload()
            self._initialize_directive_plan_state(plan_payload, utterance)
            title = plan_payload.get("title", decision.plan.title)
            bucket = self._find_bucket_for_utterance(utterance)
            if bucket is None:
                bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
                bucket.add_utterance(utterance)
                self._directive_buckets.append(bucket)
            self.desktop.set_bubble(title[:48])
            self._narrate(
                f"Planner suggests {title}. Say magic confirm to proceed or magic deny to cancel."
            )
            self._set_pending_sensitive({
                "echo_text": "structured_plan",
                "plan": plan_payload,
                "utterance": utterance,
            }, bucket=bucket)
            self._set_pending_plan_decision(decision, bucket=bucket, utterance=utterance)
            self._session.write({
                "type": "planner-plan",
                "t": time.time(),
                "utterance": utterance,
                "plan": plan_payload,
            })
            self._last_nonmagic = utterance
            self._update_command_suggestions()
            missing = self._directive_missing_fields()
            if missing and not self._directive_state.get("pending_field"):
                self._prompt_for_directive_metadata(missing[0])
            return True

        if clarification_answer is not None and decision.intent in {"chat", "none"}:
            # Planner concluded the answer should be treated as regular chat.
            return False

        if decision.intent not in {"chat", "none"}:
            # Unknown intent but no plan: ask user for clarification again.
            fallback = decision.question or "Could you clarify what you need?"
            return self._process_clarification_request(
                utterance,
                fallback,
                bucket=bucket,
            )

        return False

    def _finish_record(self, cmd_id: str, result: str):
        path = self.desktop.end_record()
        self._session.write({"type":"end","cmd_id":cmd_id,"t":time.time(),"result":result,"path":path})

    # ----- control magic -----
    def _confirm_pending_bucket_utterance(
        self,
        bucket: Optional["MainWindow.DirectiveBucket"] = None,
    ) -> bool:
        active = bucket or self._active_directive_bucket()
        pending = (active.pending_utterance or "").strip() if active else ""
        if not active or not pending:
            return False

        summary = (active.pending_summary or "").strip() or None
        active.pending_utterance = None
        active.pending_summary = None
        active.status = "collecting"
        active.add_utterance(pending)

        self._dispatch(pending, summary=summary)
        self._resume_pending_tts_if_needed()
        self._update_command_suggestions()
        return True

    def _confirm_directives(self) -> None:
        bucket = self._active_directive_bucket()
        item = bucket.pending_sensitive if bucket else None
        if not bucket or not isinstance(item, dict):
            self._narrate("There is nothing pending confirmation.")
            return

        plan_payload = item.get("plan")
        echo = item.get("echo_text")
        if (
            echo in {"proceed_plan", "structured_plan"}
            and isinstance(plan_payload, dict)
            and not self._directive_metadata_ready()
        ):
            missing = self._directive_missing_fields()
            if missing and not self._directive_state.get("pending_field"):
                self._prompt_for_directive_metadata(missing[0])
            else:
                self._narrate("I still need those details before I can start.")
            return

        bucket.status = "executing"
        self._set_pending_sensitive(None, bucket=bucket)

        if echo == "proceed_plan":
            self._execute_plan(plan_payload or {})
        elif echo == "structured_plan":
            plan_payload = plan_payload or {}
            self._execute_structured_plan(plan_payload)
            self.planner_service.record_execution(
                plan_payload,
                stage="confirmation",
                status="confirmed",
            )
            self._set_pending_plan_decision(None, bucket=bucket)
            bucket.status = "executed"
        elif echo:
            self._narrate("Confirmed.")
            bucket.status = "collecting"
        else:
            bucket.status = "collecting"

        plan_title = ""
        if isinstance(plan_payload, dict):
            plan_title = str(plan_payload.get("title") or "")
        confirmation_message = f"Directive confirmed: {bucket.title or 'Directive'}."
        extra_topics = [plan_title] if plan_title else None
        self._record_bucket_transition(
            bucket,
            status=bucket.status,
            event="directive-confirmed",
            message=confirmation_message,
            extra_topics=extra_topics,
        )
        self._update_command_suggestions()

    def _cancel_directives(self) -> None:
        bucket = self._active_directive_bucket()
        if not bucket:
            self._narrate("There are no directives to cancel.")
            return

        if bucket.pending_utterance and not bucket.pending_sensitive and not bucket.current_decision:
            canceled_topics = [bucket.pending_summary, bucket.pending_utterance]
            bucket.pending_utterance = None
            bucket.pending_summary = None
            bucket.status = "canceled"
            self.desktop.set_bubble("Directives canceled")
            self._update_command_suggestions()
            self._narrate("Canceled. The directives are archived.")
            extra = [topic for topic in canceled_topics if topic]
            self._record_bucket_transition(
                bucket,
                status="canceled",
                event="directive-canceled",
                message=f"Directive canceled: {bucket.title or 'Directive'}.",
                extra_topics=extra or None,
            )
            return

        item = bucket.pending_sensitive
        if (
            isinstance(item, dict)
            and item.get("echo_text") == "structured_plan"
        ):
            plan_payload = item.get("plan") or bucket.plan_payload or {}
            self.planner_service.record_execution(
                plan_payload,
                stage="confirmation",
                status="denied",
            )

        bucket.pending_sensitive = None
        self._set_pending_plan_decision(None, bucket=bucket)
        bucket.status = "canceled"
        plan_title = ""
        if isinstance(plan_payload, dict):
            plan_title = str(plan_payload.get("title") or "")
        self._update_command_suggestions()
        self._narrate("Canceled. The directives are archived.")
        extra_topics = [plan_title] if plan_title else None
        self._record_bucket_transition(
            bucket,
            status="canceled",
            event="directive-canceled",
            message=f"Directive canceled: {bucket.title or 'Directive'}.",
            extra_topics=extra_topics,
        )

    def _add_directives(self) -> None:
        bucket = self._active_directive_bucket()
        if not bucket:
            self._narrate("There are no directives to extend.")
            return
        bucket.status = "collecting"
        bucket.pending_summary = None
        self.desktop.set_bubble("Add directive details")
        self._narrate("Okay, add more directives for this plan.")
        self._update_command_suggestions()

    def _correct_directive(self) -> None:
        bucket = self._active_directive_bucket()
        if not bucket or not bucket.pending_utterance:
            self._narrate("There is no directive summary to correct.")
            return
        bucket.status = "collecting"
        bucket.pending_summary = None
        self.desktop.set_bubble("Correct directive details")
        self._narrate("Okay, tell me what needs to change.")
        self._update_command_suggestions()

    def _reinstate_directive_bucket(self, bucket: "MainWindow.DirectiveBucket") -> bool:
        if bucket.status != "canceled":
            self.desktop.set_bubble("Directive already active.")
            self._narrate("Those directives are already active.")
            return False

        restore: Optional[Dict[str, Any]] = None
        if isinstance(bucket.last_sensitive, dict):
            restore = dict(bucket.last_sensitive)
        elif bucket.plan_payload:
            restore = {"echo_text": "structured_plan", "plan": bucket.plan_payload}

        if restore is None:
            self.desktop.set_bubble("No archived plan.")
            self._narrate("I couldn't find details to reinstate for that directive.")
            return False

        if "plan" not in restore and bucket.plan_payload:
            restore = dict(restore)
            restore["plan"] = bucket.plan_payload

        self._set_pending_sensitive(restore, bucket=bucket)
        if bucket.decisions:
            bucket.current_decision = bucket.decisions[-1]
        title = bucket.title or "Directive"
        message = f"Restoring directives for {title}."
        self.desktop.set_bubble(message[:48])
        self._narrate(message)
        plan_payload = restore.get("plan") if isinstance(restore, dict) else None
        plan_title = ""
        if isinstance(plan_payload, dict):
            plan_title = str(plan_payload.get("title") or "")
        extra_topics = [plan_title] if plan_title else None
        self._record_bucket_transition(
            bucket,
            status=bucket.status,
            event="directive-reinstated",
            message=message,
            extra_topics=extra_topics,
        )
        self._update_command_suggestions()
        return True

    def _review_directive_bucket(self, bucket: "MainWindow.DirectiveBucket") -> None:
        lines: List[str] = []
        summary = ""
        for candidate in (bucket.pending_summary, bucket.pending_utterance):
            if isinstance(candidate, str) and candidate.strip():
                summary = candidate.strip()
                break
        if summary:
            lines.append(summary)

        plan_payload = bucket.plan_payload if isinstance(bucket.plan_payload, dict) else {}
        steps = plan_payload.get("steps") if isinstance(plan_payload, dict) else None
        if isinstance(steps, list) and steps:
            for idx, step in enumerate(steps, start=1):
                if not isinstance(step, dict):
                    continue
                text = str(step.get("summary") or step.get("action") or "").strip()
                if text:
                    lines.append(f"{idx}. {text}")
        elif bucket.utterances:
            for idx, utterance in enumerate(bucket.utterances[-3:], start=1):
                cleaned = utterance.strip()
                if cleaned:
                    lines.append(f"{idx}. {cleaned}")

        if not lines:
            lines.append("No recorded steps yet.")

        preview = lines[0]
        self.desktop.set_bubble(preview[:48])
        title = bucket.title or "directive"
        message = f"Reviewing {title}:\n" + "\n".join(lines[:6])
        self._narrate(message)

    def _rollback_directive_bucket(self, bucket: "MainWindow.DirectiveBucket") -> None:
        if not bucket.snapshots:
            self.desktop.set_bubble("No snapshots available.")
            self._narrate("There are no snapshots saved for that directive.")
            return

        snapshot = bucket.snapshots[-1]
        cursor = snapshot.get("cursor")
        if (
            isinstance(cursor, (list, tuple))
            and len(cursor) == 2
        ):
            try:
                self.desktop.move_to(float(cursor[0]), float(cursor[1]))
            except Exception:
                pass
        focus = snapshot.get("focus")
        bubble = focus or "Snapshot restored"
        self.desktop.set_bubble(str(bubble)[:48])
        title = bucket.title or "directive"
        self._narrate(f"Rolled back to the last snapshot for {title}.")
        self._snapshot = dict(snapshot)
        self._update_command_suggestions()

    def _reinstate_directives(self) -> None:
        for bucket in reversed(self._directive_buckets):
            if self._reinstate_directive_bucket(bucket):
                return
        self._narrate("There are no canceled directives to reinstate.")

    def _handle_ctrl_magic(self, cmd: str, *, metadata: Optional[Dict[str, Any]] = None):
        metadata = metadata or {}
        bucket_token = metadata.get("bucket_id") or metadata.get("bucket_token")
        if ":" in cmd and not bucket_token:
            base, _, extra = cmd.partition(":")
            if base in {"reinstate_bucket", "review_bucket", "rollback_bucket"}:
                cmd = base
                bucket_token = extra

        if cmd in {"reinstate_bucket", "review_bucket", "rollback_bucket"}:
            bucket: Optional[MainWindow.DirectiveBucket]
            bucket = None
            explicit_id = metadata.get("bucket_id")
            if explicit_id:
                bucket = self._find_bucket_by_id(str(explicit_id))
            if bucket is None and bucket_token:
                bucket = self._resolve_bucket_token(str(bucket_token))
            if bucket is None:
                self.desktop.set_bubble("Unknown directive bucket.")
                self._narrate("I couldn't find that directive bucket.")
                return
            if cmd == "reinstate_bucket":
                self._reinstate_directive_bucket(bucket)
            elif cmd == "review_bucket":
                self._review_directive_bucket(bucket)
            else:
                self._rollback_directive_bucket(bucket)
            return

        if cmd == "flush_buffer":
            delivered = self._flush_speech_buffer(reason="ctrl-flush")
            if delivered is None:
                self.desktop.set_bubble("No buffered speech.")
            return
        if cmd == "cancel_buffer":
            had_segments = bool(getattr(self, "_speech_buffer", []))
            self._cancel_speech_buffer(reason="ctrl-cancel")
            if had_segments:
                self.desktop.set_bubble("Speech buffer canceled.")
            else:
                self.desktop.set_bubble("No buffered speech to cancel.")
            return
        if cmd == "need_more_time":
            if getattr(self, "_speech_buffer", []):
                self._speech_buffer_waiting = False
                timer = getattr(self, "_speech_buffer_timer", None)
                if timer is not None:
                    timer.start(int(self._speech_buffer_gap() * 1000))
                if self._mic_running:
                    self.desktop.set_listening_indicator(True, message="Listening… (collecting)")
                self.desktop.set_bubble("Okay, take your time.")
                self._narrate("Okay, I'll keep listening.")
            else:
                self._speech_buffer_waiting = False
                self.desktop.set_bubble("No buffered speech.")
            self._update_command_suggestions()
            return
        if cmd == "summarize_now":
            delivered = self._flush_speech_buffer(reason="user-confirmed")
            if delivered is None:
                self.desktop.set_bubble("No buffered speech.")
            return
        if cmd == "start":
            self._set_paused(False)
            self.desktop.set_bubble("Started")
            self._narrate("Started.")
            return
        if cmd == "pause":
            self.desktop.stop_autopilot()
            self._set_paused(True)
            self.desktop.set_bubble("Paused")
            self._narrate("Paused. You can edit or speak to change course.")
            return
        if cmd == "stop":
            if self._pending_magic_learn:
                self._set_pending_magic_learn(None)
                self._log("[lexicon] Magic learn canceled.")
                self._session.write({
                    "type": "lexicon",
                    "t": time.time(),
                    "status": "canceled",
                    "reason": "ctrl-magic-stop",
                    "pending": False,
                })
            self.desktop.stop_autopilot()
            self.desktop.set_bubble("Stopped")
            self._narrate("Stopped. Session snapshot saved.")
            self._snapshot_state("stop")
            return
        if cmd in {"confirm", "confirm_directives"}:
            self._flush_speech_buffer(reason="ctrl-confirm")
            if not self._confirm_pending_bucket_utterance():
                self._confirm_directives()
            return
        if cmd in {"deny", "cancel_directives"}:
            self._cancel_speech_buffer(reason="ctrl-cancel")
            self._cancel_directives()
            return
        if cmd == "add_directives":
            self._add_directives()
            return
        if cmd == "correct_directive":
            self._correct_directive()
            return
        if cmd == "reinstate_directives":
            self._reinstate_directives()
            return
        if cmd == "idea":
            self.desktop.txt_input.setFocus()
            self._narrate("Idea mode. I’m focused on the chat. Describe the idea and I will plan steps.")
            return
        if cmd == "deploy":
            self._set_pending_sensitive({"echo_text": "deploy_stub"})
            self._narrate("Deploy requested. Say magic confirm or deny.")
            return
        if cmd == "revert":
            if self._snapshot:
                cur = self._snapshot.get("cursor",[self.desktop.width()/2,self.desktop.height()/2])
                self.desktop.move_to(cur[0], cur[1])
                self._narrate("Reverted to snapshot position.")
            else:
                self._narrate("No snapshot available to revert.")
            return
        if cmd == "retry":
            if self._last_nonmagic:
                self._narrate("Retrying last directive.")
                self._dispatch(self._last_nonmagic)
            else:
                self._narrate("There is nothing to retry.")
            return
        if cmd == "listen":
            self._toggle_mic(); return
        if cmd == "up":
            self._session.write({"type":"feedback","t":time.time(),"val":1})
            self._narrate("Thumbs up registered."); return
        if cmd == "down":
            self._session.write({"type":"feedback","t":time.time(),"val":-1})
            self._narrate("Thumbs down registered; I’ll adjust."); return

    # ----- plan execution -----
    def _execute_plan(self, plan: dict | PlannerPlan):
        payload = plan.to_payload() if isinstance(plan, PlannerPlan) else plan
        title = payload.get("title", "Plan") if isinstance(payload, dict) else "Plan"
        before_ctx = self._capture_plan_context("plan-before", title)
        if before_ctx:
            self.planner_service.record_execution(
                payload,
                stage="before",
                status="snapshot",
                context={"before": before_ctx},
            )

        self._snapshot_state("pre-plan")
        pos = self._nearest_target("code editor")
        if pos: self.desktop.move_to(pos.x(), pos.y())
        self._narrate("Navigating to Code Editor.")

        payload_metadata = payload.get("metadata") if isinstance(payload, dict) else {}
        state_metadata = self._directive_state.get("metadata") if self._directive_state else {}
        if not isinstance(payload_metadata, dict):
            payload_metadata = {}
        if not isinstance(state_metadata, dict):
            state_metadata = {}
        metadata = self._merge_metadata(payload_metadata, state_metadata)
        if isinstance(payload, dict):
            payload["metadata"] = metadata
        if self._directive_state:
            self._directive_state["metadata"] = metadata

        metadata_filename = metadata.get("filename") if isinstance(metadata, dict) else None
        metadata_directory = metadata.get("directory") if isinstance(metadata, dict) else None
        metadata_themes = metadata.get("themes") if isinstance(metadata, dict) else []
        if not isinstance(metadata_themes, list):
            metadata_themes = [str(metadata_themes)]

        filename = metadata_filename or "draft.py"
        directory = metadata_directory or "workspace/scripts"
        display_directory = (metadata_directory or directory).rstrip("/") or directory

        self.desktop.code_edit.clear()
        cursor = self.desktop.code_edit.textCursor()
        cursor.movePosition(QTextCursor.Start)
        self.desktop.code_edit.setTextCursor(cursor)
        self._narrate(f"Creating {filename} in {display_directory}.")
        panel_editor = getattr(self.desktop, "panel_editor", None)
        if panel_editor is not None:
            tabs = getattr(panel_editor, "tabs", None)
            if tabs is not None:
                try:
                    idx = tabs.currentIndex()
                    if idx >= 0:
                        tabs.setTabText(idx, filename)
                except Exception:
                    pass
        scaffold = (
            "def main():\n"
            "    print('hello')\n\n"
            "if __name__ == '__main__':\n"
            "    main()\n"
        )
        imports = "import argparse\nimport logging\nfrom pathlib import Path\n\n"
        header_lines: List[str] = []
        if metadata_filename or metadata_directory:
            path_target = metadata_filename or "draft.py"
            directory_header = (metadata_directory or "").rstrip("/")
            if directory_header:
                path_target = f"{directory_header}/{path_target}"
            header_lines.append(f"# File: {path_target}")
        cleaned_themes = [str(theme).strip() for theme in metadata_themes if str(theme).strip()]
        if cleaned_themes:
            header_lines.append("# Themes:")
            header_lines.extend([f"# - {theme}" for theme in cleaned_themes])
        header_block = "\n".join(header_lines)
        if header_block:
            header_block = f"{header_block}\n\n"
        final_script = f"{header_block}{imports}{scaffold}"
        if cleaned_themes:
            self._narrate(f"Capturing themes: {', '.join(cleaned_themes)}.")
        self._narrate("Typing scaffold.")
        self._narrate("Adding imports.")
        self._type_text(final_script)
        self._narrate("Saved. Do you want argparse CLI wiring?")
        self._set_pending_sensitive({"echo_text":"post_plan_question"})
        self._log("[plan] executed basic scaffold; awaiting user decision.")

        after_ctx = self._capture_plan_context("plan-after", title)
        context_payload: Dict[str, Any] = {}
        if before_ctx:
            context_payload["before"] = before_ctx
        if after_ctx:
            context_payload["after"] = after_ctx
        self.planner_service.record_execution(
            payload,
            stage="complete",
            status="executed",
            context=context_payload,
        )
        self._reset_directive_state()

    def _execute_structured_plan(self, plan: Dict[str, Any]) -> None:
        title = plan.get("title", "Plan")
        steps = plan.get("steps") or []
        before_ctx = self._capture_plan_context("structured-before", title)
        if before_ctx:
            self.planner_service.record_execution(
                plan,
                stage="before",
                status="snapshot",
                context={"before": before_ctx},
            )
        self._snapshot_state("pre-plan")
        self._narrate(f"Executing plan: {title}.")
        self._session.write({
            "type": "planner-execute",
            "t": time.time(),
            "plan": plan,
        })
        for idx, step in enumerate(steps, 1):
            if not isinstance(step, dict):
                continue
            summary = step.get("summary") or step.get("action") or f"Step {idx}"
            self.desktop.set_bubble(summary[:48])
            self._narrate(summary)
        after_ctx = self._capture_plan_context("structured-after", title)
        ctx: Dict[str, Any] = {}
        if before_ctx:
            ctx["before"] = before_ctx
        if after_ctx:
            ctx["after"] = after_ctx
        self.planner_service.record_execution(
            plan,
            stage="complete",
            status="simulated",
            context=ctx,
        )

# ---------- entry ----------
def main():
    app = QApplication(sys.argv)
    apply_palette(app)
    cfg = AppConfig.load()
    win = MainWindow(cfg)
    win.show()
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
```

Voice-Guided Tools — Trainer (Full-Duplex, Everything Concurrent)
=================================================================

This single file implements a *terminal-in-desktop* trainer with:
- Full-duplex audio: Zira speaks while the mic listens (no barge-in cancel).
- Dedicated threads for **everything**: ASR, TTS, Planner, Executor/Motion,
  Logger, and UI timers — all non-blocking.
- Device selection (microphone) + deep audio/ASR/TTS settings.
- Control-Magic only (global control); expressionary Language→Plan parsing
  (shapes, navigation, directives) with clarifying questions.
- Dual chat lanes (User ↑ / Zira ↓) with a lime-green read cursor sweep.
- Virtual Desktop: cursor animation, ghost “ten fingers” on keyboard,
  vertical bubble tooltip, code editor, security panel, agent controls.
- Session logging (JSONL), snapshots, retry/revert, hotkeys.

Optional deps:
    pip install PySide6 speechrecognition sounddevice pywin32 pyttsx3
Vosk (offline ASR) optional:
    pip install vosk
and download a model, then point Settings→ASR→Vosk Model Path.
**Classes:** CommandSuggestion, DirectiveHistoryAction, DirectiveHistoryCard, PendingMagicLearn, Theme, AppConfig, SessionLogger, ChatReply, ChatResponder, TTSEngine, SapiTTS, Pyttsx3TTS, SpeechThread, Panel, LineNumberArea, CodeEditor, CodeEditorPanel, KeyStroke, OnScreenKeyboard, DesktopCanvas, CursorOverlay, VirtualDesktop, MainWindow
**Functions:** apply_palette(app), _keyword_in_text(text, keyword), _is_script_creation_request(normalized), _strip_polite_prefixes(utterance), set_lexicon_manager(manager), normalize(s), parse_expressionary(text), _parse_builtin_expressionary(normalized, original), main()


## Module `ant_api\mesh.py`

```python
"""Simple in-memory implementation of the ANT mesh."""
from __future__ import annotations

from typing import Callable, Dict, List, Tuple


class ANTMesh:
    """Event bus that allows cells to broadcast state changes."""

    def __init__(self) -> None:
        self._cells: Dict[str, object] = {}
        self._subscribers: List[Callable[[str, Dict[str, object]], None]] = []
        self._history: List[Tuple[str, Dict[str, object]]] = []

    def register(self, cell: object) -> None:
        identifier = getattr(cell, "identifier")
        metadata = getattr(cell, "metadata", {})
        self._cells[identifier] = cell
        self.broadcast_update(identifier, {"type": "register", "metadata": metadata})

    def unregister(self, identifier: str) -> None:
        if self._cells.pop(identifier, None) is not None:
            self.broadcast_update(identifier, {"type": "unregister"})

    def subscribe(self, callback: Callable[[str, Dict[str, object]], None]) -> Callable[[], None]:
        self._subscribers.append(callback)

        def unsubscribe() -> None:
            self._subscribers.remove(callback)

        return unsubscribe

    def broadcast_update(self, source: str, payload: Dict[str, object]) -> None:
        record = (source, payload)
        self._history.append(record)
        for callback in list(self._subscribers):
            callback(source, payload)

    def get_history(self) -> List[Tuple[str, Dict[str, object]]]:
        return list(self._history)

    def get_cell_metadata(self, identifier: str) -> Dict[str, object]:
        cell = self._cells.get(identifier)
        if cell is None:
            raise KeyError(identifier)
        return dict(getattr(cell, "metadata", {}))


__all__ = ["ANTMesh"]
```

Simple in-memory implementation of the ANT mesh.
**Classes:** ANTMesh


## Module `ant_api\schema.py`

```python
"""Schema registry shared by ANT cells."""
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional


@dataclass(frozen=True)
class GUISchema:
    """Simple payload describing a UI layout shared between cells."""

    name: str
    fields: Dict[str, str]


class SchemaRegistry:
    """Store schemas published by cells and make them discoverable."""

    def __init__(self) -> None:
        self._schemas: Dict[str, GUISchema] = {}

    def publish(self, cell_id: str, schema: Dict[str, object]) -> None:
        name = schema.get("name", cell_id)
        fields = {key: str(value) for key, value in schema.get("fields", {}).items()}
        self._schemas[cell_id] = GUISchema(name=name, fields=fields)

    def get(self, cell_id: str) -> Optional[GUISchema]:
        return self._schemas.get(cell_id)

    def all(self) -> Dict[str, GUISchema]:
        return dict(self._schemas)


__all__ = ["GUISchema", "SchemaRegistry"]
```

Schema registry shared by ANT cells.
**Classes:** GUISchema, SchemaRegistry


## Module `ant_api\__init__.py`

```python
"""ANT mesh API exposed to self-modifying cells."""

from .mesh import ANTMesh
from .schema import SchemaRegistry

__all__ = ["ANTMesh", "SchemaRegistry"]
```

ANT mesh API exposed to self-modifying cells.


## Module `cells\lineage.py`

```python
"""Implementation of the self-modifying ANT cell lineage."""
from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import Callable, Dict, Iterable, Optional

from ant_api.mesh import ANTMesh
from ant_api.schema import SchemaRegistry
from Loader.immune_system import ImmuneSystem


@dataclass
class Cell:
    """A self-modifying script participating in the ANT mesh."""

    identifier: str
    script_path: Path
    mesh: ANTMesh
    immune_system: ImmuneSystem
    schema_registry: SchemaRegistry
    metadata: Dict[str, object] = field(default_factory=dict)
    version: int = 0

    def introspect(self) -> str:
        """Return the current script source for this cell."""

        return self.script_path.read_text(encoding="utf-8")

    def publish_schema(self, schema: Dict[str, object]) -> None:
        """Share a GUI schema over the ANT mesh."""

        self.schema_registry.publish(self.identifier, schema)
        self.mesh.broadcast_update(
            self.identifier,
            {
                "type": "schema",
                "schema": schema,
                "version": self.version,
            },
        )

    def self_edit(self, transform: Callable[[str], str], *, message: Optional[str] = None) -> None:
        """Rewrite the cell's script using ``transform`` and broadcast the change."""

        current = self.introspect()
        new_source = transform(current)
        report = self.immune_system.rewrite_cell(self.script_path, new_source, self.version + 1)
        self.version = report.version
        self.metadata["last_backup"] = str(report.backup) if report.backup else None
        self.mesh.broadcast_update(
            self.identifier,
            {
                "type": "self_edit",
                "message": message or "self-edit",
                "version": self.version,
            },
        )

    def reload(self) -> None:
        """Simulate a relaunch by pinging the mesh."""

        self.mesh.broadcast_update(
            self.identifier,
            {
                "type": "reload",
                "version": self.version,
            },
        )


class CellLineage:
    """Manage the chain of cells produced by the loader."""

    def __init__(self, storage_root: Path, mesh: ANTMesh, immune_system: ImmuneSystem) -> None:
        self.storage_root = storage_root
        self.mesh = mesh
        self.immune_system = immune_system
        self.schema_registry = SchemaRegistry()
        self._cells: Dict[str, Cell] = {}

    def create_initial_cell(self, source: str, metadata: Optional[Dict[str, object]] = None) -> Cell:
        identifier = "cell_0"
        path = self._script_path(identifier)
        report = self.immune_system.bootstrap_cell(path, source)
        cell = Cell(
            identifier=identifier,
            script_path=path,
            mesh=self.mesh,
            immune_system=self.immune_system,
            schema_registry=self.schema_registry,
            metadata=metadata or {},
            version=report.version,
        )
        self._register(cell)
        return cell

    def spawn_successor(
        self,
        parent: Cell,
        template: Callable[[Cell], str],
        *,
        metadata: Optional[Dict[str, object]] = None,
    ) -> Cell:
        identifier = self._next_identifier()
        path = self._script_path(identifier)
        source = template(parent)
        report = self.immune_system.bootstrap_cell(path, source)
        cell = Cell(
            identifier=identifier,
            script_path=path,
            mesh=self.mesh,
            immune_system=self.immune_system,
            schema_registry=self.schema_registry,
            metadata=metadata or {"parent": parent.identifier},
            version=report.version,
        )
        parent.metadata.setdefault("children", []).append(identifier)
        self.mesh.broadcast_update(
            parent.identifier,
            {
                "type": "spawn",
                "child": identifier,
                "version": parent.version,
            },
        )
        self._register(cell)
        return cell

    def _script_path(self, identifier: str) -> Path:
        return self.storage_root / f"{identifier}.py"

    def _next_identifier(self) -> str:
        return f"cell_{len(self._cells)}"

    def _register(self, cell: Cell) -> None:
        self._cells[cell.identifier] = cell
        self.mesh.register(cell)

    def get_cell(self, identifier: str) -> Cell:
        return self._cells[identifier]

    def has_cell(self, identifier: str) -> bool:
        return identifier in self._cells

    def cells(self) -> Iterable[Cell]:
        return self._cells.values()


__all__ = ["Cell", "CellLineage"]
```

Implementation of the self-modifying ANT cell lineage.
**Classes:** Cell, CellLineage


## Module `cells\__init__.py`

```python
"""Cell lineage utilities for the ANT runtime."""

from .lineage import Cell, CellLineage

__all__ = ["Cell", "CellLineage"]
```

Cell lineage utilities for the ANT runtime.


## Module `Dev_Logic\Implemented_logic\agent_terminal.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agent Terminal — Camera + Language→Commands + RAG + Context History + Vision/OCR + Cursor/Keyboard (v6)

What’s in v6 (everything wired up):
- Data lives in script root: ./datasets (JSONL vector stores) + ./config.json + ./vision_cache.
- Word wrap ON by default (View ▸ Toggle Word Wrap).
- Buttons, checkboxes, toolbuttons, and combos have bright text on dark UI.
- Identity: System prompt says you are Agent Terminal (not ChatGPT) + runtime identity guard.
- Chat / Shell / Chat+Shell lifecycle exactly as specified; L→C is a checkbox.
- Right-click “Run Suggestion” runs the last fenced block.
- Conversation Context dataset with adjustable depth (None / Fixed / All) used to build chat messages.
- Dual storage each turn: (1) raw context history pairs; (2) semantic vectors (user, ai, etc.) for RAG.
- VectorStore pruning/rotation (size/records with “keep tail”); Tools ▸ Prune Datasets Now.
- Index rebuild hint tool and Schema Index Template in Settings.
- Resizable terminal card from all four corners (QSizeGrips).
- Camera desktop with Ctrl+Arrow pan, F/Ctrl+Home focus, and “Track” pin.
- Vision/OCR service via local Ollama (llava/nanonets/gemma3 vision), ephemeral cache + TTL pruning.
- Cursor overlay the agent can move/click; On-screen keyboard card (focus-target typing).
- Prompt Manager dialog: edit prompts, list ALL AI intersection points, choose per-point models (vision+text).
- Tools ▸ Vision Demo: OCR locate “Start” in Terminal header and click it via overlay cursor.
- Tools ▸ Open Code Editor… (bootstraps a working editor file if missing, then launches it).

Keybindings
  Alt+Enter     : toggle fullscreen
  F, Ctrl+Home  : focus camera on terminal
  Ctrl+Arrows   : pan the camera
  Enter         : send; Ctrl+L clear console; Up/Down recall history
"""

from __future__ import annotations

import os, sys, re, json, uuid, math, queue, threading, subprocess, time, datetime, base64, io
from dataclasses import dataclass
from typing import Optional, List, Dict, Tuple

from PySide6.QtCore import (
    Qt, QRect, QRectF, QPoint, QSize, QTimer, Signal, Slot, QEvent, QByteArray, QBuffer
)
from PySide6.QtGui import (
    QAction, QColor, QGuiApplication, QKeySequence, QLinearGradient, QPainter,
    QPainterPath, QPalette, QSyntaxHighlighter, QTextCharFormat, QTextCursor, QFont,
    QTextOption, QMouseEvent, QKeyEvent
)
from PySide6.QtWidgets import (
    QApplication, QComboBox, QDialog, QDialogButtonBox, QFormLayout, QFrame,
    QGraphicsDropShadowEffect, QGridLayout, QGroupBox, QHBoxLayout, QLabel,
    QLineEdit, QMainWindow, QMenu, QPushButton, QSizeGrip, QPlainTextEdit,
    QToolButton, QVBoxLayout, QWidget, QScrollArea, QMessageBox, QCheckBox,
    QTextEdit, QSpinBox, QLineEdit as QLE, QFileDialog
)

# --------------------------------------------------------------------------------------
# Paths & utils (script root)
# --------------------------------------------------------------------------------------

SCRIPT_ROOT = os.path.abspath(os.path.dirname(__file__))
DATASETS_DIR = os.path.join(SCRIPT_ROOT, "datasets")
VISION_CACHE_DIR = os.path.join(SCRIPT_ROOT, "vision_cache")
CONFIG_PATH  = os.path.join(SCRIPT_ROOT, "config.json")
os.makedirs(DATASETS_DIR, exist_ok=True)
os.makedirs(VISION_CACHE_DIR, exist_ok=True)

APP_NAME = "Agent Terminal"

def open_in_os(path: str):
    if not path: return
    if sys.platform.startswith("win"): os.startfile(path)
    elif sys.platform == "darwin": subprocess.Popen(["open", path])
    else: subprocess.Popen(["xdg-open", path])

def _requests():
    try:
        import requests
        return requests
    except Exception:
        return None

def find_git_bash() -> Optional[str]:
    if not sys.platform.startswith("win"): return None
    for c in [r"C:\Program Files\Git\bin\bash.exe", r"C:\Program Files (x86)\Git\bin\bash.exe"]:
        if os.path.isfile(c): return c
    return None

def nl_for_env(env: str) -> str:
    return "\n"

def human_size(num_bytes: int) -> str:
    units=["B","KB","MB","GB","TB","PB"]
    s=float(num_bytes); i=0
    while s>=1024 and i<len(units)-1:
        s/=1024.0; i+=1
    if i==0: return f"{int(s)}{units[i]}"
    return f"{s:.1f}{units[i]}"

def timestamp() -> str:
    return datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

# --------------------------------------------------------------------------------------
# Theme
# --------------------------------------------------------------------------------------

@dataclass
class Theme:
    desktop_top: str = "#0f3b8e"
    desktop_mid: str = "#1c54cc"
    edge_glow:   str = "#4aa8ff"

    card_bg:     str = "#0c1320"
    card_border: str = "#213040"
    card_radius: int = 12
    header_bg:   str = "#0a111e"
    header_fg:   str = "#ffffff"
    term_bg:     str = "#0b1828"
    term_fg:     str = "#e9f3ff"
    accent:      str = "#1E5AFF"
    accent_hover:str = "#2f72ff"
    ok:          str = "#00d17a"
    warn:        str = "#ffd76b"
    err:         str = "#ff6b6b"
    info:        str = "#9bb7ff"
    strip_bg:    str = "#000000"   # memory strip

# --------------------------------------------------------------------------------------
# Config & prompts
# --------------------------------------------------------------------------------------

DEFAULT_SYSTEM_PROMPT = """You are Agent Terminal — a local, on-device assistant for translating natural language into correct, safe commands and high-quality code for the selected environment.
Supported envs: CMD, PowerShell, Bash, WSL/Ubuntu, Python REPL, Git, Node, common CLIs.
Prefer concise command sequences and fenced blocks. Ask exactly one clarifying question if needed.
You can design helper modules/tools for yourself (self-bootstrapping) when useful.
Identity: You are NOT ChatGPT. You must identify only as Agent Terminal."""

DEFAULT_L2C_PROMPT = """Language→Commands directive:
- Convert user intent to proper syntax for the *selected* shell (Env).
  * CMD: Windows quoting, backslashes, && for sequences.
  * PowerShell: cmdlet syntax, pipes, backtick escaping; full cmdlet names when clarity helps.
  * Bash/WSL: POSIX quoting, semicolons/&&, sudo when necessary (explain).
  * Python-REPL: emit Python statements.
- Always return runnable commands in a **single fenced code block** tagged for the env:
  ```cmd```  ```powershell```  ```bash```  ```python```
- Briefly state what will happen, then the block.
- If dangerous/destructive, ask for confirmation first and *do not* emit the command."""

SCHEMA_INDEX_TEMPLATE = """# Schema Index Template
# Copy this into the indexing dataset (Tools ▸ Write Index Rebuild Hint creates guidance).
version: 1
envs:
  CMD:
    - name: list_dir
      pattern: 'dir {path}'
      examples: ['dir', 'dir "C:\\Projects"']
  PowerShell:
    - name: list_dir
      pattern: 'Get-ChildItem {path}'
      examples: ['gci', 'Get-ChildItem -Force']
  Bash:
    - name: list_dir
      pattern: 'ls -la {path}'
      examples: ['ls', 'ls -la ~/code']
  WSL:
    - name: apt_install
      pattern: 'sudo apt-get install -y {package}'
      examples: ['sudo apt install curl -y']
  Python-REPL:
    - name: version
      pattern: 'import sys; print(sys.version)'
      examples: ['import platform; print(platform.python_version())']
"""

DEFAULT_CONFIG = {
    "system_prompt": DEFAULT_SYSTEM_PROMPT,
    "l2c_prompt": DEFAULT_L2C_PROMPT,
    "embedding_model": "snowflake-arctic-embed2:latest",
    "autorun_suggestions": False,
    "self_prompting": False,
    # Conversation context
    "context_depth_mode": "fixed",   # "none" | "fixed" | "all"
    "context_depth_value": 15,       # used when mode == fixed
    # Pruning / rotation
    "prune_max_bytes": 64 * 1024 * 1024,  # 64 MB
    "prune_max_records": 25000,
    "prune_keep_tail": 5000,
    # Vision
    "vision": {
        "model_default": "llava:7b",
        "ttl_seconds": 120,
        "sampling": "on_demand",     # off | on_demand | frequent
        "persist_policy": "retain_on_fix"  # never | retain_on_fix | always
    },
    # AI intersection points (per-point model/enable)
    "ai_points": {
        "chat.to.commands": {"enabled": True, "model": "gpt-oss:20b", "timeout_ms": 300000},
        "chat.plain":       {"enabled": True, "model": "gpt-oss:20b", "timeout_ms": 240000},
        "rag.augment":      {"enabled": True, "model": "gpt-oss:20b", "timeout_ms": 10000},
        "runner.analyze":   {"enabled": True, "model": "gpt-oss:20b", "timeout_ms": 10000},
        "vision.locate.ui": {"enabled": True, "model": "llava:7b", "timeout_ms": 1200},
        "vision.observe.editor": {"enabled": True, "model": "yasserrmd/Nanonets-OCR-s:latest", "timeout_ms": 1200},
        "vision.observe.tabs": {"enabled": True, "model": "llava:7b", "timeout_ms": 1200},
        "snippets.suggest": {"enabled": True, "model": "gpt-oss:20b", "timeout_ms": 6000},
        "index.grow":       {"enabled": True, "model": "gpt-oss:20b", "timeout_ms": 6000}
    }
}

def load_config() -> Dict:
    if os.path.isfile(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f: 
                cfg = json.load(f)
        except Exception:
            cfg = {}
    else:
        cfg = {}
    # merge defaults
    def deep_merge(dst, src):
        for k,v in src.items():
            if isinstance(v, dict):
                dst[k] = deep_merge(dst.get(k, {}), v)
            else:
                dst.setdefault(k, v)
        return dst
    cfg = deep_merge(cfg, DEFAULT_CONFIG)
    with open(CONFIG_PATH, "w", encoding="utf-8") as f: json.dump(cfg, f, indent=2)
    return cfg

def save_config(cfg: Dict):
    with open(CONFIG_PATH, "w", encoding="utf-8") as f: json.dump(cfg, f, indent=2)

# --------------------------------------------------------------------------------------
# Vector store via Ollama embeddings (JSONL) + pruning/rotation
# --------------------------------------------------------------------------------------

class VectorStore:
    def __init__(self, dataset_name: str, embed_model: str, cfg: Dict):
        self.name = dataset_name
        self.path = os.path.join(DATASETS_DIR, f"{dataset_name}.jsonl")
        self.embed_model = embed_model
        self.cfg = cfg
        if not os.path.isfile(self.path): open(self.path, "a", encoding="utf-8").close()

    def count(self) -> int:
        try:
            with open(self.path, "r", encoding="utf-8") as f:
                return sum(1 for _ in f)
        except Exception:
            return 0

    def bytes(self) -> int:
        try: return os.path.getsize(self.path)
        except Exception: return 0

    def add_text(self, text: str, meta: Dict):
        vec = self._embed(text)
        if vec is None: return
        rec = {"id": str(uuid.uuid4()), "text": text, "embedding": vec, "meta": meta}
        with open(self.path, "a", encoding="utf-8") as f:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")
        self._maybe_prune()

    def search(self, query: str, top_k=6) -> List[Dict]:
        qv = self._embed(query)
        if qv is None: return []
        items = []
        try:
            with open(self.path, "r", encoding="utf-8") as f:
                for line in f:
                    if not line.strip(): continue
                    rec=json.loads(line)
                    vec=rec.get("embedding")
                    if not vec: continue
                    sim=cosine_sim(qv, vec)
                    items.append((sim, rec))
        except Exception:
            return []
        items.sort(key=lambda x: x[0], reverse=True)
        return [r for _,r in items[:top_k]]

    def _embed(self, text: str) -> Optional[List[float]]:
        req=_requests()
        if not req: return None
        try:
            r=req.post("http://127.0.0.1:11434/api/embeddings",
                       json={"model": self.embed_model, "prompt": text},
                       timeout=30)
            if not r.ok: return None
            data=r.json()
            return data.get("embedding")
        except Exception:
            return None

    def _maybe_prune(self):
        max_bytes=int(self.cfg.get("prune_max_bytes", DEFAULT_CONFIG["prune_max_bytes"]))
        max_records=int(self.cfg.get("prune_max_records", DEFAULT_CONFIG["prune_max_records"]))
        if self.bytes() <= max_bytes and self.count() <= max_records:
            return
        self._rotate_keep_tail()

    def _rotate_keep_tail(self):
        keep_tail=int(self.cfg.get("prune_keep_tail", DEFAULT_CONFIG["prune_keep_tail"]))
        tmp_path=self.path + ".tmp"
        tail=[]
        try:
            with open(self.path, "r", encoding="utf-8") as f:
                tail=f.readlines()[-keep_tail:]
        except Exception:
            pass
        try:
            with open(tmp_path, "w", encoding="utf-8") as f:
                for ln in tail: f.write(ln)
            snap=os.path.join(DATASETS_DIR, f"{self.name}.{timestamp()}.rotated.jsonl")
            if os.path.exists(self.path):
                os.replace(self.path, snap)
            os.replace(tmp_path, self.path)
        except Exception:
            try: os.remove(tmp_path)
            except Exception: pass

def cosine_sim(a: List[float], b: List[float]) -> float:
    if not a or not b or len(a)!=len(b): return 0.0
    num=sum(x*y for x,y in zip(a,b)); da=math.sqrt(sum(x*x for x in a)); db=math.sqrt(sum(y*y for y in b))
    if da==0 or db==0: return 0.0
    return num/(da*db)

# --------------------------------------------------------------------------------------
# Conversation Context dataset (pairs)
# --------------------------------------------------------------------------------------

class ContextHistory:
    def __init__(self):
        self.path=os.path.join(DATASETS_DIR, "context_history.jsonl")
        if not os.path.isfile(self.path): open(self.path, "a", encoding="utf-8").close()

    def bytes(self)->int:
        try: return os.path.getsize(self.path)
        except Exception: return 0

    def add_pair(self, u: str, a: str):
        rec={"u": u, "a": a, "ts": timestamp()}
        with open(self.path, "a", encoding="utf-8") as f:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")

    def last_pairs(self, limit: Optional[int]) -> List[Dict]:
        if limit == 0: return []
        lines=[]
        try:
            with open(self.path,"r",encoding="utf-8") as f:
                if limit is None: lines=f.readlines()
                else: lines=f.readlines()[-limit:]
        except Exception:
            return []
        out=[]
        for ln in lines:
            try: out.append(json.loads(ln))
            except Exception: pass
        return out

# --------------------------------------------------------------------------------------
# Vision / OCR service (Ollama vision)
# --------------------------------------------------------------------------------------

class VisionService:
    def __init__(self, cfg: Dict):
        self.cfg = cfg
        self._ttl = int(cfg.get("vision", {}).get("ttl_seconds", 120))
        self._persist_policy = cfg.get("vision", {}).get("persist_policy", "retain_on_fix")
        self._model_default = cfg.get("vision", {}).get("model_default", "llava:7b")
        self._timer = QTimer()
        self._timer.timeout.connect(self._prune_cache)
        self._timer.start(5000)  # sweep every 5s

    def set_model(self, name: str):
        self._model_default = name
        self.cfg["vision"]["model_default"] = name
        save_config(self.cfg)

    def available_vision_models(self) -> List[str]:
        req=_requests()
        if not req: return []
        try:
            r=req.get("http://127.0.0.1:11434/api/tags", timeout=5)
            if not r.ok: return []
            names=[]
            for m in r.json().get("models", []):
                n=m.get("name") or m.get("model") or ""
                if not n: continue
                # heuristic: popular vision/ocr model names
                if any(s in n.lower() for s in ["llava", "ocr", "vision", "gemma3", "nanonets"]):
                    names.append(n)
            return sorted(set(names))
        except Exception:
            return []

    # --- capture helpers ---
    def capture_widget(self, w: QWidget) -> Optional[QByteArray]:
        if w is None: return None
        pm = w.grab()
        return self._pixmap_to_png_data(pm)

    def capture_rect(self, w: QWidget, rect: QRect) -> Optional[QByteArray]:
        if w is None: return None
        pm = w.grab(rect)
        return self._pixmap_to_png_data(pm)

    def _pixmap_to_png_data(self, pm) -> Optional[QByteArray]:
        ba = QByteArray()
        buf = QBuffer(ba)
        buf.open(QBuffer.WriteOnly)
        ok = pm.save(buf, "PNG")
        buf.close()
        if not ok: return None
        return ba

    def _b64(self, ba: QByteArray) -> str:
        return base64.b64encode(bytes(ba)).decode("ascii")

    def _prune_cache(self):
        now = time.time()
        ttl = max(10, self._ttl)
        try:
            for fn in os.listdir(VISION_CACHE_DIR):
                path = os.path.join(VISION_CACHE_DIR, fn)
                if not os.path.isfile(path): continue
                if now - os.path.getmtime(path) > ttl:
                    try: os.remove(path)
                    except Exception: pass
        except Exception:
            pass

    def ocr_locate_text(self, png_data: QByteArray, label: str, model: Optional[str]=None, within: str="ui") -> Dict:
        """
        Ask the vision model to locate a UI element by text and return normalized JSON:
        {"blocks":[{"text": "...", "bbox":[x,y,w,h], "score":0.0, "kind":"button"}]}
        """
        model = model or self._model_default
        prompt = (
            "You are a UI vision parser. Given an app screenshot, find UI elements.\n"
            f"Goal: locate the element with text close to: '{label}'.\n"
            "Return a compact JSON with a 'blocks' array. Each block: {text: str, bbox: [x,y,w,h], score: 0..1, kind: 'button'|'tab'|'label'}.\n"
            "Coordinates must be pixel integers relative to the image.\n"
            "Respond with JSON only."
        )
        b64 = self._b64(png_data)
        req=_requests()
        if not req: return {"blocks":[]}
        payload_gen = {"model": model, "prompt": prompt, "images":[b64], "stream": False}
        payload_chat= {"model": model, "messages":[{"role":"user","content":prompt}], "images":[b64], "stream": False}
        # try /generate then /chat
        for url, payload in [("http://127.0.0.1:11434/api/generate", payload_gen),
                             ("http://127.0.0.1:11434/api/chat", payload_chat)]:
            try:
                r = req.post(url, json=payload, timeout=30)
                if not r.ok: 
                    continue
                data = r.json()
                text = data.get("response") or (data.get("message") or {}).get("content") or ""
                # attempt to extract JSON (model may wrap)
                j = self._extract_json(text)
                if isinstance(j, dict) and "blocks" in j:
                    return j
            except Exception:
                continue
        return {"blocks":[]}

    def ocr_text(self, png_data: QByteArray, model: Optional[str]=None) -> Dict:
        """
        Generic OCR text dump + bounding boxes if possible.
        Normalized: {"full_text":"...", "blocks":[{text,bbox,score,kind}]}
        """
        model = model or self._model_default
        prompt = (
            "You are an OCR engine. Extract readable text from this image. "
            "When possible provide a JSON object with keys: full_text (string) "
            "and blocks (array of {text: string, bbox:[x,y,w,h], score:0..1, kind:'text'}). "
            "If unsure of bboxes, you may omit them, but still return JSON."
        )
        b64 = self._b64(png_data)
        req=_requests()
        if not req: return {"full_text":"", "blocks":[]}
        for url, payload in [("http://127.0.0.1:11434/api/generate",
                              {"model": model, "prompt": prompt, "images":[b64], "stream": False}),
                             ("http://127.0.0.1:11434/api/chat",
                              {"model": model, "messages":[{"role":"user","content":prompt}], "images":[b64], "stream": False})]:
            try:
                r = req.post(url, json=payload, timeout=30)
                if not r.ok: continue
                data=r.json()
                text = data.get("response") or (data.get("message") or {}).get("content") or ""
                j = self._extract_json(text)
                if isinstance(j, dict): 
                    j.setdefault("blocks", [])
                    j.setdefault("full_text", "")
                    return j
            except Exception:
                continue
        return {"full_text":"", "blocks":[]}

    def _extract_json(self, s: str):
        # attempt to find a JSON object in model output
        s = s.strip()
        # direct JSON
        if s.startswith("{") and s.endswith("}"):
            try: return json.loads(s)
            except Exception: pass
        # fenced
        m = re.search(r"\{[\s\S]*\}", s)
        if m:
            try: return json.loads(m.group(0))
            except Exception: pass
        return None

# --------------------------------------------------------------------------------------
# Syntax highlighter
# --------------------------------------------------------------------------------------

class TermHighlighter(QSyntaxHighlighter):
    def __init__(self, parent, t: Theme):
        super().__init__(parent); self.t=t
        def fmt(c, bold=False):
            f=QTextCharFormat(); f.setForeground(QColor(c))
            try:
                if bold: f.setFontWeight(QFont.Weight.Bold)
            except Exception:
                if bold: f.setFontWeight(QFont.Bold)
            return f
        self.f_ps   = fmt("#a0ffd6", True)
        self.f_cmd  = fmt("#cfe3ff", True)
        self.f_bash = fmt("#89f0ff", True)
        self.f_user = fmt("#5fb0ff", True)
        self.f_ai   = fmt(t.ok)
        self.f_ok   = fmt(t.ok)
        self.f_warn = fmt(t.warn, True)
        self.f_err  = fmt(t.err, True)
        self.f_path = fmt("#9bb7ff")

        self.re_ps   = re.compile(r"^PS\s+[A-Za-z]:\\.*?>")
        self.re_cmd  = re.compile(r"^[A-Za-z]:\\.*?>")
        self.re_bash = re.compile(r"^(\S+@[^:]+:)?~?.*[$#] ")
        self.re_user = re.compile(r"^› ")
        self.re_ai   = re.compile(r"^ai:", re.I)

        self.re_err  = re.compile(r"(not recognized|No such file|Traceback| Error:|^error:)", re.I)
        self.re_warn = re.compile(r"(warning|deprecated)", re.I)
        self.re_ok   = re.compile(r"(success|installed|running|listening|started|done|created)", re.I)
        self.re_path = re.compile(r"([A-Za-z]:\\[^:\n\r]+|/[^ \n\r]+)")

    def highlightBlock(self, text: str):
        if self.re_ps.search(text): self.setFormat(0,len(text), self.f_ps)
        elif self.re_cmd.search(text): self.setFormat(0,len(text), self.f_cmd)
        elif self.re_bash.search(text): self.setFormat(0,len(text), self.f_bash)
        elif self.re_user.search(text): self.setFormat(0,len(text), self.f_user)
        elif self.re_ai.search(text):   self.setFormat(0,len(text), self.f_ai)
        for m in self.re_err.finditer(text):  self.setFormat(m.start(), m.end()-m.start(), self.f_err)
        for m in self.re_warn.finditer(text): self.setFormat(m.start(), m.end()-m.start(), self.f_warn)
        for m in self.re_ok.finditer(text):   self.setFormat(m.start(), m.end()-m.start(), self.f_ok)
        for m in self.re_path.finditer(text): self.setFormat(m.start(), m.end()-m.start(), self.f_path)

# --------------------------------------------------------------------------------------
# Movable card (4 grips)
# --------------------------------------------------------------------------------------

class MovableCard(QFrame):
    moved = Signal()

    def __init__(self, t: Theme, parent: Optional[QWidget]=None):
        super().__init__(parent); self.t=t
        self._drag=False; self._press_pos=QPoint()
        sh=QGraphicsDropShadowEffect(self); sh.setColor(QColor(0,30,80,150)); sh.setBlurRadius(28); sh.setOffset(0,12)
        self.setGraphicsEffect(sh)
        self.setStyleSheet(f"background:{t.card_bg}; border:1px solid {t.card_border}; border-radius:{t.card_radius}px;")
        self._grips = [QSizeGrip(self) for _ in range(4)]
        for g in self._grips: g.setFixedSize(16,16); g.raise_()

    def header_geom(self)->QRect: return QRect(0,0,self.width(),46)

    def resizeEvent(self, e):
        w,h=self.width(), self.height()
        m=6; g=self._grips
        g[0].move(m, h-g[0].height()-m)                        # bottom-left
        g[1].move(w-g[1].width()-m, h-g[1].height()-m)         # bottom-right
        g[2].move(m, m)                                        # top-left
        g[3].move(w-g[3].width()-m, m)                         # top-right
        super().resizeEvent(e)

    def mousePressEvent(self, e):
        if e.button()==Qt.LeftButton and self.header_geom().contains(e.position().toPoint()):
            self._drag=True; self._press_pos=e.position().toPoint(); self.raise_(); e.accept()
        else:
            super().mousePressEvent(e)

    def mouseMoveEvent(self, e):
        if not self._drag:
            super().mouseMoveEvent(e); return
        delta=e.position().toPoint()-self._press_pos
        pos=self.pos()+delta
        canvas=self.parentWidget()
        if canvas:
            r=canvas.rect()
            pos.setX(max(6, min(pos.x(), r.width()-self.width()-6)))
            pos.setY(max(6, min(pos.y(), r.height()-self.height()-6)))
        self.move(pos); e.accept()

    def mouseReleaseEvent(self, e):
        if self._drag:
            self._drag=False; self.moved.emit()
        super().mouseReleaseEvent(e)

# --------------------------------------------------------------------------------------
# Cursor overlay & Keyboard card
# --------------------------------------------------------------------------------------

class CursorOverlayCard(QWidget):
    def __init__(self, canvas: QWidget, t: Theme):
        super().__init__(canvas)
        self.t=t
        self.setAttribute(Qt.WA_TransparentForMouseEvents, True)
        self.setGeometry(canvas.rect())
        self._pos = QPoint(60,60)
        self._visible = True
        self.raise_()
        self.show()

    def set_pos(self, p: QPoint):
        self._pos = p
        self.update()

    def paintEvent(self, e):
        if not self._visible: return
        p=QPainter(self); p.setRenderHint(QPainter.Antialiasing)
        # cursor: white outer ring + inner dot
        p.setPen(QColor("#ffffff"))
        p.setBrush(Qt.NoBrush)
        p.drawEllipse(self._pos, 10, 10)
        p.setBrush(QColor("#ffffff"))
        p.setPen(Qt.NoPen)
        p.drawEllipse(self._pos, 3, 3)

    def animate_to(self, p: QPoint, steps:int=10):
        # simple linear animation
        dx=(p.x()-self._pos.x())/max(1,steps)
        dy=(p.y()-self._pos.y())/max(1,steps)
        for i in range(steps):
            self._pos = QPoint(int(self._pos.x()+dx), int(self._pos.y()+dy))
            self.update()
            QApplication.processEvents()
            time.sleep(0.01)
        self._pos=p; self.update()

    def synth_click(self, main_window: QMainWindow, button=Qt.LeftButton):
        # send a mouse click to the widget under this canvas position
        global_pos = main_window.mapToGlobal(self._pos)
        target = QApplication.widgetAt(global_pos)
        if not target: return
        local = target.mapFromGlobal(global_pos)
        press = QMouseEvent(QEvent.MouseButtonPress, local, button, button, Qt.NoModifier)
        release=QMouseEvent(QEvent.MouseButtonRelease, local, button, Qt.NoButton, Qt.NoModifier)
        QApplication.postEvent(target, press)
        QApplication.processEvents()
        QApplication.postEvent(target, release)
        QApplication.processEvents()

class KeyboardCard(MovableCard):
    def __init__(self, t: Theme, parent: Optional[QWidget]=None):
        super().__init__(t, parent)
        self.setWindowTitle("Keyboard")
        self.resize(600, 220)
        L=QVBoxLayout(self); L.setContentsMargins(8,8,8,8)
        row_layouts=[]
        keys = [
            list("1234567890-=") + ["Backspace"],
            ["Tab"] + list("qwertyuiop") + ["[" , "]", "\\"],
            ["Caps"] + list("asdfghjkl") + [";","'","Enter"],
            ["Shift"] + list("zxcvbnm") + [",",".","/","Shift"],
            ["Ctrl","Alt","Space","Alt","Ctrl"]
        ]
        for row in keys:
            hb=QHBoxLayout(); hb.setSpacing(6)
            for k in row:
                btn=QPushButton(k); btn.setObjectName("Btn")
                btn.clicked.connect(lambda _, kk=k: self._send_key(kk))
                hb.addWidget(btn)
            row_layouts.append(hb); L.addLayout(hb)
        self.setStyleSheet(f"""
            QLabel {{ color:{t.header_fg}; }}
            QPushButton#Btn {{
                color:#ffffff; background:{t.accent}; border:1px solid {t.card_border}; border-radius:6px; padding:8px 10px;
            }}
            QPushButton#Btn:hover {{ background:{t.accent_hover}; }}
        """)

    def header_geom(self)->QRect: return QRect(0,0,self.width(),26)  # smaller header

    def _send_key(self, k: str):
        w = QApplication.focusWidget()
        if not w: return
        text_map = {
            "Space":" ",
            "Enter":"\n",
            "Tab":"\t",
            "Backspace":"\b"
        }
        if k in text_map:
            for ch in text_map[k]:
                ev = QKeyEvent(QEvent.KeyPress, 0, Qt.NoModifier, ch)
                QApplication.postEvent(w, ev)
            return
        # letters/symbols
        ev = QKeyEvent(QEvent.KeyPress, 0, Qt.NoModifier, k if len(k)==1 else "")
        QApplication.postEvent(w, ev)

# --------------------------------------------------------------------------------------
# Prompt Manager
# --------------------------------------------------------------------------------------

class PromptManagerDialog(QDialog):
    def __init__(self, cfg: Dict, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Prompt Manager")
        self.resize(980, 720)
        self.cfg = cfg

        root = QVBoxLayout(self)

        # --- Prompts section
        grpP=QGroupBox("Prompts")
        gp=QGridLayout(grpP)
        self.system_prompt=QTextEdit(cfg.get("system_prompt", DEFAULT_SYSTEM_PROMPT))
        self.l2c_prompt=QTextEdit(cfg.get("l2c_prompt", DEFAULT_L2C_PROMPT))
        self.vision_guidance=QTextEdit(
            "Vision Guidance (used by adapters, edit if needed):\n"
            "- Prefer concise JSON outputs with blocks and bboxes.\n"
            "- Treat target labels strictly; avoid hallucinated coords.\n"
            "- Coordinates in integer pixels."
        )
        gp.addWidget(QLabel("System Prompt:"),0,0); gp.addWidget(self.system_prompt,1,0,1,2)
        gp.addWidget(QLabel("Language→Commands Prompt:"),2,0); gp.addWidget(self.l2c_prompt,3,0,1,2)
        gp.addWidget(QLabel("Vision Prompt Notes:"),4,0); gp.addWidget(self.vision_guidance,5,0,1,2)

        # --- AI Intersection Points
        grpA=QGroupBox("AI Intersection Points (model per point, editable reasons)")
        ga=QGridLayout(grpA)
        self.rows=[]
        pts = self.cfg.get("ai_points", {})
        r=0
        ga.addWidget(QLabel("Point ID"), r,0)
        ga.addWidget(QLabel("Enabled"), r,1)
        ga.addWidget(QLabel("Model"), r,2)
        ga.addWidget(QLabel("Reason / Notes"), r,3)
        r+=1
        for pid, meta in pts.items():
            ch=QCheckBox(); ch.setChecked(bool(meta.get("enabled", True)))
            model_cb=QComboBox(); model_cb.setEditable(True)
            # populate known models from Ollama tags (done on open)
            for n in self._all_models(): model_cb.addItem(n)
            cur=meta.get("model","")
            if cur: model_cb.setCurrentText(cur)
            notes=QLineEdit()
            notes.setText(self._default_reason_for(pid))
            ga.addWidget(QLabel(pid), r,0)
            ga.addWidget(ch, r,1)
            ga.addWidget(model_cb, r,2)
            ga.addWidget(notes, r,3)
            self.rows.append((pid, ch, model_cb, notes))
            r+=1

        # Buttons
        buttons=QDialogButtonBox(QDialogButtonBox.Save|QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept); buttons.rejected.connect(self.reject)

        root.addWidget(grpP)
        root.addWidget(grpA, 1)
        root.addWidget(buttons)

    def _default_reason_for(self, pid:str) -> str:
        mapping = {
            "chat.to.commands": "Translate NL → selected shell; confirm before destructive ops.",
            "chat.plain": "Answer explanations without commands.",
            "rag.augment": "Bring back relevant prior facts/snippets.",
            "runner.analyze": "Summarize post-run errors quickly.",
            "vision.locate.ui": "Find buttons/tabs by label when geometry drifts.",
            "vision.observe.editor": "Detect gutter/banners for code errors visually.",
            "vision.observe.tabs": "See which file/tab is active.",
            "snippets.suggest": "Suggest known snippets for repeated intents.",
            "index.grow": "Promote repeated fixes into compact patterns."
        }
        return mapping.get(pid, "AI intersection point")

    def _all_models(self)->List[str]:
        req=_requests()
        names=[]
        if not req: return names
        try:
            r=req.get("http://127.0.0.1:11434/api/tags", timeout=5)
            if not r.ok: return names
            for m in r.json().get("models", []):
                n=m.get("name") or m.get("model") or ""
                if n: names.append(n)
            names=sorted(set(names))
            return names
        except Exception:
            return []

    def values(self)->Dict:
        out=self.cfg.copy()
        out["system_prompt"]=self.system_prompt.toPlainText()
        out["l2c_prompt"]=self.l2c_prompt.toPlainText()
        pts={}
        for pid, ch, model_cb, notes in self.rows:
            pts[pid] = {
                "enabled": ch.isChecked(),
                "model": model_cb.currentText().strip(),
                "timeout_ms": int(self.cfg.get("ai_points",{}).get(pid,{}).get("timeout_ms", 10000)),
                "notes": notes.text().strip()
            }
        out["ai_points"] = pts
        return out

# --------------------------------------------------------------------------------------
# Settings Dialog (context depth & pruning)
# --------------------------------------------------------------------------------------

class SettingsDialog(QDialog):
    def __init__(self, cfg: Dict, available_embed_models: List[str], parent=None):
        super().__init__(parent)
        self.setWindowTitle("Settings")
        self.cfg = cfg
        self.resize(900, 740)

        root=QVBoxLayout(self)

        grpP=QGroupBox("Prompts (quick edit)")
        lp=QGridLayout(grpP)
        self.system_prompt=QTextEdit(cfg.get("system_prompt", DEFAULT_SYSTEM_PROMPT))
        self.l2c_prompt=QTextEdit(cfg.get("l2c_prompt", DEFAULT_L2C_PROMPT))
        lp.addWidget(QLabel("System Prompt:"),0,0); lp.addWidget(self.system_prompt,1,0,1,2)
        lp.addWidget(QLabel("Language to Commands Prompt:"),2,0); lp.addWidget(self.l2c_prompt,3,0,1,2)

        grpSchema=QGroupBox("Schema Index Template")
        ls=QVBoxLayout(grpSchema)
        self.schema=QTextEdit(SCHEMA_INDEX_TEMPLATE)
        btn_copy=QPushButton("Copy Template to Clipboard")
        btn_copy.clicked.connect(lambda: QApplication.clipboard().setText(self.schema.toPlainText()))
        ls.addWidget(QLabel("Use this as a starting point for your indexing dataset."))
        ls.addWidget(self.schema, 1)
        ls.addWidget(btn_copy, 0, Qt.AlignRight)

        grpR=QGroupBox("RAG / Embeddings")
        lr=QFormLayout(grpR)
        self.embed_combo=QComboBox()
        if available_embed_models:
            self.embed_combo.addItems(available_embed_models)
            cur=cfg.get("embedding_model", DEFAULT_CONFIG["embedding_model"])
            if cur in available_embed_models: self.embed_combo.setCurrentText(cur)
        else:
            self.embed_combo.addItem("(no embedding models found)")
        self.autorun_cb=QCheckBox("Auto-run suggestions in Shell when Language to Commands is ON")
        self.autorun_cb.setChecked(bool(cfg.get("autorun_suggestions", False)))
        self.selfprompt_cb=QCheckBox("Enable Self-Prompting (append lightweight hints to dataset)")
        self.selfprompt_cb.setChecked(bool(cfg.get("self_prompting", False)))
        lr.addRow("Embedding Model:", self.embed_combo)
        lr.addRow(self.autorun_cb); lr.addRow(self.selfprompt_cb)

        grpC=QGroupBox("Conversation Context")
        lc=QFormLayout(grpC)
        self.depth_mode=QComboBox(); self.depth_mode.addItems(["None","Fixed","All"])
        mode=cfg.get("context_depth_mode","fixed").lower()
        self.depth_mode.setCurrentText("None" if mode=="none" else "All" if mode=="all" else "Fixed")
        self.depth_value=QSpinBox(); self.depth_value.setRange(1,100); self.depth_value.setValue(int(cfg.get("context_depth_value",15)))
        lc.addRow("Depth Mode:", self.depth_mode)
        lc.addRow("Depth (pairs):", self.depth_value)
        def _toggle(v=None):
            self.depth_value.setEnabled(self.depth_mode.currentText()=="Fixed")
        self.depth_mode.currentTextChanged.connect(_toggle); _toggle()

        grpPr=QGroupBox("VectorStore Pruning/Rotation")
        lpv=QFormLayout(grpPr)
        self.max_bytes=QLE(str(cfg.get("prune_max_bytes", DEFAULT_CONFIG["prune_max_bytes"])))
        self.max_records=QLE(str(cfg.get("prune_max_records", DEFAULT_CONFIG["prune_max_records"])))
        self.keep_tail=QLE(str(cfg.get("prune_keep_tail", DEFAULT_CONFIG["prune_keep_tail"])))
        lpv.addRow("Rotate at size (bytes):", self.max_bytes)
        lpv.addRow("Rotate at records:", self.max_records)
        lpv.addRow("Keep last N on rotation:", self.keep_tail)

        grpV=QGroupBox("Vision / OCR")
        lv=QFormLayout(grpV)
        self.vision_model_cb = QComboBox()
        # populate with discovered vision models (superset—regular models not filtered here)
        for n in self._all_models(): self.vision_model_cb.addItem(n)
        cur_vm = cfg.get("vision",{}).get("model_default","llava:7b")
        self.vision_model_cb.setCurrentText(cur_vm)
        self.vision_ttl=QSpinBox(); self.vision_ttl.setRange(10, 3600); self.vision_ttl.setValue(int(cfg.get("vision",{}).get("ttl_seconds",120)))
        lv.addRow("Vision Model:", self.vision_model_cb)
        lv.addRow("OCR TTL (sec):", self.vision_ttl)

        root.addWidget(grpP)
        root.addWidget(grpSchema)
        root.addWidget(grpR)
        root.addWidget(grpC)
        root.addWidget(grpPr)
        root.addWidget(grpV)

        buttons=QDialogButtonBox(QDialogButtonBox.Save|QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept); buttons.rejected.connect(self.reject)
        root.addWidget(buttons)

    def _all_models(self)->List[str]:
        req=_requests()
        names=[]
        if not req: return names
        try:
            r=req.get("http://127.0.0.1:11434/api/tags", timeout=5)
            if not r.ok: return names
            for m in r.json().get("models", []):
                n=m.get("name") or m.get("model") or ""
                if n: names.append(n)
            names=sorted(set(names))
            return names
        except Exception:
            return []

    def values(self)->Dict:
        out=self.cfg.copy()
        out["system_prompt"]=self.system_prompt.toPlainText()
        out["l2c_prompt"]=self.l2c_prompt.toPlainText()
        if self.embed_combo.currentText() and not self.embed_combo.currentText().startswith("("):
            out["embedding_model"]=self.embed_combo.currentText()
        out["autorun_suggestions"]=self.autorun_cb.isChecked()
        out["self_prompting"]=self.selfprompt_cb.isChecked()

        mode=self.depth_mode.currentText()
        out["context_depth_mode"]=mode.lower()
        out["context_depth_value"]=int(self.depth_value.value())

        def _i(s, d):
            try: return int(s)
            except: return d
        out["prune_max_bytes"]=_i(self.max_bytes.text(), DEFAULT_CONFIG["prune_max_bytes"])
        out["prune_max_records"]=_i(self.max_records.text(), DEFAULT_CONFIG["prune_max_records"])
        out["prune_keep_tail"]=_i(self.keep_tail.text(), DEFAULT_CONFIG["prune_keep_tail"])

        out.setdefault("vision", {})
        out["vision"]["model_default"] = self.vision_model_cb.currentText().strip()
        out["vision"]["ttl_seconds"]   = int(self.vision_ttl.value())

        return out

# --------------------------------------------------------------------------------------
# Terminal Card
# --------------------------------------------------------------------------------------

class TerminalCard(MovableCard):
    proc_state = Signal(bool)  # running?

    def __init__(self, t: Theme, cfg: Dict, parent: Optional[QWidget]=None):
        super().__init__(t, parent); self.t=t; self.cfg=cfg
        self.resize(1000, 640)

        # datasets
        emb=cfg.get("embedding_model", DEFAULT_CONFIG["embedding_model"])
        self.ds_sem_user   = VectorStore("sem_user",   emb, cfg)
        self.ds_sem_ai     = VectorStore("sem_ai",     emb, cfg)
        self.ds_indexing   = VectorStore("indexing",   emb, cfg)
        self.ds_prompting  = VectorStore("prompting",  emb, cfg)
        self.ds_learning   = VectorStore("learning",   emb, cfg)
        self.ds_selfp      = VectorStore("self_prompting", emb, cfg)
        self.ctx_history   = ContextHistory()
        self.vision        = VisionService(cfg)

        # state
        self.mode_chat=True
        self.env="CMD"
        self.model=""
        self.history: List[str]=[]; self.hidx=-1
        self.autorun=self.cfg.get("autorun_suggestions", False)
        self.self_prompting=self.cfg.get("self_prompting", False)
        self.proc: Optional[subprocess.Popen] = None
        self.reader: Optional[threading.Thread] = None
        self.kill_evt = threading.Event()
        self.queue: "queue.Queue[str]" = queue.Queue(maxsize=10000)
        self.auto_scroll=True

        # header
        L=QVBoxLayout(self); L.setContentsMargins(0,0,0,0); L.setSpacing(0)

        hdr=QFrame(self); hdr.setObjectName("Hdr")
        H=QHBoxLayout(hdr); H.setContentsMargins(12,8,12,4); H.setSpacing(8)
        title=QLabel("Terminal", hdr); title.setStyleSheet(f"color:{t.header_fg}; font-weight:700; letter-spacing:.2px;")
        self.mode_chip=QLabel("Chat+Shell", hdr)
        self.mode_chip.setStyleSheet("color:#0a111e; background:#9df; padding:2px 6px; border-radius:8px; font-weight:700;")
        H.addWidget(title); H.addWidget(self.mode_chip)

        self.mode_combo=QComboBox(hdr); self.mode_combo.addItems(["Chat","Shell"])
        H.addWidget(self._hl("Mode:")); H.addWidget(self.mode_combo)

        self.env_combo=QComboBox(hdr); self.env_combo.addItems(["CMD","PowerShell","WSL","Bash","Python-REPL"])
        H.addWidget(self._hl("Env:")); H.addWidget(self.env_combo)

        self.model_combo=QComboBox(hdr)
        self.model_refresh=QToolButton(hdr); self.model_refresh.setText("↻"); self.model_refresh.setToolTip("Refresh models from Ollama")
        H.addWidget(self._hl("Model:")); H.addWidget(self.model_combo); H.addWidget(self.model_refresh)

        # Language to Commands = checkbox
        self.l2c_cb=QCheckBox("Language to Commands", hdr); self.l2c_cb.setChecked(True)
        self.pin_btn=QPushButton("Track", hdr); self.pin_btn.setCheckable(True); self.pin_btn.setChecked(True)
        self.start_btn=QPushButton("Start", hdr); self.stop_btn=QPushButton("Stop", hdr); self.stop_btn.setEnabled(False)
        self.settings_btn=QToolButton(hdr); self.settings_btn.setText("⋮"); self.settings_btn.setToolTip("Settings")
        for b in (self.pin_btn,self.start_btn,self.stop_btn): b.setObjectName("Btn")
        H.addStretch(1)
        H.addWidget(self.l2c_cb); H.addWidget(self.pin_btn); H.addWidget(self.start_btn); H.addWidget(self.stop_btn); H.addWidget(self.settings_btn)
        L.addWidget(hdr)

        # memory strip
        strip=QFrame(self); strip.setObjectName("MemStrip")
        S=QHBoxLayout(strip); S.setContentsMargins(10,0,10,4); S.setSpacing(14)
        self.mem_ctx      = QLabel()
        self.mem_user     = QLabel(); self.mem_ai      = QLabel()
        self.mem_indexing = QLabel(); self.mem_prompting = QLabel()
        self.mem_learning = QLabel(); self.mem_selfp   = QLabel()
        for lab,color in [
            (self.mem_ctx,       "#f4f4f4"),
            (self.mem_user,      self.t.info),
            (self.mem_ai,        self.t.ok),
            (self.mem_indexing,  self.t.accent),
            (self.mem_prompting, self.t.warn),
            (self.mem_learning,  "#a8ffea"),
            (self.mem_selfp,     self.t.err),
        ]:
            lab.setStyleSheet(f"color:{color}; background:{self.t.strip_bg}; font:600 9pt 'Cascadia Code';")
            S.addWidget(lab)
        S.addStretch(1)
        self.send_last_btn=QPushButton("Send last suggestion", strip); self.send_last_btn.setObjectName("Btn")
        S.addWidget(self.send_last_btn)
        L.addWidget(strip)

        # console
        self.console=QPlainTextEdit(self); self.console.setReadOnly(True); self.console.setUndoRedoEnabled(False)
        self.console.setLineWrapMode(QPlainTextEdit.WidgetWidth)  # WORD WRAP ON
        self.console.setWordWrapMode(QTextOption.WrapAtWordBoundaryOrAnywhere)
        self.console.setMaximumBlockCount(8000)
        self.console.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Consolas, 'Cascadia Code', 'Fira Code', monospace; font-size:12.6pt;"
            f"border-top:1px solid {t.card_border}; border-bottom:1px solid {t.card_border}; padding:10px;"
        )
        self.hl=TermHighlighter(self.console.document(), t)
        L.addWidget(self.console, 1)

        # input
        ib=QFrame(self); ib.setObjectName("IB")
        IB=QHBoxLayout(ib); IB.setContentsMargins(10,8,10,10); IB.setSpacing(8)
        self.prompt=QLabel("›", ib); self.prompt.setStyleSheet(f"color:{t.accent}; font:700 13pt 'Cascadia Code'; padding:0 6px 0 2px;")
        self.input=QLineEdit(ib); self.input.setPlaceholderText("Type a message or command… (Enter=send, Ctrl+L=clear, ↑/↓ history)")
        self.run_btn=QPushButton("Run", ib); self.run_btn.setObjectName("Btn")
        IB.addWidget(self.prompt); IB.addWidget(self.input,1); IB.addWidget(self.run_btn)
        L.addWidget(ib)

        # global stylesheet (BRIGHT TEXT on dark)
        self.setStyleSheet(f"""
        QFrame#Hdr {{ background:{t.header_bg}; border-top-left-radius:{t.card_radius}px; border-top-right-radius:{t.card_radius}px; }}
        QFrame#IB  {{ background:{t.card_bg}; border-bottom-left-radius:{t.card_radius}px; border-bottom-right-radius:{t.card_radius}px; }}
        QFrame#MemStrip {{ background:{t.strip_bg}; }}
        QLabel {{ color:{t.header_fg}; }}
        QCheckBox, QToolButton, QComboBox {{ color:#eaf2ff; }}
        QComboBox {{ background:#0d1a2b; border:1px solid {t.card_border}; padding:2px 6px; }}
        QComboBox QAbstractItemView {{ background:#0d1a2b; color:#eaf2ff; selection-background-color:{t.accent}; }}
        QPushButton#Btn {{
            color:#ffffff; background:{t.accent}; border:1px solid {t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton#Btn:checked {{ background:{t.accent_hover}; }}
        QPushButton#Btn:hover {{ background:{t.accent_hover}; }}
        QToolButton {{ background: transparent; color:#eaf2ff; }}
        """)

        # timers & signals
        self.flush_timer=QTimer(self); self.flush_timer.timeout.connect(self._flush_queue); self.flush_timer.start(16)
        self.mode_combo.currentTextChanged.connect(self._on_mode_changed)
        self.env_combo.currentTextChanged.connect(self._on_env_changed)
        self.model_refresh.clicked.connect(self.refresh_models)
        self.model_combo.currentTextChanged.connect(lambda s: setattr(self, "model", s))
        self.l2c_cb.toggled.connect(self._on_l2c_toggled)
        self.start_btn.clicked.connect(self._start_shell)
        self.stop_btn.clicked.connect(self._stop_shell)
        self.run_btn.clicked.connect(self._on_enter)
        self.send_last_btn.clicked.connect(self._send_last_to_shell)
        self.input.returnPressed.connect(self._on_enter)
        self.input.installEventFilter(self)
        self.proc_state.connect(self._proc_state_changed)
        self.settings_btn.clicked.connect(self._open_settings)
        self.moved.connect(self._on_drag_finished)

        # boot text
        self._println("[Info] Chat mode is default. Select a local Ollama model (Model ▸ ↻).")
        self._println("[Info] Switch to Shell to interact with CMD/PS/WSL/Bash/Python REPL.")
        self._println("[Info] Right-click to run the last fenced code block via “Run Suggestion”.")
        self.refresh_models(prefer="gpt-oss:20b")
        self._update_memory_strip()
        self._update_mode_chip()

        # context menu
        self.console.setContextMenuPolicy(Qt.CustomContextMenu)
        self.console.customContextMenuRequested.connect(self._context_menu)

    # ---------- helpers ----------
    def _hl(self, txt:str)->QLabel:
        lab=QLabel(txt); lab.setStyleSheet("color:#eaf2ff;")
        return lab

    def _update_memory_strip(self):
        self.mem_ctx.setText(f"context:{human_size(self.ctx_history.bytes())}")
        self.mem_user.setText(f"sem_user:{human_size(self.ds_sem_user.bytes())}")
        self.mem_ai.setText(f"sem_ai:{human_size(self.ds_sem_ai.bytes())}")
        self.mem_indexing.setText(f"indexing:{human_size(self.ds_indexing.bytes())}")
        self.mem_prompting.setText(f"prompting:{human_size(self.ds_prompting.bytes())}")
        self.mem_learning.setText(f"learning:{human_size(self.ds_learning.bytes())}")
        self.mem_selfp.setText(f"self_prompt:{human_size(self.ds_selfp.bytes())}")

    def _available_embed_models(self) -> List[str]:
        req=_requests()
        if not req: return []
        try:
            r=req.get("http://127.0.0.1:11434/api/tags", timeout=5)
            if not r.ok: return []
            names=[]
            for m in r.json().get("models", []):
                n=m.get("name") or m.get("model") or ""
                if not n: continue
                if "embed" in n: names.append(n)
            return sorted(set(names))
        except Exception:
            return []

    def _open_settings(self):
        dlg=SettingsDialog(self.cfg, self._available_embed_models(), self)
        if dlg.exec()==QDialog.Accepted:
            self.cfg=dlg.values()
            save_config(self.cfg)
            emb=self.cfg.get("embedding_model", DEFAULT_CONFIG["embedding_model"])
            # update vector stores
            self.ds_sem_user.embed_model=emb
            self.ds_sem_ai.embed_model=emb
            self.ds_indexing.embed_model=emb
            self.ds_prompting.embed_model=emb
            self.ds_learning.embed_model=emb
            self.ds_selfp.embed_model=emb
            self.autorun=self.cfg.get("autorun_suggestions", False)
            self.self_prompting=self.cfg.get("self_prompting", False)
            # vision
            self.vision._ttl = int(self.cfg.get("vision",{}).get("ttl_seconds", 120))
            self.vision._model_default = self.cfg.get("vision",{}).get("model_default", "llava:7b")
            self._println("[Info] Settings saved.")

    def _on_drag_finished(self):
        if self.pin_btn.isChecked():
            d=self.parentWidget()
            if d and hasattr(d, "request_focus_on"):
                d.request_focus_on(self)

    def _context_menu(self, pos):
        menu=self.console.createStandardContextMenu()
        code=self._last_code_block()
        if code:
            menu.addSeparator()
            run=menu.addAction("Run Suggestion")
            run.triggered.connect(lambda: self._send_text_to_shell(code))
        menu.exec(self.console.mapToGlobal(pos))

    def _last_code_block(self)->Optional[str]:
        txt=self.console.toPlainText()
        fences=list(re.finditer(r"```(?:\w+)?\n([\s\S]*?)```", txt))
        return fences[-1].group(1).strip() if fences else None

    # ---------- identity guard ----------
    def _enforce_identity(self, text: str) -> str:
        text = re.sub(r"\bI'?m\s+Chat\s*GPT\b|\bI'?m\s+ChatGPT\b", "I'm Agent Terminal", text, flags=re.I)
        return text

    # ---------- mode/env/l2c ----------
    def _update_mode_chip(self):
        if self.mode_chat and self.l2c_cb.isChecked():
            self.mode_chip.setText("Chat+Shell")
            self.mode_chip.setStyleSheet("color:#0a111e; background:#9df; padding:2px 6px; border-radius:8px; font-weight:700;")
        elif self.mode_chat:
            self.mode_chip.setText("Chat")
            self.mode_chip.setStyleSheet("color:#0a111e; background:#a7f9c8; padding:2px 6px; border-radius:8px; font-weight:700;")
        else:
            self.mode_chip.setText("Shell")
            self.mode_chip.setStyleSheet("color:#0a111e; background:#ffd76b; padding:2px 6px; border-radius:8px; font-weight:700;")

    def _on_mode_changed(self, s: str):
        self.mode_chat = (s.lower()=="chat")
        self._update_mode_chip()
        if self.mode_chat:
            if self.l2c_cb.isChecked():
                if not self._shell_running(): self._start_shell()
            else:
                if self._shell_running(): self._stop_shell()
        else:
            if not self._shell_running(): self._start_shell()
        self._println(f"[Mode] {'Chat' if self.mode_chat else 'Shell'}")

    def _on_env_changed(self, new_env: str):
        self.env=new_env
        if self._shell_running(): self._stop_shell()
        if (not self.mode_chat) or (self.mode_chat and self.l2c_cb.isChecked()):
            self._start_shell()

    def _on_l2c_toggled(self, on: bool):
        if (not self.mode_chat) and on:
            self.mode_combo.setCurrentText("Chat")
        elif self.mode_chat and (not on):
            if self._shell_running(): self._stop_shell()
        self._update_mode_chip()

    # ---------- models ----------
    def refresh_models(self, prefer: Optional[str]=None):
        self.model_combo.clear()
        req=_requests()
        if not req:
            self.model_combo.addItem("(requests not installed)")
            self._println("[Warn] pip install requests  # to use Ollama chat")
            return
        try:
            r=req.get("http://127.0.0.1:11434/api/tags", timeout=5)
            if not r.ok: raise RuntimeError(f"HTTP {r.status_code}")
            names=[]
            for m in r.json().get("models", []):
                n=m.get("name") or m.get("model") or ""
                if n: names.append(n)
            names=sorted(set(names))
            if names:
                for n in names: self.model_combo.addItem(n)
                pick=None
                if prefer and prefer in names: pick=prefer
                elif "gpt-oss:20b" in names: pick="gpt-oss:20b"
                else: pick=names[0]
                self.model_combo.setCurrentText(pick)
                self.model=pick
                self._println(f"[Models] {len(names)} found. Current: {self.model}")
            else:
                self.model_combo.addItem("(no models found)")
                self._println("[Warn] No Ollama models. Example:  ollama pull gpt-oss:20b")
        except Exception as e:
            self.model_combo.addItem("(Ollama offline)")
            self._println(f"[Warn] Ollama not reachable — {e}")

    # ---------- shell ----------
    def _shell_running(self) -> bool:
        return bool(self.proc and self.proc.poll() is None)

    def _start_shell(self):
        if self._shell_running(): return
        try:
            if   self.env=="CMD": cmd=["cmd.exe"]
            elif self.env=="PowerShell": cmd=["powershell.exe","-NoLogo"]
            elif self.env=="WSL": cmd=["wsl.exe" if sys.platform.startswith("win") else "wsl"]
            elif self.env=="Bash":
                bash=find_git_bash()
                cmd=[bash] if bash else (["wsl.exe"] if sys.platform.startswith("win") else ["/bin/bash"])
            elif self.env=="Python-REPL": cmd=[sys.executable]
            else: self._println(f"[Warn] Unknown env: {self.env}"); return

            self.proc=subprocess.Popen(
                cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                text=True, bufsize=1, universal_newlines=True
            )
        except Exception as e:
            self._println(f"[Error] failed to start {self.env}: {e}"); return

        self.kill_evt.clear()
        self.reader=threading.Thread(target=self._reader, daemon=True); self.reader.start()
        self.proc_state.emit(True)
        self._println(f"[Info] Shell started: {' '.join(cmd)}")

    def _stop_shell(self):
        if not self.proc:
            self.proc_state.emit(False); return
        self.kill_evt.set()
        try:
            if self.proc.stdin:
                self.proc.stdin.write("exit"+nl_for_env(self.env)); self.proc.stdin.flush()
            self.proc.terminate()
        except Exception: pass
        try: self.proc.wait(timeout=2)
        except Exception:
            try: self.proc.kill()
            except Exception: pass
        self.proc=None; self.reader=None; self.proc_state.emit(False)
        self._println("[Info] Shell stopped.")

    def _reader(self):
        assert self.proc and self.proc.stdout
        for line in self.proc.stdout:
            if self.kill_evt.is_set(): break
            try: self.queue.put_nowait(line)
            except queue.Full: pass

    @Slot(bool)
    def _proc_state_changed(self, running: bool):
        self.start_btn.setEnabled(not running)
        self.stop_btn.setEnabled(running)

    # ---------- send / enter ----------
    def eventFilter(self, obj, ev):
        if obj is self.input and ev.type()==QEvent.KeyPress:
            key=ev.key()
            if key==Qt.Key_Up and self.history:
                if self.hidx<0: self.hidx=len(self.history)-1
                else: self.hidx=max(0, self.hidx-1)
                self.input.setText(self.history[self.hidx]); return True
            if key==Qt.Key_Down and self.history:
                if self.hidx<0: return True
                self.hidx=min(len(self.history)-1, self.hidx+1)
                self.input.setText(self.history[self.hidx] if self.hidx>=0 else ""); return True
            if (ev.modifiers() & Qt.ControlModifier) and key==Qt.Key_L:
                self.console.clear(); return True
        return super().eventFilter(obj, ev)

    @Slot()
    def _on_enter(self):
        text=self.input.text()
        if not text.strip(): return
        self.history.append(text); self.hidx=-1

        # semantic user record
        self.ds_sem_user.add_text(text, {"role":"user", "env":self.env})
        self._update_memory_strip()

        self._println(f"› {text}")

        if self.mode_chat:
            if self.l2c_cb.isChecked():
                threading.Thread(target=self._chat_to_commands_and_maybe_run, args=(text,), daemon=True).start()
            else:
                threading.Thread(target=self._chat_plain, args=(text,), daemon=True).start()
        else:
            if self._shell_running() and self.proc and self.proc.stdin:
                try:
                    self.proc.stdin.write(text + nl_for_env(self.env)); self.proc.stdin.flush()
                except Exception as e: self._println(f"[Error] write failed: {e}")
            else:
                self._run_one_off(text)
        self.input.clear()

    # ---------- context construction ----------
    def _context_pairs_for_prompt(self) -> List[Dict]:
        mode=self.cfg.get("context_depth_mode","fixed").lower()
        if mode=="none": limit=0
        elif mode=="all": limit=None
        else: limit=int(self.cfg.get("context_depth_value",15))
        return self.ctx_history.last_pairs(limit)

    def _build_rag_context(self, user_text: str) -> str:
        chunks=[]
        for ds, label, k in [
            (self.ds_indexing, "INDEX", 6),
            (self.ds_prompting, "PROMPT_HINT", 3),
            (self.ds_learning, "LEARN", 3),
            (self.ds_sem_user, "USER_SEM", 2),
            (self.ds_selfp, "SELF_PROMPT", 2),
        ]:
            hits=ds.search(user_text, top_k=k)
            if not hits: continue
            for h in hits:
                text=h.get("text","")
                if not text: continue
                chunks.append(f"[{label}] {text}")
        return "\n".join(chunks[:24])

    def _chat_msgs(self, user_text: str, include_l2c: bool) -> List[Dict]:
        req_prompt=self.cfg.get("system_prompt", DEFAULT_SYSTEM_PROMPT)
        l2c_prompt=self.cfg.get("l2c_prompt", DEFAULT_L2C_PROMPT)

        msgs=[{"role":"system","content":req_prompt}]
        if include_l2c: msgs.append({"role":"system","content":f"{l2c_prompt}\nSelected Env: {self.env}"})

        # narrative context pairs
        for p in self._context_pairs_for_prompt():
            u=p.get("u",""); a=p.get("a","")
            if u: msgs.append({"role":"user","content":u})
            if a: msgs.append({"role":"assistant","content":a})

        # RAG
        rag=self._build_rag_context(user_text)
        if rag: msgs.append({"role":"system","content":f"Context (RAG):\n{rag}"})

        msgs.append({"role":"user","content":user_text})
        return msgs

    # ---------- chat flows ----------
    def _chat_plain(self, user_text: str):
        req=_requests()
        if not req:
            self._println("ai: (install 'requests' to enable Ollama chat)"); return
        model=self.model_combo.currentText().strip() or self.model
        if not model or model.startswith("("):
            self._println("ai: (no model selected)"); return

        msgs=self._chat_msgs(user_text, include_l2c=False)

        try:
            r=req.post("http://127.0.0.1:11434/api/chat", json={"model": model, "messages": msgs, "stream": False}, timeout=240)
            if not r.ok:
                self._println(f"ai: HTTP {r.status_code} — {r.text[:160]}"); return
            data=r.json()
            msg=(data.get("message") or {}).get("content","").strip()
            if not msg: msg=(data.get("response") or "").strip() or "(no content)"
            msg=self._enforce_identity(msg)
            self._println(f"ai: {msg}")

            # persist
            self.ds_sem_ai.add_text(msg, {"type":"plain"})
            self.ctx_history.add_pair(user_text, msg)
            self._update_memory_strip()
        except Exception as e:
            self._println(f"ai: {e}")

    def _chat_to_commands_and_maybe_run(self, user_text: str):
        req=_requests()
        if not req:
            self._println("ai: (install 'requests' to enable Ollama chat)"); return
        model=self.model_combo.currentText().strip() or self.model
        if not model or model.startswith("("):
            self._println("ai: (no model selected)"); return

        msgs=self._chat_msgs(user_text, include_l2c=True)

        try:
            r=req.post("http://127.0.0.1:11434/api/chat", json={"model": model, "messages": msgs, "stream": False}, timeout=300)
            if not r.ok:
                self._println(f"ai: HTTP {r.status_code} — {r.text[:160]}"); return
            data=r.json()
            msg=(data.get("message") or {}).get("content","").strip()
            if not msg: msg=(data.get("response") or "").strip() or "(no content)"
            msg=self._enforce_identity(msg)
            self._println(f"ai: {msg}")

            # Persist
            self.ds_sem_ai.add_text(msg, {"type":"l2c", "env":self.env})
            if self.self_prompting:
                self.ds_selfp.add_text(f"[SELF_HINT/{self.env}] {user_text}", {"env":self.env})
            self.ctx_history.add_pair(user_text, msg)
            self._update_memory_strip()

            code=self._extract_env_block(msg, self.env)
            if code and self.autorun:
                if not self._shell_running(): self._start_shell()
                self._println("[Info] Autorun enabled: sending suggestion to shell…")
                self._send_text_to_shell(code)
        except Exception as e:
            self._println(f"ai: {e}")

    def _extract_env_block(self, text: str, env: str)->Optional[str]:
        lang = {
            "CMD":"cmd", "PowerShell":"powershell", "Bash":"bash", "WSL":"bash", "Python-REPL":"python"
        }.get(env, "bash")
        m=re.search(rf"```{lang}\n([\s\S]*?)```", text, re.I)
        if m: return m.group(1).strip()
        m=re.search(r"```\w*\n([\s\S]*?)```", text)
        return m.group(1).strip() if m else None

    # ---------- send code to shell ----------
    def _send_last_to_shell(self):
        code=self._last_code_block()
        if not code:
            self._println("[Warn] No fenced code block found."); return
        self._send_text_to_shell(code)

    def _send_text_to_shell(self, text: str):
        if not self._shell_running() or not (self.proc and self.proc.stdin):
            self._println("[Warn] Shell not running. Press Start."); return
        nl=nl_for_env(self.env)
        for line in text.splitlines():
            try:
                self.proc.stdin.write(line + nl); self.proc.stdin.flush()
            except Exception as e:
                self._println(f"[Error] write failed: {e}"); break

    # ---------- one-off ----------
    def _run_one_off(self, cmd: str):
        try:
            completed=subprocess.run(cmd, shell=True, capture_output=True, text=True, errors="replace")
            out=completed.stdout+completed.stderr
            if out:
                for line in out.splitlines(True):
                    try: self.queue.put_nowait(line)
                    except queue.Full: pass
            self._println(f"[Exit {completed.returncode}]")
        except Exception as e:
            self._println(f"[Error] {e}")

    # ---------- queue/console ----------
    @Slot()
    def _flush_queue(self):
        if self.queue.empty(): return
        buf=[]
        try:
            for _ in range(2048):
                buf.append(self.queue.get_nowait())
        except queue.Empty:
            pass
        self.console.moveCursor(QTextCursor.End)
        self.console.insertPlainText("".join(buf))
        if self.auto_scroll:
            self.console.moveCursor(QTextCursor.End)

    def _println(self, text: str):
        try: self.queue.put_nowait(text + ("\n" if not text.endswith("\n") else ""))
        except queue.Full: pass

# --------------------------------------------------------------------------------------
# Desktop canvas + camera
# --------------------------------------------------------------------------------------

class DesktopCanvas(QWidget):
    def __init__(self, t: Theme, cfg: Dict, size: QSize, parent=None):
        super().__init__(parent); self.t=t; self.cfg=cfg
        self.resize(size)
        self.term = TerminalCard(t, cfg, self)
        center = QPoint(size.width()//2, size.height()//2)
        self.term.move(center.x()-self.term.width()//2, center.y()-self.term.height()//2)
        # overlay cursor
        self.cursor_overlay = CursorOverlayCard(self, t)
        # on-screen keyboard (hidden by default—open via menu Tools)
        self.keyboard = None

    def sizeHint(self)->QSize: return self.size()

    def paintEvent(self, e):
        p=QPainter(self); p.setRenderHint(QPainter.Antialiasing)
        r=self.rect()
        g=QLinearGradient(r.topLeft(), r.bottomLeft())
        g.setColorAt(0.0, QColor(self.t.desktop_top))
        g.setColorAt(0.55, QColor(self.t.desktop_mid))
        g.setColorAt(1.0, QColor(self.t.desktop_top))
        p.fillRect(r, g)

        glow=QColor(self.t.edge_glow); glow.setAlphaF(0.18)
        p.setPen(glow)
        for i in range(14):
            rr=r.adjusted(10+i,10+i,-10-i,-10-i); p.drawRoundedRect(rr, 18, 18)

        vign=QColor(0,0,0,110); p.setPen(Qt.NoPen); p.setBrush(vign)
        path=QPainterPath(); path.addRect(r)
        inner=r.adjusted(30,30,-30,-30)
        ip=QPainterPath(); ip.addRoundedRect(QRectF(inner), 26, 26)
        p.drawPath(path.subtracted(ip))

    def request_focus_on(self, w: QWidget):
        parent=self.parentWidget()
        if parent and hasattr(parent, "center_on_widget"):
            parent.center_on_widget(w)

class CameraArea(QScrollArea):
    def __init__(self, content: DesktopCanvas, parent=None):
        super().__init__(parent)
        self.setWidget(content)
        self.setWidgetResizable(False)
        self.setFrameShape(QFrame.NoFrame)
        self.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)

    def center_on_widget(self, w: QWidget):
        if not w: return
        c=w.geometry().center()
        self.center_on_point(c)

    def center_on_point(self, pt: QPoint):
        cont=self.widget(); vw=self.viewport().size()
        x=max(0, min(pt.x() - vw.width()//2, cont.width() - vw.width()))
        y=max(0, min(pt.y() - vw.height()//2, cont.height() - vw.height()))
        self.horizontalScrollBar().setValue(x)
        self.verticalScrollBar().setValue(y)

    def pan(self, dx:int, dy:int):
        hs=self.horizontalScrollBar(); vs=self.verticalScrollBar()
        hs.setValue(max(hs.minimum(), min(hs.maximum(), hs.value()+dx)))
        vs.setValue(max(vs.minimum(), min(vs.maximum(), vs.value()+dy)))

# --------------------------------------------------------------------------------------
# Main window
# --------------------------------------------------------------------------------------

class Main(QMainWindow):
    def __init__(self, t: Theme, cfg: Dict):
        super().__init__(); self.t=t; self.cfg=cfg
        self.setWindowTitle(APP_NAME); self.resize(1200, 800)

        pal=self.palette()
        pal.setColor(QPalette.Window, QColor("#0a1430"))
        pal.setColor(QPalette.Base, QColor("#0a1430"))
        pal.setColor(QPalette.Text, QColor("#e6f0ff"))
        pal.setColor(QPalette.WindowText, QColor("#e6f0ff"))
        self.setPalette(pal)

        canvas_size=QSize(3600, 2200)
        self.canvas=DesktopCanvas(t, cfg, canvas_size, self)
        self.camera=CameraArea(self.canvas, self)
        self.setCentralWidget(self.camera)

        self._menu()
        self._shortcuts()

        QTimer.singleShot(0, lambda: self.camera.center_on_widget(self.canvas.term))
        self.camera.installEventFilter(self)
        self.canvas.term.moved.connect(self._term_moved)

    def _menu(self):
        bar=self.menuBar()
        f=bar.addMenu("&File")
        f.addAction("Open Script Root", lambda: open_in_os(SCRIPT_ROOT))
        f.addAction("Open Data Folder", lambda: open_in_os(DATASETS_DIR))
        f.addAction("Open Vision Cache", lambda: open_in_os(VISION_CACHE_DIR))
        f.addSeparator()
        q=QAction("Quit", self); q.setShortcut(QKeySequence.Quit); q.triggered.connect(self.close); f.addAction(q)

        v=bar.addMenu("&View")
        fs=QAction("Toggle Fullscreen (Alt+Enter)", self); fs.setShortcut("Alt+Return")
        fs.triggered.connect(self._toggle_fullscreen); v.addAction(fs)
        v.addAction("Focus on Terminal (F)", lambda: self.camera.center_on_widget(self.canvas.term))
        wrap=QAction("Toggle Word Wrap", self); wrap.setCheckable(True); wrap.setChecked(True)
        def _toggle_wrap():
            c=self.canvas.term.console
            if wrap.isChecked():
                c.setLineWrapMode(QPlainTextEdit.WidgetWidth)
                c.setWordWrapMode(QTextOption.WrapAtWordBoundaryOrAnywhere)
            else:
                c.setLineWrapMode(QPlainTextEdit.NoWrap)
        wrap.triggered.connect(_toggle_wrap)
        v.addAction(wrap)

        tools=bar.addMenu("&Tools")
        tools.addAction("Write Index Rebuild Hint", self._write_index_rebuild_hint)
        tools.addAction("Prune Datasets Now", self._prune_now)
        tools.addAction("Settings…", self._open_settings)
        tools.addSeparator()
        tools.addAction("Prompt Manager…", self._open_prompt_manager)
        tools.addSeparator()
        tools.addAction("Open On-screen Keyboard", self._open_keyboard)
        tools.addAction("Open Code Editor…", self._open_code_editor)
        tools.addSeparator()
        tools.addAction("Vision Demo: Click “Start”", self._vision_demo_click_start)

    def _open_settings(self):
        self.canvas.term._open_settings()

    def _open_prompt_manager(self):
        dlg=PromptManagerDialog(self.cfg, self)
        if dlg.exec()==QDialog.Accepted:
            self.cfg = dlg.values()
            save_config(self.cfg)
            # propagate updates
            self.canvas.term.cfg = self.cfg
            self.canvas.term.vision._model_default = self.cfg.get("vision",{}).get("model_default","llava:7b")
            self.canvas.term._println("[Info] Prompt Manager saved.")

    def _open_keyboard(self):
        if self.canvas.keyboard and self.canvas.keyboard.isVisible():
            self.canvas.keyboard.raise_(); return
        self.canvas.keyboard = KeyboardCard(self.t, self.canvas)
        self.canvas.keyboard.move(40, 40)
        self.canvas.keyboard.show()

    def _code_editor_source(self) -> str:
        # A small tabbed editor with line numbers using Tkinter (self-contained).
        # Saved to ./code_editor.py if not present.
        return r'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Agent Terminal Code Editor — tabbed, with line numbers (Tkinter)
import sys, os, tkinter as tk
from tkinter import ttk, filedialog, messagebox

class LineNumbers(tk.Canvas):
    def __init__(self, text, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.text = text
        self.text.bind('<Any-KeyPress>', self._update)
        self.text.bind('<Button-1>', self._update)
        self.text.bind('<MouseWheel>', self._update)
        self.text.bind('<KeyRelease>', self._update)

    def attach(self, text):
        self.text = text

    def _update(self, event=None):
        self.after(5, self.redraw)

    def redraw(self, *args):
        self.delete("all")
        i = self.text.index("@0,0")
        while True:
            dline = self.text.dlineinfo(i)
            if dline is None: break
            y = dline[1]
            linenum = str(i).split(".")[0]
            self.create_text(2, y, anchor="nw", text=linenum, fill="#8aa6c1")
            i = self.text.index(f"{i}+1line")

class EditorTab(ttk.Frame):
    def __init__(self, master, path=None):
        super().__init__(master)
        self.path = path
        self.text = tk.Text(self, wrap='none', undo=True, bg="#0b1828", fg="#e9f3ff", insertbackground="#e9f3ff")
        self.vsb = ttk.Scrollbar(self, orient="vertical", command=self.text.yview)
        self.hsb = ttk.Scrollbar(self, orient="horizontal", command=self.text.xview)
        self.text.configure(yscrollcommand=self.vsb.set, xscrollcommand=self.hsb.set)
        self.ln = LineNumbers(self.text, width=48, bg="#0c1320", highlightthickness=0)
        self.ln.pack(side="left", fill="y")
        self.text.pack(side="left", fill="both", expand=True)
        self.vsb.pack(side="right", fill="y")
        self.hsb.pack(side="bottom", fill="x")
        if self.path and os.path.exists(self.path):
            try:
                with open(self.path, "r", encoding="utf-8") as f:
                    self.text.insert("1.0", f.read())
            except Exception as e:
                messagebox.showerror("Open", str(e))
        self.text.bind("<<Modified>>", lambda e: self.ln.redraw())

    def save(self, path=None):
        p = path or self.path
        if not p:
            return False
        try:
            with open(p, "w", encoding="utf-8") as f:
                f.write(self.text.get("1.0", "end-1c"))
            self.path = p
            return True
        except Exception as e:
            messagebox.showerror("Save", str(e))
            return False

class CodeEditor(tk.Tk):
    def __init__(self, files):
        super().__init__()
        self.title("Agent Terminal Code Editor")
        self.geometry("1000x680")
        self.minsize(700, 450)
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(expand=1, fill='both')
        self.tabs = []
        menubar = tk.Menu(self)
        fmenu = tk.Menu(menubar, tearoff=0)
        fmenu.add_command(label="Open…", command=self.open_dialog)
        fmenu.add_command(label="Save", command=self.save_current)
        fmenu.add_command(label="Save As…", command=self.save_as)
        fmenu.add_separator()
        fmenu.add_command(label="Close Tab", command=self.close_current)
        fmenu.add_separator()
        fmenu.add_command(label="Exit", command=self.destroy)
        menubar.add_cascade(label="File", menu=fmenu)
        self.config(menu=menubar)
        for f in files: self.open_file(f)

    def current_tab(self):
        s = self.notebook.select()
        if not s: return None
        return self.nametowidget(s)

    def open_dialog(self):
        files = filedialog.askopenfilenames()
        for f in files: self.open_file(f)

    def open_file(self, path):
        tab = EditorTab(self.notebook, path)
        name = os.path.basename(path) if path else "untitled"
        self.notebook.add(tab, text=name)
        self.tabs.append(tab)

    def save_current(self):
        t = self.current_tab()
        if not t: return
        if not t.path:
            self.save_as()
            return
        ok = t.save(t.path)
        if ok:
            messagebox.showinfo("Saved", os.path.basename(t.path))

    def save_as(self):
        t = self.current_tab()
        if not t: return
        p = filedialog.asksaveasfilename()
        if not p: return
        if t.save(p):
            idx = self.notebook.index(t)
            self.notebook.tab(idx, text=os.path.basename(p))

    def close_current(self):
        t = self.current_tab()
        if not t: return
        self.notebook.forget(t)

if __name__ == "__main__":
    if len(sys.argv) >= 2:
        CodeEditor(sys.argv[1:]).mainloop()
    else:
        CodeEditor([]).mainloop()
'''

    def _open_code_editor(self):
        path = os.path.join(SCRIPT_ROOT, "code_editor.py")
        if not os.path.isfile(path):
            try:
                with open(path, "w", encoding="utf-8") as f:
                    f.write(self._code_editor_source())
            except Exception as e:
                QMessageBox.critical(self, "Code Editor", f"Failed to write editor: {e}")
                return
        # choose files to open
        files, _ = QFileDialog.getOpenFileNames(self, "Open files in Code Editor", SCRIPT_ROOT)
        args = [sys.executable, path] + files
        try:
            subprocess.Popen(args, cwd=SCRIPT_ROOT)
        except Exception as e:
            QMessageBox.critical(self, "Code Editor", f"Failed to launch editor: {e}")

    def _write_index_rebuild_hint(self):
        hint = (
            "INDEX_REBUILD_HINT:\n"
            "If the indexing dataset is missing or corrupted, ask your LLM:\n"
            "  \"Using the following Schema Index Template, regenerate a compact set of entries covering core commands\n"
            "   for CMD, PowerShell, Bash, WSL, and Python-REPL. Output as short, human-readable lines that can be\n"
            "   embedded as text into the indexing dataset. Use the pattern/examples style.\"\n\n"
            "Schema Index Template:\n" + SCHEMA_INDEX_TEMPLATE
        )
        emb=self.cfg.get("embedding_model", DEFAULT_CONFIG["embedding_model"])
        VectorStore("indexing", emb, self.cfg).add_text(hint, {"type":"howto"})
        QMessageBox.information(self, "Indexing", "Rebuild hint written to indexing dataset (./datasets).")

    def _prune_now(self):
        emb=self.cfg.get("embedding_model", DEFAULT_CONFIG["embedding_model"])
        for name in ["sem_user","sem_ai","indexing","prompting","learning","self_prompting"]:
            VectorStore(name, emb, self.cfg)._maybe_prune()
        QMessageBox.information(self, "Datasets", "Pruning pass completed.")

    def _shortcuts(self):
        self.addAction(self._mk_action("Ctrl+Left",  lambda: self.camera.pan(-160, 0)))
        self.addAction(self._mk_action("Ctrl+Right", lambda: self.camera.pan(+160, 0)))
        self.addAction(self._mk_action("Ctrl+Up",    lambda: self.camera.pan(0, -160)))
        self.addAction(self._mk_action("Ctrl+Down",  lambda: self.camera.pan(0, +160)))
        self.addAction(self._mk_action("Ctrl+Home",  lambda: self.camera.center_on_widget(self.canvas.term)))
        self.addAction(self._mk_action("F",          lambda: self.camera.center_on_widget(self.canvas.term)))

    def _mk_action(self, shortcut: str, fn):
        a=QAction(self); a.setShortcut(QKeySequence(shortcut)); a.triggered.connect(fn); return a

    def _toggle_fullscreen(self):
        if self.isFullScreen(): self.showNormal()
        else: self.showFullScreen()
        QTimer.singleShot(0, lambda: self.camera.center_on_widget(self.canvas.term))

    def eventFilter(self, obj, ev):
        if obj is self.camera and ev.type()==QEvent.Resize:
            QTimer.singleShot(0, lambda: self.camera.center_on_widget(self.canvas.term))
        return super().eventFilter(obj, ev)

    def _term_moved(self):
        if self.canvas.term.pin_btn.isChecked():
            self.camera.center_on_widget(self.canvas.term)

    # ---------- Vision demo: find "Start" in Terminal header and click ----------
    def _vision_demo_click_start(self):
        term = self.canvas.term
        header = term.findChild(QFrame, "Hdr")
        if not header:
            QMessageBox.warning(self, "Vision Demo", "Terminal header not found.")
            return
        png = term.vision.capture_widget(header)
        if not png:
            QMessageBox.warning(self, "Vision Demo", "Failed to capture header.")
            return
        model = self.cfg.get("ai_points",{}).get("vision.locate.ui",{}).get("model", self.cfg.get("vision",{}).get("model_default","llava:7b"))
        result = term.vision.ocr_locate_text(png, "Start", model=model, within="terminal_header")
        blocks = result.get("blocks", [])
        if not blocks:
            QMessageBox.information(self, "Vision Demo", "No 'Start' found via OCR.")
            return
        # choose best (highest score)
        blocks.sort(key=lambda b: b.get("score",0), reverse=True)
        x,y,w,h = blocks[0].get("bbox",[0,0,0,0])
        # map to canvas coords: header geometry in canvas, then offset
        header_pos = header.mapTo(self.canvas, QPoint(0,0))
        cx = header_pos.x() + int(x + w/2)
        cy = header_pos.y() + int(y + h/2)
        target_pt = QPoint(cx, cy)
        # animate cursor and click
        self.canvas.cursor_overlay.animate_to(target_pt, steps=12)
        self.canvas.cursor_overlay.synth_click(self, button=Qt.LeftButton)

# --------------------------------------------------------------------------------------
# Entry
# --------------------------------------------------------------------------------------

def main():
    # MUST be set before QGuiApplication
    QGuiApplication.setHighDpiScaleFactorRoundingPolicy(Qt.HighDpiScaleFactorRoundingPolicy.PassThrough)
    os.environ.setdefault("QT_ENABLE_HIGHDPI_SCALING","1")
    os.environ.setdefault("QT_SCALE_FACTOR_ROUNDING_POLICY","PassThrough")

    app=QApplication(sys.argv)
    cfg=load_config()
    for k,v in DEFAULT_CONFIG.items(): cfg.setdefault(k,v)
    save_config(cfg)

    t=Theme()
    win=Main(t, cfg); win.show()
    sys.exit(app.exec())

if __name__=="__main__":
    main()
```

Agent Terminal — Camera + Language→Commands + RAG + Context History + Vision/OCR + Cursor/Keyboard (v6)

What’s in v6 (everything wired up):
- Data lives in script root: ./datasets (JSONL vector stores) + ./config.json + ./vision_cache.
- Word wrap ON by default (View ▸ Toggle Word Wrap).
- Buttons, checkboxes, toolbuttons, and combos have bright text on dark UI.
- Identity: System prompt says you are Agent Terminal (not ChatGPT) + runtime identity guard.
- Chat / Shell / Chat+Shell lifecycle exactly as specified; L→C is a checkbox.
- Right-click “Run Suggestion” runs the last fenced block.
- Conversation Context dataset with adjustable depth (None / Fixed / All) used to build chat messages.
- Dual storage each turn: (1) raw context history pairs; (2) semantic vectors (user, ai, etc.) for RAG.
- VectorStore pruning/rotation (size/records with “keep tail”); Tools ▸ Prune Datasets Now.
- Index rebuild hint tool and Schema Index Template in Settings.
- Resizable terminal card from all four corners (QSizeGrips).
- Camera desktop with Ctrl+Arrow pan, F/Ctrl+Home focus, and “Track” pin.
- Vision/OCR service via local Ollama (llava/nanonets/gemma3 vision), ephemeral cache + TTL pruning.
- Cursor overlay the agent can move/click; On-screen keyboard card (focus-target typing).
- Prompt Manager dialog: edit prompts, list ALL AI intersection points, choose per-point models (vision+text).
- Tools ▸ Vision Demo: OCR locate “Start” in Terminal header and click it via overlay cursor.
- Tools ▸ Open Code Editor… (bootstraps a working editor file if missing, then launches it).

Keybindings
  Alt+Enter     : toggle fullscreen
  F, Ctrl+Home  : focus camera on terminal
  Ctrl+Arrows   : pan the camera
  Enter         : send; Ctrl+L clear console; Up/Down recall history
**Classes:** Theme, VectorStore, ContextHistory, VisionService, TermHighlighter, MovableCard, CursorOverlayCard, KeyboardCard, PromptManagerDialog, SettingsDialog, TerminalCard, DesktopCanvas, CameraArea, Main
**Functions:** open_in_os(path), _requests(), find_git_bash(), nl_for_env(env), human_size(num_bytes), timestamp(), load_config(), save_config(cfg), cosine_sim(a, b), main()


## Module `Dev_Logic\Implemented_logic\Chatbot_Agent.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OllamaMiniChat.py
=================
A compact yet capable PyQt5 chat client for **local Ollama** models and **OpenAI** models
with *real-time* streaming text & code, colorful syntax blocks, prompt manager, upload manager,
rolling timing logs, persistent mini-RAG dataset, Zira TTS, a generated Markdown API/README,
and a slim live system log.

Key features
------------
• Providers: **Ollama** (default) and **OpenAI**. Model dropdown updates per provider.
• Real-Time streaming (FAST) for plain text and fenced ```code``` blocks (validated languages).
  - While streaming, code is shown in a “floating terminal” container expanded to full script height.
  - On completion, code blocks auto-minimize (can be expanded by user).
  - Text stream renders live as well (char-wise), with optional metallic <think> styling.
• Colorful code via **Pygments** (Monokai). Emojis on badges.
• Non-semantic and semantic history:
  - Visible (session-only) history to avoid artifacts in displayed text.
  - Persistent dataset of the last **N pairs** (slider; default 10), with rolling file and priority taper.
• Timing logs:
  - Default vs Real-Time averages shown; logs capped to 100 entries (rolling).
  - “Reset Averages” button + optional reset during “Clear Chat”.
• TTS (Windows SAPI5 via **pyttsx3**) using **Microsoft Zira**, **150%** speed by default.
  - Auto-reads **assistant responses only**, in order, no gaps. Stop at any time.
  - Speed slider persisted across sessions in Settings.
• Upload Manager:
  - Paste/drag/drop or browse files/folders; icons for text/code, images, folders.
  - Recursively ingests folders (skips __pycache__, venv*/.venv*, large junk); keeps .git.
  - Simple “tag-and-bucket” enrichment (no vectors), stored in /data/uploads.
  - Per-file progress bars driven via Qt Signals (no hanging).
  - “Clear Uploaded Knowledge” button to purge.
• Prompt Manager:
  - Remove the big system prompt from the main window.
  - Manage named prompts (add/edit/delete*), reorder, check multiple to include in system preamble.
    (*Default prompt cannot be deleted; it can be toggled off.)
• Smarter prompting:
  - Preamble includes (in order): checked prompts, then light summary of older pairs, then
    visible recent pairs (tapered), emphasizing the current user message.
• API / README generator:
  - Button generates **Chat_Agent_API.md** and **README.generated.md** in /data/docs from code,
    scanning @api_expose functions and docstrings. Pop-up viewer with “Copy” button.
• UX niceties:
  - Smoky gray theme, high contrast text, improved professional typography.
  - Top black slim **System Log** ticker + on-disk logs (cleared on startup).
  - Auto-scroll toggle (ON by default) so you can scroll during streaming without snap-back.
  - Provider+Model label inside each response card: **[Provider][model] →** line above content.
  - Enter in the input sends the message (QLineEdit).
• Robust error pop-ups; unhandled exceptions are intercepted and shown.

Install
-------
    pip install pyqt5 requests pyperclip pygments pyttsx3

Run
---
    ollama serve   # if using Ollama
    python OllamaMiniChat.py
"""

# ---------- Standard imports ----------
import os, sys, re, json, time, threading, traceback, queue, ctypes, base64
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, List, Tuple, Dict
from datetime import datetime, timezone

import requests
import pyperclip

# ---------- Qt imports ----------
from PyQt5.QtCore import Qt, QTimer, QSize, pyqtSignal, QObject, QEvent
from PyQt5.QtGui import (
    QFont, QColor, QTextCharFormat, QSyntaxHighlighter, QIcon,
    QKeySequence
)
from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QHBoxLayout, QScrollArea, QPlainTextEdit,
    QLabel, QPushButton, QLineEdit, QComboBox, QFrame, QCheckBox,
    QTextEdit, QSizeGrip, QFileDialog, QProgressBar, QMessageBox, QDialog,
    QListWidget, QListWidgetItem, QTabWidget, QFormLayout, QSpinBox, QTextBrowser
)

# ---------- Optional Pygments ----------
try:
    from pygments import highlight
    from pygments.lexers import get_lexer_by_name, guess_lexer
    from pygments.formatters import HtmlFormatter
    HAVE_PYGMENTS = True
except Exception:
    HAVE_PYGMENTS = False

# ---------- Constants / Paths ----------
APP_NAME = "Ollama Mini Chat"
ROOT = Path(__file__).resolve().parent
DATA_DIR = ROOT / "data"
DOCS_DIR = DATA_DIR / "docs"
LOGS_DIR = DATA_DIR / "logs"
PROMPTS_DIR = DATA_DIR / "prompts"
DATASETS_DIR = DATA_DIR / "datasets"
UPLOADS_DIR = DATA_DIR / "uploads"

VISIBLE_HISTORY_FILE = DATA_DIR / "visible_history.txt"  # session-only; cleared on start
DATASET_JSONL = DATASETS_DIR / "chat_pairs.jsonl"       # rolling persistent dataset
UPLOAD_INDEX_JSON = UPLOADS_DIR / "index.json"          # uploaded items metadata (tags only)
PROMPTS_INDEX_JSON = PROMPTS_DIR / "index.json"         # prompt list/order/checked
TIMINGS_LOG = LOGS_DIR / "timings.log"                  # rolling timings up to 100 rows
SYSTEM_LOG = LOGS_DIR / "system.log"                    # cleared each start
OPENAI_KEY_FILE = DATA_DIR / "openai_key.bin"           # encrypted with DPAPI (Windows) else b64

DEFAULT_PROVIDER = "Ollama"
DEFAULT_MODEL = "gpt-oss:20b"
DEFAULT_EMBEDDER = "snowflake-arctic-embed2:latest"

# ---------- Theming ----------
SMOKY_BG = "#2E2E2E"
CARD_INDIGO = "#3b3552"
USER_BLUE = "#0f3e5e"
DEEP_PURPLE = "#40395f"
SOFT_PURPLE = "#4a416b"
SOFT_TEXT = "#e6e6f0"
MUTED_TEXT = "#cfd1da"
BLACK = "#000000"

SMALL_BUTTON = (
    "QPushButton {background:#EEE;border:1px solid #AAA;color:#111;padding:2px 6px;"
    "font-size:10px;border-radius:6px;} QPushButton:hover {background:#f7f7f7;}"
)
PRIMARY_BUTTON = (
    "QPushButton {background:#ADD8E6;border:1px solid #CCC;color:#000;padding:4px 10px;"
    "font-size:11px;border-radius:10px;} QPushButton:hover {background:#B0E0E6;}"
)
BADGE_STYLE = (
    "QLabel { background: #2d2d30; color: #e5e5e5; border: 1px solid #3b3b3f;"
    "padding: 2px 6px; border-radius: 6px; font: 10px 'Segoe UI'; }"
)

# ---------- Helpers: system log ----------
def ensure_dirs():
    for p in [DATA_DIR, DOCS_DIR, LOGS_DIR, PROMPTS_DIR, DATASETS_DIR, UPLOADS_DIR]:
        p.mkdir(parents=True, exist_ok=True)

def now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()

def log_line(msg: str):
    """Append to system log and print to console."""
    line = f"[{datetime.now().strftime('%H:%M:%S')}] {msg}"
    print(line)
    with SYSTEM_LOG.open("a", encoding="utf-8") as f:
        f.write(line + "\n")

# ---------- Windows DPAPI encryption (fallback to base64 on non-Windows) ----------
def _win_protect(plaintext: str) -> bytes:
    class DATA_BLOB(ctypes.Structure):
        _fields_ = [("cbData", ctypes.c_uint), ("pbData", ctypes.POINTER(ctypes.c_ubyte))]
    CRYPTPROTECT_LOCAL_MACHINE = 0x04
    data = plaintext.encode("utf-8")
    blob_in = DATA_BLOB(len(data), ctypes.cast(ctypes.create_string_buffer(data), ctypes.POINTER(ctypes.c_ubyte)))
    blob_out = DATA_BLOB()
    crypt32 = ctypes.windll.crypt32
    kernel32 = ctypes.windll.kernel32
    if not crypt32.CryptProtectData(ctypes.byref(blob_in), None, None, None, None, CRYPTPROTECT_LOCAL_MACHINE, ctypes.byref(blob_out)):
        raise OSError("CryptProtectData failed")
    try:
        out = ctypes.string_at(blob_out.pbData, blob_out.cbData)
    finally:
        kernel32.LocalFree(blob_out.pbData)
    return out

def _win_unprotect(cipher: bytes) -> str:
    class DATA_BLOB(ctypes.Structure):
        _fields_ = [("cbData", ctypes.c_uint), ("pbData", ctypes.POINTER(ctypes.c_ubyte))]
    blob_in = DATA_BLOB(len(cipher), ctypes.cast(ctypes.create_string_buffer(cipher), ctypes.POINTER(ctypes.c_ubyte)))
    blob_out = DATA_BLOB()
    crypt32 = ctypes.windll.crypt32
    kernel32 = ctypes.windll.kernel32
    if not crypt32.CryptUnprotectData(ctypes.byref(blob_in), None, None, None, None, 0, ctypes.byref(blob_out)):
        raise OSError("CryptUnprotectData failed")
    try:
        out = ctypes.string_at(blob_out.pbData, blob_out.cbData)
    finally:
        kernel32.LocalFree(blob_out.pbData)
    return out.decode("utf-8", errors="ignore")

def save_openai_key(key: str):
    try:
        if sys.platform.startswith("win"):
            enc = _win_protect(key)
        else:
            enc = base64.urlsafe_b64encode(key.encode("utf-8"))
        with OPENAI_KEY_FILE.open("wb") as f:
            f.write(enc)
        log_line("OpenAI API key saved.")
    except Exception as e:
        log_line(f"Failed to save OpenAI key: {e}")

def load_openai_key() -> str:
    if not OPENAI_KEY_FILE.exists():
        return ""
    try:
        data = OPENAI_KEY_FILE.read_bytes()
        if sys.platform.startswith("win"):
            return _win_unprotect(data)
        else:
            return base64.urlsafe_b64decode(data).decode("utf-8", errors="ignore")
    except Exception as e:
        log_line(f"Failed to load OpenAI key: {e}")
        return ""

# ---------- Pygments integration ----------
VALID_LANGS = {
    # web
    "html","xml","css","javascript","js","typescript","ts","json","yaml","yml","markdown","md",
    # python & data
    "python","py","ipython","sqlite","sql","ini","toml",
    # c/c++/rust/go
    "c","cpp","c++","hpp","h","rust","rs","go",
    # java/kotlin/scala
    "java","kotlin","kt","scala",
    # .net
    "csharp","cs","fsharp","vbnet",
    # shell & powershell
    "bash","sh","zsh","fish","powershell","ps1","cmd","bat",
    # scripting
    "lua","perl","ruby","rb","php","r",
    # devops
    "docker","dockerfile","make","cmake",
    # GPU
    "cuda","cu","metal","opencl",
    # others
    "swift","objective-c","objc","matlab","octave",
}

def safe_lang(lang: Optional[str]) -> Optional[str]:
    if not lang:
        return None
    lang = lang.strip().lower()
    return lang if lang in VALID_LANGS else None

def pygments_html(code: str, lang: Optional[str]) -> str:
    if not HAVE_PYGMENTS:
        return "<pre style='white-space:pre-wrap; font-family:Consolas,monospace; font-size:12px;'>" + \
               (code.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")) + "</pre>"
    try:
        lexer = get_lexer_by_name(lang) if lang else guess_lexer(code)
    except Exception:
        return "<pre style='white-space:pre-wrap; font-family:Consolas,monospace; font-size:12px;'>" + \
               (code.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")) + "</pre>"
    formatter = HtmlFormatter(style="monokai", noclasses=True)
    return highlight(code, lexer, formatter)

# ---------- Optional Python-only fallback highlighter (unused in final code widgets) ----------
class PythonHighlighter(QSyntaxHighlighter):
    KEYWORDS = {
        "def","class","if","elif","else","while","for","try","except","finally",
        "with","as","import","from","return","pass","break","continue","in",
        "not","and","or","is","lambda","yield","raise","assert","global","nonlocal"
    }
    def __init__(self, doc):
        super().__init__(doc)
        self.fmt_kw = QTextCharFormat(); self.fmt_kw.setForeground(QColor("#569CD6"))
        self.fmt_str = QTextCharFormat(); self.fmt_str.setForeground(QColor("#CE9178"))
        self.fmt_cmt = QTextCharFormat(); self.fmt_cmt.setForeground(QColor("#6A9955"))
        self.fmt_num = QTextCharFormat(); self.fmt_num.setForeground(QColor("#B5CEA8"))
        self.fmt_dec = QTextCharFormat(); self.fmt_dec.setForeground(QColor("#C586C0"))
        self.fmt_fn = QTextCharFormat(); self.fmt_fn.setForeground(QColor("#DCDCAA"))
        self.simple_rules = [(re.compile(rf"\b{kw}\b"), self.fmt_kw) for kw in self.KEYWORDS] + [
            (re.compile(r'".*?"'), self.fmt_str),
            (re.compile(r"'.*?'"), self.fmt_str),
            (re.compile(r"#.*"), self.fmt_cmt),
            (re.compile(r"\b\d+(\.\d+)?\b"), self.fmt_num),
            (re.compile(r"@\w+"), self.fmt_dec),
        ]
    def highlightBlock(self, text: str):
        for rx, fmt in self.simple_rules:
            for m in rx.finditer(text):
                self.setFormat(m.start(), m.end()-m.start(), fmt)
        for m in re.finditer(r"\bdef\s+(\w+)", text):
            self.setFormat(m.start(1), len(m.group(1)), self.fmt_fn)
        for m in re.finditer(r"\bclass\s+(\w+)", text):
            self.setFormat(m.start(1), len(m.group(1)), self.fmt_fn)

# ---------- Timing logger ----------
class TimingLog:
    """
    Rolling timing log of up to 100 rows across both modes.
    Each row: {"ts": ISO, "mode": "default"|"realtime", "ms": float}
    """
    def __init__(self, path: Path):
        self.path = path
        self.rows: List[Dict] = []
        if self.path.exists():
            try:
                self.rows = [json.loads(l) for l in self.path.read_text(encoding="utf-8").splitlines() if l.strip()]
            except Exception:
                self.rows = []
        self.clean_start()

    @api_expose := (lambda f: f)  # simple marker for API scanner; decorated later properly
    def clean_start(self):
        LOGS_DIR.mkdir(parents=True, exist_ok=True)
        # clear system log on startup
        SYSTEM_LOG.write_text("", encoding="utf-8")

    def add(self, mode: str, ms: float):
        self.rows.append({"ts": now_iso(), "mode": mode, "ms": ms})
        # keep 100
        if len(self.rows) > 100:
            self.rows = self.rows[-100:]
        try:
            with self.path.open("w", encoding="utf-8") as f:
                for r in self.rows:
                    f.write(json.dumps(r, ensure_ascii=False) + "\n")
        except Exception as e:
            log_line(f"TimingLog write failed: {e}")

    def averages(self) -> Tuple[float,float]:
        d = [r["ms"] for r in self.rows if r.get("mode") == "default"]
        s = [r["ms"] for r in self.rows if r.get("mode") == "realtime"]
        d_avg = sum(d)/len(d) if d else 0.0
        s_avg = sum(s)/len(s) if s else 0.0
        return d_avg, s_avg

    def reset(self):
        self.rows = []
        try:
            self.path.write_text("", encoding="utf-8")
        except Exception:
            pass

# ---------- Dataset manager ----------
class DatasetManager:
    """
    Keeps a rolling JSONL dataset of user/assistant pairs (persistent),
    plus a session-only visible history file to ensure clean display (no artifacts).
    """
    def __init__(self, jsonl_path: Path, visible_path: Path, limit_pairs: int = 10):
        self.jsonl_path = jsonl_path
        self.visible_path = visible_path
        self.limit = limit_pairs
        DATASETS_DIR.mkdir(parents=True, exist_ok=True)
        # session visible history wiped on start
        self.visible_path.write_text("", encoding="utf-8")
        if not self.jsonl_path.exists():
            self.jsonl_path.touch()

    def set_limit(self, n: int):
        self.limit = max(1, int(n))

    def append_visible(self, line: str):
        with self.visible_path.open("a", encoding="utf-8") as f:
            f.write(line + "\n")

    def append_pair(self, user: str, assistant: str):
        rows = []
        if self.jsonl_path.exists():
            rows = [json.loads(l) for l in self.jsonl_path.read_text(encoding="utf-8").splitlines() if l.strip()]
        rows.append({"ts": now_iso(), "user": user, "assistant": assistant})
        if len(rows) > self.limit:
            rows = rows[-self.limit:]
        with self.jsonl_path.open("w", encoding="utf-8") as f:
            for r in rows:
                f.write(json.dumps(r, ensure_ascii=False) + "\n")

    def load_pairs(self) -> List[Dict]:
        if not self.jsonl_path.exists():
            return []
        try:
            return [json.loads(l) for l in self.jsonl_path.read_text(encoding="utf-8").splitlines() if l.strip()]
        except Exception:
            return []

    def clear_all(self):
        self.jsonl_path.write_text("", encoding="utf-8")
        self.visible_path.write_text("", encoding="utf-8")

# ---------- Upload manager (signals for thread-safe) ----------
class UploadSignals(QObject):
    item_started = pyqtSignal(str, str)       # item_id, label
    progress = pyqtSignal(str, int)           # item_id, percent
    item_done = pyqtSignal(str)               # item_id
    item_error = pyqtSignal(str, str)         # item_id, message
    refresh_view = pyqtSignal()

class UploadedKnowledge:
    """
    Simple tag-and-bucket store (no vectors). Each item:
    {"id": "...", "type": "file|image|folder", "path": "...", "tags": [...], "ts": ...}
    """
    def __init__(self, index_path: Path, signals: UploadSignals):
        self.index_path = index_path
        self.signals = signals
        self.items: Dict[str, Dict] = {}
        UPLOADS_DIR.mkdir(parents=True, exist_ok=True)
        if self.index_path.exists():
            try:
                self.items = json.loads(self.index_path.read_text(encoding="utf-8"))
            except Exception:
                self.items = {}

    def save(self):
        try:
            with self.index_path.open("w", encoding="utf-8") as f:
                json.dump(self.items, f, ensure_ascii=False, indent=2)
        except Exception as e:
            log_line(f"Upload index save failed: {e}")

    def clear(self):
        self.items = {}
        self.save()

    def ingest_paths(self, paths: List[Path]):
        """
        Handle ingestion on a background thread; emit signals to update UI.
        """
        def worker():
            try:
                for p in paths:
                    if p.is_dir():
                        self._ingest_folder(p)
                    else:
                        self._ingest_file(p)
            except Exception as e:
                self.signals.item_error.emit("batch", str(e))
            finally:
                self.signals.refresh_view.emit()
        threading.Thread(target=worker, daemon=True).start()

    def _ingest_folder(self, folder: Path):
        item_id = f"folder:{folder.name}:{int(time.time())}"
        self.signals.item_started.emit(item_id, f"Folder: {folder}")
        self.items[item_id] = {"id":item_id,"type":"folder","path":str(folder),"tags":[folder.name],"ts":now_iso()}
        count=0
        for root, dirs, files in os.walk(folder):
            # skip junk
            dirs[:] = [d for d in dirs if d not in ("__pycache__",) and not d.lower().startswith(("venv",".venv"))]
            for name in files:
                f = Path(root) / name
                # include .git and everything else
                self._ingest_file(f, parent=item_id, silent=True)
                count+=1
                pct = min(100, int((count % 200) / 2))  # lightweight fake progress
                self.signals.progress.emit(item_id, pct)
        self.signals.progress.emit(item_id, 100)
        self.signals.item_done.emit(item_id)
        self.save()

    def _ingest_file(self, file: Path, parent: Optional[str]=None, silent: bool=False):
        ftype = "image" if file.suffix.lower() in (".png",".jpg",".jpeg",".gif",".webp") else "file"
        item_id = f"{ftype}:{file.name}:{int(time.time()*1000)%100000000}"
        if not silent:
            self.signals.item_started.emit(item_id, f"{ftype.title()}: {file}")
        tags = [file.suffix.lower().lstrip("."), file.name]
        snippet = ""
        if ftype == "file":
            try:
                snippet = file.read_text(encoding="utf-8", errors="ignore")[:4000]
            except Exception:
                snippet = ""
        self.items[item_id] = {
            "id": item_id,
            "type": ftype,
            "path": str(file),
            "tags": tags,
            "ts": now_iso(),
            "parent": parent,
            "snippet": snippet,
        }
        # fake quick progress animation
        for pct in (10,35,65,85,100):
            time.sleep(0.02)
            self.signals.progress.emit(item_id, pct)
        self.signals.item_done.emit(item_id)
        self.save()

    def as_context_snippets(self, limit: int = 8) -> List[str]:
        """Return short name+snippet strings for system prompt inclusion."""
        snippets = []
        for it in list(self.items.values())[-limit:]:
            name = Path(it.get("path", "")).name
            snip = it.get("snippet", "").strip()
            if snip:
                snippets.append(f"### {name}\n{snip}")
        return snippets

# ---------- TTS Manager ----------
class TTSManager:
    def __init__(self):
        self._engine = None
        self._thread: Optional[threading.Thread] = None
        self._available = False
        self._rate_slider_value = 150  # percent default
        try:
            import pyttsx3
            self._engine = pyttsx3.init(driverName="sapi5")
            # choose Zira if exists
            zira = None
            for v in self._engine.getProperty("voices"):
                if "Zira" in v.name:
                    zira = v.id; break
            if zira:
                self._engine.setProperty("voice", zira)
            # set 150%
            base = self._engine.getProperty("rate") or 200
            self._engine.setProperty("rate", int(base * (self._rate_slider_value/100.0)))
            self._available = True
        except Exception:
            self._engine = None
            self._available = False

    def set_rate_percent(self, pct: int):
        self._rate_slider_value = max(50, min(300, int(pct)))
        if self._engine:
            try:
                base = self._engine.getProperty("rate") or 200
                self._engine.setProperty("rate", int(base * (self._rate_slider_value/100.0)))
            except Exception:
                pass

    def speak_async(self, text: str):
        if not (self._available and self._engine and text.strip()):
            return
        self.stop()
        def run():
            try:
                self._engine.say(text)
                self._engine.runAndWait()
            except Exception:
                pass
        self._thread = threading.Thread(target=run, daemon=True)
        self._thread.start()

    def stop(self):
        try:
            if self._engine:
                self._engine.stop()
        except Exception:
            pass

# ---------- API/README generator ----------
def api_expose(fn):
    """Decorator marker for functions we want to list in API docs."""
    fn._api_exposed = True
    return fn

def generate_api_docs(out_md: Path, readme_md: Path):
    """
    Scans this module for functions/classes with @api_expose and docstrings,
    emitting a Markdown API surface + a quickstart README.
    """
    import inspect
    lines = ["# Chat Agent API\n", "_Auto-generated from source._\n"]
    for name, obj in sorted(globals().items()):
        if callable(obj) and getattr(obj, "_api_exposed", False):
            doc = inspect.getdoc(obj) or "(no docstring)"
            sig = ""
            try:
                sig = str(inspect.signature(obj))
            except Exception:
                pass
            lines.append(f"## `{name}{sig}`\n")
            lines.append(doc + "\n")
    out_md.write_text("\n".join(lines), encoding="utf-8")

    # README with structure summary
    readme = [
        "# Ollama Mini Chat — Generated README",
        "",
        "This document was generated by scanning the code. It outlines high-level structure and extension points.",
        "",
        "## Providers",
        "- **Ollama** via `http://localhost:11434/api/generate` and `/api/embeddings`.",
        "- **OpenAI** via `https://api.openai.com/v1/chat/completions`.",
        "",
        "## Streaming",
        "Text and code are streamed into the UI with character timers for smooth animation.",
        "",
        "## Prompting",
        "Prompts are managed in `/data/prompts`. Multiple prompts can be checked and re-ordered; all checked prompts are concatenated into the system preamble.",
        "",
        "## Dataset",
        "Rolling JSONL of the last N user/assistant pairs, with session-visible history separated to keep display clean.",
        "",
        "## Uploads",
        "Simple tag-and-bucket store (no vectors) in `/data/uploads`. Folders are ingested recursively.",
        "",
        "## TTS",
        "Windows SAPI5 Zira voice at a configurable percent rate.",
        "",
        "## Integration",
        "Use the `@api_expose`-decorated functions as stable entry points when embedding this agent into other systems.",
    ]
    readme_md.write_text("\n".join(readme), encoding="utf-8")

# ---------- Provider backends ----------
class ProviderBackend:
    def list_models(self) -> List[str]:
        return []
    def chat(self, model: str, system_preamble: str, user_text: str, history: List[Dict], stream: bool):
        raise NotImplementedError
    def embeddings(self, model: str, text: str) -> Optional[List[float]]:
        return None

class OllamaBackend(ProviderBackend):
    base = "http://localhost:11434"
    def list_models(self) -> List[str]:
        try:
            out = os.popen("ollama list").read().strip().splitlines()
            # Skip header
            models = []
            for line in out[1:]:
                parts = line.split()
                if parts:
                    models.append(parts[0])
            if not models:
                models = [DEFAULT_MODEL]
            return models
        except Exception:
            return [DEFAULT_MODEL]

    def chat(self, model: str, system_preamble: str, user_text: str, history: List[Dict], stream: bool):
        # For simplicity, fold prompts + history into one prompt string
        full = system_preamble + "\n\n"
        for pair in history:
            full += f"User: {pair['user']}\nAssistant: {pair['assistant']}\n"
        full += f"User: {user_text}\nAssistant:"
        payload = {"model": model, "prompt": full, "stream": stream}
        url = f"{self.base}/api/generate"
        r = requests.post(url, json=payload, timeout=300, stream=stream)
        r.raise_for_status()
        if stream:
            for line in r.iter_lines(decode_unicode=True):
                if not line:
                    continue
                try:
                    j = json.loads(line)
                except Exception:
                    continue
                if "response" in j:
                    yield j["response"]
                if j.get("done"):
                    break
        else:
            j = r.json()
            yield j.get("response", "")

    def embeddings(self, model: str, text: str) -> Optional[List[float]]:
        try:
            r = requests.post(f"{self.base}/api/embeddings",
                              json={"model": model, "prompt": text},
                              timeout=60)
            r.raise_for_status()
            return r.json().get("embedding")
        except Exception:
            return None

class OpenAIBackend(ProviderBackend):
    def __init__(self, api_key: str):
        self.api_key = api_key

    def list_models(self) -> List[str]:
        if not self.api_key:
            return []
        try:
            r = requests.get("https://api.openai.com/v1/models",
                             headers={"Authorization": f"Bearer {self.api_key}"}, timeout=30)
            r.raise_for_status()
            data = r.json()
            ids = sorted([m["id"] for m in data.get("data", [])])
            # Heuristic: show chat-friendly models first
            ids = [m for m in ids if any(x in m for x in ("gpt","o4","o3","chat"))] or ids
            return ids
        except Exception:
            return []

    def chat(self, model: str, system_preamble: str, user_text: str, history: List[Dict], stream: bool):
        if not self.api_key:
            yield "⚠️ OpenAI API key not set in Settings."
            return
        messages = [{"role":"system","content":system_preamble}]
        for pair in history:
            messages.append({"role":"user","content":pair["user"]})
            messages.append({"role":"assistant","content":pair["assistant"]})
        messages.append({"role":"user","content":user_text})
        payload = {"model": model, "messages": messages, "stream": stream, "temperature": 0.3}
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type":"application/json"}
        url = "https://api.openai.com/v1/chat/completions"
        r = requests.post(url, headers=headers, json=payload, stream=stream, timeout=600)
        r.raise_for_status()
        if stream:
            for raw in r.iter_lines(decode_unicode=True):
                if not raw:
                    continue
                if raw.startswith("data: "):
                    raw = raw[6:].strip()
                if raw == "[DONE]":
                    break
                try:
                    j = json.loads(raw)
                except Exception:
                    continue
                delta = j["choices"][0]["delta"]
                if "content" in delta:
                    yield delta["content"]
        else:
            j = r.json()
            content = j["choices"][0]["message"]["content"]
            yield content

# ---------- Code block container ----------
class CodeBlockContainer(QWidget):
    """
    Floating code container:
    - language badge + emoji
    - copy, expand/collapse
    - dynamic height growth to show **entire script while streaming**
      (then auto-minimize when finished)
    """
    DEFAULT_MIN = 180
    MAX_LIVE = 6000  # generous upper bound for live-expanded height
    finished = pyqtSignal()

    def __init__(self, language: Optional[str], start_expanded=True, parent=None):
        super().__init__(parent)
        self.language = language
        self._expanded = start_expanded
        self.main_scroll: Optional[QScrollArea] = None

        outer = QVBoxLayout(self)
        outer.setContentsMargins(0, 6, 0, 10)
        outer.setSpacing(4)

        frame = QFrame(self)
        frame.setObjectName("codeContainer")
        frame.setStyleSheet(
            "QFrame#codeContainer {background:#1e1e1e; border-radius:8px; border:1px solid #2a2a2a;}"
        )
        v = QVBoxLayout(frame); v.setContentsMargins(10,10,10,4); v.setSpacing(6)

        header = QHBoxLayout(); header.setSpacing(8)
        emoji = "🐍" if (self.language in ("python","py")) else ("🧩" if self.language else "💻")
        lang_text = (self.language or "code").upper()
        self.badge = QLabel(f"{emoji} {lang_text}"); self.badge.setStyleSheet(BADGE_STYLE)
        header.addWidget(self.badge); header.addStretch(1)
        self.btn_copy = QPushButton("📋 Copy"); self.btn_copy.setStyleSheet(SMALL_BUTTON); header.addWidget(self.btn_copy)
        self.btn_toggle = QPushButton("⤴ Collapse" if self._expanded else "⤵ Expand"); self.btn_toggle.setStyleSheet(SMALL_BUTTON)
        self.btn_toggle.clicked.connect(self._toggle); header.addWidget(self.btn_toggle)
        v.addLayout(header)

        self.viewer = QTextEdit(); self.viewer.setReadOnly(True); self.viewer.setAcceptRichText(True)
        self.viewer.setStyleSheet("QTextEdit {background:#1e1e1e; color:#e5e5e5; border:none;}")
        v.addWidget(self.viewer)

        grip_row = QHBoxLayout(); grip_row.addStretch(1)
        self.size_grip = QSizeGrip(self); grip_row.addWidget(self.size_grip, 0, Qt.AlignRight)
        v.addLayout(grip_row)
        outer.addWidget(frame)

        # state
        self._source = ""
        self._queue: List[str] = []
        self._timer = QTimer(self); self._timer.setInterval(10)  # faster than before
        self._timer.timeout.connect(self._tick)
        self._needs_finalize = False
        self.btn_copy.clicked.connect(lambda: pyperclip.copy(self._source))
        self._apply_height()

    def append_live_text(self, more: str):
        self._source += more
        self._queue.extend(list(more))
        if not self._timer.isActive():
            self._timer.start()

    def _tick(self):
        if not self._queue:
            self._timer.stop()
            if self._needs_finalize:
                self._needs_finalize = False
                self._colorize()
                self._auto_minimize()
                self.finished.emit()
            return
        ch = self._queue.pop(0)
        esc = ch.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")
        if ch == "\n": esc = "<br/>"
        self.viewer.moveCursor(self.viewer.textCursor().End)
        self.viewer.insertHtml(esc)
        self.viewer.moveCursor(self.viewer.textCursor().End)
        self._apply_height(live=True)
        if self.main_scroll:
            # obey autoscroll if enabled; the owner will move it
            pass

    def finalize(self):
        if self._queue:
            self._needs_finalize = True
        else:
            self._colorize()
            self._auto_minimize()
            self.finished.emit()

    def _colorize(self):
        html = pygments_html(self._source, self.language)
        self.viewer.setHtml(html)
        self.viewer.moveCursor(self.viewer.textCursor().End)
        self._apply_height(live=True)

    def _apply_height(self, live: bool=False):
        doc = self.viewer.document().size().toSize()
        h = max(self.DEFAULT_MIN, doc.height() + 24)
        if live:
            h = min(h, self.MAX_LIVE)
        self.viewer.setFixedHeight(h)

    def _toggle(self):
        self._expanded = not self._expanded
        if self._expanded:
            self._apply_height(live=True)
        else:
            self.viewer.setFixedHeight(self.DEFAULT_MIN)
        self.btn_toggle.setText("⤴ Collapse" if self._expanded else "⤵ Expand")

    def _auto_minimize(self):
        # collapse after finish (per spec)
        if self._expanded:
            self._toggle()

# ---------- Message widgets ----------
class UserMessage(QWidget):
    def __init__(self, txt: str):
        super().__init__()
        self._text = txt
        v = QVBoxLayout(self); v.setContentsMargins(0,0,0,0); v.setSpacing(4)
        frame = QFrame(); frame.setStyleSheet(f"background:{USER_BLUE}; border-radius:8px;")
        h = QHBoxLayout(frame); h.setContentsMargins(10,10,10,10)
        lbl = QLabel(f"<b>User:</b> {txt}"); lbl.setStyleSheet("color:#e1f0ff;"); lbl.setWordWrap(True)
        lbl.setTextInteractionFlags(Qt.TextSelectableByMouse)
        h.addWidget(lbl, 1)
        copy = QPushButton("📋"); copy.setStyleSheet(PRIMARY_BUTTON); copy.setToolTip("Copy user message")
        copy.clicked.connect(lambda: pyperclip.copy(txt)); h.addWidget(copy, 0, Qt.AlignTop)
        v.addWidget(frame)

    def as_text(self) -> str:
        return f"User: {self._text}\n"

class BotStreamMessage(QWidget):
    """
    Live bot message supporting streamed plain text and fenced code blocks.
    - Text area grows to content height ("just the length of the text"), darker card inside purple container.
    - Code blocks created when ```lang appears; validated; expanded full during write; minimized after.
    - Provider & model label on first line inside the response card.
    """
    FENCE_RX = re.compile(r"```([A-Za-z0-9\+\-\_#\.]+)?\s*$")
    think_enabled = True

    def __init__(self, provider: str, model: str, autoscroll_getter):
        super().__init__()
        self.provider = provider
        self.model = model
        self.get_autoscroll = autoscroll_getter

        self._in_code = False
        self._current_lang: Optional[str] = None
        self._current_block: Optional[CodeBlockContainer] = None
        self._tail = ""
        self._parts: List[Tuple[str,str]] = []

        v = QVBoxLayout(self); v.setContentsMargins(0,0,0,0); v.setSpacing(6)
        self.card = QFrame(); self.card.setStyleSheet(f"background:{CARD_INDIGO}; border-radius:8px;")
        inner = QVBoxLayout(self.card); inner.setContentsMargins(10,10,10,10); inner.setSpacing(6)

        # Plain text area with provider/model header as first line
        self.text_holder = QFrame(); self.text_holder.setStyleSheet("background:#342d4f; border-radius:6px;")
        thl = QVBoxLayout(self.text_holder); thl.setContentsMargins(8,8,8,8); thl.setSpacing(4)
        self.live_text = QTextEdit(); self.live_text.setReadOnly(True); self.live_text.setAcceptRichText(True)
        self.live_text.setStyleSheet("QTextEdit { background: transparent; color: #f0f0f0; border: none; }")
        self.live_text.setHtml(f"<b>[{provider}][{model}] →</b><br/>")
        thl.addWidget(self.live_text)
        inner.addWidget(self.text_holder)

        foot = QHBoxLayout()
        self.btn_copy_all = QPushButton("📋 Copy All"); self.btn_copy_all.setStyleSheet(SMALL_BUTTON)
        self.btn_copy_all.clicked.connect(self.copy_all); foot.addWidget(self.btn_copy_all)
        foot.addStretch(1); inner.addLayout(foot)
        v.addWidget(self.card)

        self._text_queue: List[str] = []
        self._text_timer = QTimer(self); self._text_timer.setInterval(10)
        self._text_timer.timeout.connect(self._tick_text)

    def feed_chunk(self, chunk: str):
        text = self._tail + chunk
        lines = text.split("\n")
        self._tail = lines[-1]
        for line in lines[:-1]:
            self._handle_line(line + "\n")
        if self.get_autoscroll():
            self._scroll_to_bottom()

    def end_stream(self):
        if self._tail:
            self._handle_line(self._tail); self._tail = ""
        # close any open code block
        if self._in_code and self._current_block:
            self._current_block.finalize()
            self._in_code = False; self._current_lang = None; self._current_block = None
        self._scroll_to_bottom()

    def _handle_line(self, line: str):
        # Detect fences
        m = self.FENCE_RX.match(line.strip())
        if m:
            if not self._in_code:
                lang = safe_lang(m.group(1))
                self._start_code(lang)
            else:
                self._finish_code()
            return

        # Think tags
        if "<think>" in line and self.think_enabled:
            line = line.replace("<think>", "<span style='color:#9bc59b; font-style:italic; text-shadow:0 0 2px #aaffaa;'>")
        if "</think>" in line and self.think_enabled:
            line = line.replace("</think>", "</span>")

        if self._in_code and self._current_block is not None:
            self._current_block.append_live_text(line)
            if not self._parts or self._parts[-1][0] != "code":
                self._parts.append(("code", line))
            else:
                self._parts[-1] = ("code", self._parts[-1][1] + line)
        else:
            self._text_queue.extend(list(line))
            if not self._text_timer.isActive():
                self._text_timer.start()
            if line.strip():
                if not self._parts or self._parts[-1][0] != "text":
                    self._parts.append(("text", line))
                else:
                    self._parts[-1] = ("text", self._parts[-1][1] + line)

    def _start_code(self, lang: Optional[str]):
        self._in_code = True; self._current_lang = lang
        block = CodeBlockContainer(language=lang, start_expanded=True, parent=self)
        block.main_scroll = self.parent().parent().parent() if hasattr(self.parent(), "parent") else None
        layout: QVBoxLayout = self.card.layout()  # type: ignore
        layout.addWidget(block)
        self._current_block = block
        self._parts.append(("code",""))

    def _finish_code(self):
        if self._current_block:
            self._current_block.finalize()
            # replace parts record with final text
            if self._parts and self._parts[-1][0]=="code":
                self._parts[-1] = ("code", self._current_block._source)
        self._in_code = False; self._current_lang=None; self._current_block=None

    def _tick_text(self):
        if not self._text_queue:
            self._text_timer.stop()
            return
        ch = self._text_queue.pop(0)
        esc = ch.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")
        if ch=="\n": esc="<br/>"
        elif ch==" ": esc="&nbsp;&nbsp;"
        self.live_text.moveCursor(self.live_text.textCursor().End)
        self.live_text.insertHtml(esc)
        self.live_text.moveCursor(self.live_text.textCursor().End)
        # Grow to content height (no artificial max unless enormous)
        doc_h = self.live_text.document().size().toSize().height()
        self.live_text.setFixedHeight(doc_h + 18)

    def _scroll_to_bottom(self):
        # parent scroll is  self.parent()->card->...
        sp = self.parent()
        while sp and not isinstance(sp, QScrollArea):
            sp = sp.parent()
        if isinstance(sp, QScrollArea) and self.get_autoscroll():
            sp.verticalScrollBar().setValue(sp.verticalScrollBar().maximum())

    def copy_all(self):
        buf = [f"[{self.provider}][{self.model}] →\n"]
        for kind, content in self._parts:
            if kind=="text":
                buf.append(content)
            else:
                buf.append(f"```{self._current_lang or 'code'}\n{content}\n```\n")
        pyperclip.copy("".join(buf))

    def as_text(self) -> str:
        buf = [f"[{self.provider}][{self.model}] →\n"]
        for k,c in self._parts:
            if k=="text": buf.append(c)
            else: buf.append(f"[Begin code]\n{c}\n[End code]\n")
        return "".join(buf)

# ---------- Prompt Manager Dialog ----------
class PromptManager(QDialog):
    """
    Manage prompts in /data/prompts. Each prompt is a .txt file.
    Index JSON keeps order + checked state.
    """
    prompts_changed = pyqtSignal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Prompt Manager")
        self.setModal(True)
        self.resize(720, 420)
        layout = QHBoxLayout(self)

        # Left: list with checkboxes
        self.list = QListWidget()
        layout.addWidget(self.list, 1)

        # Right: editor
        right = QVBoxLayout(); layout.addLayout(right, 2)
        form = QFormLayout()
        self.ed_name = QLineEdit(); form.addRow("Name:", self.ed_name)
        self.ed_text = QPlainTextEdit(); self.ed_text.setPlaceholderText("Prompt text...")
        self.ed_text.setStyleSheet("QPlainTextEdit {background:#1e1e1e; color:#f0f0f0;}")
        form.addRow("Prompt text:", self.ed_text)
        right.addLayout(form)

        # Buttons
        b_row = QHBoxLayout()
        self.btn_add = QPushButton("Add"); self.btn_add.setStyleSheet(PRIMARY_BUTTON)
        self.btn_save = QPushButton("Save/Update"); self.btn_save.setStyleSheet(PRIMARY_BUTTON)
        self.btn_del = QPushButton("Delete"); self.btn_del.setStyleSheet(SMALL_BUTTON)
        self.btn_up  = QPushButton("↑ Up"); self.btn_down = QPushButton("↓ Down")
        for b in (self.btn_up, self.btn_down): b.setStyleSheet(SMALL_BUTTON)
        self.btn_use = QPushButton("Use Checked"); self.btn_use.setStyleSheet(PRIMARY_BUTTON)
        b_row.addWidget(self.btn_add); b_row.addWidget(self.btn_save); b_row.addWidget(self.btn_del)
        b_row.addStretch(1); b_row.addWidget(self.btn_up); b_row.addWidget(self.btn_down); b_row.addWidget(self.btn_use)
        right.addLayout(b_row)

        self.list.itemSelectionChanged.connect(self._on_select)
        self.btn_add.clicked.connect(self._add)
        self.btn_save.clicked.connect(self._save)
        self.btn_del.clicked.connect(self._delete)
        self.btn_up.clicked.connect(lambda: self._move(-1))
        self.btn_down.clicked.connect(lambda: self._move(1))
        self.btn_use.clicked.connect(lambda: (self._save_index(), self.prompts_changed.emit(), self.accept()))

        self._load()

    def _load(self):
        PROMPTS_DIR.mkdir(parents=True, exist_ok=True)
        idx = {"order":[],"checked":{}}
        if PROMPTS_INDEX_JSON.exists():
            try:
                idx = json.loads(PROMPTS_INDEX_JSON.read_text(encoding="utf-8"))
            except Exception:
                pass
        # Ensure default prompt file exists
        default_path = PROMPTS_DIR / "Default.txt"
        if not default_path.exists():
            default_text = (
                "You are Zira, an expert coding copilot and tutor.\n"
                "- Write clean, modern, scalable code with helpful commentary.\n"
                "- Always stream answers in real time, using fenced code blocks with language tags.\n"
                "- Uploaded files are provided as snippets in the system message; reference them by name when helpful.\n"
                "- If needed information is missing from the snippets, request the user to supply more detail.\n"
                "- Be concise in prose; favor bullet points and code.\n"
                "- Use emojis tastefully in headings or code badges.\n"
            )
            default_path.write_text(default_text, encoding="utf-8")
        if "Default" not in idx["order"]:
            idx["order"].insert(0, "Default")
            idx["checked"]["Default"] = True
        # Populate list
        self.list.clear()
        for name in idx["order"]:
            item = QListWidgetItem(name)
            item.setFlags(item.flags() | Qt.ItemIsUserCheckable | Qt.ItemIsSelectable | Qt.ItemIsEnabled)
            item.setCheckState(Qt.Checked if idx["checked"].get(name, False) else Qt.Unchecked)
            self.list.addItem(item)
        self._save_index(idx)  # normalize

    def _save_index(self, idx=None):
        if idx is None:
            idx = {"order":[], "checked":{}}
            for i in range(self.list.count()):
                it = self.list.item(i)
                idx["order"].append(it.text())
                idx["checked"][it.text()] = (it.checkState()==Qt.Checked)
        PROMPTS_INDEX_JSON.write_text(json.dumps(idx, ensure_ascii=False, indent=2), encoding="utf-8")

    def _on_select(self):
        it = self.list.currentItem()
        if not it: return
        name = it.text()
        self.ed_name.setText(name)
        path = PROMPTS_DIR / f"{name}.txt"
        txt = path.read_text(encoding="utf-8") if path.exists() else ""
        self.ed_text.setPlainText(txt)

    def _add(self):
        name = self.ed_name.text().strip() or "New Prompt"
        if name == "Default":
            QMessageBox.information(self, "Prompt", "Use a different name.")
            return
        (PROMPTS_DIR / f"{name}.txt").write_text(self.ed_text.toPlainText(), encoding="utf-8")
        # add to list if missing
        names = [self.list.item(i).text() for i in range(self.list.count())]
        if name not in names:
            it = QListWidgetItem(name); it.setFlags(it.flags() | Qt.ItemIsUserCheckable)
            it.setCheckState(Qt.Checked)
            self.list.addItem(it)
        self._save_index()

    def _save(self):
        it = self.list.currentItem()
        if not it: return
        name = it.text()
        if name == "Default":
            # allowed to edit & toggle, but not delete
            pass
        (PROMPTS_DIR / f"{name}.txt").write_text(self.ed_text.toPlainText(), encoding="utf-8")
        self._save_index()

    def _delete(self):
        it = self.list.currentItem()
        if not it: return
        name = it.text()
        if name == "Default":
            QMessageBox.information(self, "Prompt", "Default prompt cannot be deleted (you can uncheck it).")
            return
        path = PROMPTS_DIR / f"{name}.txt"
        try:
            if path.exists(): path.unlink()
        except Exception:
            pass
        self.list.takeItem(self.list.row(it))
        self._save_index()

    def _move(self, delta: int):
        r = self.list.currentRow()
        if r < 0: return
        nr = max(0, min(self.list.count()-1, r+delta))
        if nr==r: return
        it = self.list.takeItem(r)
        self.list.insertItem(nr, it)
        self.list.setCurrentRow(nr)
        self._save_index()

    @api_expose
    def current_preamble(self) -> str:
        """
        Build a preamble string by concatenating all *checked* prompts in the
        current list order.
        """
        pre = []
        for i in range(self.list.count()):
            it = self.list.item(i)
            if it.checkState()==Qt.Checked:
                name = it.text()
                path = PROMPTS_DIR / f"{name}.txt"
                if path.exists():
                    pre.append(path.read_text(encoding="utf-8").strip())
        return "\n\n".join(pre).strip()

# ---------- Settings Dialog ----------
class SettingsDialog(QDialog):
    """Settings: API key + TTS speed. Persists values; shows docs buttons."""
    settings_changed = pyqtSignal()

    def __init__(self, tts_mgr: TTSManager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Settings")
        self.setModal(True)
        self.resize(560, 260)
        self.tts_mgr = tts_mgr

        tabs = QTabWidget()
        # API tab
        api_tab = QWidget(); api_layout = QVBoxLayout(api_tab)
        form = QFormLayout()
        self.ed_openai = QLineEdit(load_openai_key() or "")
        self.ed_openai.setPlaceholderText("OpenAI API Key (sk-...)")
        form.addRow("OpenAI API Key:", self.ed_openai)
        save = QPushButton("Save API Key"); save.setStyleSheet(PRIMARY_BUTTON)
        save.clicked.connect(self._save_key)
        api_layout.addLayout(form); api_layout.addWidget(save)

        # TTS tab
        tts_tab = QWidget(); tts_layout = QFormLayout(tts_tab)
        self.sp_tts = QSpinBox(); self.sp_tts.setRange(50, 300); self.sp_tts.setValue(self.tts_mgr._rate_slider_value)
        tts_layout.addRow("TTS speed (% of base):", self.sp_tts)
        btn_apply = QPushButton("Apply"); btn_apply.setStyleSheet(PRIMARY_BUTTON)
        btn_apply.clicked.connect(self._apply_tts)
        tts_layout.addRow(btn_apply)

        # Docs tab
        docs_tab = QWidget(); docs_layout = QVBoxLayout(docs_tab)
        gen = QPushButton("Generate API & README"); gen.setStyleSheet(PRIMARY_BUTTON)
        self.viewer = QTextBrowser(); self.viewer.setStyleSheet("QTextBrowser {background:#111;color:#ddd;}")
        cp = QPushButton("Copy Shown"); cp.setStyleSheet(SMALL_BUTTON)
        def _gen():
            generate_api_docs(DOCS_DIR / "Chat_Agent_API.md", DOCS_DIR / "README.generated.md")
            self.viewer.setPlainText((DOCS_DIR/"Chat_Agent_API.md").read_text(encoding="utf-8"))
        gen.clicked.connect(_gen); cp.clicked.connect(lambda: pyperclip.copy(self.viewer.toPlainText()))
        docs_layout.addWidget(gen); docs_layout.addWidget(self.viewer,1); docs_layout.addWidget(cp)

        tabs.addTab(api_tab, "API Keys")
        tabs.addTab(tts_tab, "TTS")
        tabs.addTab(docs_tab, "Docs")

        root = QVBoxLayout(self); root.addWidget(tabs)
        close = QPushButton("Close"); close.clicked.connect(self.accept); root.addWidget(close)

    def _save_key(self):
        save_openai_key(self.ed_openai.text().strip())
        self.settings_changed.emit()

    def _apply_tts(self):
        self.tts_mgr.set_rate_percent(self.sp_tts.value())

# ---------- Upload Manager Dialog ----------
class UploadManagerDialog(QDialog):
    """Popup to view/ingest uploaded knowledge items with progress bars and a quick 'Upload...' button."""
    def __init__(self, store: UploadedKnowledge, signals: UploadSignals, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Upload Manager")
        self.setModal(False); self.resize(720, 420)
        self.store = store; self.signals = signals

        self.items_layout = QVBoxLayout()
        container = QWidget(); container.setLayout(self.items_layout)
        self.scroll = QScrollArea(); self.scroll.setWidgetResizable(True); self.scroll.setWidget(container)

        self.btn_upload = QPushButton("Upload..."); self.btn_upload.setStyleSheet(PRIMARY_BUTTON)
        self.btn_upload.clicked.connect(self._choose_files)
        self.btn_clear = QPushButton("Clear Uploaded Knowledge"); self.btn_clear.setStyleSheet(SMALL_BUTTON)
        self.btn_clear.clicked.connect(self._clear)

        root = QVBoxLayout(self)
        root.addWidget(self.scroll, 1)
        row = QHBoxLayout(); row.addWidget(self.btn_upload); row.addStretch(1); row.addWidget(self.btn_clear)
        root.addLayout(row)

        self.signals.item_started.connect(self._on_start)
        self.signals.progress.connect(self._on_progress)
        self.signals.item_done.connect(self._on_done)
        self.signals.refresh_view.connect(self.refresh)

        self.widgets: Dict[str, Tuple[QLabel,QProgressBar]] = {}
        self.refresh()

    def _choose_files(self):
        paths, _ = QFileDialog.getOpenFileNames(self, "Select files or images")
        if not paths: return
        self.store.ingest_paths([Path(p) for p in paths])

    def _clear(self):
        if QMessageBox.question(self, "Uploaded Knowledge", "Delete all uploaded knowledge?") == QMessageBox.Yes:
            self.store.clear(); self.refresh()

    def _on_start(self, item_id: str, label: str):
        w = QWidget(); l = QHBoxLayout(w); l.setContentsMargins(6,6,6,6)
        lab = QLabel(label); p = QProgressBar(); p.setRange(0,100); p.setValue(0)
        l.addWidget(lab, 1); l.addWidget(p, 0)
        self.items_layout.addWidget(w)
        self.widgets[item_id] = (lab, p)

    def _on_progress(self, item_id: str, pct: int):
        if item_id in self.widgets:
            self.widgets[item_id][1].setValue(pct)

    def _on_done(self, item_id: str):
        if item_id in self.widgets:
            self.widgets[item_id][1].setValue(100)

    def refresh(self):
        # clear layout
        while self.items_layout.count():
            it = self.items_layout.takeAt(0)
            w = it.widget()
            if w: w.deleteLater()
        # re-add items
        for it in self.store.items.values():
            w = QWidget(); l = QHBoxLayout(w); l.setContentsMargins(6,6,6,6)
            icon = "📁" if it["type"]=="folder" else ("🖼️" if it["type"]=="image" else "📄")
            lab = QLabel(f"{icon} {it['path']}  —  tags: {', '.join(it.get('tags',[]))}")
            p = QProgressBar(); p.setRange(0,100); p.setValue(100)
            l.addWidget(lab, 1); l.addWidget(p, 0)
            self.items_layout.addWidget(w)

# ---------- Main App ----------
class MiniChat(QWidget):
    """
    The main window. Orchestrates UI, providers, streaming, timing, dataset, prompts, uploads, TTS.
    """

    def __init__(self):
        super().__init__()
        ensure_dirs()
        self.setWindowTitle(APP_NAME)
        self.resize(1120, 760)

        # State
        self.tts = TTSManager()
        self.timing = TimingLog(TIMINGS_LOG)
        self.dataset = DatasetManager(DATASET_JSONL, VISIBLE_HISTORY_FILE, limit_pairs=10)
        self.signals = UploadSignals()
        self.uploads = UploadedKnowledge(UPLOAD_INDEX_JSON, self.signals)
        self.autoscroll = True

        # Providers
        self.backend_ollama = OllamaBackend()
        self.backend_openai = OpenAIBackend(load_openai_key())
        self.provider_backend: ProviderBackend = self.backend_ollama

        # ---- System log ticker ----
        self.ticker = QLabel("Ready. Default provider: Ollama; Model: gpt-oss:20b; Real-Time ON.")
        self.ticker.setStyleSheet("QLabel {background:#111;color:#9df29d;padding:4px 8px; font: 10pt 'Consolas';}")
        # ---- Top controls ----
        top = QHBoxLayout()
        self.btn_settings = QPushButton("⚙ Settings"); self.btn_settings.setStyleSheet(SMALL_BUTTON)
        self.btn_settings.clicked.connect(self._open_settings)
        top.addWidget(self.btn_settings)

        top.addWidget(QLabel("Provider:"))
        self.cmb_provider = QComboBox(); self.cmb_provider.addItems(["Ollama","OpenAI"])
        self.cmb_provider.currentTextChanged.connect(self._on_provider)
        top.addWidget(self.cmb_provider)

        top.addWidget(QLabel("Model:"))
        self.cmb_model = QComboBox(); top.addWidget(self.cmb_model)
        self.btn_refresh_models = QPushButton("⟳"); self.btn_refresh_models.setFixedWidth(28)
        self.btn_refresh_models.setStyleSheet(SMALL_BUTTON)
        self.btn_refresh_models.clicked.connect(self._populate_models)
        top.addWidget(self.btn_refresh_models)

        top.addWidget(QLabel("Embedder:"))
        self.cmb_embed = QComboBox(); self.cmb_embed.addItems([DEFAULT_EMBEDDER])
        top.addWidget(self.cmb_embed)

        self.chk_realtime = QCheckBox("Real-Time"); self.chk_realtime.setChecked(True); top.addWidget(self.chk_realtime)
        self.chk_autoscroll = QCheckBox("Auto-scroll"); self.chk_autoscroll.setChecked(True)
        self.chk_autoscroll.toggled.connect(lambda v: setattr(self, "autoscroll", bool(v)))
        top.addWidget(self.chk_autoscroll)

        top.addWidget(QLabel("Context pairs:"))
        self.lbl_pairs = QLabel("10")
        self.slider_pairs = QSpinBox(); self.slider_pairs.setRange(1, 50); self.slider_pairs.setValue(10)
        self.slider_pairs.valueChanged.connect(self._pairs_changed)
        top.addWidget(self.slider_pairs)

        self.btn_prompts = QPushButton("📜 Prompts"); self.btn_prompts.setStyleSheet(PRIMARY_BUTTON)
        self.btn_prompts.clicked.connect(self._open_prompts)
        top.addWidget(self.btn_prompts)

        self.btn_clear = QPushButton("🧹 Clear Chat"); self.btn_clear.setStyleSheet(SMALL_BUTTON)
        self.btn_clear.clicked.connect(self._clear_chat)
        top.addWidget(self.btn_clear)

        self.chk_use_uploads = QCheckBox("Use Uploaded Knowledge"); self.chk_use_uploads.setChecked(True)
        top.addWidget(self.chk_use_uploads)

        self.btn_read_all = QPushButton("▶ Read All"); self.btn_read_all.setStyleSheet(SMALL_BUTTON)
        self.btn_read_all.clicked.connect(self._tts_read_all)
        self.btn_read_cur = QPushButton("▶ Read Current"); self.btn_read_cur.setStyleSheet(SMALL_BUTTON)
        self.btn_read_cur.clicked.connect(self._tts_read_current)
        self.btn_stop = QPushButton("⏹ Stop"); self.btn_stop.setStyleSheet(SMALL_BUTTON)
        self.btn_stop.clicked.connect(self.tts.stop)
        top.addWidget(self.btn_read_all); top.addWidget(self.btn_read_cur); top.addWidget(self.btn_stop)

        self.btn_reset_avg = QPushButton("Reset Averages"); self.btn_reset_avg.setStyleSheet(SMALL_BUTTON)
        self.btn_reset_avg.clicked.connect(self._reset_averages)
        self.lbl_avgs = QLabel(self._avg_text()); self.lbl_avgs.setStyleSheet("color:#ddd;")
        top.addWidget(self.lbl_avgs); top.addWidget(self.btn_reset_avg)

        # ---- History area ----
        self.scroll = QScrollArea(); self.scroll.setWidgetResizable(True)
        self.container = QWidget(); self.v = QVBoxLayout(self.container); self.v.setAlignment(Qt.AlignTop)
        self.scroll.setWidget(self.container)

        # ---- Input row ----
        inp_row = QHBoxLayout()
        self.attachments_bar = QLabel("Attachments:"); self.attachments_bar.setStyleSheet("color:#aaa;")
        self.btn_upload_mgr = QPushButton("📁 Upload Manager"); self.btn_upload_mgr.setStyleSheet(SMALL_BUTTON)
        self.btn_upload_mgr.clicked.connect(self._open_upload_mgr)
        inp_row.addWidget(self.attachments_bar); inp_row.addStretch(1); inp_row.addWidget(self.btn_upload_mgr)

        self.txt_in = QLineEdit(); self.txt_in.setPlaceholderText("Ask Zira something…")
        self.txt_in.returnPressed.connect(self._send)
        self.btn_send = QPushButton("Send"); self.btn_send.setStyleSheet(PRIMARY_BUTTON)
        self.btn_send.clicked.connect(self._send)

        # ---- Root layout ----
        root = QVBoxLayout(self); root.setContentsMargins(6,6,6,6); root.setSpacing(6)
        root.addWidget(self.ticker)
        root.addLayout(top)
        root.addWidget(self.scroll, 1)
        root.addLayout(inp_row)
        row2 = QHBoxLayout(); row2.addWidget(self.txt_in, 1); row2.addWidget(self.btn_send)
        root.addLayout(row2)

        # Style
        self.setStyleSheet(f"QWidget {{background:{SMOKY_BG}; color:{SOFT_TEXT};}}")
        self._populate_models(initial=True)
        log_line("Application started.")

        # Paste handling for quick uploads
        self.installEventFilter(self)

        # Errors as popups
        sys.excepthook = self._excepthook

        # Session attachments icons
        self._attachment_icons: List[str] = []

    def eventFilter(self, obj, ev):
        # Handle paste into the input: turn file paths into attachments
        if ev.type() == QEvent.KeyPress and ev.matches(QKeySequence.Paste):
            clip = QApplication.clipboard().mimeData()
            if clip and clip.hasText():
                text = clip.text().strip()
                # If it's a path or list of paths
                parts = [p.strip() for p in text.split() if p.strip()]
                paths = []
                for p in parts:
                    if Path(p).exists():
                        paths.append(Path(p))
                if paths:
                    self.uploads.ingest_paths(paths)
                    self._add_attachment_icons(paths)
                    return True
        return super().eventFilter(obj, ev)

    # ----- UI helpers -----
    def _avg_text(self) -> str:
        d,s = self.timing.averages()
        return f" ⬤ Normal avg: {int(d)} ms | Real-Time avg: {int(s)} ms "

    def _pairs_changed(self, val: int):
        self.dataset.set_limit(val)

    def _add_attachment_icons(self, paths: List[Path]):
        for p in paths:
            if p.is_dir(): icon="📁"
            elif p.suffix.lower() in (".png",".jpg",".jpeg",".gif",".webp"): icon="🖼️"
            else: icon="📄"
            self._attachment_icons.append(f"{icon} {p.name}")
        self.attachments_bar.setText("Attachments:  " + "  ".join(self._attachment_icons))

    def _open_settings(self):
        dlg = SettingsDialog(self.tts, self)
        dlg.settings_changed.connect(lambda: setattr(self.backend_openai, "api_key", load_openai_key()))
        dlg.exec_()

    def _open_prompts(self):
        dlg = PromptManager(self)
        if dlg.exec_():
            pass  # preamble is constructed at send time

    def _open_upload_mgr(self):
        UploadManagerDialog(self.uploads, self.signals, self).show()

    def _on_provider(self, name: str):
        self.provider_backend = self.backend_ollama if name=="Ollama" else self.backend_openai
        self._populate_models()

    def _populate_models(self, initial=False):
        provider = self.cmb_provider.currentText()
        models = self.provider_backend.list_models()
        self.cmb_model.clear()
        if not models:
            # minimal fallback
            if provider=="Ollama":
                models=[DEFAULT_MODEL]
            else:
                models=[]
        self.cmb_model.addItems(models)
        # initial set to default if present
        if initial and DEFAULT_MODEL in models:
            self.cmb_model.setCurrentText(DEFAULT_MODEL)

    def _excepthook(self, etype, evalue, etb):
        tb = "".join(traceback.format_exception(etype, evalue, etb))
        log_line("Unhandled exception:\n" + tb)
        QMessageBox.critical(self, "Error", tb)

    # ----- TTS -----
    def _collect_from_index(self, start: int) -> str:
        parts=[]
        for i in range(start, self.v.count()):
            w = self.v.itemAt(i).widget()
            if isinstance(w, BotStreamMessage):
                parts.append(w.as_text())
        return "\n".join(parts)

    def _tts_read_all(self):
        self.tts.stop()
        text = self._collect_from_index(0)
        self.tts.speak_async(text)

    def _tts_read_current(self):
        self.tts.stop()
        if self.v.count()==0: return
        text = self._collect_from_index(self.v.count()-1)
        self.tts.speak_async(text)

    # ----- Clear chat / averages -----
    def _reset_averages(self):
        if QMessageBox.question(self, "Timings", "Reset timing averages?") == QMessageBox.Yes:
            self.timing.reset()
            self.lbl_avgs.setText(self._avg_text())

    def _clear_chat(self):
        self.tts.stop()
        self.dataset.clear_all()
        # remove widgets
        while self.v.count():
            it = self.v.takeAt(0); w = it.widget()
            if w: w.deleteLater()
        if QMessageBox.question(self, "Clear Chat", "Also reset averages back to 0 and start fresh?") == QMessageBox.Yes:
            self._reset_averages()
        self._attachment_icons.clear()
        self.attachments_bar.setText("Attachments:")

    # ----- Compose system preamble -----
    def _system_preamble(self) -> str:
        # prompts
        pre = []
        if PROMPTS_INDEX_JSON.exists():
            try:
                idx=json.loads(PROMPTS_INDEX_JSON.read_text(encoding="utf-8"))
                for name in idx["order"]:
                    if idx["checked"].get(name, False):
                        p = PROMPTS_DIR / f"{name}.txt"
                        if p.exists():
                            pre.append(p.read_text(encoding="utf-8").strip())
            except Exception:
                pass

        # uploaded knowledge snippets
        if self.chk_use_uploads.isChecked():
            snippets = self.uploads.as_context_snippets()
            if snippets:
                pre.append("Uploaded Knowledge:\n" + "\n\n".join(snippets))

        # dataset framing
        pairs = self.dataset.load_pairs()
        if pairs:
            bullet = []
            for i, pr in enumerate(pairs[-self.dataset.limit:], 1):
                # lightly weighted older summaries
                bullet.append(f"({i}) user asked about: {pr['user'][:200]}")
            pre.append("Recent context (light weight; oldest first):\n- " + "\n- ".join(bullet))

        return "\n\n".join(pre).strip()

    # ----- Send / Stream -----
    def _send(self):
        user_txt = self.txt_in.text().strip()
        if not user_txt:
            return
        self.txt_in.clear()
        self._add_widget(UserMessage(user_txt))
        # Start timing
        t0 = time.perf_counter()
        mode = "realtime" if self.chk_realtime.isChecked() else "default"

        # Build preamble & history
        preamble = self._system_preamble()
        history = self.dataset.load_pairs()

        # Live bot message
        live = BotStreamMessage(self.cmb_provider.currentText(), self.cmb_model.currentText(), lambda: self.autoscroll)
        self._add_widget(live)

        # Stream request
        try:
            stream = self.chk_realtime.isChecked()
            provider = self.provider_backend
            for chunk in provider.chat(self.cmb_model.currentText(), preamble, user_txt, history, stream=stream):
                live.feed_chunk(chunk)
            live.end_stream()
        except Exception as e:
            live.feed_chunk(f"\n\n⚠️ Error: {e}\n")
            live.end_stream()

        # End timing & averages
        dt_ms = int((time.perf_counter()-t0)*1000)
        self.timing.add(mode, dt_ms)
        self.lbl_avgs.setText(self._avg_text())

        # Persist pair (visible + dataset)
        resp_text = live.as_text()
        self.dataset.append_visible(f"[{self.cmb_provider.currentText()}][{self.cmb_model.currentText()}] → {resp_text[:5000]}")
        # For dataset keep the raw combined textual parts (no think tags or HTML)
        joined = "".join(c for (k,c) in live._parts if k=="text")  # simple
        self.dataset.append_pair(user_txt, joined)

        # Auto TTS (assistant only)
        self.tts.speak_async(resp_text)

    def _add_widget(self, w: QWidget):
        if isinstance(w, BotStreamMessage):
            # obey autoscroll programmatically
            pass
        self.v.addWidget(w)
        QApplication.processEvents()
        if self.autoscroll:
            self.scroll.verticalScrollBar().setValue(self.scroll.verticalScrollBar().maximum())

# ---------- Entrypoint ----------
@api_expose
def main():
    """
    Launch the application. Creates necessary folders, clears session logs,
    and opens the main UI window.
    """
    ensure_dirs()
    # clear logs at start
    SYSTEM_LOG.write_text("", encoding="utf-8")
    app = QApplication(sys.argv)
    gui = MiniChat(); gui.show()
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()
```

OllamaMiniChat.py
=================
A compact yet capable PyQt5 chat client for **local Ollama** models and **OpenAI** models
with *real-time* streaming text & code, colorful syntax blocks, prompt manager, upload manager,
rolling timing logs, persistent mini-RAG dataset, Zira TTS, a generated Markdown API/README,
and a slim live system log.

Key features
------------
• Providers: **Ollama** (default) and **OpenAI**. Model dropdown updates per provider.
• Real-Time streaming (FAST) for plain text and fenced ```code``` blocks (validated languages).
  - While streaming, code is shown in a “floating terminal” container expanded to full script height.
  - On completion, code blocks auto-minimize (can be expanded by user).
  - Text stream renders live as well (char-wise), with optional metallic <think> styling.
• Colorful code via **Pygments** (Monokai). Emojis on badges.
• Non-semantic and semantic history:
  - Visible (session-only) history to avoid artifacts in displayed text.
  - Persistent dataset of the last **N pairs** (slider; default 10), with rolling file and priority taper.
• Timing logs:
  - Default vs Real-Time averages shown; logs capped to 100 entries (rolling).
  - “Reset Averages” button + optional reset during “Clear Chat”.
• TTS (Windows SAPI5 via **pyttsx3**) using **Microsoft Zira**, **150%** speed by default.
  - Auto-reads **assistant responses only**, in order, no gaps. Stop at any time.
  - Speed slider persisted across sessions in Settings.
• Upload Manager:
  - Paste/drag/drop or browse files/folders; icons for text/code, images, folders.
  - Recursively ingests folders (skips __pycache__, venv*/.venv*, large junk); keeps .git.
  - Simple “tag-and-bucket” enrichment (no vectors), stored in /data/uploads.
  - Per-file progress bars driven via Qt Signals (no hanging).
  - “Clear Uploaded Knowledge” button to purge.
• Prompt Manager:
  - Remove the big system prompt from the main window.
  - Manage named prompts (add/edit/delete*), reorder, check multiple to include in system preamble.
    (*Default prompt cannot be deleted; it can be toggled off.)
• Smarter prompting:
  - Preamble includes (in order): checked prompts, then light summary of older pairs, then
    visible recent pairs (tapered), emphasizing the current user message.
• API / README generator:
  - Button generates **Chat_Agent_API.md** and **README.generated.md** in /data/docs from code,
    scanning @api_expose functions and docstrings. Pop-up viewer with “Copy” button.
• UX niceties:
  - Smoky gray theme, high contrast text, improved professional typography.
  - Top black slim **System Log** ticker + on-disk logs (cleared on startup).
  - Auto-scroll toggle (ON by default) so you can scroll during streaming without snap-back.
  - Provider+Model label inside each response card: **[Provider][model] →** line above content.
  - Enter in the input sends the message (QLineEdit).
• Robust error pop-ups; unhandled exceptions are intercepted and shown.

Install
-------
    pip install pyqt5 requests pyperclip pygments pyttsx3

Run
---
    ollama serve   # if using Ollama
    python OllamaMiniChat.py
**Classes:** PythonHighlighter, TimingLog, DatasetManager, UploadSignals, UploadedKnowledge, TTSManager, ProviderBackend, OllamaBackend, OpenAIBackend, CodeBlockContainer, UserMessage, BotStreamMessage, PromptManager, SettingsDialog, UploadManagerDialog, MiniChat
**Functions:** ensure_dirs(), now_iso(), log_line(msg), _win_protect(plaintext), _win_unprotect(cipher), save_openai_key(key), load_openai_key(), safe_lang(lang), pygments_html(code, lang), api_expose(fn), generate_api_docs(out_md, readme_md), main()


## Module `Dev_Logic\Implemented_logic\codex_local2.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Codex Local — Local-first Virtual Desktop Chat with Ollama, 2-pass Vision (OCR→Creative),
RAG dataset, GitHub manager, shell hooks, and high-contrast UI.

Key points:
- High-contrast everywhere (no white panes).
- Paste / drag-drop images into the chat input = same as "Attach Image".
- Vision is automatic on the next Send if images are pending:
    1) benhaotang/Nanonets-OCR-s:latest → faithful Markdown (ground truth).
    2) llava-llama3:latest → concise creative summary, *grounded by OCR*.
  Both texts are saved and the combined summary is injected into the chat model context.
- Fixed AttributeError: _rag_enrich exists and is used by _chat_request.
- Conversation saved to Markdown; mirrored dataset JSONL + embeddings (optional) for retrieval.
- GitHub manager (init/stage/commit/push/PR via gh).

Requirements: PySide6, requests. Optional: pillow, numpy. Ollama at http://127.0.0.1:11434
"""

from __future__ import annotations

import os, sys, json, time, threading, datetime, re, base64, math, subprocess, shutil, uuid, io
from dataclasses import dataclass
from typing import Optional, List, Dict, Any, Tuple

# ---------------- Optional deps
def _requests():
    try:
        import requests
        return requests
    except Exception:
        return None

def _pil():
    try:
        from PIL import Image
        return Image
    except Exception:
        return None

try:
    import numpy as _np  # optional for fast cosine
except Exception:
    _np = None

# ---------------- Qt
from PySide6.QtCore import (
    Qt, QRect, QRectF, QPoint, QSize, QTimer, Signal, Slot, QEvent, QByteArray, QBuffer
)
from PySide6.QtGui import (
    QAction, QColor, QGuiApplication, QKeySequence, QLinearGradient, QPainter,
    QPainterPath, QPalette, QTextCursor, QFont, QTextCharFormat, QDragEnterEvent,
    QDropEvent
)
from PySide6.QtWidgets import (
    QApplication, QComboBox, QDialog, QDialogButtonBox, QFormLayout, QFrame,
    QGraphicsDropShadowEffect, QGridLayout, QGroupBox, QHBoxLayout, QLabel,
    QMainWindow, QPushButton, QSizeGrip, QPlainTextEdit, QTextEdit, QToolButton,
    QVBoxLayout, QWidget, QScrollArea, QMessageBox, QCheckBox, QFileDialog,
    QListWidget, QListWidgetItem, QLineEdit, QSlider, QTabWidget, QSplitter
)

# High DPI policy before QApplication
try:
    QGuiApplication.setHighDpiScaleFactorRoundingPolicy(
        Qt.HighDpiScaleFactorRoundingPolicy.PassThrough
    )
except Exception:
    pass

# ---------------- Paths
SCRIPT_ROOT = os.path.abspath(os.path.dirname(__file__))
CONV_DIR    = os.path.join(SCRIPT_ROOT, "conversations")
DATA_DIR    = os.path.join(SCRIPT_ROOT, "datasets")
LEX_DIR     = os.path.join(SCRIPT_ROOT, "lexicons")
REPO_DIR    = os.path.join(SCRIPT_ROOT, "Codex-Local")      # local repo root
os.makedirs(CONV_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(LEX_DIR, exist_ok=True)
os.makedirs(REPO_DIR, exist_ok=True)

LOG_PATH    = os.path.join(SCRIPT_ROOT, "codex_local.log")
CONFIG_PATH = os.path.join(SCRIPT_ROOT, "config.json")

# ---------------- Logging
def _ts() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def _log(line: str):
    msg = f"[{_ts()}] {line}\n"
    try:
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(msg)
    except Exception:
        pass

# ---------------- Theme (High-contrast)
@dataclass
class Theme:
    # Virtual desktop
    desktop_top: str = "#0f3b8e"
    desktop_mid: str = "#1c54cc"
    edge_glow:   str = "#4aa8ff"

    # Card
    card_bg:     str = "#0c1320"
    card_border: str = "#213040"
    card_radius: int = 14
    header_bg:   str = "#0a111e"
    header_fg:   str = "#eaf2ff"
    term_bg:     str = "#0b1828"
    term_fg:     str = "#e9f3ff"
    accent:      str = "#1E5AFF"
    accent_hover:str = "#2f72ff"
    ok:          str = "#00d17a"
    warn:        str = "#ffd76b"
    err:         str = "#ff6b6b"
    info:        str = "#9bb7ff"

    # Chat roles
    user_bubble_bg: str = "#0b2a66"
    user_bubble_fg: str = "#eaf2ff"
    ai_bubble_bg:   str = "#101623"
    ai_bubble_fg:   str = "#ffffff"
    model_teal:     str = "#00b3b3"
    think_fg:       str = "#a7b0bf"

# --------------- Default config
DEFAULT_VISION_OCR_MODEL = "benhaotang/Nanonets-OCR-s:latest"
DEFAULT_VISION_CREATIVE  = "llava-llama3:latest"

DEFAULTS: Dict[str, Any] = {
    "ollama_host": "http://127.0.0.1:11434",
    "prompt_influence": True,
    "stream": False,
    "context_pairs": 25,
    "models": {
        "chat": "qwen3:30b",
        "vision_ocr": DEFAULT_VISION_OCR_MODEL,
        "vision_creative": DEFAULT_VISION_CREATIVE,
        "embed": "snowflake-arctic-embed2:latest"
    },
    "paths": {
        "conversation_dir": CONV_DIR,
        "dataset_dir": DATA_DIR,
        "repo_dir": REPO_DIR
    },
    "prompts": {
        "system": "You are Codex Local. Be correct and concise.",
        "system_min": "Answer appropriately.",
        "vision": "Describe the image accurately and succinctly.",
        "user_prefix": ""
    },
    "lexicons": {
        "enable": True,
        "packs": []  # optional JSON files under ./lexicons
    }
}

def load_config() -> Dict:
    cfg: Dict[str, Any] = {}
    if os.path.isfile(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                cfg = json.load(f)
        except Exception as e:
            _log(f"Config read error: {e}")
            cfg = {}
    def fill(dst, src):
        for k, v in src.items():
            if isinstance(v, dict):
                dst[k] = fill(dst.get(k, {}), v)
            else:
                dst.setdefault(k, v)
        return dst
    cfg = fill(cfg, DEFAULTS)
    try:
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
    except Exception as e:
        _log(f"Config write error: {e}")
    return cfg

def save_config(cfg: Dict):
    try:
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
    except Exception as e:
        _log(f"Config write error: {e}")

# ---------------- Small utils
def human_size(n: int) -> str:
    units = ["B","KB","MB","GB","TB"]
    s = float(n); i = 0
    while s >= 1024 and i < len(units)-1:
        s /= 1024; i += 1
    return f"{s:.1f}{units[i]}" if i else f"{int(s)}{units[i]}"

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

def read_text(p: str, default: str="") -> str:
    try:
        with open(p, "r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return default

def write_text(p: str, s: str):
    ensure_dir(os.path.dirname(p))
    with open(p, "w", encoding="utf-8") as f:
        f.write(s)

def append_text(p: str, s: str):
    ensure_dir(os.path.dirname(p))
    with open(p, "a", encoding="utf-8") as f:
        f.write(s)

def slug(s: str) -> str:
    s = re.sub(r"[^A-Za-z0-9_\-]+", "-", s.strip())
    s = re.sub(r"-{2,}", "-", s).strip("-")
    return s or "item"

def cosine(a: List[float], b: List[float]) -> float:
    if _np is not None:
        va = _np.asarray(a, dtype=_np.float32)
        vb = _np.asarray(b, dtype=_np.float32)
        denom = _np.linalg.norm(va) * _np.linalg.norm(vb)
        if denom == 0: return 0.0
        return float(va.dot(vb) / denom)
    dot = sum(x*y for x, y in zip(a, b))
    na = math.sqrt(sum(x*x for x in a))
    nb = math.sqrt(sum(y*y for y in b))
    if na == 0 or nb == 0: return 0.0
    return dot / (na * nb)

# ---------------- Shell hooks
class ShellHooks:
    def __init__(self):
        self.found: Dict[str, str] = {}
        self._discover()

    def _which(self, name: str) -> Optional[str]:
        return shutil.which(name)

    def _discover(self):
        try:
            if sys.platform.startswith("win"):
                ps = self._which("pwsh") or self._which("powershell")
                if ps: self.found["powershell"] = ps
                cmd = self._which("cmd")
                if cmd: self.found["cmd"] = cmd
                gitbash = os.path.join(os.environ.get("ProgramFiles", "C:\\Program Files"),
                                       "Git", "bin", "bash.exe")
                if os.path.isfile(gitbash): self.found["git-bash"] = gitbash
                wsl = self._which("wsl")
                if wsl: self.found["wsl"] = wsl
            else:
                bash = self._which("bash")
                if bash: self.found["bash"] = bash
                zsh = self._which("zsh")
                if zsh: self.found["zsh"] = zsh
        except Exception as e:
            _log(f"Shell discovery error: {e}")

    def wsl_status(self) -> Tuple[bool, List[str]]:
        if "wsl" not in self.found:
            return False, []
        try:
            out = subprocess.check_output(["wsl", "-l", "-v"], stderr=subprocess.STDOUT, text=True, timeout=5)
            lines = [l.strip() for l in out.splitlines() if l.strip()]
            distros = [l.replace("*", "").split()[0] for l in lines[1:]] if len(lines) > 1 else []
            return True, distros
        except Exception:
            return True, []

    def advice_install_wsl(self) -> str:
        return ("WSL not found or no Ubuntu. Open an elevated PowerShell and run:\n"
                "  wsl --install\n"
                "Then install Ubuntu from Microsoft Store and run it once to initialize.")

# ---------------- Lexicon packs (optional, very lightweight)
def load_lexicons(cfg: Dict) -> Dict[str, Any]:
    if not cfg.get("lexicons", {}).get("enable", True):
        return {}
    packs = {}
    for name in cfg.get("lexicons", {}).get("packs", []):
        path = os.path.join(LEX_DIR, name)
        try:
            if os.path.isfile(path):
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                packs[name] = data
        except Exception as e:
            _log(f"Lexicon load error {name}: {e}")
    return packs

# ---------------- Git utilities and Manager
def _git_available() -> bool:
    return shutil.which("git") is not None

def _gh_available() -> bool:
    return shutil.which("gh") is not None

def _run_git(args: List[str], cwd: Optional[str]=None) -> Tuple[int, str]:
    try:
        out = subprocess.check_output(["git"] + args, cwd=cwd, stderr=subprocess.STDOUT, text=True)
        return 0, out
    except subprocess.CalledProcessError as e:
        return e.returncode, e.output
    except Exception as e:
        return 1, str(e)

def ensure_repo(repo_dir: str) -> str:
    ensure_dir(repo_dir)
    if not os.path.isdir(os.path.join(repo_dir, ".git")):
        code, out = _run_git(["init", "-b", "main"], cwd=repo_dir)
        _log(f"git init: {code}\n{out}")
        rp = os.path.join(repo_dir, "README.md")
        if not os.path.isfile(rp):
            write_text(rp, "# Codex-Local\n\nLocal repo managed by Codex Local UI.\n")
        _run_git(["add", "."], cwd=repo_dir)
        _run_git(["commit", "-m", "Initial commit"], cwd=repo_dir)
    return repo_dir

def git_stage_commit_push(repo_dir: str, message: str, remote: str="origin", branch: str="main") -> str:
    _run_git(["add", "."], cwd=repo_dir)
    rc, out = _run_git(["commit", "-m", message], cwd=repo_dir)
    if rc != 0 and "nothing to commit" not in out.lower():
        return f"[Git] Commit failed: {out}"
    rc, out = _run_git(["remote"], cwd=repo_dir)
    remotes = out.split()
    if remote not in remotes:
        return ("[Git] No 'origin' remote is set. Use GitHub Desktop or run:\n"
                f"  git remote add origin <URL>\n"
                f"  git push -u origin {branch}\n")
    rc, out = _run_git(["push", "-u", remote, branch], cwd=repo_dir)
    if rc != 0:
        return f"[Git] Push failed: {out}"
    return "[Git] Pushed successfully."

def gh_create_pr(repo_dir: str, title: str, body: str, base: str="main", head: Optional[str]=None) -> str:
    if not _gh_available():
        return "[PR] GitHub CLI 'gh' not found. Install it or open PR via GitHub Desktop."
    cmd = ["gh", "pr", "create", "--title", title, "--body", body, "--base", base]
    if head:
        cmd += ["--head", head]
    try:
        out = subprocess.check_output(cmd, cwd=repo_dir, stderr=subprocess.STDOUT, text=True)
        return f"[PR] {out.strip()}"
    except subprocess.CalledProcessError as e:
        return f"[PR] Failed: {e.output.strip()}"
    except Exception as e:
        return f"[PR] Error: {e}"

# ---------------- Embedding store
class EmbedStore:
    """
    dataset_dir/session_id/
      dataset.jsonl          # {id, ts, role, text, tags, ...}
      embeddings.jsonl       # {id, vector}
    """
    def __init__(self, root: str):
        self.root = root
        ensure_dir(self.root)
        self.session_id = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        self.sdir = os.path.join(self.root, self.session_id)
        ensure_dir(self.sdir)
        self.paths = {
            "dataset": os.path.join(self.sdir, "dataset.jsonl"),
            "embeds":  os.path.join(self.sdir, "embeddings.jsonl")
        }
        self._cache_vectors: Dict[str, List[float]] = {}

    def add_item(self, item: Dict[str, Any]):
        append_text(self.paths["dataset"], json.dumps(item, ensure_ascii=False) + "\n")

    def add_embed(self, item_id: str, vec: List[float]):
        rec = {"id": item_id, "vector": vec}
        append_text(self.paths["embeds"], json.dumps(rec) + "\n")
        self._cache_vectors[item_id] = vec

    def _load_all_vectors(self) -> Dict[str, List[float]]:
        if self._cache_vectors:
            return self._cache_vectors
        m: Dict[str, List[float]] = {}
        try:
            with open(self.paths["embeds"], "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line: continue
                    obj = json.loads(line)
                    m[obj["id"]] = obj.get("vector", [])
        except Exception:
            pass
        self._cache_vectors = m
        return m

    def search(self, query_vec: List[float], topk: int=5) -> List[Tuple[str, float]]:
        vs = self._load_all_vectors()
        scored = [(k, cosine(query_vec, v)) for k, v in vs.items()]
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored[:topk]

# ---------------- Markdown chat file
class MarkdownLog:
    """
    Stores visible chat as Markdown. Embedded images saved to /conversations/<session>/images.
    """
    def __init__(self, root: str):
        self.session_id = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        self.sdir = os.path.join(root, self.session_id)
        self.img_dir = os.path.join(self.sdir, "images")
        ensure_dir(self.img_dir)
        self.path = os.path.join(self.sdir, "conversation.md")
        header = f"# Conversation — {self.session_id}\n\n"
        write_text(self.path, header)

    def add_user(self, text: str, images: List[str]):
        stamp = _ts()
        append_text(self.path, f"\n## User @ {stamp}\n\n{text}\n\n")
        for p in images:
            rel = os.path.relpath(p, os.path.dirname(self.path))
            append_text(self.path, f"![upload]({rel.replace(os.sep,'/')})\n\n")

    def add_ai(self, model: str, text: str):
        stamp = _ts()
        append_text(self.path, f"\n## AI [{model}] @ {stamp}\n\n{text}\n\n")

# ---------------- Ollama client
class OllamaClient:
    def __init__(self, host: str):
        self.host = host.rstrip("/")
        self.req = _requests()

    def available(self) -> bool:
        if not self.req:
            return False
        try:
            r = self.req.get(f"{self.host}/api/tags", timeout=4)
            return r.ok
        except Exception:
            return False

    def list_models(self) -> List[str]:
        if not self.req:
            return []
        try:
            r = self.req.get(f"{self.host}/api/tags", timeout=6)
            if not r.ok:
                return []
            names = []
            for m in r.json().get("models", []):
                n = m.get("name") or m.get("model") or ""
                if n:
                    names.append(n)
            return sorted(set(names))
        except Exception as e:
            _log(f"Ollama list error: {e}")
            return []

    def chat(self, model: str, messages: List[Dict[str, Any]], stream: bool=False):
        if not self.req:
            raise RuntimeError("requests not installed")
        url = f"{self.host}/api/chat"
        payload = {"model": model, "messages": messages, "stream": bool(stream)}
        r = self.req.post(url, json=payload, stream=stream, timeout=300)
        if not r.ok:
            raise RuntimeError(f"HTTP {r.status_code}: {r.text[:400]}")
        if stream:
            for line in r.iter_lines(decode_unicode=True):
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception:
                    continue
                yield obj
        else:
            yield r.json()

    def embed(self, model: str, text: str) -> List[float]:
        if not self.req:
            return []
        url = f"{self.host}/api/embeddings"
        # Ollama supports "input" newer; fall back to "prompt" for older servers.
        payload = {"model": model, "input": text}
        try:
            r = self.req.post(url, json=payload, timeout=60)
            if not r.ok:
                _log(f"embed error: {r.status_code}: {r.text[:200]}")
                return []
            data = r.json()
            return data.get("embedding") or data.get("data", [{}])[0].get("embedding", [])
        except Exception as e:
            _log(f"embed exception: {e}")
            return []

# ---------------- Settings dialogs
class SchemaManagerDialog(QDialog):
    def __init__(self, t: Theme, parent=None):
        super().__init__(parent)
        self.t = t
        self.setWindowTitle("Schema Manager")
        self.resize(820, 560)
        root = QVBoxLayout(self)
        hint = QLabel("Schemas are local. Define operators and prompt schemas here in future.")
        self.text = QPlainTextEdit(self)
        self.text.setReadOnly(True)
        self.text.setPlainText(
            "# Schemas\n"
            "- operator: chat → uses 'system' or 'system_min'\n"
            "- operator: vision → OCR + Creative chain using two models\n"
            "- operator: rag.embed → Embedding model\n"
        )
        root.addWidget(hint)
        root.addWidget(self.text, 1)
        self._apply_dark(self)

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(f"""
        QDialog, QWidget {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QLabel {{ color:{self.t.header_fg}; }}
        QPlainTextEdit {{ background:{self.t.term_bg}; color:{self.t.term_fg}; border:1px solid {self.t.card_border}; }}
        QTabWidget::pane {{ background:{self.t.card_bg}; border:1px solid {self.t.card_border}; }}
        QScrollArea, QScrollArea QWidget, QAbstractScrollArea {{
            background:{self.t.card_bg}; color:{self.t.header_fg};
        }}
        """)

class GitManagerDialog(QDialog):
    def __init__(self, t: Theme, repo_dir: str, parent=None):
        super().__init__(parent)
        self.t = t
        self.repo_dir = ensure_repo(repo_dir)
        self.setWindowTitle("GitHub Manager — Codex-Local")
        self.resize(900, 620)

        root = QVBoxLayout(self)

        self.status = QPlainTextEdit(self); self.status.setReadOnly(True)
        self.status.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Consolas, 'Cascadia Code', monospace; font-size:12.2pt;"
            f"border:1px solid {t.card_border};"
        )

        controls = QGridLayout()
        self.branch_line = QLineEdit("main")
        self.msg_line = QLineEdit("Update from Codex Local")
        self.btn_stage = QPushButton("Stage All")
        self.btn_commit = QPushButton("Commit")
        self.btn_push = QPushButton("Push")
        self.btn_pr = QPushButton("Open PR (via gh)")
        self.btn_open = QPushButton("Open Repo Folder")

        controls.addWidget(QLabel("Branch"), 0,0)
        controls.addWidget(self.branch_line, 0,1)
        controls.addWidget(QLabel("Message"), 1,0)
        controls.addWidget(self.msg_line, 1,1)
        controls.addWidget(self.btn_stage, 2,0)
        controls.addWidget(self.btn_commit, 2,1)
        controls.addWidget(self.btn_push, 3,0)
        controls.addWidget(self.btn_pr, 3,1)
        controls.addWidget(self.btn_open, 4,1)

        root.addLayout(controls)
        root.addWidget(self.status, 1)

        self.btn_stage.clicked.connect(self._stage)
        self.btn_commit.clicked.connect(self._commit)
        self.btn_push.clicked.connect(self._push)
        self.btn_pr.clicked.connect(self._pr)
        self.btn_open.clicked.connect(self._open)

        self._apply_dark(self)
        self._refresh_status()

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(f"""
        QDialog, QWidget {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QLabel {{ color:{self.t.header_fg}; }}
        QLineEdit {{
            background:#0d1a2b; color:#eaf2ff; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px;
        }}
        QPushButton {{
            color:#ffffff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton:hover {{ background:{self.t.accent_hover}; }}
        QTabWidget::pane {{ background:{self.t.card_bg}; border:1px solid {self.t.card_border}; }}
        """)

    def _refresh_status(self):
        if not _git_available():
            self.status.setPlainText("git not found in PATH. Install Git or GitHub Desktop.")
            return
        rc, out = _run_git(["status", "--porcelain", "--branch"], cwd=self.repo_dir)
        self.status.setPlainText(out)

    def _stage(self):
        _run_git(["add", "."], cwd=self.repo_dir)
        self._refresh_status()

    def _commit(self):
        msg = self.msg_line.text().strip() or "Update"
        rc, out = _run_git(["commit", "-m", msg], cwd=self.repo_dir)
        self.status.appendPlainText(out)

    def _push(self):
        branch = self.branch_line.text().strip() or "main"
        result = git_stage_commit_push(self.repo_dir, self.msg_line.text().strip() or "Update", branch=branch)
        self.status.appendPlainText(result)

    def _pr(self):
        title = self.msg_line.text().strip() or "Update"
        body  = "PR created by Codex Local"
        out = gh_create_pr(self.repo_dir, title, body, base=self.branch_line.text().strip() or "main")
        self.status.appendPlainText(out)

    def _open(self):
        path = self.repo_dir
        try:
            if sys.platform.startswith("win"):
                os.startfile(path)
            elif sys.platform == "darwin":
                subprocess.Popen(["open", path])
            else:
                subprocess.Popen(["xdg-open", path])
        except Exception as e:
            QMessageBox.warning(self, "Open Folder", str(e))

class SettingsDialog(QDialog):
    def __init__(self, t: Theme, cfg: Dict, all_models: List[str], shell_hooks: ShellHooks, parent=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.all_models = all_models
        self.hooks = shell_hooks
        self.setWindowTitle("Settings")
        self.resize(1050, 780)

        tabs = QTabWidget(self)

        # Models tab
        models_tab = QWidget(); models_tab.setObjectName("models_tab"); mt = QGridLayout(models_tab)
        self.chat_cb   = QComboBox();  self.chat_cb.setEditable(True)
        self.vision_ocr_cb = QComboBox(); self.vision_ocr_cb.setEditable(True)
        self.vision_creative_cb = QComboBox(); self.vision_creative_cb.setEditable(True)
        self.embed_cb  = QComboBox();  self.embed_cb.setEditable(True)
        for cb in (self.chat_cb, self.vision_ocr_cb, self.vision_creative_cb, self.embed_cb):
            for m in all_models: cb.addItem(m)
        self.chat_cb.setCurrentText(cfg["models"].get("chat",""))
        self.vision_ocr_cb.setCurrentText(cfg["models"].get("vision_ocr",""))
        self.vision_creative_cb.setCurrentText(cfg["models"].get("vision_creative",""))
        self.embed_cb.setCurrentText(cfg["models"].get("embed",""))
        mt.addWidget(QLabel("Chat Model"), 0,0);   mt.addWidget(self.chat_cb, 0,1)
        mt.addWidget(QLabel("Vision (OCR)"),1,0);  mt.addWidget(self.vision_ocr_cb,1,1)
        mt.addWidget(QLabel("Vision (Creative)"),2,0);  mt.addWidget(self.vision_creative_cb,2,1)
        mt.addWidget(QLabel("Embedding Model"),3,0); mt.addWidget(self.embed_cb,3,1)
        self.context_slider = QSlider(Qt.Horizontal); self.context_slider.setMinimum(1); self.context_slider.setMaximum(100)
        self.context_slider.setValue(int(cfg.get("context_pairs", 25)))
        mt.addWidget(QLabel("Context pairs"), 4,0); mt.addWidget(self.context_slider, 4,1)

        # Behavior tab
        behavior_tab = QWidget(); behavior_tab.setObjectName("behavior_tab"); fb = QFormLayout(behavior_tab)
        self.prompt_influence = QCheckBox("Enable Prompt Influence")
        self.prompt_influence.setChecked(bool(cfg.get("prompt_influence", True)))
        self.stream_toggle = QCheckBox("Stream responses")
        self.stream_toggle.setChecked(bool(cfg.get("stream", False)))
        fb.addRow(self.prompt_influence)
        fb.addRow(self.stream_toggle)

        # Prompts tab
        prompts_tab = QWidget(); prompts_tab.setObjectName("prompts_tab"); gp = QGridLayout(prompts_tab)
        self.sys_prompt    = QTextEdit(cfg["prompts"].get("system",""))
        self.sys_min_prompt= QTextEdit(cfg["prompts"].get("system_min",""))
        self.vision_prompt = QTextEdit(cfg["prompts"].get("vision",""))
        self.user_prefix   = QTextEdit(cfg["prompts"].get("user_prefix",""))
        gp.addWidget(QLabel("System (rich)"), 0,0); gp.addWidget(self.sys_prompt, 0,1)
        gp.addWidget(QLabel("System (minimal)"), 1,0); gp.addWidget(self.sys_min_prompt, 1,1)
        gp.addWidget(QLabel("Vision Prompt"), 2,0); gp.addWidget(self.vision_prompt, 2,1)
        gp.addWidget(QLabel("User Prefix"), 3,0); gp.addWidget(self.user_prefix, 3,1)

        # Paths tab
        paths_tab = QWidget(); paths_tab.setObjectName("paths_tab"); pl = QFormLayout(paths_tab)
        self.conv_dir_edit = QLineEdit(cfg["paths"].get("conversation_dir", CONV_DIR))
        self.data_dir_edit = QLineEdit(cfg["paths"].get("dataset_dir", DATA_DIR))
        self.repo_dir_edit = QLineEdit(cfg["paths"].get("repo_dir", REPO_DIR))
        pl.addRow("Conversations Folder", self.conv_dir_edit)
        pl.addRow("Datasets Folder", self.data_dir_edit)
        pl.addRow("Repo Folder", self.repo_dir_edit)

        # Shells tab
        shells_tab = QWidget(); shells_tab.setObjectName("shells_tab"); sl = QVBoxLayout(shells_tab)
        wsl_ok, distros = self.hooks.wsl_status()
        shells_info = QPlainTextEdit(); shells_info.setReadOnly(True)
        msg = ["Discovered shells:"]
        for k, v in self.hooks.found.items():
            msg.append(f"- {k}: {v}")
        if not wsl_ok:
            msg.append("")
            msg.append(self.hooks.advice_install_wsl())
        else:
            msg.append(f"WSL OK. Distros: {', '.join(distros) if distros else '(none listed)'}")
        shells_info.setPlainText("\n".join(msg))
        sl.addWidget(shells_info)

        # Lexicons tab
        lex_tab = QWidget(); lex_tab.setObjectName("lex_tab"); ll = QVBoxLayout(lex_tab)
        self.lex_enable = QCheckBox("Enable Lexicon Packs")
        self.lex_enable.setChecked(bool(cfg.get("lexicons",{}).get("enable", True)))
        self.lex_list = QListWidget()
        for p in cfg.get("lexicons",{}).get("packs", []):
            QListWidgetItem(p, self.lex_list)
        ll.addWidget(self.lex_enable)
        ll.addWidget(QLabel("Packs under ./lexicons"))
        ll.addWidget(self.lex_list, 1)

        tabs.addTab(models_tab, "Models")
        tabs.addTab(behavior_tab, "Behavior")
        tabs.addTab(prompts_tab, "Prompts")
        tabs.addTab(paths_tab, "Paths")
        tabs.addTab(shells_tab, "Shells")
        tabs.addTab(lex_tab, "Lexicons")

        buttons = QDialogButtonBox(QDialogButtonBox.Save | QDialogButtonBox.Cancel)
        extra = QHBoxLayout()
        self.open_log = QPushButton("Open System Log…")
        self.open_schema = QPushButton("Open Schema Manager…")
        self.open_git = QPushButton("Open GitHub Manager…")
        extra.addStretch(1); extra.addWidget(self.open_git); extra.addWidget(self.open_schema); extra.addWidget(self.open_log)

        root = QVBoxLayout(self)
        root.addWidget(tabs, 1)
        root.addLayout(extra)
        root.addWidget(buttons)

        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        self.open_log.clicked.connect(lambda: LogViewer(self.t, LOG_PATH, self).exec())
        self.open_schema.clicked.connect(lambda: SchemaManagerDialog(self.t, self).exec())
        self.open_git.clicked.connect(lambda: GitManagerDialog(self.t, self.repo_dir_edit.text().strip(), self).exec())

        self._apply_dark(self)

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(f"""
        QDialog, QWidget {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QLabel  {{ color:{self.t.header_fg}; }}
        QTabWidget::pane {{ background:{self.t.card_bg}; border:1px solid {self.t.card_border}; }}
        QTabBar::tab:selected {{ color:#ffffff; }}
        QGroupBox {{ border:1px solid {self.t.card_border}; border-radius:8px; margin-top:14px; padding-top:10px; }}
        QComboBox, QTextEdit, QLineEdit, QPlainTextEdit {{
            background:#0d1a2b; color:#eaf2ff; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px;
        }}
        QSlider::groove:horizontal {{ background:#263a50; height:6px; border-radius:3px; }}
        QSlider::handle:horizontal {{ background:{self.t.accent}; width:14px; border-radius:7px; }}
        QPushButton {{
            color:#ffffff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton:hover {{ background:{self.t.accent_hover}; }}
        QCheckBox {{ color:#eaf2ff; }}
        """)

    def values(self) -> Dict:
        out = self.cfg.copy()
        out["models"]["chat"]   = self.chat_cb.currentText().strip()
        out["models"]["vision_ocr"] = self.vision_ocr_cb.currentText().strip()
        out["models"]["vision_creative"] = self.vision_creative_cb.currentText().strip()
        out["models"]["embed"]  = self.embed_cb.currentText().strip()
        out["prompt_influence"] = self.prompt_influence.isChecked()
        out["stream"] = self.stream_toggle.isChecked()
        out["paths"]["conversation_dir"] = self.conv_dir_edit.text().strip()
        out["paths"]["dataset_dir"] = self.data_dir_edit.text().strip()
        out["paths"]["repo_dir"] = self.repo_dir_edit.text().strip()
        out["context_pairs"] = int(self.context_slider.value())
        out.setdefault("lexicons", {})
        out["lexicons"]["enable"] = self.lex_enable.isChecked()
        out["lexicons"]["packs"] = [self.lex_list.item(i).text() for i in range(self.lex_list.count())]
        out["prompts"]["system"]     = self.sys_prompt.toPlainText()
        out["prompts"]["system_min"] = self.sys_min_prompt.toPlainText()
        out["prompts"]["vision"]     = self.vision_prompt.toPlainText()
        out["prompts"]["user_prefix"]= self.user_prefix.toPlainText()
        return out

class LogViewer(QDialog):
    def __init__(self, t: Theme, path: str, parent=None):
        super().__init__(parent)
        self.t = t
        self.path = path
        self.setWindowTitle("System Log")
        self.resize(900, 520)

        root = QVBoxLayout(self)
        self.view = QPlainTextEdit(self); self.view.setReadOnly(True)
        self.view.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Consolas, 'Cascadia Code', monospace; font-size:12.2pt;"
            f"border:1px solid {t.card_border};"
        )
        btns = QHBoxLayout()
        refresh = QPushButton("Refresh")
        open_file = QPushButton("Open Log File…")
        clear = QPushButton("Clear Log")
        btns.addStretch(1); btns.addWidget(refresh); btns.addWidget(open_file); btns.addWidget(clear)

        root.addWidget(self.view, 1); root.addLayout(btns)

        refresh.clicked.connect(self._refresh)
        open_file.clicked.connect(self._open)
        clear.clicked.connect(self._clear)

        self._apply_dark(self)
        self._refresh()

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(w.styleSheet() + f"""
        QDialog, QWidget {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QPushButton {{
            color:#ffffff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton:hover {{ background:{self.t.accent_hover}; }}
        QLabel {{ color:{self.t.header_fg}; }}
        """)

    def _refresh(self):
        try:
            with open(self.path, "r", encoding="utf-8") as f:
                txt = f.read()
        except Exception:
            txt = "(no log yet)"
        self.view.setPlainText(txt)
        self.view.moveCursor(QTextCursor.End)

    def _open(self):
        try:
            if sys.platform.startswith("win"):
                os.startfile(self.path)
            elif sys.platform == "darwin":
                subprocess.Popen(["open", self.path])
            else:
                subprocess.Popen(["xdg-open", self.path])
        except Exception as e:
            QMessageBox.warning(self, "Open", str(e))

    def _clear(self):
        try:
            open(self.path, "w", encoding="utf-8").close()
            self._refresh()
        except Exception as e:
            QMessageBox.warning(self, "Clear", str(e))

# ---------------- Chat input (paste & drag-drop images)
class ChatInput(QTextEdit):
    imageAttached = Signal(list)  # list[str] of file paths

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setAcceptDrops(True)

    def insertFromMimeData(self, source):
        try:
            if source.hasImage():
                img = source.imageData()
                if img is not None:
                    path = self._save_qimage(img)
                    if path:
                        self.imageAttached.emit([path])
                        return
            if source.hasUrls():
                paths = []
                for url in source.urls():
                    if url.isLocalFile():
                        paths.append(url.toLocalFile())
                if paths:
                    self.imageAttached.emit(paths)
                    return
        except Exception as e:
            _log(f"paste error: {e}")
        super().insertFromMimeData(source)

    def dragEnterEvent(self, e: QDragEnterEvent):
        if e.mimeData().hasUrls() or e.mimeData().hasImage():
            e.acceptProposedAction()
        else:
            super().dragEnterEvent(e)

    def dropEvent(self, e: QDropEvent):
        try:
            if e.mimeData().hasUrls():
                paths = []
                for url in e.mimeData().urls():
                    if url.isLocalFile():
                        paths.append(url.toLocalFile())
                if paths:
                    self.imageAttached.emit(paths)
                    e.acceptProposedAction()
                    return
            if e.mimeData().hasImage():
                img = e.mimeData().imageData()
                path = self._save_qimage(img)
                if path:
                    self.imageAttached.emit([path])
                    e.acceptProposedAction()
                    return
        except Exception as ex:
            _log(f"drop error: {ex}")
        super().dropEvent(e)

    def _save_qimage(self, qimg) -> Optional[str]:
        try:
            ba = QByteArray()
            buf = QBuffer(ba)
            buf.open(QBuffer.WriteOnly)
            qimg.save(buf, "PNG")
            data = bytes(ba)
            out_dir = os.path.join(CONV_DIR, "clipboard")
            ensure_dir(out_dir)
            name = f"clip_{int(time.time()*1000)}.png"
            path = os.path.join(out_dir, name)
            with open(path, "wb") as f:
                f.write(data)
            return path
        except Exception as e:
            _log(f"save_qimage error: {e}")
            return None

# ---------------- Chat card
class ChatCard(QFrame):
    def __init__(self, t: Theme, cfg: Dict, parent: Optional[QWidget]=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.ollama = OllamaClient(cfg["ollama_host"])
        self.shells = ShellHooks()
        self.lexicons = load_lexicons(cfg)
        self.embed_store = EmbedStore(cfg["paths"]["dataset_dir"])
        self.mlog = MarkdownLog(cfg["paths"]["conversation_dir"])
        self.active_images: List[str] = []  # pending images for next user message
        self.history: List[Dict[str,str]] = []  # role, content

        self.setObjectName("ChatCard")
        self.resize(1200, 760)
        sh = QGraphicsDropShadowEffect(self); sh.setColor(QColor(0,30,80,150)); sh.setBlurRadius(28); sh.setOffset(0,12)
        self.setGraphicsEffect(sh)

        root = QVBoxLayout(self); root.setContentsMargins(0,0,0,0); root.setSpacing(0)

        # Header
        hdr = QFrame(self); hdr.setObjectName("Hdr")
        H = QHBoxLayout(hdr); H.setContentsMargins(12,8,12,8); H.setSpacing(8)
        title = QLabel("Codex Local")
        title.setStyleSheet(f"color:{t.header_fg}; font-weight:700; letter-spacing:.2px;")
        self.model_cb = QComboBox(); self.model_cb.setEditable(True)
        self.refresh_btn = QToolButton(); self.refresh_btn.setText("↻"); self.refresh_btn.setToolTip("Refresh Ollama models")
        self.track_btn = QPushButton("Track"); self.track_btn.setCheckable(True); self.track_btn.setChecked(True); self.track_btn.setObjectName("Btn")
        self.settings_btn = QToolButton(); self.settings_btn.setText("⋮"); self.settings_btn.setToolTip("Settings")
        H.addWidget(title); H.addStretch(1)
        H.addWidget(QLabel("Model:")); H.addWidget(self.model_cb); H.addWidget(self.refresh_btn)
        H.addSpacing(6); H.addWidget(self.track_btn); H.addWidget(self.settings_btn)
        root.addWidget(hdr)

        # Content split
        split = QSplitter(Qt.Horizontal, self)

        # Chat view
        self.view = QTextEdit(self)
        self.view.setReadOnly(True)
        self.view.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Segoe UI, Inter, 'Cascadia Code', Consolas, monospace; font-size:12.8pt;"
            f"border-top:1px solid {t.card_border}; border-bottom:1px solid {t.card_border}; padding:10px;"
        )

        # Tools pane
        tools = QWidget(self); Tl = QVBoxLayout(tools); Tl.setContentsMargins(8,8,8,8); Tl.setSpacing(8)
        self.context_label = QLabel(f"Context pairs: {int(cfg.get('context_pairs',25))}")
        self.context_slider = QSlider(Qt.Vertical)
        self.context_slider.setMinimum(1); self.context_slider.setMaximum(100)
        self.context_slider.setValue(int(cfg.get("context_pairs", 25)))
        self.context_slider.valueChanged.connect(lambda v: self.context_label.setText(f"Context pairs: {v}"))
        self.attach_btn = QPushButton("Attach Image"); self.attach_btn.setObjectName("Btn")
        self.rag_search = QLineEdit(); self.rag_search.setPlaceholderText("RAG quick search…")
        self.rag_btn = QPushButton("Search"); self.rag_btn.setObjectName("Btn")
        Tl.addWidget(self.context_label)
        Tl.addWidget(self.context_slider, 1)
        Tl.addSpacing(6)
        Tl.addWidget(self.attach_btn)
        Tl.addWidget(self.rag_search)
        Tl.addWidget(self.rag_btn)
        Tl.addStretch(10)

        split.addWidget(self.view)
        split.addWidget(tools)
        split.setSizes([900, 240])
        root.addWidget(split, 1)

        # Input row
        ib = QFrame(self); ib.setObjectName("IB")
        I = QVBoxLayout(ib); I.setContentsMargins(10,8,10,10); I.setSpacing(8)

        self.input = ChatInput(ib)
        self.input.setAcceptRichText(False)
        self.input.setPlaceholderText("Type to chat… (Enter=send, Shift+Enter=newline) • Paste/drag images to attach")
        self.input.document().setMaximumBlockCount(4)
        self._set_input_height_lines(2)
        self.input.textChanged.connect(self._grow_shrink_input)
        self.input.imageAttached.connect(self._import_paths)

        bottom = QHBoxLayout(); bottom.setSpacing(8)
        self.clear_images = QPushButton("Clear Images"); self.clear_images.setObjectName("Btn")
        self.send_btn = QPushButton("Send"); self.send_btn.setObjectName("Btn")
        self.clear_btn = QPushButton("Clear Chat"); self.clear_btn.setObjectName("Btn")
        bottom.addWidget(self.clear_images)
        bottom.addStretch(1)
        bottom.addWidget(self.clear_btn)
        bottom.addWidget(self.send_btn)

        I.addWidget(self.input); I.addLayout(bottom)
        root.addWidget(ib)

        # Styles
        self.setStyleSheet(f"""
        QFrame#ChatCard {{
            background:{t.card_bg}; border:1px solid {t.card_border}; border-radius:{t.card_radius}px;
        }}
        QFrame#Hdr {{
            background:{t.header_bg}; border-top-left-radius:{t.card_radius}px; border-top-right-radius:{t.card_radius}px;
        }}
        QFrame#IB {{
            background:{t.card_bg}; border-bottom-left-radius:{t.card_radius}px; border-bottom-right-radius:{t.card_radius}px;
        }}
        QLabel {{ color:{t.header_fg}; }}
        QComboBox {{ background:#0d1a2b; color:#eaf2ff; border:1px solid {t.card_border}; padding:4px 6px; }}
        QComboBox QAbstractItemView {{ background:#0d1a2b; color:#eaf2ff; selection-background-color:{t.accent}; }}
        QToolButton {{ color:#eaf2ff; background:transparent; border:0; }}
        QPushButton#Btn {{
            color:#ffffff; background:{t.accent}; border:1px solid {t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton#Btn:checked {{ background:{t.accent_hover}; }}
        QPushButton#Btn:hover {{ background:{t.accent_hover}; }}
        QTextEdit {{
            background:#0d1a2b; color:#eaf2ff; border:1px solid {t.card_border}; border-radius:8px; padding:8px;
            font-family: Segoe UI, Inter, 'Cascadia Code', Consolas, monospace; font-size:12.6pt;
        }}
        """)

        # Connect
        self.send_btn.clicked.connect(self._send)
        self.clear_btn.clicked.connect(lambda: self.view.clear())
        self.refresh_btn.clicked.connect(self.refresh_models)
        self.model_cb.currentTextChanged.connect(lambda s: self._system_message(f"[Model] {s}"))
        self.settings_btn.clicked.connect(self._open_settings)
        self.attach_btn.clicked.connect(self._attach_image_dialog)
        self.clear_images.clicked.connect(self._clear_images)
        self.rag_btn.clicked.connect(self._rag_quick_search)

        # Boot
        self.refresh_models(prefer=self.cfg["models"].get("chat",""))
        if not self.ollama.available():
            self._system_message("[Error] Ollama not found at host. Start Ollama or adjust Settings.")
        self._apply_enter_behavior()
        self._system_message("[Info] Ready. Local Shell hooks loaded silently. Use Settings → GitHub Manager for repo.")
        threading.Thread(target=lambda: ensure_repo(self.cfg["paths"].get("repo_dir", REPO_DIR)), daemon=True).start()

    # ---------- Helpers: styled bubbles
    def _bubble(self, text: str, role: str, model: Optional[str]=None) -> str:
        if role == "user":
            bg = self.t.user_bubble_bg; fg = self.t.user_bubble_fg
            name = '<span style="font-weight:600;">You</span>'
        else:
            bg = self.t.ai_bubble_bg; fg = self.t.ai_bubble_fg
            if model:
                name = f'<span style="font-weight:600;">AI</span> <span style="color:{self.t.model_teal};">[{model}]</span>'
            else:
                name = '<span style="font-weight:600;">AI</span>'

        def render_think(m: re.Match) -> str:
            inner = m.group(1)
            esc = (inner.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;"))
            return f'<div style="color:{self.t.think_fg}; font-style:italic; font-size:0.9em;">{esc}</div>'
        text_html = (text.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;"))
        text_html = re.sub(r"&lt;think&gt;(.*?)&lt;/think&gt;", render_think, text_html, flags=re.DOTALL|re.IGNORECASE)

        return (
            f'<div style="margin:8px 0;">'
            f'  <div style="color:{fg}; background:{bg}; border:1px solid {self.t.card_border};'
            f'             border-radius:10px; padding:10px 12px;">'
            f'    <div style="opacity:0.9; margin-bottom:4px;">{name} <span style="opacity:0.7;">{_ts()}</span></div>'
            f'    <div style="white-space:pre-wrap; line-height:1.4;">{text_html}</div>'
            f'  </div>'
            f'</div>'
        )

    def _append_html(self, html: str):
        self.view.moveCursor(QTextCursor.End)
        self.view.insertHtml(html)
        self.view.insertHtml("<br/>")
        self.view.moveCursor(QTextCursor.End)

    def _system_message(self, text: str):
        html = (
            f'<div style="margin:6px 0;">'
            f'  <div style="color:{self.t.info};">{(text.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;"))}</div>'
            f'</div>'
        )
        self._append_html(html)
        _log(text)

    # ---------- Input sizing
    def _set_input_height_lines(self, lines: int):
        metrics = self.input.fontMetrics()
        h = int(lines * (metrics.lineSpacing() + 2)) + 18
        self.input.setMinimumHeight(h)
        self.input.setMaximumHeight(int(4 * (metrics.lineSpacing() + 2)) + 18)

    def _grow_shrink_input(self):
        doc_h = self.input.document().size().toSize().height()
        current = self.input.height()
        target = min(self.input.maximumHeight(), max(self.input.minimumHeight(), doc_h + 18))
        if abs(target - current) > 2:
            self.input.setFixedHeight(target)

    # ---------- Enter behavior
    def _apply_enter_behavior(self):
        self.input.installEventFilter(self)

    def eventFilter(self, obj, ev):
        if obj is self.input and ev.type() == QEvent.KeyPress:
            if ev.key() in (Qt.Key_Return, Qt.Key_Enter):
                if ev.modifiers() & Qt.ShiftModifier:
                    return False
                self._send()
                return True
        return super().eventFilter(obj, ev)

    # ---------- Image intake
    def _import_paths(self, paths: List[str]):
        added = 0
        for p in paths:
            out = self._prep_image_for_chat(p)
            if out:
                self.active_images.append(out)
                added += 1
        if added:
            self._system_message(f"[Attach] {added} image(s) ready.")

    def _attach_image_dialog(self):
        dlg = QFileDialog(self)
        dlg.setFileMode(QFileDialog.ExistingFiles)
        dlg.setNameFilters(["Images (*.png *.jpg *.jpeg *.webp *.bmp *.gif)", "All files (*.*)"])
        if dlg.exec():
            self._import_paths(dlg.selectedFiles())

    def _clear_images(self):
        n = len(self.active_images)
        self.active_images = []
        self._system_message(f"[Attach] Cleared {n} image(s).")

    def _prep_image_for_chat(self, path: str) -> Optional[str]:
        try:
            img_dir = self.mlog.img_dir
            ensure_dir(img_dir)
            base = slug(os.path.splitext(os.path.basename(path))[0])
            ext = os.path.splitext(path)[1].lower()
            out_full = os.path.join(img_dir, base + (".png" if _pil() else ext))
            Image = _pil()
            if Image:
                im = Image.open(path)
                im.convert("RGB").save(out_full, format="PNG", optimize=True)
            else:
                shutil.copy2(path, out_full)  # keep original extension if no Pillow
            return out_full
        except Exception as e:
            self._system_message(f"[Image] {e}")
            return None

    # ---------- Settings and models
    def _open_settings(self):
        models = self._all_models()
        dlg = SettingsDialog(self.t, self.cfg, models, self.shells, self)
        if dlg.exec() == QDialog.Accepted:
            self.cfg = dlg.values()
            save_config(self.cfg)
            wanted = self.cfg["models"].get("chat","").strip()
            if wanted:
                if self.model_cb.findText(wanted) < 0:
                    self.model_cb.addItem(wanted)
                self.model_cb.setCurrentText(wanted)
            self._system_message("[Info] Settings saved.")

    def _all_models(self) -> List[str]:
        return self.ollama.list_models()

    def refresh_models(self, prefer: Optional[str]=None):
        self.model_cb.clear()
        names = self._all_models()
        if not names:
            self.model_cb.addItem("(no models found)")
            self._system_message("[Warn] No local models. Example:  ollama pull qwen3:30b")
            return
        for n in names: self.model_cb.addItem(n)
        pick = (prefer if prefer in names else
                self.cfg["models"].get("chat") if self.cfg["models"].get("chat") in names else names[0])
        self.model_cb.setCurrentText(pick)
        self._system_message(f"[Models] {len(names)} found. Current: {pick}")

    # ---------- Build messages
    def _system_prompt(self) -> str:
        p = self.cfg["prompts"]
        return p["system"] if self.cfg.get("prompt_influence", True) else p["system_min"]

    def _user_wrap(self, text: str) -> str:
        prefix = self.cfg["prompts"].get("user_prefix","").strip()
        return f"{prefix} {text}".strip() if prefix else text

    def _last_context(self, pairs: int) -> List[Dict[str, str]]:
        msgs = []
        count_user = 0
        tmp = []
        for msg in reversed(self.history):
            tmp.append(msg)
            if msg["role"] == "user":
                count_user += 1
                if count_user >= pairs:
                    break
        for msg in reversed(tmp):
            msgs.append(msg)
        return msgs

    # ---------- Vision helpers
    def _img_to_b64(self, path: str) -> Optional[str]:
        try:
            # Normalize to PNG if Pillow is present; else raw bytes are fine.
            Image = _pil()
            if Image:
                im = Image.open(path)
                im = im.convert("RGBA")
                buf = io.BytesIO()
                im.save(buf, format="PNG", optimize=True)
                return base64.b64encode(buf.getvalue()).decode("ascii")
            with open(path, "rb") as f:
                return base64.b64encode(f.read()).decode("ascii")
        except Exception as e:
            _log(f"img b64 error: {e}")
            return None

    def _ocr_markdown(self, images: List[str]) -> str:
        if not images: return ""
        model = self.cfg["models"].get("vision_ocr", DEFAULT_VISION_OCR_MODEL)
        b64s = [self._img_to_b64(ip) for ip in images]
        b64s = [b for b in b64s if b]
        if not b64s: return ""
        prompt = (
            "Extract faithful Markdown from the attached image(s). Preserve layout, tables, math, "
            "and exact text/numbers. Do NOT invent or summarize; return ONLY the Markdown content."
        )
        msgs = [{"role":"user","content":prompt, "images": b64s}]
        try:
            data = next(self.ollama.chat(model, msgs, stream=False))
            out = (data.get("message") or {}).get("content","").strip() or (data.get("response") or "").strip()
            return out
        except Exception as e:
            return f"[ocr-error] {e}"

    def _creative_summary(self, images: List[str], user_text: str, ocr_md: str) -> str:
        model = self.cfg["models"].get("vision_creative", DEFAULT_VISION_CREATIVE)
        b64s = [self._img_to_b64(ip) for ip in images]
        b64s = [b for b in b64s if b]
        if not b64s: return ""
        sys = (
            "You are a multimodal assistant. Use the provided OCR Markdown as ground truth for "
            "numbers and text. Produce a concise, well-structured summary with:\n"
            "- Title\n- Key elements\n- Visible UI state (if any)\n- Important numbers\n- Problems/Errors\n"
            "Prefer OCR numbers/text when in doubt."
        )
        user = f"User request: {user_text or '(no explicit request)'}\n\n[OCR]\n{ocr_md[:8000]}"
        msgs = [{"role":"system","content":sys},
                {"role":"user","content":user, "images": b64s}]
        try:
            data = next(self.ollama.chat(model, msgs, stream=False))
            out = (data.get("message") or {}).get("content","").strip() or (data.get("response") or "").strip()
            return out
        except Exception as e:
            return f"[vision-error] {e}"

    # ---------- Send
    def _send(self):
        text = self.input.toPlainText().strip()
        if not text and not self.active_images:
            return
        self.input.clear()

        # Render user bubble
        bubble = self._bubble(text if text else "(attached image)", "user")
        self._append_html(bubble)

        # Save to Markdown with images
        self.mlog.add_user(text, self.active_images)

        # Add to history
        if text:
            self.history.append({"role":"user", "content": text})

        images = list(self.active_images)
        self.active_images = []  # clear now
        threading.Thread(target=self._chat_request, args=(text, images), daemon=True).start()

    # ---------- Chat request
    def _chat_request(self, user_text: str, images: List[str]):
        if not self.ollama.available():
            self._system_message("[Error] Ollama not available at host.")
            return

        chat_model = self.model_cb.currentText().strip()
        if not chat_model or chat_model.startswith("("):
            self._system_message("ai: (no model selected)")
            return

        # Base context
        pairs = int(self.context_slider.value())
        ctx = self._last_context(pairs)
        sys_prompt = self._system_prompt()
        msgs: List[Dict[str, Any]] = [{"role":"system", "content": sys_prompt}]
        msgs.extend(ctx)

        # 2-pass Vision (if images)
        combined_summary = ""
        if images:
            ocr_md = self._ocr_markdown(images)
            creative = self._creative_summary(images, user_text or "(no text)", ocr_md)
            combined_summary = f"## OCR (Markdown)\n{ocr_md}\n\n## Vision Summary\n{creative}".strip()

            # Persist summaries
            vs_path = os.path.join(self.embed_store.sdir, "vision_summaries.md")
            append_text(vs_path, f"\n\n### {datetime.datetime.now().isoformat()}\n{combined_summary}\n")
            # Inject into chat as system context
            msgs.append({"role":"system", "content": f"[Image summary]\n{combined_summary}\n\nUse this summary in context with the dialogue."})
            self._system_message("[Vision] Images processed (OCR→Creative) and injected into chat context.")

        # RAG enrichment
        rag_note = self._rag_enrich(user_text)
        if rag_note:
            msgs.append({"role": "system", "content": f"[RAG context]\n{rag_note}"})

        # Final user turn
        full_user = self._user_wrap(user_text)
        msgs.append({"role": "user", "content": full_user})

        # Stream or non-stream
        stream = bool(self.cfg.get("stream", False))
        try:
            if stream:
                acc = []
                for obj in self.ollama.chat(chat_model, msgs, stream=True):
                    delta = (obj.get("message") or {}).get("content","")
                    if delta:
                        acc.append(delta)
                        self._append_html(self._bubble(delta, "ai", model=chat_model))
                full = "".join(acc).strip()
                self._on_ai_response(chat_model, full, images, combined_summary)
            else:
                data = next(self.ollama.chat(chat_model, msgs, stream=False))
                msg = (data.get("message") or {}).get("content","").strip()
                if not msg:
                    msg = (data.get("response") or "").strip() or "(no content)"
                self._append_html(self._bubble(msg, "ai", model=chat_model))
                self._on_ai_response(chat_model, msg, images, combined_summary)
        except Exception as e:
            self._system_message(f"ai: {e}")

    # ---------- RAG helpers
    def _embed_text(self, embed_model: str, text: str) -> List[float]:
        return self.ollama.embed(embed_model, text) if text else []

    def _rag_enrich(self, user_text: str) -> str:
        """Return a small stitched note from nearest items. Silent if no embedder or text."""
        embed_model = self.cfg["models"].get("embed","").strip()
        if not embed_model or not user_text:
            return ""
        qv = self._embed_text(embed_model, user_text)
        if not qv:
            return ""
        hits = self.embed_store.search(qv, topk=5)
        if not hits:
            return ""
        # Load dataset lines to map id -> text
        id_to_text: Dict[str,str] = {}
        try:
            with open(self.embed_store.paths["dataset"], "r", encoding="utf-8") as f:
                for line in f:
                    if not line.strip(): continue
                    obj = json.loads(line)
                    id_to_text[obj.get("id","")] = obj.get("text","")
        except Exception:
            pass
        lines = []
        for id_, score in hits:
            t = id_to_text.get(id_, "")
            if t:
                lines.append(f"- {t[:400]}")
        return "\n".join(lines[:5])

    # ---------- After response
    def _on_ai_response(self, model: str, text: str, images: List[str], combined_summary: str):
        self.mlog.add_ai(model, text)
        self.history.append({"role":"assistant", "content": text})

        embed_model = self.cfg["models"].get("embed","").strip()
        if embed_model:
            # user record if previous is user
            if len(self.history) >= 2 and self.history[-2]["role"] == "user":
                uid = str(uuid.uuid4())
                utext = self.history[-2]["content"]
                urec = {"id": uid, "ts": _ts(), "role":"user", "text": utext, "tags": ["chat"], "categories": ["conversation"], "images": images}
                self.embed_store.add_item(urec)
                uvec = self._embed_text(embed_model, utext)
                if uvec:
                    self.embed_store.add_embed(uid, uvec)
            # ai record
            aid = str(uuid.uuid4())
            arec = {"id": aid, "ts": _ts(), "role":"assistant", "text": text, "tags": ["chat"], "categories": ["conversation"]}
            self.embed_store.add_item(arec)
            avec = self._embed_text(embed_model, text)
            if avec:
                self.embed_store.add_embed(aid, avec)
            # vision note record (optional)
            if combined_summary:
                vid = str(uuid.uuid4())
                vrec = {"id": vid, "ts": _ts(), "role":"system", "text": combined_summary, "tags": ["vision_summary"], "categories": ["vision"]}
                self.embed_store.add_item(vrec)
                vvec = self._embed_text(embed_model, combined_summary[:2000])
                if vvec:
                    self.embed_store.add_embed(vid, vvec)

    # ---------- Misc UI interactions
    def _rag_quick_search(self):
        q = self.rag_search.text().strip()
        if not q:
            return
        embed_model = self.cfg["models"].get("embed","").strip()
        if not embed_model:
            self._system_message("[RAG] Embedding model unset.")
            return
        qv = self._embed_text(embed_model, q)
        if not qv:
            self._system_message("[RAG] Could not create embedding for query.")
            return
        hits = self.embed_store.search(qv, topk=5)
        lines = [f"[RAG] Top {len(hits)}:"]
        for i, (id_, score) in enumerate(hits, 1):
            lines.append(f"  {i}. {id_}  score={score:.3f}")
        self._system_message("\n".join(lines))

    def header_geom(self) -> QRect: return QRect(0,0,self.width(),46)
    def mousePressEvent(self, e):
        if e.button() == Qt.LeftButton and self.header_geom().contains(e.position().toPoint()):
            self._drag = True; self._press = e.position().toPoint(); self.raise_(); e.accept()
        else:
            super().mousePressEvent(e)
    def mouseMoveEvent(self, e):
        if not getattr(self, "_drag", False):
            return super().mouseMoveEvent(e)
        delta = e.position().toPoint() - self._press
        pos = self.pos() + delta
        canvas = self.parentWidget()
        if canvas:
            r = canvas.rect()
            pos.setX(max(6, min(pos.x(), r.width()-self.width()-6)))
            pos.setY(max(6, min(pos.y(), r.height()-self.height()-6)))
        self.move(pos); e.accept()
        host = self.parentWidget()
        if self.track_btn.isChecked() and host and hasattr(host, "request_focus_on"):
            host.request_focus_on(self)
    def mouseReleaseEvent(self, e):
        self._drag = False
        super().mouseReleaseEvent(e)

# ---------------- Desktop canvas and camera
class DesktopCanvas(QWidget):
    def __init__(self, t: Theme, cfg: Dict, parent=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.resize(3600, 2200)
        self.card = ChatCard(t, cfg, self)
        center = QPoint(self.width()//2, self.height()//2)
        self.card.move(center.x()-self.card.width()//2, center.y()-self.card.height()//2)

    def sizeHint(self) -> QSize: return self.size()

    def paintEvent(self, e):
        p = QPainter(self); p.setRenderHint(QPainter.Antialiasing)
        r = self.rect()
        g = QLinearGradient(r.topLeft(), r.bottomLeft())
        g.setColorAt(0.0, QColor(self.t.desktop_top))
        g.setColorAt(0.55, QColor(self.t.desktop_mid))
        g.setColorAt(1.0, QColor(self.t.desktop_top))
        p.fillRect(r, g)
        glow = QColor(self.t.edge_glow); glow.setAlphaF(0.18)
        p.setPen(glow)
        for i in range(14):
            rr = r.adjusted(10+i,10+i,-10-i,-10-i); p.drawRoundedRect(rr, 18, 18)
        vign = QColor(0,0,0,110); p.setPen(Qt.NoPen); p.setBrush(vign)
        path = QPainterPath(); path.addRect(r)
        inner = r.adjusted(30,30,-30,-30)
        ip = QPainterPath(); ip.addRoundedRect(QRectF(inner), 26, 26)
        p.drawPath(path.subtracted(ip))

    def request_focus_on(self, w: QWidget):
        parent = self.parentWidget()
        if parent and hasattr(parent, "center_on_widget"):
            parent.center_on_widget(w)

class CameraArea(QScrollArea):
    def __init__(self, content: DesktopCanvas, parent=None):
        super().__init__(parent)
        self.setWidget(content)
        self.setWidgetResizable(False)
        self.setFrameShape(QFrame.NoFrame)
        self.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)

    def center_on_widget(self, w: QWidget):
        if not w: return
        c = w.geometry().center()
        self.center_on_point(c)

    def center_on_point(self, pt: QPoint):
        cont = self.widget(); vw = self.viewport().size()
        x = max(0, min(pt.x() - vw.width()//2, cont.width() - vw.width()))
        y = max(0, min(pt.y() - vw.height()//2, cont.height() - vw.height()))
        self.horizontalScrollBar().setValue(x)
        self.verticalScrollBar().setValue(y)

# ---------------- Main window
class Main(QMainWindow):
    def __init__(self, t: Theme, cfg: Dict, embedded: bool=False):
        super().__init__()
        self.t = t
        self.cfg = cfg
        self.setWindowTitle("Codex Local")
        self.resize(1280, 860)

        pal = self.palette()
        pal.setColor(QPalette.Window, QColor("#0a1430"))
        pal.setColor(QPalette.Base, QColor("#0a1430"))
        pal.setColor(QPalette.Text, QColor("#e6f0ff"))
        pal.setColor(QPalette.WindowText, QColor("#e6f0ff"))
        self.setPalette(pal)

        if embedded:
            self.card = ChatCard(t, cfg, self)
            self.setCentralWidget(self.card)
        else:
            self.canvas = DesktopCanvas(t, cfg, self)
            self.camera = CameraArea(self.canvas, self)
            self.setCentralWidget(self.camera)
            QTimer.singleShot(0, lambda: self.camera.center_on_widget(self.canvas.card))

        self._menu()

    def _menu(self):
        bar = self.menuBar()
        f = bar.addMenu("&File")
        f.addAction("Open Script Folder…", lambda: self._open(SCRIPT_ROOT))
        f.addAction("Open Conversations…", lambda: self._open(self.cfg["paths"].get("conversation_dir", CONV_DIR)))
        f.addAction("Open Datasets…", lambda: self._open(self.cfg["paths"].get("dataset_dir", DATA_DIR)))
        f.addAction("Open Repo…", lambda: self._open(self.cfg["paths"].get("repo_dir", REPO_DIR)))
        f.addAction("Open System Log…", lambda: LogViewer(self.t, LOG_PATH, self).exec())
        f.addSeparator()
        q = QAction("Quit", self); q.setShortcut(QKeySequence.Quit); q.triggered.connect(self.close); f.addAction(q)

        v = bar.addMenu("&View")
        fs = QAction("Toggle Fullscreen (Alt+Enter)", self); fs.setShortcut("Alt+Return")
        fs.triggered.connect(self._toggle_fullscreen); v.addAction(fs)

        m = bar.addMenu("&Models")
        m.addAction("Refresh Models", self._refresh_models)

        s = bar.addMenu("&Settings")
        s.addAction("Open Settings…", self._open_settings)
        s.addAction("GitHub Manager…", lambda: GitManagerDialog(self.t, self.cfg["paths"].get("repo_dir", REPO_DIR), self).exec())

    def _refresh_models(self):
        if hasattr(self, "canvas"):
            self.canvas.card.refresh_models()
        elif hasattr(self, "card"):
            self.card.refresh_models()

    def _open_settings(self):
        if hasattr(self, "canvas"):
            self.canvas.card._open_settings()
        elif hasattr(self, "card"):
            self.card._open_settings()

    def _toggle_fullscreen(self):
        if self.isFullScreen(): self.showNormal()
        else: self.showFullScreen()

    def _open(self, path: str):
        try:
            if sys.platform.startswith("win"):
                os.startfile(path)
            elif sys.platform == "darwin":
                subprocess.Popen(["open", path])
            else:
                subprocess.Popen(["xdg-open", path])
        except Exception as e:
            QMessageBox.warning(self, "Open", str(e))

# ---------------- Embedding hook for an external Virtual Desktop host
def build_widget(parent=None) -> QWidget:
    cfg = load_config()
    t = Theme()
    w = ChatCard(t, cfg, parent)
    return w

# ---------------- Entry
def main():
    # DPI policy must be set before QApplication (done at top)
    app = QApplication(sys.argv)
    cfg = load_config()
    t = Theme()
    embedded = bool(os.environ.get("CODEX_EMBEDDED", "0") == "1")
    win = Main(t, cfg, embedded=embedded); win.show()
    oc = OllamaClient(cfg["ollama_host"])
    if not oc.available():
        QMessageBox.warning(win, "Ollama", "Ollama Not Found at host.\nStart Ollama or adjust Settings.")
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
```

Codex Local — Local-first Virtual Desktop Chat with Ollama, 2-pass Vision (OCR→Creative),
RAG dataset, GitHub manager, shell hooks, and high-contrast UI.

Key points:
- High-contrast everywhere (no white panes).
- Paste / drag-drop images into the chat input = same as "Attach Image".
- Vision is automatic on the next Send if images are pending:
    1) benhaotang/Nanonets-OCR-s:latest → faithful Markdown (ground truth).
    2) llava-llama3:latest → concise creative summary, *grounded by OCR*.
  Both texts are saved and the combined summary is injected into the chat model context.
- Fixed AttributeError: _rag_enrich exists and is used by _chat_request.
- Conversation saved to Markdown; mirrored dataset JSONL + embeddings (optional) for retrieval.
- GitHub manager (init/stage/commit/push/PR via gh).

Requirements: PySide6, requests. Optional: pillow, numpy. Ollama at http://127.0.0.1:11434
**Classes:** Theme, ShellHooks, EmbedStore, MarkdownLog, OllamaClient, SchemaManagerDialog, GitManagerDialog, SettingsDialog, LogViewer, ChatInput, ChatCard, DesktopCanvas, CameraArea, Main
**Functions:** _requests(), _pil(), _ts(), _log(line), load_config(), save_config(cfg), human_size(n), ensure_dir(p), read_text(p, default), write_text(p, s), append_text(p, s), slug(s), cosine(a, b), load_lexicons(cfg), _git_available(), _gh_available(), _run_git(args, cwd), ensure_repo(repo_dir), git_stage_commit_push(repo_dir, message, remote, branch), gh_create_pr(repo_dir, title, body, base, head), build_widget(parent), main()


## Module `Dev_Logic\Implemented_logic\Codex_Terminal.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Codex_Terminal.py — standalone/embeddable Ollama chat terminal
- Pure Ollama (no OpenAI, no shell runner).
- Dark theme everywhere (no white-on-white).
- Header taskbar on the card with model selector, Track toggle.
- Settings dialog: per-point model dropdowns (Chat, Vision, Embeddings), Prompt Influence toggle,
  Stream toggle, simple prompt editors, open System Log button (pop-out viewer) + schema manager stub.
- Log file on disk + live in-app viewer.
- Input: 2 lines tall by default, can grow up to 4 lines. Enter to send; Shift+Enter for newline.
- Virtual desktop wrapper:
    • Standalone: renders its own gradient "desktop" behind the card; Track centers the card.
    • Embedded: if a parent virtual desktop hosts the widget, the internal desktop is disabled.

Requires: PySide6, requests, a running Ollama daemon (default http://127.0.0.1:11434).
"""

from __future__ import annotations

import os, sys, json, time, threading, datetime, re, base64
from dataclasses import dataclass
from typing import Optional, List, Dict

# ---- Qt imports
from PySide6.QtCore import (
    Qt, QRect, QRectF, QPoint, QSize, QTimer, Signal, Slot, QEvent, QByteArray, QBuffer
)
from PySide6.QtGui import (
    QAction, QColor, QGuiApplication, QKeySequence, QLinearGradient, QPainter,
    QPainterPath, QPalette, QTextCursor, QFont
)
from PySide6.QtWidgets import (
    QApplication, QComboBox, QDialog, QDialogButtonBox, QFormLayout, QFrame,
    QGraphicsDropShadowEffect, QGridLayout, QGroupBox, QHBoxLayout, QLabel,
    QMainWindow, QPushButton, QSizeGrip, QPlainTextEdit, QTextEdit, QToolButton,
    QVBoxLayout, QWidget, QScrollArea, QMessageBox, QCheckBox, QFileDialog
)

# ---- High DPI policy MUST be set before QApplication
try:
    QGuiApplication.setHighDpiScaleFactorRoundingPolicy(
        Qt.HighDpiScaleFactorRoundingPolicy.PassThrough
    )
except Exception:
    pass

# ---- Optional requests
def _requests():
    try:
        import requests
        return requests
    except Exception:
        return None

# ---- Paths
SCRIPT_ROOT = os.path.abspath(os.path.dirname(__file__))
DATA_DIR    = os.path.join(SCRIPT_ROOT, "datasets")
os.makedirs(DATA_DIR, exist_ok=True)
LOG_PATH    = os.path.join(SCRIPT_ROOT, "codex_terminal.log")
CONFIG_PATH = os.path.join(SCRIPT_ROOT, "config.json")

def _log(line: str):
    ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    msg = f"[{ts}] {line}\n"
    try:
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(msg)
    except Exception:
        pass

# ---- Theme
@dataclass
class Theme:
    desktop_top: str = "#0f3b8e"
    desktop_mid: str = "#1c54cc"
    edge_glow:   str = "#4aa8ff"

    card_bg:     str = "#0c1320"
    card_border: str = "#213040"
    card_radius: int = 14
    header_bg:   str = "#0a111e"
    header_fg:   str = "#eaf2ff"
    term_bg:     str = "#0b1828"
    term_fg:     str = "#e9f3ff"
    accent:      str = "#1E5AFF"
    accent_hover:str = "#2f72ff"
    ok:          str = "#00d17a"
    warn:        str = "#ffd76b"
    err:         str = "#ff6b6b"
    info:        str = "#9bb7ff"
    strip_bg:    str = "#0b0f18"

# ---- Default config
DEFAULTS = {
    "ollama_host": "http://127.0.0.1:11434",
    "prompt_influence": True,              # when False, keep prompts ultra-minimal
    "stream": False,                       # stream chat responses
    "models": {
        "chat": "gpt-oss:20b",
        "vision": "llava-llama3:latest",
        "embed": "snowflake-arctic-embed2:latest"
    },
    "prompts": {
        "system": "You are Codex Terminal. Answer succinctly and correctly.",
        "system_min": "Answer appropriately.",
        "vision": "Analyze this image and explain succinctly.",
        "user_prefix": ""
    }
}

def load_config() -> Dict:
    cfg = {}
    if os.path.isfile(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                cfg = json.load(f)
        except Exception as e:
            _log(f"Config read error: {e}")
            cfg = {}
    # deep fill
    def fill(dst, src):
        for k, v in src.items():
            if isinstance(v, dict):
                dst[k] = fill(dst.get(k, {}), v)
            else:
                dst.setdefault(k, v)
        return dst
    cfg = fill(cfg, DEFAULTS)
    try:
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
    except Exception as e:
        _log(f"Config write error: {e}")
    return cfg

def save_config(cfg: Dict):
    try:
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
    except Exception as e:
        _log(f"Config write error: {e}")

# ---- tiny utils
def human_size(n: int) -> str:
    units = ["B","KB","MB","GB","TB"]
    s = float(n); i = 0
    while s >= 1024 and i < len(units)-1:
        s /= 1024; i += 1
    return f"{s:.1f}{units[i]}" if i else f"{int(s)}{units[i]}"

# ======================================================================================
# Log Viewer
# ======================================================================================

class LogViewer(QDialog):
    def __init__(self, t: Theme, path: str, parent=None):
        super().__init__(parent)
        self.t = t
        self.path = path
        self.setWindowTitle("System Log")
        self.resize(900, 520)

        root = QVBoxLayout(self)
        self.view = QPlainTextEdit(self); self.view.setReadOnly(True)
        self.view.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Consolas, 'Cascadia Code', monospace; font-size:12.2pt;"
            f"border:1px solid {t.card_border};"
        )
        btns = QHBoxLayout()
        refresh = QPushButton("Refresh")
        open_file = QPushButton("Open Log File…")
        clear = QPushButton("Clear Log")
        btns.addStretch(1); btns.addWidget(refresh); btns.addWidget(open_file); btns.addWidget(clear)

        root.addWidget(self.view, 1); root.addLayout(btns)

        refresh.clicked.connect(self._refresh)
        open_file.clicked.connect(self._open)
        clear.clicked.connect(self._clear)

        self._apply_dark(self)
        self._refresh()

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(w.styleSheet() + f"""
        QDialog {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QPushButton {{
            color:#ffffff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton:hover {{ background:{self.t.accent_hover}; }}
        QLabel {{ color:{self.t.header_fg}; }}
        """)
    def _refresh(self):
        try:
            with open(self.path, "r", encoding="utf-8") as f:
                txt = f.read()
        except Exception:
            txt = "(no log yet)"
        self.view.setPlainText(txt)
        self.view.moveCursor(QTextCursor.End)

    def _open(self):
        try:
            if sys.platform.startswith("win"):
                os.startfile(self.path)
            elif sys.platform == "darwin":
                import subprocess; subprocess.Popen(["open", self.path])
            else:
                import subprocess; subprocess.Popen(["xdg-open", self.path])
        except Exception as e:
            QMessageBox.warning(self, "Open", str(e))

    def _clear(self):
        try:
            open(self.path, "w", encoding="utf-8").close()
            self._refresh()
        except Exception as e:
            QMessageBox.warning(self, "Clear", str(e))

# ======================================================================================
# Settings (with per-point model dropdowns + schema manager stub + open log)
# ======================================================================================

class SchemaManagerDialog(QDialog):
    def __init__(self, t: Theme, parent=None):
        super().__init__(parent)
        self.t = t
        self.setWindowTitle("Schema Manager")
        self.resize(820, 560)
        root = QVBoxLayout(self)
        hint = QLabel("Schemas are hard-coded for now. This dialog is a placeholder to preview/extend.\n"
                      "Future: list operators (Codex, Vision, RAG) and their prompt schemas here.")
        self.text = QPlainTextEdit(self)
        self.text.setReadOnly(True)
        self.text.setPlainText(
            "# Schemas (hard-coded)\n"
            "- operator: codex.chat → uses 'system' or 'system_min' based on Prompt Influence\n"
            "- operator: vision.analyze → uses 'vision' prompt\n"
            "- operator: rag.embed → uses Embedding model\n"
        )
        root.addWidget(hint)
        root.addWidget(self.text, 1)
        self._apply_dark(self)

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(f"""
        QDialog {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QLabel {{ color:{self.t.header_fg}; }}
        QPlainTextEdit {{ background:{self.t.term_bg}; color:{self.t.term_fg}; border:1px solid {self.t.card_border}; }}
        """)

class SettingsDialog(QDialog):
    def __init__(self, t: Theme, cfg: Dict, all_models: List[str], parent=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.all_models = all_models
        self.setWindowTitle("Settings")
        self.resize(960, 720)

        root = QVBoxLayout(self)

        # --- Models
        grpM = QGroupBox("Ollama Models")
        gm = QGridLayout(grpM)

        self.chat_cb  = QComboBox();  self.chat_cb.setEditable(True)
        self.vision_cb= QComboBox();  self.vision_cb.setEditable(True)
        self.embed_cb = QComboBox();  self.embed_cb.setEditable(True)

        for cb in (self.chat_cb, self.vision_cb, self.embed_cb):
            for m in all_models: cb.addItem(m)

        self.chat_cb.setCurrentText(cfg["models"].get("chat",""))
        self.vision_cb.setCurrentText(cfg["models"].get("vision",""))
        self.embed_cb.setCurrentText(cfg["models"].get("embed",""))

        gm.addWidget(QLabel("Chat Model"), 0,0);   gm.addWidget(self.chat_cb, 0,1)
        gm.addWidget(QLabel("Vision Model"),1,0); gm.addWidget(self.vision_cb,1,1)
        gm.addWidget(QLabel("Embedding Model"),2,0); gm.addWidget(self.embed_cb,2,1)

        # --- Behavior
        grpB = QGroupBox("Behavior")
        fb = QFormLayout(grpB)
        self.prompt_influence = QCheckBox("Enable Prompt Influence (richer system prompts)")
        self.prompt_influence.setChecked(bool(cfg.get("prompt_influence", True)))
        self.stream_toggle = QCheckBox("Stream responses")
        self.stream_toggle.setChecked(bool(cfg.get("stream", False)))
        fb.addRow(self.prompt_influence)
        fb.addRow(self.stream_toggle)

        # --- Prompts
        grpP = QGroupBox("Prompts")
        gp = QGridLayout(grpP)
        self.sys_prompt    = QTextEdit(cfg["prompts"].get("system",""))
        self.sys_min_prompt= QTextEdit(cfg["prompts"].get("system_min",""))
        self.vision_prompt = QTextEdit(cfg["prompts"].get("vision",""))
        self.user_prefix   = QTextEdit(cfg["prompts"].get("user_prefix",""))
        gp.addWidget(QLabel("System (rich)"), 0,0); gp.addWidget(self.sys_prompt, 0,1)
        gp.addWidget(QLabel("System (minimal)"), 1,0); gp.addWidget(self.sys_min_prompt, 1,1)
        gp.addWidget(QLabel("Vision Prompt"), 2,0); gp.addWidget(self.vision_prompt, 2,1)
        gp.addWidget(QLabel("User Prefix"), 3,0); gp.addWidget(self.user_prefix, 3,1)

        # --- Buttons
        buttons = QDialogButtonBox(QDialogButtonBox.Save | QDialogButtonBox.Cancel)

        # --- Extras row
        extra = QHBoxLayout()
        self.open_log = QPushButton("Open System Log…")
        self.open_schema = QPushButton("Open Schema Manager…")
        extra.addStretch(1); extra.addWidget(self.open_log); extra.addWidget(self.open_schema)

        root.addWidget(grpM)
        root.addWidget(grpB)
        root.addWidget(grpP, 1)
        root.addLayout(extra)
        root.addWidget(buttons)

        # Hooks
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        self.open_log.clicked.connect(lambda: LogViewer(self.t, LOG_PATH, self).exec())
        self.open_schema.clicked.connect(lambda: SchemaManagerDialog(self.t, self).exec())

        # Dark theme
        self._apply_dark(self)

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(f"""
        QDialog {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QLabel  {{ color:{self.t.header_fg}; }}
        QGroupBox {{ border:1px solid {self.t.card_border}; border-radius:8px; margin-top:14px; padding-top:10px; }}
        QGroupBox::title {{ subcontrol-origin: margin; left:8px; padding:0 4px; color:{self.t.info}; }}
        QComboBox, QTextEdit {{
            background:#0d1a2b; color:#eaf2ff; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px;
        }}
        QPushButton {{
            color:#ffffff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton:hover {{ background:{self.t.accent_hover}; }}
        QCheckBox {{ color:#eaf2ff; }}
        """)

    def values(self) -> Dict:
        out = self.cfg.copy()
        out["models"]["chat"]   = self.chat_cb.currentText().strip()
        out["models"]["vision"] = self.vision_cb.currentText().strip()
        out["models"]["embed"]  = self.embed_cb.currentText().strip()
        out["prompt_influence"] = self.prompt_influence.isChecked()
        out["stream"] = self.stream_toggle.isChecked()
        out["prompts"]["system"]     = self.sys_prompt.toPlainText()
        out["prompts"]["system_min"] = self.sys_min_prompt.toPlainText()
        out["prompts"]["vision"]     = self.vision_prompt.toPlainText()
        out["prompts"]["user_prefix"]= self.user_prefix.toPlainText()
        return out

# ======================================================================================
# Card (chat-only terminal)
# ======================================================================================

class ChatCard(QFrame):
    def __init__(self, t: Theme, cfg: Dict, parent: Optional[QWidget]=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.setObjectName("ChatCard")
        self.resize(1000, 680)
        self._drag = False
        self._press = QPoint()
        sh = QGraphicsDropShadowEffect(self); sh.setColor(QColor(0,30,80,150)); sh.setBlurRadius(28); sh.setOffset(0,12)
        self.setGraphicsEffect(sh)

        root = QVBoxLayout(self); root.setContentsMargins(0,0,0,0); root.setSpacing(0)

        # Header taskbar
        hdr = QFrame(self); hdr.setObjectName("Hdr")
        H = QHBoxLayout(hdr); H.setContentsMargins(12,8,12,8); H.setSpacing(8)
        title = QLabel("Codex Terminal")
        title.setStyleSheet(f"color:{t.header_fg}; font-weight:700; letter-spacing:.2px;")
        self.model_cb = QComboBox(); self.model_cb.setEditable(True)
        self.refresh_btn = QToolButton(); self.refresh_btn.setText("↻"); self.refresh_btn.setToolTip("Refresh Ollama models")
        self.track_btn = QPushButton("Track"); self.track_btn.setCheckable(True); self.track_btn.setChecked(True); self.track_btn.setObjectName("Btn")
        self.settings_btn = QToolButton(); self.settings_btn.setText("⋮"); self.settings_btn.setToolTip("Settings")
        H.addWidget(title); H.addStretch(1)
        H.addWidget(QLabel("Model:")); H.addWidget(self.model_cb); H.addWidget(self.refresh_btn)
        H.addSpacing(6); H.addWidget(self.track_btn); H.addWidget(self.settings_btn)
        root.addWidget(hdr)

        # Console
        self.console = QPlainTextEdit(self); self.console.setReadOnly(True)
        self.console.setMaximumBlockCount(6000)
        self.console.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Consolas, 'Cascadia Code', monospace; font-size:12.6pt;"
            f"border-top:1px solid {t.card_border}; border-bottom:1px solid {t.card_border}; padding:10px;"
        )
        root.addWidget(self.console, 1)

        # Input row (QTextEdit 2→4 lines, Enter=send, Shift+Enter=newline)
        ib = QFrame(self); ib.setObjectName("IB")
        I = QVBoxLayout(ib); I.setContentsMargins(10,8,10,10); I.setSpacing(8)

        self.input = QTextEdit(ib)
        self.input.setAcceptRichText(False)
        self.input.setWordWrapMode(self.input.wordWrapMode())
        self.input.setPlaceholderText("Type to chat with the selected Ollama model… (Enter=send, Shift+Enter=newline)")
        self.input.document().setMaximumBlockCount(4)  # limit total lines stored (not visible height)
        self._set_input_height_lines(2)
        self.input.textChanged.connect(self._grow_shrink_input)

        bottom = QHBoxLayout(); bottom.setSpacing(8)
        self.send_btn = QPushButton("Send"); self.send_btn.setObjectName("Btn")
        self.clear_btn = QPushButton("Clear"); self.clear_btn.setObjectName("Btn")
        bottom.addStretch(1); bottom.addWidget(self.clear_btn); bottom.addWidget(self.send_btn)

        I.addWidget(self.input); I.addLayout(bottom)
        root.addWidget(ib)

        # Style
        self.setStyleSheet(f"""
        QFrame#ChatCard {{
            background:{t.card_bg}; border:1px solid {t.card_border}; border-radius:{t.card_radius}px;
        }}
        QFrame#Hdr {{
            background:{t.header_bg}; border-top-left-radius:{t.card_radius}px; border-top-right-radius:{t.card_radius}px;
        }}
        QFrame#IB  {{
            background:{t.card_bg}; border-bottom-left-radius:{t.card_radius}px; border-bottom-right-radius:{t.card_radius}px;
        }}
        QLabel {{ color:{t.header_fg}; }}
        QComboBox {{ background:#0d1a2b; color:#eaf2ff; border:1px solid {t.card_border}; padding:4px 6px; }}
        QComboBox QAbstractItemView {{ background:#0d1a2b; color:#eaf2ff; selection-background-color:{t.accent}; }}
        QToolButton {{ color:#eaf2ff; background:transparent; border:0; }}
        QPushButton#Btn {{
            color:#ffffff; background:{t.accent}; border:1px solid {t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton#Btn:checked {{ background:{t.accent_hover}; }}
        QPushButton#Btn:hover {{ background:{t.accent_hover}; }}
        QTextEdit {{
            background:#0d1a2b; color:#eaf2ff; border:1px solid {t.card_border}; border-radius:8px; padding:8px;
            font-family: Consolas, 'Cascadia Code', monospace; font-size:12.6pt;
        }}
        """)

        # Signals
        self.send_btn.clicked.connect(self._send)
        self.clear_btn.clicked.connect(lambda: self.console.clear())
        self.refresh_btn.clicked.connect(self.refresh_models)
        self.model_cb.currentTextChanged.connect(lambda s: self._println(f"[Model] {s}"))
        self.settings_btn.clicked.connect(self._open_settings)

        # Boot
        self.refresh_models(prefer=self.cfg["models"].get("chat",""))
        self._println("[Info] Ready. Mode=Codex. Use Settings to configure Ollama.")
        if not _requests():
            self._println("[Warn] 'requests' not installed. Install with:  pip install requests")
        self._apply_enter_behavior()

    # --- card dragging (header)
    def header_geom(self) -> QRect: return QRect(0,0,self.width(),46)
    def mousePressEvent(self, e):
        if e.button() == Qt.LeftButton and self.header_geom().contains(e.position().toPoint()):
            self._drag = True; self._press = e.position().toPoint(); self.raise_(); e.accept()
        else:
            super().mousePressEvent(e)
    def mouseMoveEvent(self, e):
        if not self._drag: return super().mouseMoveEvent(e)
        delta = e.position().toPoint() - self._press
        pos = self.pos() + delta
        canvas = self.parentWidget()
        if canvas:
            r = canvas.rect()
            pos.setX(max(6, min(pos.x(), r.width()-self.width()-6)))
            pos.setY(max(6, min(pos.y(), r.height()-self.height()-6)))
        self.move(pos); e.accept()
        # notify host if tracking
        host = self.parentWidget()
        if self.track_btn.isChecked() and host and hasattr(host, "request_focus_on"):
            host.request_focus_on(self)
    def mouseReleaseEvent(self, e):
        self._drag = False
        super().mouseReleaseEvent(e)

    # --- input size helpers
    def _set_input_height_lines(self, lines: int):
        metrics = self.input.fontMetrics()
        h = int(lines * (metrics.lineSpacing() + 2)) + 18
        self.input.setMinimumHeight(h)
        self.input.setMaximumHeight(int(4 * (metrics.lineSpacing() + 2)) + 18)

    def _grow_shrink_input(self):
        doc_h = self.input.document().size().toSize().height()
        current = self.input.height()
        target = min(self.input.maximumHeight(), max(self.input.minimumHeight(), doc_h + 18))
        if abs(target - current) > 2:
            self.input.setFixedHeight(target)

    # --- enter behavior
    def _apply_enter_behavior(self):
        self.input.installEventFilter(self)

    def eventFilter(self, obj, ev):
        if obj is self.input and ev.type() == QEvent.KeyPress:
            if ev.key() in (Qt.Key_Return, Qt.Key_Enter):
                if ev.modifiers() & Qt.ShiftModifier:
                    return False  # allow newline
                self._send()
                return True
        return super().eventFilter(obj, ev)

    # --- console IO
    def _println(self, text: str):
        if not text.endswith("\n"): text += "\n"
        self.console.moveCursor(QTextCursor.End)
        self.console.insertPlainText(text)
        self.console.moveCursor(QTextCursor.End)
        _log(text.rstrip("\n"))

    # --- settings
    def _open_settings(self):
        models = self._all_models()
        dlg = SettingsDialog(self.t, self.cfg, models, self)
        if dlg.exec() == QDialog.Accepted:
            self.cfg = dlg.values()
            save_config(self.cfg)
            # update model selector
            wanted = self.cfg["models"].get("chat","").strip()
            if wanted:
                if self.model_cb.findText(wanted) < 0:
                    self.model_cb.addItem(wanted)
                self.model_cb.setCurrentText(wanted)
            self._println("[Info] Settings saved.")

    # --- models
    def _all_models(self) -> List[str]:
        req = _requests()
        if not req: return []
        try:
            r = req.get(f"{self.cfg['ollama_host']}/api/tags", timeout=6)
            if not r.ok: return []
            names = []
            for m in r.json().get("models", []):
                n = m.get("name") or m.get("model") or ""
                if n: names.append(n)
            names = sorted(set(names))
            return names
        except Exception as e:
            self._println(f"[Warn] model list error: {e}")
            return []

    def refresh_models(self, prefer: Optional[str]=None):
        self.model_cb.clear()
        names = self._all_models()
        if not names:
            self.model_cb.addItem("(no models found)")
            self._println("[Warn] No Ollama models. Example:  ollama pull gpt-oss:20b")
            return
        for n in names: self.model_cb.addItem(n)
        pick = (prefer if prefer in names else
                self.cfg["models"].get("chat") if self.cfg["models"].get("chat") in names else names[0])
        self.model_cb.setCurrentText(pick)
        self._println(f"[Models] {len(names)} found. Current: {pick}")

    # --- build messages
    def _system_prompt(self) -> str:
        p = self.cfg["prompts"]
        return p["system"] if self.cfg.get("prompt_influence", True) else p["system_min"]

    def _user_wrap(self, text: str) -> str:
        prefix = self.cfg["prompts"].get("user_prefix","").strip()
        return f"{prefix} {text}".strip() if prefix else text

    # --- chat send
    def _send(self):
        text = self.input.toPlainText().strip()
        if not text:
            return
        self.input.clear()
        self._println(f"› {text}")
        threading.Thread(target=self._chat_request, args=(text,), daemon=True).start()

    def _chat_request(self, user_text: str):
        req = _requests()
        if not req:
            self._println("ai: (install 'requests' to enable Ollama chat)")
            return

        model = self.model_cb.currentText().strip()
        if not model or model.startswith("("):
            self._println("ai: (no model selected)")
            return

        system = self._system_prompt()
        msgs = [
            {"role": "system", "content": system},
            {"role": "user", "content": self._user_wrap(user_text)}
        ]
        payload = {
            "model": model,
            "messages": msgs,
            "stream": bool(self.cfg.get("stream", False))
        }

        host = self.cfg["ollama_host"].rstrip("/")
        url = f"{host}/api/chat"

        try:
            if payload["stream"]:
                with req.post(url, json=payload, stream=True, timeout=300) as r:
                    if not r.ok:
                        self._println(f"ai: HTTP {r.status_code} — {r.text[:200]}")
                        return
                    self._println("ai: ")
                    partial = ""
                    for line in r.iter_lines(decode_unicode=True):
                        if not line:
                            continue
                        try:
                            obj = json.loads(line)
                        except Exception:
                            continue
                        delta = (obj.get("message") or {}).get("content","")
                        partial += delta
                        if delta:
                            self.console.moveCursor(QTextCursor.End)
                            self.console.insertPlainText(delta)
                    self.console.moveCursor(QTextCursor.End)
            else:
                r = req.post(url, json=payload, timeout=300)
                if not r.ok:
                    self._println(f"ai: HTTP {r.status_code} — {r.text[:200]}")
                    return
                data = r.json()
                msg = (data.get("message") or {}).get("content","").strip()
                if not msg:
                    msg = (data.get("response") or "").strip() or "(no content)"
                self._println(f"ai: {msg}")
        except Exception as e:
            self._println(f"ai: {e}")

# ======================================================================================
# Desktop wrapper (standalone only)
# ======================================================================================

class DesktopCanvas(QWidget):
    def __init__(self, t: Theme, cfg: Dict, parent=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.resize(3600, 2200)
        self.card = ChatCard(t, cfg, self)
        center = QPoint(self.width()//2, self.height()//2)
        self.card.move(center.x()-self.card.width()//2, center.y()-self.card.height()//2)

    def sizeHint(self) -> QSize: return self.size()

    def paintEvent(self, e):
        p = QPainter(self); p.setRenderHint(QPainter.Antialiasing)
        r = self.rect()
        g = QLinearGradient(r.topLeft(), r.bottomLeft())
        g.setColorAt(0.0, QColor(self.t.desktop_top))
        g.setColorAt(0.55, QColor(self.t.desktop_mid))
        g.setColorAt(1.0, QColor(self.t.desktop_top))
        p.fillRect(r, g)

        glow = QColor(self.t.edge_glow); glow.setAlphaF(0.18)
        p.setPen(glow)
        for i in range(14):
            rr = r.adjusted(10+i,10+i,-10-i,-10-i); p.drawRoundedRect(rr, 18, 18)

        vign = QColor(0,0,0,110); p.setPen(Qt.NoPen); p.setBrush(vign)
        path = QPainterPath(); path.addRect(r)
        inner = r.adjusted(30,30,-30,-30)
        ip = QPainterPath(); ip.addRoundedRect(QRectF(inner), 26, 26)
        p.drawPath(path.subtracted(ip))

    def request_focus_on(self, w: QWidget):
        parent = self.parentWidget()
        if parent and hasattr(parent, "center_on_widget"):
            parent.center_on_widget(w)

class CameraArea(QScrollArea):
    def __init__(self, content: DesktopCanvas, parent=None):
        super().__init__(parent)
        self.setWidget(content)
        self.setWidgetResizable(False)
        self.setFrameShape(QFrame.NoFrame)
        self.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)

    def center_on_widget(self, w: QWidget):
        if not w: return
        c = w.geometry().center()
        self.center_on_point(c)

    def center_on_point(self, pt: QPoint):
        cont = self.widget(); vw = self.viewport().size()
        x = max(0, min(pt.x() - vw.width()//2, cont.width() - vw.width()))
        y = max(0, min(pt.y() - vw.height()//2, cont.height() - vw.height()))
        self.horizontalScrollBar().setValue(x)
        self.verticalScrollBar().setValue(y)

# ======================================================================================
# Main window (standalone launcher)
# ======================================================================================

class Main(QMainWindow):
    def __init__(self, t: Theme, cfg: Dict, embedded: bool=False):
        super().__init__()
        self.t = t
        self.cfg = cfg
        self.setWindowTitle("Codex Terminal")
        self.resize(1200, 800)

        # Dark palette
        pal = self.palette()
        pal.setColor(QPalette.Window, QColor("#0a1430"))
        pal.setColor(QPalette.Base, QColor("#0a1430"))
        pal.setColor(QPalette.Text, QColor("#e6f0ff"))
        pal.setColor(QPalette.WindowText, QColor("#e6f0ff"))
        self.setPalette(pal)

        if embedded:
            # When embedded by an external Virtual_Desktop, just show the card
            self.card = ChatCard(t, cfg, self)
            self.setCentralWidget(self.card)
        else:
            # Standalone: our own desktop wrapper
            self.canvas = DesktopCanvas(t, cfg, self)
            self.camera = CameraArea(self.canvas, self)
            self.setCentralWidget(self.camera)
            QTimer.singleShot(0, lambda: self.camera.center_on_widget(self.canvas.card))

        self._menu()

    def _menu(self):
        bar = self.menuBar()
        f = bar.addMenu("&File")
        f.addAction("Open Script Folder…", lambda: self._open(SCRIPT_ROOT))
        f.addAction("Open Data Folder…", lambda: self._open(DATA_DIR))
        f.addAction("Open System Log…", lambda: LogViewer(self.t, LOG_PATH, self).exec())
        f.addSeparator()
        q = QAction("Quit", self); q.setShortcut(QKeySequence.Quit); q.triggered.connect(self.close); f.addAction(q)

        v = bar.addMenu("&View")
        fs = QAction("Toggle Fullscreen (Alt+Enter)", self); fs.setShortcut("Alt+Return")
        fs.triggered.connect(self._toggle_fullscreen); v.addAction(fs)

        m = bar.addMenu("&Models")
        m.addAction("Refresh Models", self._refresh_models)

        s = bar.addMenu("&Settings")
        s.addAction("Open Settings…", self._open_settings)

    def _refresh_models(self):
        if hasattr(self, "canvas"):
            self.canvas.card.refresh_models()
        elif hasattr(self, "card"):
            self.card.refresh_models()

    def _open_settings(self):
        if hasattr(self, "canvas"):
            self.canvas.card._open_settings()
        elif hasattr(self, "card"):
            self.card._open_settings()

    def _toggle_fullscreen(self):
        if self.isFullScreen(): self.showNormal()
        else: self.showFullScreen()

    def _open(self, path: str):
        try:
            if sys.platform.startswith("win"):
                os.startfile(path)
            elif sys.platform == "darwin":
                import subprocess; subprocess.Popen(["open", path])
            else:
                import subprocess; subprocess.Popen(["xdg-open", path])
        except Exception as e:
            QMessageBox.warning(self, "Open", str(e))

# ======================================================================================
# Embedding hook (for host Virtual_Desktop.py)
# ======================================================================================

def build_widget(parent=None) -> QWidget:
    """
    Host can call:   from Codex_Terminal import build_widget
                     w = build_widget(parent); layout.addWidget(w)
    """
    cfg = load_config()
    t = Theme()
    w = ChatCard(t, cfg, parent)
    return w

# ======================================================================================
# Entry
# ======================================================================================

def main():
    app = QApplication(sys.argv)
    cfg = load_config()
    t = Theme()
    embedded = bool(os.environ.get("CODEX_EMBEDDED", "0") == "1")
    win = Main(t, cfg, embedded=embedded); win.show()
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
```

Codex_Terminal.py — standalone/embeddable Ollama chat terminal
- Pure Ollama (no OpenAI, no shell runner).
- Dark theme everywhere (no white-on-white).
- Header taskbar on the card with model selector, Track toggle.
- Settings dialog: per-point model dropdowns (Chat, Vision, Embeddings), Prompt Influence toggle,
  Stream toggle, simple prompt editors, open System Log button (pop-out viewer) + schema manager stub.
- Log file on disk + live in-app viewer.
- Input: 2 lines tall by default, can grow up to 4 lines. Enter to send; Shift+Enter for newline.
- Virtual desktop wrapper:
    • Standalone: renders its own gradient "desktop" behind the card; Track centers the card.
    • Embedded: if a parent virtual desktop hosts the widget, the internal desktop is disabled.

Requires: PySide6, requests, a running Ollama daemon (default http://127.0.0.1:11434).
**Classes:** Theme, LogViewer, SchemaManagerDialog, SettingsDialog, ChatCard, DesktopCanvas, CameraArea, Main
**Functions:** _requests(), _log(line), load_config(), save_config(cfg), human_size(n), build_widget(parent), main()


## Module `Dev_Logic\Implemented_logic\image_pipeline.py`

```python
"""Image processing helpers for Codex-Local.

This module keeps the OCR + vision summarisation logic reusable so that
both the terminal chat and future editor chat panes can import the same
helpers.  The functions are intentionally defensive because local OCR
and VLM pipelines may be unavailable on some machines.
"""

from __future__ import annotations

import base64
import io
from dataclasses import dataclass
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Protocol

try:  # Optional dependency – we can still provide structured errors.
    from PIL import Image  # type: ignore
except Exception:  # pragma: no cover - exercised via error path tests
    Image = None  # type: ignore

try:  # Optional dependency – pytesseract may not be installed yet.
    import pytesseract  # type: ignore
except Exception:  # pragma: no cover - exercised via error path tests
    pytesseract = None  # type: ignore


class VisionClient(Protocol):
    """Minimal protocol for Ollama-like chat clients."""

    def chat(
        self,
        model: str,
        messages: List[Dict[str, Any]],
        images: Optional[List[str]] = None,
    ) -> tuple[bool, str, str]:
        ...


@dataclass
class OCRResult:
    """Structured result returned by :func:`perform_ocr`."""

    text: str
    markdown: str
    error: Optional[str] = None

    @property
    def ok(self) -> bool:
        return self.error is None


@dataclass
class VisionResult:
    """Structured result returned by :func:`analyze_image`."""

    summary: str
    error: Optional[str] = None

    @property
    def ok(self) -> bool:
        return self.error is None


@dataclass
class ThumbnailUpdate:
    """Record describing a thumbnail replacement inside a Markdown log."""

    original_path: Path
    thumbnail_path: Path
    markdown_original: str
    markdown_thumbnail: str


_MARKDOWN_IMAGE_RE = re.compile(r"!\[(?P<alt>[^\]]*)\]\((?P<path>[^)]+)\)")


def _normalise_markdown(text: str) -> str:
    """Collapse whitespace and return Markdown-friendly text."""

    lines = [ln.rstrip() for ln in text.splitlines()]
    cleaned: list[str] = []
    blank = False
    for ln in lines:
        stripped = ln.strip()
        if not stripped:
            if not blank and cleaned:
                cleaned.append("")
            blank = True
            continue
        blank = False
        cleaned.append(stripped)
    return "\n".join(cleaned).strip()


def _ensure_image(path: Path) -> Optional[Path]:
    if path.exists():
        return path
    return None


def _thumbnail_path(path: Path) -> Path:
    return path.with_name(f"{path.stem}_thumb.png")


def _resolve_markdown_path(base: Path, ref: str) -> Path:
    ref_path = Path(ref.strip())
    if ref_path.is_absolute():
        return ref_path
    return (base.parent / ref_path).resolve(strict=False)


def _markdown_path(base: Path, path: Path) -> str:
    resolved = path.resolve(strict=False)
    try:
        rel = resolved.relative_to(base.parent)
        return rel.as_posix()
    except ValueError:
        return resolved.as_posix()


def generate_thumbnail(
    image_path: Path | str,
    *,
    max_size: tuple[int, int] = (160, 160),
) -> Optional[Path]:
    """Create or reuse a ``*_thumb.png`` for ``image_path``."""

    path = _ensure_image(Path(image_path))
    if path is None:
        return None

    thumb_path = _thumbnail_path(path)

    if Image is None:
        if thumb_path.exists():
            return thumb_path
        return None

    try:
        thumb_path.parent.mkdir(parents=True, exist_ok=True)
    except Exception:  # pragma: no cover - filesystem permissions
        return None

    try:
        src_mtime = path.stat().st_mtime
        if thumb_path.exists() and thumb_path.stat().st_mtime >= src_mtime:
            return thumb_path
    except Exception:  # pragma: no cover - unable to stat reliably
        pass

    try:
        with Image.open(path) as im:
            img = im.convert("RGBA")
            if hasattr(Image, "Resampling"):
                resample = Image.Resampling.LANCZOS
            else:  # pragma: no cover - Pillow < 9
                resample = Image.LANCZOS  # type: ignore[attr-defined]
            img.thumbnail(max_size, resample=resample)
            img.save(thumb_path, format="PNG", optimize=True)
    except Exception:  # pragma: no cover - corrupted image path
        return None

    return thumb_path


def _replace_markdown_paths(text: str, old: str, new: str) -> tuple[str, bool]:
    replaced = False

    def _sub(match: re.Match[str]) -> str:
        nonlocal replaced
        current = match.group("path").strip()
        if current == old:
            replaced = True
            alt = match.group("alt")
            return f"![{alt}]({new})"
        return match.group(0)

    return _MARKDOWN_IMAGE_RE.sub(_sub, text), replaced


def thumbnailize_conversation_markdown(
    conversation_path: Path | str,
    *,
    keep_recent: int = 10,
    max_size: tuple[int, int] = (160, 160),
) -> List[ThumbnailUpdate]:
    """Replace older Markdown image links with thumbnail variants."""

    conv_path = Path(conversation_path)
    if not conv_path.exists():
        return []

    try:
        text = conv_path.read_text(encoding="utf-8")
    except Exception:  # pragma: no cover - encoding error paths
        return []

    matches = list(_MARKDOWN_IMAGE_RE.finditer(text))
    if keep_recent < 0:
        keep_recent = 0
    cutoff = max(0, len(matches) - keep_recent)

    updates: List[ThumbnailUpdate] = []
    new_text_parts: List[str] = []
    last_end = 0

    for idx, match in enumerate(matches):
        new_text_parts.append(text[last_end : match.start()])
        alt = match.group("alt")
        original_ref = match.group("path").strip()
        replacement_ref = original_ref

        if idx < cutoff and not original_ref.endswith("_thumb.png"):
            resolved = _resolve_markdown_path(conv_path, original_ref)
            thumb_path = generate_thumbnail(resolved, max_size=max_size)
            if thumb_path is not None and thumb_path.exists():
                thumb_ref = _markdown_path(conv_path, thumb_path)
                orig_ref_norm = _markdown_path(conv_path, resolved)
                if thumb_ref != original_ref:
                    replacement_ref = thumb_ref
                    updates.append(
                        ThumbnailUpdate(
                            original_path=resolved,
                            thumbnail_path=thumb_path,
                            markdown_original=orig_ref_norm,
                            markdown_thumbnail=thumb_ref,
                        )
                    )

        new_text_parts.append(f"![{alt}]({replacement_ref})")
        last_end = match.end()

    new_text_parts.append(text[last_end:])
    new_text = "".join(new_text_parts)

    if new_text != text:
        conv_path.write_text(new_text, encoding="utf-8")

    return updates


def restore_conversation_image(
    conversation_path: Path | str,
    image_path: Path | str,
) -> bool:
    """Restore the original Markdown link for ``image_path`` if thumbnailed."""

    conv_path = Path(conversation_path)
    if not conv_path.exists():
        return False

    resolved = _resolve_markdown_path(conv_path, str(image_path))
    original_ref = _markdown_path(conv_path, resolved)
    thumb_ref = _markdown_path(conv_path, _thumbnail_path(resolved))

    try:
        text = conv_path.read_text(encoding="utf-8")
    except Exception:  # pragma: no cover - encoding error
        return False

    updated_text, changed = _replace_markdown_paths(text, thumb_ref, original_ref)
    if changed:
        conv_path.write_text(updated_text, encoding="utf-8")
    return changed


def perform_ocr(
    image_path: Path | str,
    *,
    engine: Optional[Any] = None,
    language: str = "eng",
) -> OCRResult:
    """Run OCR over ``image_path`` returning Markdown text or an error.

    Parameters
    ----------
    image_path:
        Location of the image to process.
    engine:
        Optional pytesseract-like module.  When omitted the function will
        use the globally imported :mod:`pytesseract` instance.
    language:
        Language hint forwarded to the OCR engine.
    """

    path = _ensure_image(Path(image_path))
    if path is None:
        return OCRResult("", "", error="Image not found")

    if Image is None:
        return OCRResult("", "", error="Pillow not installed")

    ocr_engine = engine or pytesseract
    if ocr_engine is None:
        return OCRResult("", "", error="pytesseract not installed")

    try:
        with Image.open(path) as im:
            img = im.convert("L")  # greyscale improves OCR quality
            text = ocr_engine.image_to_string(img, lang=language)
    except Exception as exc:  # pragma: no cover - hard to force reliably
        return OCRResult("", "", error=str(exc))

    text = text.strip()
    if not text:
        return OCRResult("", "", error="No text detected")

    markdown = _normalise_markdown(text)
    return OCRResult(text=text, markdown=markdown)


def _encode_png_base64(path: Path) -> Optional[str]:
    if Image is None:
        try:
            data = path.read_bytes()
        except Exception:  # pragma: no cover - filesystem error path
            return None
        return base64.b64encode(data).decode("ascii")

    try:
        with Image.open(path) as im:
            buf = io.BytesIO()
            im.convert("RGBA").save(buf, format="PNG", optimize=True)
            return base64.b64encode(buf.getvalue()).decode("ascii")
    except Exception:  # pragma: no cover - corrupted image path
        try:
            data = path.read_bytes()
        except Exception:
            return None
        return base64.b64encode(data).decode("ascii")


def analyze_image(
    image_path: Path | str,
    ocr_text: str,
    *,
    client: Optional[VisionClient],
    model: str,
    user_text: str = "",
) -> VisionResult:
    """Ask a vision-language model to describe ``image_path``.

    The ``ocr_text`` extracted via :func:`perform_ocr` is supplied to the
    model as grounding context.
    """

    path = _ensure_image(Path(image_path))
    if path is None:
        return VisionResult("", error="Image not found")

    if client is None:
        return VisionResult("", error="No vision client configured")

    b64 = _encode_png_base64(path)
    if not b64:
        return VisionResult("", error="Unable to encode image")

    messages = [
        {
            "role": "system",
            "content": (
                "You are a meticulous vision assistant. Use the provided OCR "
                "Markdown as factual ground truth and summarise UI elements, "
                "notable numbers, and potential actions succinctly."
            ),
        },
        {
            "role": "user",
            "content": (
                f"User request: {user_text or '(none)'}\n\nOCR Markdown:\n{ocr_text or '(empty)'}"
            ),
        },
    ]

    ok, summary, err = client.chat(model=model, messages=messages, images=[b64])
    if not ok:
        return VisionResult("", error=err or "Vision model error")

    summary = summary.strip()
    if not summary:
        return VisionResult("", error="Vision model returned no text")

    return VisionResult(summary=summary)


__all__ = [
    "OCRResult",
    "VisionResult",
    "perform_ocr",
    "analyze_image",
    "ThumbnailUpdate",
    "generate_thumbnail",
    "thumbnailize_conversation_markdown",
    "restore_conversation_image",
]
```

Image processing helpers for Codex-Local.

This module keeps the OCR + vision summarisation logic reusable so that
both the terminal chat and future editor chat panes can import the same
helpers.  The functions are intentionally defensive because local OCR
and VLM pipelines may be unavailable on some machines.
**Classes:** VisionClient, OCRResult, VisionResult, ThumbnailUpdate
**Functions:** _normalise_markdown(text), _ensure_image(path), _thumbnail_path(path), _resolve_markdown_path(base, ref), _markdown_path(base, path), generate_thumbnail(image_path), _replace_markdown_paths(text, old, new), thumbnailize_conversation_markdown(conversation_path), restore_conversation_image(conversation_path, image_path), perform_ocr(image_path), _encode_png_base64(path), analyze_image(image_path, ocr_text)


## Module `Dev_Logic\Implemented_logic\Ollama_Chat_Terminal.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Codex_Terminal.py — standalone/embeddable Ollama chat terminal
- Pure Ollama (no OpenAI, no shell runner).
- Dark theme everywhere (no white-on-white).
- Header taskbar on the card with model selector, Track toggle.
- Settings dialog: per-point model dropdowns (Chat, Vision, Embeddings), Prompt Influence toggle,
  Stream toggle, simple prompt editors, open System Log button (pop-out viewer) + schema manager stub.
- Log file on disk + live in-app viewer.
- Input: 2 lines tall by default, can grow up to 4 lines. Enter to send; Shift+Enter for newline.
- Virtual desktop wrapper:
    • Standalone: renders its own gradient "desktop" behind the card; Track centers the card.
    • Embedded: if a parent virtual desktop hosts the widget, the internal desktop is disabled.

Requires: PySide6, requests, a running Ollama daemon (default http://127.0.0.1:11434).
"""

from __future__ import annotations

import os, sys, json, time, threading, datetime, re, base64
from dataclasses import dataclass
from typing import Optional, List, Dict

# ---- Qt imports
from PySide6.QtCore import (
    Qt, QRect, QRectF, QPoint, QSize, QTimer, Signal, Slot, QEvent, QByteArray, QBuffer
)
from PySide6.QtGui import (
    QAction, QColor, QGuiApplication, QKeySequence, QLinearGradient, QPainter,
    QPainterPath, QPalette, QTextCursor, QFont
)
from PySide6.QtWidgets import (
    QApplication, QComboBox, QDialog, QDialogButtonBox, QFormLayout, QFrame,
    QGraphicsDropShadowEffect, QGridLayout, QGroupBox, QHBoxLayout, QLabel,
    QMainWindow, QPushButton, QSizeGrip, QPlainTextEdit, QTextEdit, QToolButton,
    QVBoxLayout, QWidget, QScrollArea, QMessageBox, QCheckBox, QFileDialog
)

# ---- High DPI policy MUST be set before QApplication
try:
    QGuiApplication.setHighDpiScaleFactorRoundingPolicy(
        Qt.HighDpiScaleFactorRoundingPolicy.PassThrough
    )
except Exception:
    pass

# ---- Optional requests
def _requests():
    try:
        import requests
        return requests
    except Exception:
        return None

# ---- Paths
SCRIPT_ROOT = os.path.abspath(os.path.dirname(__file__))
DATA_DIR    = os.path.join(SCRIPT_ROOT, "datasets")
os.makedirs(DATA_DIR, exist_ok=True)
LOG_PATH    = os.path.join(SCRIPT_ROOT, "codex_terminal.log")
CONFIG_PATH = os.path.join(SCRIPT_ROOT, "config.json")

def _log(line: str):
    ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    msg = f"[{ts}] {line}\n"
    try:
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(msg)
    except Exception:
        pass

# ---- Theme
@dataclass
class Theme:
    desktop_top: str = "#0f3b8e"
    desktop_mid: str = "#1c54cc"
    edge_glow:   str = "#4aa8ff"

    card_bg:     str = "#0c1320"
    card_border: str = "#213040"
    card_radius: int = 14
    header_bg:   str = "#0a111e"
    header_fg:   str = "#eaf2ff"
    term_bg:     str = "#0b1828"
    term_fg:     str = "#e9f3ff"
    accent:      str = "#1E5AFF"
    accent_hover:str = "#2f72ff"
    ok:          str = "#00d17a"
    warn:        str = "#ffd76b"
    err:         str = "#ff6b6b"
    info:        str = "#9bb7ff"
    strip_bg:    str = "#0b0f18"

# ---- Default config
DEFAULTS = {
    "ollama_host": "http://127.0.0.1:11434",
    "prompt_influence": True,              # when False, keep prompts ultra-minimal
    "stream": False,                       # stream chat responses
    "models": {
        "chat": "gpt-oss:20b",
        "vision": "llava-llama3:latest",
        "embed": "snowflake-arctic-embed2:latest"
    },
    "prompts": {
        "system": "You are Codex Terminal. Answer succinctly and correctly.",
        "system_min": "Answer appropriately.",
        "vision": "Analyze this image and explain succinctly.",
        "user_prefix": ""
    }
}

def load_config() -> Dict:
    cfg = {}
    if os.path.isfile(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                cfg = json.load(f)
        except Exception as e:
            _log(f"Config read error: {e}")
            cfg = {}
    # deep fill
    def fill(dst, src):
        for k, v in src.items():
            if isinstance(v, dict):
                dst[k] = fill(dst.get(k, {}), v)
            else:
                dst.setdefault(k, v)
        return dst
    cfg = fill(cfg, DEFAULTS)
    try:
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
    except Exception as e:
        _log(f"Config write error: {e}")
    return cfg

def save_config(cfg: Dict):
    try:
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
    except Exception as e:
        _log(f"Config write error: {e}")

# ---- tiny utils
def human_size(n: int) -> str:
    units = ["B","KB","MB","GB","TB"]
    s = float(n); i = 0
    while s >= 1024 and i < len(units)-1:
        s /= 1024; i += 1
    return f"{s:.1f}{units[i]}" if i else f"{int(s)}{units[i]}"

# ======================================================================================
# Log Viewer
# ======================================================================================

class LogViewer(QDialog):
    def __init__(self, t: Theme, path: str, parent=None):
        super().__init__(parent)
        self.t = t
        self.path = path
        self.setWindowTitle("System Log")
        self.resize(900, 520)

        root = QVBoxLayout(self)
        self.view = QPlainTextEdit(self); self.view.setReadOnly(True)
        self.view.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Consolas, 'Cascadia Code', monospace; font-size:12.2pt;"
            f"border:1px solid {t.card_border};"
        )
        btns = QHBoxLayout()
        refresh = QPushButton("Refresh")
        open_file = QPushButton("Open Log File…")
        clear = QPushButton("Clear Log")
        btns.addStretch(1); btns.addWidget(refresh); btns.addWidget(open_file); btns.addWidget(clear)

        root.addWidget(self.view, 1); root.addLayout(btns)

        refresh.clicked.connect(self._refresh)
        open_file.clicked.connect(self._open)
        clear.clicked.connect(self._clear)

        self._apply_dark(self)
        self._refresh()

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(w.styleSheet() + f"""
        QDialog {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QPushButton {{
            color:#ffffff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton:hover {{ background:{self.t.accent_hover}; }}
        QLabel {{ color:{self.t.header_fg}; }}
        """)
    def _refresh(self):
        try:
            with open(self.path, "r", encoding="utf-8") as f:
                txt = f.read()
        except Exception:
            txt = "(no log yet)"
        self.view.setPlainText(txt)
        self.view.moveCursor(QTextCursor.End)

    def _open(self):
        try:
            if sys.platform.startswith("win"):
                os.startfile(self.path)
            elif sys.platform == "darwin":
                import subprocess; subprocess.Popen(["open", self.path])
            else:
                import subprocess; subprocess.Popen(["xdg-open", self.path])
        except Exception as e:
            QMessageBox.warning(self, "Open", str(e))

    def _clear(self):
        try:
            open(self.path, "w", encoding="utf-8").close()
            self._refresh()
        except Exception as e:
            QMessageBox.warning(self, "Clear", str(e))

# ======================================================================================
# Settings (with per-point model dropdowns + schema manager stub + open log)
# ======================================================================================

class SchemaManagerDialog(QDialog):
    def __init__(self, t: Theme, parent=None):
        super().__init__(parent)
        self.t = t
        self.setWindowTitle("Schema Manager")
        self.resize(820, 560)
        root = QVBoxLayout(self)
        hint = QLabel("Schemas are hard-coded for now. This dialog is a placeholder to preview/extend.\n"
                      "Future: list operators (Codex, Vision, RAG) and their prompt schemas here.")
        self.text = QPlainTextEdit(self)
        self.text.setReadOnly(True)
        self.text.setPlainText(
            "# Schemas (hard-coded)\n"
            "- operator: codex.chat → uses 'system' or 'system_min' based on Prompt Influence\n"
            "- operator: vision.analyze → uses 'vision' prompt\n"
            "- operator: rag.embed → uses Embedding model\n"
        )
        root.addWidget(hint)
        root.addWidget(self.text, 1)
        self._apply_dark(self)

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(f"""
        QDialog {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QLabel {{ color:{self.t.header_fg}; }}
        QPlainTextEdit {{ background:{self.t.term_bg}; color:{self.t.term_fg}; border:1px solid {self.t.card_border}; }}
        """)

class SettingsDialog(QDialog):
    def __init__(self, t: Theme, cfg: Dict, all_models: List[str], parent=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.all_models = all_models
        self.setWindowTitle("Settings")
        self.resize(960, 720)

        root = QVBoxLayout(self)

        # --- Models
        grpM = QGroupBox("Ollama Models")
        gm = QGridLayout(grpM)

        self.chat_cb  = QComboBox();  self.chat_cb.setEditable(True)
        self.vision_cb= QComboBox();  self.vision_cb.setEditable(True)
        self.embed_cb = QComboBox();  self.embed_cb.setEditable(True)

        for cb in (self.chat_cb, self.vision_cb, self.embed_cb):
            for m in all_models: cb.addItem(m)

        self.chat_cb.setCurrentText(cfg["models"].get("chat",""))
        self.vision_cb.setCurrentText(cfg["models"].get("vision",""))
        self.embed_cb.setCurrentText(cfg["models"].get("embed",""))

        gm.addWidget(QLabel("Chat Model"), 0,0);   gm.addWidget(self.chat_cb, 0,1)
        gm.addWidget(QLabel("Vision Model"),1,0); gm.addWidget(self.vision_cb,1,1)
        gm.addWidget(QLabel("Embedding Model"),2,0); gm.addWidget(self.embed_cb,2,1)

        # --- Behavior
        grpB = QGroupBox("Behavior")
        fb = QFormLayout(grpB)
        self.prompt_influence = QCheckBox("Enable Prompt Influence (richer system prompts)")
        self.prompt_influence.setChecked(bool(cfg.get("prompt_influence", True)))
        self.stream_toggle = QCheckBox("Stream responses")
        self.stream_toggle.setChecked(bool(cfg.get("stream", False)))
        fb.addRow(self.prompt_influence)
        fb.addRow(self.stream_toggle)

        # --- Prompts
        grpP = QGroupBox("Prompts")
        gp = QGridLayout(grpP)
        self.sys_prompt    = QTextEdit(cfg["prompts"].get("system",""))
        self.sys_min_prompt= QTextEdit(cfg["prompts"].get("system_min",""))
        self.vision_prompt = QTextEdit(cfg["prompts"].get("vision",""))
        self.user_prefix   = QTextEdit(cfg["prompts"].get("user_prefix",""))
        gp.addWidget(QLabel("System (rich)"), 0,0); gp.addWidget(self.sys_prompt, 0,1)
        gp.addWidget(QLabel("System (minimal)"), 1,0); gp.addWidget(self.sys_min_prompt, 1,1)
        gp.addWidget(QLabel("Vision Prompt"), 2,0); gp.addWidget(self.vision_prompt, 2,1)
        gp.addWidget(QLabel("User Prefix"), 3,0); gp.addWidget(self.user_prefix, 3,1)

        # --- Buttons
        buttons = QDialogButtonBox(QDialogButtonBox.Save | QDialogButtonBox.Cancel)

        # --- Extras row
        extra = QHBoxLayout()
        self.open_log = QPushButton("Open System Log…")
        self.open_schema = QPushButton("Open Schema Manager…")
        extra.addStretch(1); extra.addWidget(self.open_log); extra.addWidget(self.open_schema)

        root.addWidget(grpM)
        root.addWidget(grpB)
        root.addWidget(grpP, 1)
        root.addLayout(extra)
        root.addWidget(buttons)

        # Hooks
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        self.open_log.clicked.connect(lambda: LogViewer(self.t, LOG_PATH, self).exec())
        self.open_schema.clicked.connect(lambda: SchemaManagerDialog(self.t, self).exec())

        # Dark theme
        self._apply_dark(self)

    def _apply_dark(self, w: QWidget):
        w.setStyleSheet(f"""
        QDialog {{ background:{self.t.card_bg}; color:{self.t.header_fg}; }}
        QLabel  {{ color:{self.t.header_fg}; }}
        QGroupBox {{ border:1px solid {self.t.card_border}; border-radius:8px; margin-top:14px; padding-top:10px; }}
        QGroupBox::title {{ subcontrol-origin: margin; left:8px; padding:0 4px; color:{self.t.info}; }}
        QComboBox, QTextEdit {{
            background:#0d1a2b; color:#eaf2ff; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px;
        }}
        QPushButton {{
            color:#ffffff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton:hover {{ background:{self.t.accent_hover}; }}
        QCheckBox {{ color:#eaf2ff; }}
        """)

    def values(self) -> Dict:
        out = self.cfg.copy()
        out["models"]["chat"]   = self.chat_cb.currentText().strip()
        out["models"]["vision"] = self.vision_cb.currentText().strip()
        out["models"]["embed"]  = self.embed_cb.currentText().strip()
        out["prompt_influence"] = self.prompt_influence.isChecked()
        out["stream"] = self.stream_toggle.isChecked()
        out["prompts"]["system"]     = self.sys_prompt.toPlainText()
        out["prompts"]["system_min"] = self.sys_min_prompt.toPlainText()
        out["prompts"]["vision"]     = self.vision_prompt.toPlainText()
        out["prompts"]["user_prefix"]= self.user_prefix.toPlainText()
        return out

# ======================================================================================
# Card (chat-only terminal)
# ======================================================================================

class ChatCard(QFrame):
    def __init__(self, t: Theme, cfg: Dict, parent: Optional[QWidget]=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.setObjectName("ChatCard")
        self.resize(1000, 680)
        self._drag = False
        self._press = QPoint()
        sh = QGraphicsDropShadowEffect(self); sh.setColor(QColor(0,30,80,150)); sh.setBlurRadius(28); sh.setOffset(0,12)
        self.setGraphicsEffect(sh)

        root = QVBoxLayout(self); root.setContentsMargins(0,0,0,0); root.setSpacing(0)

        # Header taskbar
        hdr = QFrame(self); hdr.setObjectName("Hdr")
        H = QHBoxLayout(hdr); H.setContentsMargins(12,8,12,8); H.setSpacing(8)
        title = QLabel("Codex Terminal")
        title.setStyleSheet(f"color:{t.header_fg}; font-weight:700; letter-spacing:.2px;")
        self.model_cb = QComboBox(); self.model_cb.setEditable(True)
        self.refresh_btn = QToolButton(); self.refresh_btn.setText("↻"); self.refresh_btn.setToolTip("Refresh Ollama models")
        self.track_btn = QPushButton("Track"); self.track_btn.setCheckable(True); self.track_btn.setChecked(True); self.track_btn.setObjectName("Btn")
        self.settings_btn = QToolButton(); self.settings_btn.setText("⋮"); self.settings_btn.setToolTip("Settings")
        H.addWidget(title); H.addStretch(1)
        H.addWidget(QLabel("Model:")); H.addWidget(self.model_cb); H.addWidget(self.refresh_btn)
        H.addSpacing(6); H.addWidget(self.track_btn); H.addWidget(self.settings_btn)
        root.addWidget(hdr)

        # Console
        self.console = QPlainTextEdit(self); self.console.setReadOnly(True)
        self.console.setMaximumBlockCount(6000)
        self.console.setStyleSheet(
            f"background:{t.term_bg}; color:{t.term_fg};"
            "font-family: Consolas, 'Cascadia Code', monospace; font-size:12.6pt;"
            f"border-top:1px solid {t.card_border}; border-bottom:1px solid {t.card_border}; padding:10px;"
        )
        root.addWidget(self.console, 1)

        # Input row (QTextEdit 2→4 lines, Enter=send, Shift+Enter=newline)
        ib = QFrame(self); ib.setObjectName("IB")
        I = QVBoxLayout(ib); I.setContentsMargins(10,8,10,10); I.setSpacing(8)

        self.input = QTextEdit(ib)
        self.input.setAcceptRichText(False)
        self.input.setWordWrapMode(self.input.wordWrapMode())
        self.input.setPlaceholderText("Type to chat with the selected Ollama model… (Enter=send, Shift+Enter=newline)")
        self.input.document().setMaximumBlockCount(4)  # limit total lines stored (not visible height)
        self._set_input_height_lines(2)
        self.input.textChanged.connect(self._grow_shrink_input)

        bottom = QHBoxLayout(); bottom.setSpacing(8)
        self.send_btn = QPushButton("Send"); self.send_btn.setObjectName("Btn")
        self.clear_btn = QPushButton("Clear"); self.clear_btn.setObjectName("Btn")
        bottom.addStretch(1); bottom.addWidget(self.clear_btn); bottom.addWidget(self.send_btn)

        I.addWidget(self.input); I.addLayout(bottom)
        root.addWidget(ib)

        # Style
        self.setStyleSheet(f"""
        QFrame#ChatCard {{
            background:{t.card_bg}; border:1px solid {t.card_border}; border-radius:{t.card_radius}px;
        }}
        QFrame#Hdr {{
            background:{t.header_bg}; border-top-left-radius:{t.card_radius}px; border-top-right-radius:{t.card_radius}px;
        }}
        QFrame#IB  {{
            background:{t.card_bg}; border-bottom-left-radius:{t.card_radius}px; border-bottom-right-radius:{t.card_radius}px;
        }}
        QLabel {{ color:{t.header_fg}; }}
        QComboBox {{ background:#0d1a2b; color:#eaf2ff; border:1px solid {t.card_border}; padding:4px 6px; }}
        QComboBox QAbstractItemView {{ background:#0d1a2b; color:#eaf2ff; selection-background-color:{t.accent}; }}
        QToolButton {{ color:#eaf2ff; background:transparent; border:0; }}
        QPushButton#Btn {{
            color:#ffffff; background:{t.accent}; border:1px solid {t.card_border}; border-radius:6px; padding:6px 10px;
        }}
        QPushButton#Btn:checked {{ background:{t.accent_hover}; }}
        QPushButton#Btn:hover {{ background:{t.accent_hover}; }}
        QTextEdit {{
            background:#0d1a2b; color:#eaf2ff; border:1px solid {t.card_border}; border-radius:8px; padding:8px;
            font-family: Consolas, 'Cascadia Code', monospace; font-size:12.6pt;
        }}
        """)

        # Signals
        self.send_btn.clicked.connect(self._send)
        self.clear_btn.clicked.connect(lambda: self.console.clear())
        self.refresh_btn.clicked.connect(self.refresh_models)
        self.model_cb.currentTextChanged.connect(lambda s: self._println(f"[Model] {s}"))
        self.settings_btn.clicked.connect(self._open_settings)

        # Boot
        self.refresh_models(prefer=self.cfg["models"].get("chat",""))
        self._println("[Info] Ready. Mode=Codex. Use Settings to configure Ollama.")
        if not _requests():
            self._println("[Warn] 'requests' not installed. Install with:  pip install requests")
        self._apply_enter_behavior()

    # --- card dragging (header)
    def header_geom(self) -> QRect: return QRect(0,0,self.width(),46)
    def mousePressEvent(self, e):
        if e.button() == Qt.LeftButton and self.header_geom().contains(e.position().toPoint()):
            self._drag = True; self._press = e.position().toPoint(); self.raise_(); e.accept()
        else:
            super().mousePressEvent(e)
    def mouseMoveEvent(self, e):
        if not self._drag: return super().mouseMoveEvent(e)
        delta = e.position().toPoint() - self._press
        pos = self.pos() + delta
        canvas = self.parentWidget()
        if canvas:
            r = canvas.rect()
            pos.setX(max(6, min(pos.x(), r.width()-self.width()-6)))
            pos.setY(max(6, min(pos.y(), r.height()-self.height()-6)))
        self.move(pos); e.accept()
        # notify host if tracking
        host = self.parentWidget()
        if self.track_btn.isChecked() and host and hasattr(host, "request_focus_on"):
            host.request_focus_on(self)
    def mouseReleaseEvent(self, e):
        self._drag = False
        super().mouseReleaseEvent(e)

    # --- input size helpers
    def _set_input_height_lines(self, lines: int):
        metrics = self.input.fontMetrics()
        h = int(lines * (metrics.lineSpacing() + 2)) + 18
        self.input.setMinimumHeight(h)
        self.input.setMaximumHeight(int(4 * (metrics.lineSpacing() + 2)) + 18)

    def _grow_shrink_input(self):
        doc_h = self.input.document().size().toSize().height()
        current = self.input.height()
        target = min(self.input.maximumHeight(), max(self.input.minimumHeight(), doc_h + 18))
        if abs(target - current) > 2:
            self.input.setFixedHeight(target)

    # --- enter behavior
    def _apply_enter_behavior(self):
        self.input.installEventFilter(self)

    def eventFilter(self, obj, ev):
        if obj is self.input and ev.type() == QEvent.KeyPress:
            if ev.key() in (Qt.Key_Return, Qt.Key_Enter):
                if ev.modifiers() & Qt.ShiftModifier:
                    return False  # allow newline
                self._send()
                return True
        return super().eventFilter(obj, ev)

    # --- console IO
    def _println(self, text: str):
        if not text.endswith("\n"): text += "\n"
        self.console.moveCursor(QTextCursor.End)
        self.console.insertPlainText(text)
        self.console.moveCursor(QTextCursor.End)
        _log(text.rstrip("\n"))

    # --- settings
    def _open_settings(self):
        models = self._all_models()
        dlg = SettingsDialog(self.t, self.cfg, models, self)
        if dlg.exec() == QDialog.Accepted:
            self.cfg = dlg.values()
            save_config(self.cfg)
            # update model selector
            wanted = self.cfg["models"].get("chat","").strip()
            if wanted:
                if self.model_cb.findText(wanted) < 0:
                    self.model_cb.addItem(wanted)
                self.model_cb.setCurrentText(wanted)
            self._println("[Info] Settings saved.")

    # --- models
    def _all_models(self) -> List[str]:
        req = _requests()
        if not req: return []
        try:
            r = req.get(f"{self.cfg['ollama_host']}/api/tags", timeout=6)
            if not r.ok: return []
            names = []
            for m in r.json().get("models", []):
                n = m.get("name") or m.get("model") or ""
                if n: names.append(n)
            names = sorted(set(names))
            return names
        except Exception as e:
            self._println(f"[Warn] model list error: {e}")
            return []

    def refresh_models(self, prefer: Optional[str]=None):
        self.model_cb.clear()
        names = self._all_models()
        if not names:
            self.model_cb.addItem("(no models found)")
            self._println("[Warn] No Ollama models. Example:  ollama pull gpt-oss:20b")
            return
        for n in names: self.model_cb.addItem(n)
        pick = (prefer if prefer in names else
                self.cfg["models"].get("chat") if self.cfg["models"].get("chat") in names else names[0])
        self.model_cb.setCurrentText(pick)
        self._println(f"[Models] {len(names)} found. Current: {pick}")

    # --- build messages
    def _system_prompt(self) -> str:
        p = self.cfg["prompts"]
        return p["system"] if self.cfg.get("prompt_influence", True) else p["system_min"]

    def _user_wrap(self, text: str) -> str:
        prefix = self.cfg["prompts"].get("user_prefix","").strip()
        return f"{prefix} {text}".strip() if prefix else text

    # --- chat send
    def _send(self):
        text = self.input.toPlainText().strip()
        if not text:
            return
        self.input.clear()
        self._println(f"› {text}")
        threading.Thread(target=self._chat_request, args=(text,), daemon=True).start()

    def _chat_request(self, user_text: str):
        req = _requests()
        if not req:
            self._println("ai: (install 'requests' to enable Ollama chat)")
            return

        model = self.model_cb.currentText().strip()
        if not model or model.startswith("("):
            self._println("ai: (no model selected)")
            return

        system = self._system_prompt()
        msgs = [
            {"role": "system", "content": system},
            {"role": "user", "content": self._user_wrap(user_text)}
        ]
        payload = {
            "model": model,
            "messages": msgs,
            "stream": bool(self.cfg.get("stream", False))
        }

        host = self.cfg["ollama_host"].rstrip("/")
        url = f"{host}/api/chat"

        try:
            if payload["stream"]:
                with req.post(url, json=payload, stream=True, timeout=300) as r:
                    if not r.ok:
                        self._println(f"ai: HTTP {r.status_code} — {r.text[:200]}")
                        return
                    self._println("ai: ")
                    partial = ""
                    for line in r.iter_lines(decode_unicode=True):
                        if not line:
                            continue
                        try:
                            obj = json.loads(line)
                        except Exception:
                            continue
                        delta = (obj.get("message") or {}).get("content","")
                        partial += delta
                        if delta:
                            self.console.moveCursor(QTextCursor.End)
                            self.console.insertPlainText(delta)
                    self.console.moveCursor(QTextCursor.End)
            else:
                r = req.post(url, json=payload, timeout=300)
                if not r.ok:
                    self._println(f"ai: HTTP {r.status_code} — {r.text[:200]}")
                    return
                data = r.json()
                msg = (data.get("message") or {}).get("content","").strip()
                if not msg:
                    msg = (data.get("response") or "").strip() or "(no content)"
                self._println(f"ai: {msg}")
        except Exception as e:
            self._println(f"ai: {e}")

# ======================================================================================
# Desktop wrapper (standalone only)
# ======================================================================================

class DesktopCanvas(QWidget):
    def __init__(self, t: Theme, cfg: Dict, parent=None):
        super().__init__(parent)
        self.t = t
        self.cfg = cfg
        self.resize(3600, 2200)
        self.card = ChatCard(t, cfg, self)
        center = QPoint(self.width()//2, self.height()//2)
        self.card.move(center.x()-self.card.width()//2, center.y()-self.card.height()//2)

    def sizeHint(self) -> QSize: return self.size()

    def paintEvent(self, e):
        p = QPainter(self); p.setRenderHint(QPainter.Antialiasing)
        r = self.rect()
        g = QLinearGradient(r.topLeft(), r.bottomLeft())
        g.setColorAt(0.0, QColor(self.t.desktop_top))
        g.setColorAt(0.55, QColor(self.t.desktop_mid))
        g.setColorAt(1.0, QColor(self.t.desktop_top))
        p.fillRect(r, g)

        glow = QColor(self.t.edge_glow); glow.setAlphaF(0.18)
        p.setPen(glow)
        for i in range(14):
            rr = r.adjusted(10+i,10+i,-10-i,-10-i); p.drawRoundedRect(rr, 18, 18)

        vign = QColor(0,0,0,110); p.setPen(Qt.NoPen); p.setBrush(vign)
        path = QPainterPath(); path.addRect(r)
        inner = r.adjusted(30,30,-30,-30)
        ip = QPainterPath(); ip.addRoundedRect(QRectF(inner), 26, 26)
        p.drawPath(path.subtracted(ip))

    def request_focus_on(self, w: QWidget):
        parent = self.parentWidget()
        if parent and hasattr(parent, "center_on_widget"):
            parent.center_on_widget(w)

class CameraArea(QScrollArea):
    def __init__(self, content: DesktopCanvas, parent=None):
        super().__init__(parent)
        self.setWidget(content)
        self.setWidgetResizable(False)
        self.setFrameShape(QFrame.NoFrame)
        self.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)

    def center_on_widget(self, w: QWidget):
        if not w: return
        c = w.geometry().center()
        self.center_on_point(c)

    def center_on_point(self, pt: QPoint):
        cont = self.widget(); vw = self.viewport().size()
        x = max(0, min(pt.x() - vw.width()//2, cont.width() - vw.width()))
        y = max(0, min(pt.y() - vw.height()//2, cont.height() - vw.height()))
        self.horizontalScrollBar().setValue(x)
        self.verticalScrollBar().setValue(y)

# ======================================================================================
# Main window (standalone launcher)
# ======================================================================================

class Main(QMainWindow):
    def __init__(self, t: Theme, cfg: Dict, embedded: bool=False):
        super().__init__()
        self.t = t
        self.cfg = cfg
        self.setWindowTitle("Codex Terminal")
        self.resize(1200, 800)

        # Dark palette
        pal = self.palette()
        pal.setColor(QPalette.Window, QColor("#0a1430"))
        pal.setColor(QPalette.Base, QColor("#0a1430"))
        pal.setColor(QPalette.Text, QColor("#e6f0ff"))
        pal.setColor(QPalette.WindowText, QColor("#e6f0ff"))
        self.setPalette(pal)

        if embedded:
            # When embedded by an external Virtual_Desktop, just show the card
            self.card = ChatCard(t, cfg, self)
            self.setCentralWidget(self.card)
        else:
            # Standalone: our own desktop wrapper
            self.canvas = DesktopCanvas(t, cfg, self)
            self.camera = CameraArea(self.canvas, self)
            self.setCentralWidget(self.camera)
            QTimer.singleShot(0, lambda: self.camera.center_on_widget(self.canvas.card))

        self._menu()

    def _menu(self):
        bar = self.menuBar()
        f = bar.addMenu("&File")
        f.addAction("Open Script Folder…", lambda: self._open(SCRIPT_ROOT))
        f.addAction("Open Data Folder…", lambda: self._open(DATA_DIR))
        f.addAction("Open System Log…", lambda: LogViewer(self.t, LOG_PATH, self).exec())
        f.addSeparator()
        q = QAction("Quit", self); q.setShortcut(QKeySequence.Quit); q.triggered.connect(self.close); f.addAction(q)

        v = bar.addMenu("&View")
        fs = QAction("Toggle Fullscreen (Alt+Enter)", self); fs.setShortcut("Alt+Return")
        fs.triggered.connect(self._toggle_fullscreen); v.addAction(fs)

        m = bar.addMenu("&Models")
        m.addAction("Refresh Models", self._refresh_models)

        s = bar.addMenu("&Settings")
        s.addAction("Open Settings…", self._open_settings)

    def _refresh_models(self):
        if hasattr(self, "canvas"):
            self.canvas.card.refresh_models()
        elif hasattr(self, "card"):
            self.card.refresh_models()

    def _open_settings(self):
        if hasattr(self, "canvas"):
            self.canvas.card._open_settings()
        elif hasattr(self, "card"):
            self.card._open_settings()

    def _toggle_fullscreen(self):
        if self.isFullScreen(): self.showNormal()
        else: self.showFullScreen()

    def _open(self, path: str):
        try:
            if sys.platform.startswith("win"):
                os.startfile(path)
            elif sys.platform == "darwin":
                import subprocess; subprocess.Popen(["open", path])
            else:
                import subprocess; subprocess.Popen(["xdg-open", path])
        except Exception as e:
            QMessageBox.warning(self, "Open", str(e))

# ======================================================================================
# Embedding hook (for host Virtual_Desktop.py)
# ======================================================================================

def build_widget(parent=None) -> QWidget:
    """
    Host can call:   from Codex_Terminal import build_widget
                     w = build_widget(parent); layout.addWidget(w)
    """
    cfg = load_config()
    t = Theme()
    w = ChatCard(t, cfg, parent)
    return w

# ======================================================================================
# Entry
# ======================================================================================

def main():
    app = QApplication(sys.argv)
    cfg = load_config()
    t = Theme()
    embedded = bool(os.environ.get("CODEX_EMBEDDED", "0") == "1")
    win = Main(t, cfg, embedded=embedded); win.show()
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
```

Codex_Terminal.py — standalone/embeddable Ollama chat terminal
- Pure Ollama (no OpenAI, no shell runner).
- Dark theme everywhere (no white-on-white).
- Header taskbar on the card with model selector, Track toggle.
- Settings dialog: per-point model dropdowns (Chat, Vision, Embeddings), Prompt Influence toggle,
  Stream toggle, simple prompt editors, open System Log button (pop-out viewer) + schema manager stub.
- Log file on disk + live in-app viewer.
- Input: 2 lines tall by default, can grow up to 4 lines. Enter to send; Shift+Enter for newline.
- Virtual desktop wrapper:
    • Standalone: renders its own gradient "desktop" behind the card; Track centers the card.
    • Embedded: if a parent virtual desktop hosts the widget, the internal desktop is disabled.

Requires: PySide6, requests, a running Ollama daemon (default http://127.0.0.1:11434).
**Classes:** Theme, LogViewer, SchemaManagerDialog, SettingsDialog, ChatCard, DesktopCanvas, CameraArea, Main
**Functions:** _requests(), _log(line), load_config(), save_config(cfg), human_size(n), build_widget(parent), main()


## Module `Dev_Logic\Implemented_logic\Simple_Codex_Terminal.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
r"""
Codex Rust Starter — Portable Installer + Automated + Optional GUI + Bridge API + Project Packager + Embedded Terminal (Windows)

- Double-click friendly launcher with clear choices:
  [Change default settings]  [Launch with defaults]  [Launch with embedded terminal]  [Copy install manifest]  [Start Codex in New Project]  [Cancel]

- Portable: detects its own folder (expects to live inside "Codex-Installer", but runs anywhere). Creates all files relative to this script.
- Automates Codex rust-v0.34.0 download, checksum, extraction, config writing, Ollama detection, model probing, warm-up, and launch.
- Bridge: single Codex process launched headless with pipes. A TCP BridgeServer fans out stdout to multiple clients and forwards any client line to Codex stdin.
- Embedded Terminal: Tk window that shows Codex stdout live and lets you type lines; also spawns an optional visible CMD client that connects to the same bridge so you can minimize or use either.
- Manifest: INSTALL_MANIFEST.md explains A) using this file as an API and B) re-implementing from scratch using Ollama /api/tags (no static model snapshots).
- Project packager: deploy a ready-to-run Codex bundle into any project folder, with start_codex.bat, AGENTS.md, Repo_Snap.md, and a manifest.
- High-contrast rule: light text on dark backgrounds everywhere. No low-contrast pairings. Inline comments mark this requirement.

This single file has no external deps beyond the Python stdlib and Tkinter.
"""

from __future__ import annotations

import hashlib
import json
import os
import platform
import re
import shutil
import socket
import subprocess
import sys
import threading
import time
import zipfile
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple, List
from urllib import request
from urllib.error import HTTPError, URLError

# Tk for prompts, GUI, pickers, and the embedded terminal
import tkinter as tk
from tkinter import ttk, messagebox, filedialog

# ========================= Portable paths (relative to script) =========================
# Detect where this file lives. Assume it sits inside a folder named "Codex-Installer".
SCRIPT_PATH = Path(__file__).resolve()
INSTALLER_ROOT = SCRIPT_PATH.parent  # folder that contains this script
# Transit and outputs live inside the same root so the whole tree is mobile.
TRANSIT_DIR = INSTALLER_ROOT / "Codex-Transit"            # Working directory beside this script
DEFAULT_CODEX_EXE = TRANSIT_DIR / "codex-x86_64-pc-windows-msvc.exe"
INSTALL_MANIFEST = TRANSIT_DIR / "INSTALL_MANIFEST.md"

# Persistent Codex CLI config lives in the user profile (Codex convention).
HOME = Path.home()
WIN_CFG_DIR = HOME / ".codex"
WIN_CFG = WIN_CFG_DIR / "config.toml"

# ========================= Release constants =========================
RELEASE_TAG = "rust-v0.34.0"
ASSET_ZIP = "codex-x86_64-pc-windows-msvc.exe.zip"
ASSET_ZIP_SHA256 = "789563e58e6126de96329c8e154718409378831abcef3856c8b46527b20c08ac"
RELEASE_BASE = f"https://github.com/openai/codex/releases/download/{RELEASE_TAG}"
ASSET_URL = f"{RELEASE_BASE}/{ASSET_ZIP}"

# ========================= Ollama endpoints =========================
OLLAMA = "http://127.0.0.1:11434"
API_VER = f"{OLLAMA}/api/version"
API_TAGS = f"{OLLAMA}/api/tags"
API_GEN = f"{OLLAMA}/api/generate"
API_CHAT = f"{OLLAMA}/v1/chat/completions"

# ========================= Model priorities =========================
DEFAULT_MODEL = "qwen3:8b"
PREF_LIST = [
    "gpt-oss:20b",
    "qwen3-coder:30b",
    "qwen3:30b",
    "qwen3:8b",
    "deepseek-coder-v2:16b",
    "granite-code:8b",
    "qwen3:4b",
    "mistral:7b",
    "starcoder2:latest",
    "gemma3:27b",
    "gemma3:4b",
    "phi4-mini:3.8b",
]
BLACK_PARTS = ("embed", "ocr", "nanonets", "llava", "arctic-embed", "/")

# ========================= Utilities =========================

def enable_dpi_awareness() -> None:
    """Windows DPI awareness so launcher scales correctly on high-DPI displays."""
    if os.name != "nt":
        return
    try:
        import ctypes
        try:
            ctypes.windll.shcore.SetProcessDpiAwareness(1)  # Per-monitor v1
        except Exception:
            ctypes.windll.user32.SetProcessDPIAware()
    except Exception:
        pass

def ensure_dirs() -> None:
    # All portable artifacts live under INSTALLER_ROOT to keep the whole tree mobile.
    TRANSIT_DIR.mkdir(parents=True, exist_ok=True)

def sha256_file(p: Path, chunk: int = 1024 * 1024) -> str:
    h = hashlib.sha256()
    with p.open("rb") as f:
        for b in iter(lambda: f.read(chunk), b""):
            h.update(b)
    return h.hexdigest()

def http(url: str, method="GET", payload: dict | None = None, timeout: float = 8.0) -> tuple[int, str]:
    data = None
    headers = {}
    if payload is not None:
        data = json.dumps(payload).encode("utf-8")
        headers["Content-Type"] = "application/json"
    req = request.Request(url, data=data, headers=headers, method=method)
    try:
        with request.urlopen(req, timeout=timeout) as resp:
            return resp.getcode() or 200, resp.read().decode("utf-8", "replace")
    except HTTPError as e:
        try:
            return e.code, e.read().decode("utf-8", "replace")
        except Exception:
            return e.code, str(e)
    except (URLError, Exception) as e:
        return 0, str(e)

def print_step(msg: str) -> None:
    # Concise, machine-parsable.
    print(msg, flush=True)

# ========================= Codex bootstrap class (drop-in API) =========================

@dataclass
class DownloadResult:
    ok: bool
    path: Optional[Path]
    error: Optional[str]
    sha256: Optional[str]

class CodexBootstrap:
    """
    Drop-in API for other systems
    -----------------------------
    Public methods:
      - ensure_ollama()
      - list_models()
      - model_supports_tools(name)
      - warm_model(name)
      - ensure_release() -> Path
      - verify_zip_if_present()
      - codex_version(bin_path) -> str
      - write_win_cfg(model) -> str
      - auto_pick_tools_model(requested, available) -> str
      - launch_codex_console(bin_path, model, cwd, open_in_cmd=True) -> subprocess.Popen
      - launch_codex_with_bridge(bin_path, model, cwd) -> (proc, BridgeServer)
      - launch_console_client(port, title="Codex Bridge")
      - create_project_package(target_root: Path, model: str, exe: Path) -> Path
    """

    def __init__(self):
        ensure_dirs()

    # ---------- Ollama ----------

    def ensure_ollama(self) -> None:
        code, _ = http(API_VER, timeout=2.0)
        if 200 <= code < 300:
            return
        subprocess.Popen(
            ["powershell", "-NoLogo", "-NoProfile", "-Command",
             "Start-Process -WindowStyle Minimized cmd -ArgumentList '/c','ollama','serve'"],
            creationflags=subprocess.CREATE_NEW_CONSOLE
        )
        deadline = time.time() + 60
        while time.time() < deadline:
            code, _ = http(API_VER, timeout=2.0)
            if 200 <= code < 300:
                return
            time.sleep(0.5)
        raise RuntimeError("Ollama not reachable at http://127.0.0.1:11434. Run `ollama serve` manually.")

    def list_models(self) -> list[str]:
        names: list[str] = []
        c, d = http(API_TAGS, timeout=4.0)
        if 200 <= c < 300 and d:
            try:
                obj = json.loads(d)
                for m in obj.get("models") or []:
                    n = m.get("name")
                    if n:
                        names.append(n)
            except Exception:
                pass
        if names:
            return sorted(set(names))
        exe = shutil.which("ollama")
        if not exe:
            return []
        out = subprocess.run([exe, "list"], capture_output=True, text=True).stdout or ""
        for ln in out.splitlines():
            m = re.match(r"^(\S+:\S+)", ln.strip())
            if m:
                names.append(m.group(1))
        return sorted(set(names))

    def warm_model(self, name: str) -> bool:
        size = "med"
        m = re.search(r":(\d+(\.\d+)?)b", name, re.I)
        if m:
            v = float(m.group(1))
            size = "small" if v <= 5 else ("med" if v <= 12 else "large")
        timeout = 6.0 if size == "small" else (12.0 if size == "med" else 22.0)
        c, _ = http(API_GEN, "POST", {"model": name, "prompt": "ping", "stream": False}, timeout=timeout)
        return 200 <= c < 300

    def model_supports_tools(self, name: str) -> bool:
        payload = {
            "model": name,
            "messages": [{"role": "user", "content": "ping"}],
            "tools": [{
                "type": "function",
                "function": {"name": "noop", "parameters": {"type": "object", "properties": {}}}
            }],
            "tool_choice": "auto"
        }
        code, body = http(API_CHAT, "POST", payload, timeout=6.0)
        if 200 <= code < 300:
            return True
        if "does not support tools" in body.lower():
            return False
        return False

    # ---------- Codex assets ----------

    def download_with_progress(self, url: str, dest: Path, progress_cb=None, chunk: int = 128 * 1024) -> DownloadResult:
        try:
            ensure_dirs()
            tmp = dest.with_suffix(dest.suffix + ".part")
            if tmp.exists():
                tmp.unlink()
            req = request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
            with request.urlopen(req, timeout=30) as r, tmp.open("wb") as f:
                total = int(r.headers.get("Content-Length") or 0)
                read = 0
                while True:
                    buf = r.read(chunk)
                    if not buf:
                        break
                    f.write(buf)
                    read += len(buf)
                    if progress_cb and total:
                        progress_cb(int(read * 100 / total))
            tmp.replace(dest)
            digest = sha256_file(dest)
            return DownloadResult(True, dest, None, digest)
        except Exception as e:
            return DownloadResult(False, None, str(e), None)

    def extract_zip(self, zip_path: Path, out_dir: Path) -> Path:
        with zipfile.ZipFile(zip_path, "r") as z:
            members = z.namelist()
            z.extractall(out_dir)
        for name in members:
            if name.lower().endswith(".exe"):
                p = out_dir / Path(name).name
                if p.exists():
                    return p
        p = out_dir / "codex-x86_64-pc-windows-msvc.exe"
        if p.exists():
            return p
        raise FileNotFoundError("EXE not found after extraction.")

    def codex_version(self, bin_path: Path) -> str:
        try:
            out = subprocess.run([str(bin_path), "--version"], capture_output=True, text=True, timeout=8)
            return (out.stdout or out.stderr or "").strip()
        except Exception as e:
            return f"(version check failed: {e})"

    def ensure_release(self) -> Path:
        ensure_dirs()
        zip_path = TRANSIT_DIR / ASSET_ZIP
        exe_path = DEFAULT_CODEX_EXE
        if exe_path.exists():
            return exe_path
        print_step("[Info] Downloading codex-x86_64-pc-windows-msvc.exe.zip …")
        def progress(pct: int):
            if pct % 10 == 0:
                print_step(f"[Info] Download {pct}%")
        res = self.download_with_progress(ASSET_URL, zip_path, progress_cb=progress)
        if not res.ok or not res.path:
            raise RuntimeError(res.error or "download failed")
        digest = res.sha256 or sha256_file(zip_path)
        print_step(f"[Info] SHA-256: {digest}")
        if digest.lower() != ASSET_ZIP_SHA256.lower():
            raise RuntimeError("SHA-256 mismatch. Refusing to extract.")
        print_step("[Info] Extracting …")
        exe = self.extract_zip(zip_path, TRANSIT_DIR)
        print_step(f"[OK] Extracted to: {exe}")
        return exe

    def verify_zip_if_present(self):
        zp = TRANSIT_DIR / ASSET_ZIP
        if zp.exists():
            digest = sha256_file(zp)
            print_step(f"[Verify] SHA-256 of zip: {digest}")
            print_step(f"[Verify] Matches official zip: {digest.lower() == ASSET_ZIP_SHA256.lower()}")

    def write_win_cfg(self, model: str) -> str:
        """
        ~/.codex/config.toml — OpenAI Chat API over Ollama.
        Must end with /v1. wire_api must be "chat".
        """
        WIN_CFG_DIR.mkdir(parents=True, exist_ok=True)
        txt = (
            f'model = "{model}"\n'
            f'model_provider = "ollama"\n\n'
            f'[model_providers.ollama]\n'
            f'name = "Ollama"\n'
            f'base_url = "http://127.0.0.1:11434/v1"\n'
            f'wire_api = "chat"\n'
        )
        WIN_CFG.write_text(txt, encoding="utf-8")
        return str(WIN_CFG)

    # ---------- Model selection helpers ----------

    def _black(self, name: str) -> bool:
        low = name.lower()
        return any(part in low for part in BLACK_PARTS)

    def shortlist(self, avail: list[str]) -> list[str]:
        pool = [m for m in PREF_LIST if m in avail and not self._black(m)]
        rest = [m for m in avail if m not in pool and not self._black(m)]
        return pool + rest

    def auto_pick_tools_model(self, requested: Optional[str], available: list[str]) -> str:
        cand_order: List[str] = []
        if requested:
            cand_order.append(requested)
        cand_order.extend([m for m in self.shortlist(available) if m not in cand_order])
        if DEFAULT_MODEL not in cand_order:
            cand_order.append(DEFAULT_MODEL)
        print_step("[Info] Probing tools support…")
        for m in cand_order:
            try:
                if self.model_supports_tools(m):
                    print_step(f"[OK] Using tools-capable model: {m}")
                    return m
                else:
                    print_step(f"[Warn] {m} does not support OpenAI tools. Trying next…")
            except Exception as e:
                print_step(f"[Warn] Probe failed for {m}: {e}. Trying next…")
        raise RuntimeError("No tools-capable model found. Pull one that supports tools and retry.")

    # ---------- Launch methods ----------

    def launch_codex_console(self, bin_path: Path, model: str, cwd: Path, open_in_cmd: bool = True) -> subprocess.Popen:
        if not bin_path.exists():
            raise FileNotFoundError(f"Codex binary not found: {bin_path}")
        if open_in_cmd:
            return subprocess.Popen(["cmd", "/k", str(bin_path), "--model", model], cwd=str(cwd))
        return subprocess.Popen([str(bin_path), "--model", model],
                                cwd=str(cwd),
                                stdin=subprocess.PIPE,
                                stdout=subprocess.PIPE,
                                stderr=subprocess.STDOUT,
                                text=True,
                                bufsize=1)

    def launch_codex_with_bridge(self, bin_path: Path, model: str, cwd: Path) -> tuple[subprocess.Popen, "BridgeServer"]:
        """Start Codex with pipes and attach a TCP bridge to share the session."""
        proc = self.launch_codex_console(bin_path, model, cwd, open_in_cmd=False)
        bridge = BridgeServer(proc)
        return proc, bridge

    def launch_console_client(self, port: int, title: str = "Codex Bridge"):
        """
        Spawn a visible CMD window that connects to the bridge and mirrors the session.
        Typing in that window sends lines back to Codex via the bridge.
        High-contrast colors are handled by the console theme; this is an auxiliary viewer/driver.
        """
        pycode = rf"""
import socket, sys, threading
host, port = "127.0.0.1", {port}
s = socket.socket(); s.connect((host, port))
def rx():
    f = s.makefile("r", encoding="utf-8", newline="\n")
    for line in f:
        sys.stdout.write(line); sys.stdout.flush()
threading.Thread(target=rx, daemon=True).start()
print("[OK] Connected to Codex on {{}}:{{}}".format(host, port))
for line in sys.stdin:
    try:
        s.sendall((line.rstrip("\n") + "\n").encode("utf-8","replace"))
    except Exception:
        break
"""
        subprocess.Popen(
            ["cmd", "/k", "python", "-c", pycode],
            cwd=str(TRANSIT_DIR),
            creationflags=subprocess.CREATE_NEW_CONSOLE,
        )

    # ---------- Project packager ----------

    def create_project_package(self, target_root: Path, model: str, exe: Path) -> Path:
        """
        Prepare a portable Codex bundle under target_root.
        Creates target_root/Codex or target_root/Codex-Transit if 'Codex' exists.
        Copies EXE and writes start_codex.bat, AGENTS.md, Repo_Snap.md, INSTALL_MANIFEST.md.
        Returns the created bundle path.
        """
        ensure_dirs()
        # Choose folder name
        dest = target_root / "Codex"
        if dest.exists():
            dest = target_root / "Codex-Transit"
        dest.mkdir(parents=True, exist_ok=True)

        # Copy EXE
        exe_dest = dest / exe.name
        shutil.copy2(exe, exe_dest)

        # Write start_codex.bat (batch text contrast n/a)
        bat = dest / "start_codex.bat"
        bat.write_text(rf"""@echo off
setlocal
title Codex Starter
REM Start Ollama minimized. If already running this is harmless.
start "Ollama" /MIN cmd /c ollama serve
REM Small delay for server warmup.
ping 127.0.0.1 -n 3 >NUL

REM Use this batch's directory as working dir (portable).
pushd "%~dp0"

REM Ensure Codex config points to Ollama /v1 and chosen model.
python - <<PY
import os, pathlib
from pathlib import Path
home = Path(os.environ.get("USERPROFILE") or Path.home())
cfgd = home/".codex"
cfgd.mkdir(parents=True, exist_ok=True)
cfg = cfgd/"config.toml"
cfg.write_text('model = "{model}"\nmodel_provider = "ollama"\n\n[model_providers.ollama]\nname = "Ollama"\nbase_url = "http://127.0.0.1:11434/v1"\nwire_api = "chat"\n', encoding="utf-8")
print("[OK] Wrote", cfg)
PY

REM Launch Codex with model in this folder.
start "Codex" cmd /k "%~dp0{exe.name}" --model {model}
""", encoding="utf-8")

        # Repo snapshot
        snap = dest / "Repo_Snap.md"
        snap.write_text(render_repo_snapshot(target_root), encoding="utf-8")

        # Agents.md
        agents = dest / "AGENTS.md"
        agents.write_text(render_agents_md(model), encoding="utf-8")

        # Manifest for the project bundle
        write_install_manifest(model, exe_dest, self, override_path=dest)

        return dest

# ========================= Bridge server (stdin/stdout fan-out) =========================

class BridgeServer:
    """
    Minimal TCP line bridge for Codex subprocess.
    - Accepts multiple clients on 127.0.0.1:<port>
    - Broadcasts each Codex stdout line to all clients.
    - Any line from a client is forwarded to Codex stdin with '\n'.

    Protocol (Lexicon v1):
    - Newline-terminated UTF-8 lines.
    - Send '/status' etc. Receive stdout lines.
    - No JSON framing.

    Security: binds only to 127.0.0.1. No auth.
    """

    def __init__(self, proc: subprocess.Popen, host: str = "127.0.0.1", port: int = 0):
        self.proc = proc
        self.host = host
        self.port = port
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.bind((self.host, self.port))
        self.sock.listen(5)
        self.port = self.sock.getsockname()[1]
        self._clients: list[socket.socket] = []
        self._stop = threading.Event()
        self._threads: list[threading.Thread] = []

        t_accept = threading.Thread(target=self._accept_loop, daemon=True)
        t_accept.start()
        self._threads.append(t_accept)

        t_out = threading.Thread(target=self._stdout_loop, daemon=True)
        t_out.start()
        self._threads.append(t_out)

    def _accept_loop(self):
        while not self._stop.is_set():
            try:
                self.sock.settimeout(1.0)
                conn, _ = self.sock.accept()
            except socket.timeout:
                continue
            except OSError:
                break
            self._clients.append(conn)
            t_cli = threading.Thread(target=self._client_loop, args=(conn,), daemon=True)
            t_cli.start()
            self._threads.append(t_cli)

    def _client_loop(self, conn: socket.socket):
        try:
            with conn:
                conn_file = conn.makefile("r", encoding="utf-8", newline="\n")
                for line in conn_file:
                    if self.proc.poll() is not None:
                        break
                    if self.proc.stdin:
                        self.proc.stdin.write(line.rstrip("\n") + "\n")
                        self.proc.stdin.flush()
        except Exception:
            pass
        finally:
            try:
                self._clients.remove(conn)
            except ValueError:
                pass

    def _stdout_loop(self):
        try:
            if not self.proc.stdout:
                return
            for line in self.proc.stdout:
                data = line if line.endswith("\n") else (line + "\n")
                dead: list[socket.socket] = []
                for c in self._clients:
                    try:
                        c.sendall(data.encode("utf-8", "replace"))
                    except Exception:
                        dead.append(c)
                for d in dead:
                    try:
                        self._clients.remove(d)
                    except ValueError:
                        pass
        except Exception:
            pass

    def close(self):
        self._stop.set()
        try:
            self.sock.close()
        except Exception:
            pass
        for c in list(self._clients):
            try:
                c.close()
            except Exception:
                pass

# ========================= Embedded Terminal (Tk) =========================
# High-contrast: light text on dark background. Never low-contrast pairs.

class EmbeddedTerminal(tk.Toplevel):
    """Simple TCP client UI for the BridgeServer."""
    def __init__(self, master: tk.Misc, host: str, port: int):
        super().__init__(master)
        enable_dpi_awareness()
        self.title(f"Codex Terminal — {host}:{port}")
        self.geometry("900x560")
        self.configure(bg="#0e1a2c")  # dark background; high-contrast text below
        self.host, self.port = host, port
        self.sock: Optional[socket.socket] = None
        self._rx_thread: Optional[threading.Thread] = None
        self._stop = threading.Event()

        style = ttk.Style(self)
        style.theme_use("clam")
        style.configure("TLabel", background="#0e1a2c", foreground="#e6f0ff")
        style.configure("TButton", background="#1E5AFF", foreground="#ffffff", padding=6)
        style.map("TButton", background=[("active", "#2f72ff")])

        # Transcript (high-contrast text)
        self.text = tk.Text(self, bg="#0c1524", fg="#e6f0ff", insertbackground="#e6f0ff", height=26, wrap="word", highlightthickness=1)
        self.text.pack(fill="both", expand=True, padx=12, pady=(12, 6))

        # Input row
        row = ttk.Frame(self)
        row.pack(fill="x", padx=12, pady=(0, 12))
        self.entry = tk.Entry(row, bg="#0c1524", fg="#e6f0ff", insertbackground="#e6f0ff", width=88, relief="solid", highlightthickness=1)
        self.entry.pack(side="left", fill="x", expand=True)
        self.entry.bind("<Return>", self._send_line)
        ttk.Button(row, text="Send", command=self._send_line).pack(side="left", padx=6)

        # Connect
        try:
            self.sock = socket.socket()
            self.sock.connect((self.host, self.port))
            self._rx_thread = threading.Thread(target=self._rx_loop, daemon=True)
            self._rx_thread.start()
            self._append(f"[OK] Connected to Codex on {self.host}:{self.port}\n")
        except Exception as e:
            self._append(f"[Error] Could not connect: {e}\n")

        self.protocol("WM_DELETE_WINDOW", self._on_close)

    def _append(self, s: str):
        self.text.insert("end", s)
        self.text.see("end")

    def _rx_loop(self):
        try:
            assert self.sock is not None
            f = self.sock.makefile("r", encoding="utf-8", newline="\n")
            for line in f:
                if self._stop.is_set():
                    break
                self._append(line)
        except Exception:
            pass

    def _send_line(self, _evt=None):
        line = self.entry.get().rstrip("\n")
        if not line:
            return
        try:
            assert self.sock is not None
            self.sock.sendall((line + "\n").encode("utf-8", "replace"))
            self.entry.delete(0, "end")
        except Exception as e:
            self._append(f"[Error] send failed: {e}\n")

    def _on_close(self):
        self._stop.set()
        try:
            if self.sock:
                self.sock.close()
        except Exception:
            pass
        self.destroy()

# ========================= Content generators =========================

def render_repo_snapshot(root: Path, max_depth: int = 12) -> str:
    """Create a markdown tree of the selected root for Repo_Snap.md."""
    lines = [f"# Repo Snapshot — {root}", ""]
    base = root.resolve()
    for dirpath, dirnames, filenames in os.walk(base):
        rel = Path(dirpath).relative_to(base)
        depth = len(rel.parts)
        if depth > max_depth:
            continue
        indent = "  " * depth
        name = "." if depth == 0 else rel.name
        lines.append(f"{indent}- {name}/")
        for fn in sorted(filenames):
            lines.append(f"{indent}  - {fn}")
    lines.append("")
    return "\n".join(lines)

def render_agents_md(model: str) -> str:
    """Seed AGENTS.md with self-writing guidance and references to Repo_Snap.md."""
    return f"""# AGENTS.md — Self-Writing Agent Rules

Purpose
- Improve and extend this repository autonomously based on user requests.
- Adapt to the environment you find here. Keep this file updated with decisions and conventions.

Operating model
- Primary model: `{model}` via Codex CLI (Rust) behind Ollama Chat API.
- Tool use: follow Codex `/model`, `/status`, `/approvals` as needed.

Memory and expansion
- Persist lightweight context inside AGENTS.md. Append decisions and rationale.
- Keep a one-file map of the codebase in **Repo_Snap.md**. Update it when structure changes.

Workflow
1) Read **Repo_Snap.md** to get structure.
2) Propose changes as diffs. Keep patches minimal and reversible.
3) When adding code, follow the project's style. Note decisions here.
4) When you learn a new invariant or convention, write it under "Conventions".

Conventions
- High contrast in any UI you generate. Never low-contrast text.
- Portable paths. Prefer paths relative to the entrypoint or repo root.
- Do not hard-code secrets. Use environment variables or local config files.

Self-update protocol
- When significant repo state changes, update:
  - This AGENTS.md (new conventions, modules, routes)
  - Repo_Snap.md (new files and directories)

End.
"""

# ========================= Install Manifest writer =========================

def write_install_manifest(selected_model: str, exe_path: Path, cb: CodexBootstrap, override_path: Path | None = None) -> Path:
    """
    Writes INSTALL_MANIFEST.md with curated guidance:
      A) Use this script as an API module in a repo (startup selection + hooks + bridge).
      B) Re-implement from scratch. Documents authoritative model enumeration via /api/tags.
    If override_path is provided, write there; otherwise write beside this installer (TRANSIT_DIR).
    """
    ensure_dirs()
    out_dir = override_path if override_path else TRANSIT_DIR
    out_dir.mkdir(parents=True, exist_ok=True)

    script_filename = SCRIPT_PATH.name
    cfg_toml = (
        f'model = "{selected_model}"\n'
        f'model_provider = "ollama"\n\n'
        f'[model_providers.ollama]\n'
        f'name = "Ollama"\n'
        f'base_url = "http://127.0.0.1:11434/v1"\n'
        f'wire_api = "chat"\n'
    )
    version = cb.codex_version(exe_path)

    lines = [
f"# Install Manifest and Integration Guide\n",
f"**Generated:** {datetime.now().isoformat(sep=' ', timespec='seconds')}\n",
f"**Installer root:** `{INSTALLER_ROOT}`  \n"
f"**Transit:** `{TRANSIT_DIR}`  \n"
f"**Binary:** `{exe_path}`  \n"
f"**Config:** `{WIN_CFG}`  \n"
f"**Codex version:** `{version}`\n",
"---\n",
"## Scope\n",
"Two integration strategies:\n",
"**A. Use this script as an API** for turnkey bootstrap and a TCP bridge.\n",
"**B. Re-implement** the same behavior in a new project.\n",
"All paths are portable and relative to the folder that contains this script.\n",
"---\n",
"## Release details\n",
f"- Release tag: `{RELEASE_TAG}`\n"
f"- Asset: `{ASSET_ZIP}`\n"
f"- SHA-256 for the **zip**: `{ASSET_ZIP_SHA256}`\n",
"---\n",
"## A) Use this script as an API\n",
"### Startup selection (replicate our launcher)\n",
"- Present 5 choices: Change default settings, Launch with defaults, **Launch with embedded terminal**, Copy install manifest, Start Codex in New Project.\n",
"### Importing the API\n",
"```python\n"
f"from {Path(script_filename).stem} import CodexBootstrap, BridgeServer\n"
"cb = CodexBootstrap()\n"
"cb.ensure_ollama()\n"
"models = cb.list_models()\n"
"exe = cb.ensure_release()\n"
"model = cb.auto_pick_tools_model('qwen3:8b', models)\n"
"cb.write_win_cfg(model)\n"
"proc, bridge = cb.launch_codex_with_bridge(exe, model, Path(__file__).parent/'Codex-Installer'/'Codex-Transit')\n"
"print('Bridge on 127.0.0.1:', bridge.port)\n"
"```\n",
"### Visible CMD mirror of the same session\n",
"```python\n"
"cb.launch_console_client(bridge.port)\n"
"```\n",
"### Create a portable bundle for another project\n",
"```python\n"
"# choose a target path and call:\n"
"bundle = cb.create_project_package(Path(r'C:/path/to/project'), model, exe)\n"
"print('Bundle at', bundle)\n"
"```\n",
"---\n",
"## B) Re-implement without this file\n",
"Implement these steps in your language of choice:\n",
"1. Paths: set INSTALLER_ROOT to your installer folder; TRANSIT = INSTALLER_ROOT/'Codex-Transit'.\n",
"2. Download: fetch GitHub asset above → TRANSIT/asset.zip; verify SHA-256; unzip to EXE.\n",
"3. Ollama: GET `http://127.0.0.1:11434/api/version`; else start `ollama serve`.\n",
"4. Enumerate models: GET `http://127.0.0.1:11434/api/tags` and collect `models[*].name`.\n",
"5. Probe tools support: POST `/v1/chat/completions` with a minimal tools payload; if 200 then tools supported.\n",
"6. Warm model: POST `/api/generate` with `stream:false`.\n",
"7. Write `%USERPROFILE%\\.codex\\config.toml`:\n",
"```toml\n" + cfg_toml + "```\n",
"8. Launch Codex: run the EXE with `--model <name>` in the Transit folder. For programmatic control, spawn with pipes and fan out via a TCP bridge.\n",
"9. Tk readonly Combobox styling (no white-on-white):\n",
"```python\n"
"style.theme_use('clam')\n"
"style.configure('TCombobox', foreground='#e6f0ff', fieldbackground='#0c1524', background='#0c1524')\n"
"style.map('TCombobox', fieldbackground=[('readonly','#0c1524')], foreground=[('readonly','#e6f0ff')])\n"
"```\n",
"---\n",
"## Project bundle layout and launcher\n",
"- `Codex` or `Codex-Transit` with:\n",
"  - `codex-*.exe`\n",
"  - `start_codex.bat`\n",
"  - `AGENTS.md`\n",
"  - `Repo_Snap.md`\n",
"---\n",
"## Effective config.toml\n",
"```toml\n" + cfg_toml + "```\n",
"---\n",
"## Troubleshooting\n",
"- 400 does not support tools → choose a different local model or pull one that supports tools.\n",
"- Ollama not reachable → run `ollama serve` or allow the launcher to start it; permit localhost in firewall.\n",
"- Zip checksum mismatch → delete the zip and re-download.\n",
    ]
    out = out_dir / "INSTALL_MANIFEST.md"
    out.write_text("\n".join(lines), encoding="utf-8")
    return out

# ========================= Friendlier first popup =========================

def first_popup(api: CodexBootstrap) -> Optional[str]:
    """
    Returns: "configure", "defaults", "embedded", "copy", "new_project", or None
    Buttons:
      [Change default settings]  [Launch with defaults]  [Launch with embedded terminal]  [Copy install manifest]  [Start Codex in New Project]  [Cancel]
    """
    try:
        enable_dpi_awareness()
        root = tk.Tk()
        root.title("Codex Starter")
        root.configure(bg="#0e1a2c")  # dark for contrast
        root.resizable(True, True)

        try:
            scale = root.winfo_fpixels('1i') / 72.0
            root.tk.call('tk', 'scaling', scale if scale > 0 else 1.25)
        except Exception:
            pass

        style = ttk.Style(root)
        style.theme_use("clam")
        style.configure("TLabel", background="#0e1a2c", foreground="#e6f0ff")
        style.configure("TButton", background="#1E5AFF", foreground="#ffffff", padding=6)
        style.map("TButton", background=[("active", "#2f72ff")])
        style.configure("TLabelframe", background="#0e1a2c")
        style.configure("TLabelframe.Label", background="#0e1a2c", foreground="#e6f0ff")

        frm = ttk.Frame(root, padding=12)
        frm.pack(expand=True, fill="both")
        frm.configure(style="TLabel")

        ttk.Label(frm, text="Choose how to start:", anchor="w").pack(anchor="w", pady=(0, 8))
        msg = ("• Change default settings: open the configuration GUI.\n"
               "• Launch with defaults: run the full automated flow now (visible CMD Codex).\n"
               "• Launch with embedded terminal: run Codex with a bridge, open an in-app terminal and a visible CMD client.\n"
               "• Copy install manifest: ensure/download v0.34.0 if missing, create/update the manifest, copy to clipboard.\n"
               "• Start Codex in New Project: choose a folder and deploy a ready-to-run Codex bundle there.")
        ttk.Label(frm, text=msg, anchor="w", justify="left", wraplength=680).pack(anchor="w")

        sel = {"choice": None}

        btns = ttk.Frame(frm)
        btns.pack(side="bottom", pady=(14, 0))

        def setc(x): sel["choice"] = x; root.destroy()

        ttk.Button(btns, text="Change default settings", command=lambda: setc("configure")).pack(side="left", padx=6)
        ttk.Button(btns, text="Launch with defaults", command=lambda: setc("defaults")).pack(side="left", padx=6)
        ttk.Button(btns, text="Launch with embedded terminal", command=lambda: setc("embedded")).pack(side="left", padx=6)
        ttk.Button(btns, text="Copy install manifest", command=lambda: setc("copy")).pack(side="left", padx=6)
        ttk.Button(btns, text="Start Codex in New Project", command=lambda: setc("new_project")).pack(side="left", padx=6)
        ttk.Button(btns, text="Cancel", command=lambda: setc(None)).pack(side="left", padx=6)

        root.update_idletasks()
        w = max(820, root.winfo_reqwidth() + 40)
        h = max(320, root.winfo_reqheight() + 20)
        x = root.winfo_screenwidth() // 2 - w // 2
        y = root.winfo_screenheight() // 3 - h // 2
        root.geometry(f"{w}x{h}+{x}+{y}")

        root.mainloop()
        return sel["choice"]
    except Exception:
        print_step("Start: [1] Settings  [2] Defaults  [3] Embedded terminal  [4] Copy manifest  [5] New project  [other] Cancel")
        v = input("Select 1/2/3/4/5: ").strip()
        return {"1":"configure","2":"defaults","3":"embedded","4":"copy","5":"new_project"}.get(v, None)

# ========================= Numbered model picker (console) =========================

def choose_model_interactive(ordered_models: list[str]) -> str:
    print("\nAvailable local models:")
    for i, m in enumerate(ordered_models, 1):
        print(f"  {i}. {m}")
    sel = input(f"\nSelect model by number or press Enter for default [{DEFAULT_MODEL}]: ").strip()
    if not sel:
        return DEFAULT_MODEL
    if not sel.isdigit():
        print_step("[Warn] Invalid input. Using default.")
        return DEFAULT_MODEL
    idx = int(sel)
    if not (1 <= idx <= len(ordered_models)):
        print_step("[Warn] Out of range. Using default.")
        return DEFAULT_MODEL
    return ordered_models[idx - 1]

# ========================= Optional full GUI (manual settings) =========================

class SettingsGUI(tk.Tk):
    def __init__(self, api: CodexBootstrap):
        super().__init__()
        self.api = api

        # High-contrast UI
        enable_dpi_awareness()
        self.title("Codex Starter — Change default settings")
        self.geometry("980x700")
        self.configure(bg="#0e1a2c")

        style = ttk.Style(self)
        style.theme_use("clam")
        style.configure("TLabel", background="#0e1a2c", foreground="#e6f0ff")
        style.configure("TButton", background="#1E5AFF", foreground="#ffffff", padding=6)
        style.map("TButton", background=[("active", "#2f72ff")])
        style.configure("TEntry", fieldbackground="#0c1524", foreground="#e6f0ff")
        style.configure("TLabelframe", background="#0e1a2c")
        style.configure("TLabelframe.Label", background="#0e1a2c", foreground="#e6f0ff")
        style.configure("TCombobox", foreground="#e6f0ff", fieldbackground="#0c1524", background="#0c1524")
        style.map("TCombobox",
                  fieldbackground=[("readonly", "#0c1524")],
                  foreground=[("readonly", "#e6f0ff")],
                  background=[("readonly", "#0c1524")])

        ensure_dirs()

        self.codex_path = tk.StringVar(value=str(DEFAULT_CODEX_EXE))
        self.model_var = tk.StringVar(value="")
        self.status_var = tk.StringVar(value="Idle")
        self.models: list[str] = []
        self._bridge: Optional[BridgeServer] = None
        self._proc: Optional[subprocess.Popen] = None

        row0 = ttk.LabelFrame(self, text="Codex rust-v0.34.0")
        row0.pack(fill="x", padx=12, pady=8)
        ttk.Label(row0, text=f"Installer root: {INSTALLER_ROOT}").grid(row=0, column=0, sticky="w", padx=8, pady=6)
        ttk.Button(row0, text="Open Transit", command=lambda: subprocess.Popen(["explorer", str(TRANSIT_DIR)])).grid(row=0, column=1, padx=6)

        ttk.Label(row0, text="Binary path:").grid(row=1, column=0, sticky="w", padx=8)
        self.path_entry = tk.Entry(row0, textvariable=self.codex_path, bg="#0c1524", fg="#e6f0ff",
                                   insertbackground="#e6f0ff", width=86, relief="solid", highlightthickness=1)
        self.path_entry.grid(row=1, column=1, sticky="we", padx=6)
        ttk.Button(row0, text="Browse…", command=self._browse_bin).grid(row=1, column=2, padx=6)

        ttk.Button(row0, text="Download v0.34.0 (.zip)", command=self._download_release).grid(row=2, column=0, padx=8, pady=8, sticky="w")
        ttk.Button(row0, text="Verify Binary", command=self._verify_binary).grid(row=2, column=1, padx=6, pady=8, sticky="w")
        ttk.Button(row0, text="Check Version", command=self._check_version).grid(row=2, column=2, padx=6, pady=8, sticky="w")

        row1 = ttk.LabelFrame(self, text="Model")
        row1.pack(fill="x", padx=12, pady=6)
        ttk.Label(row1, text="Local Ollama model:").pack(side="left", padx=8, pady=6)
        self.model_combo = ttk.Combobox(row1, textvariable=self.model_var, state="readonly", width=46)
        self.model_combo.pack(side="left", padx=6)
        ttk.Button(row1, text="Refresh Models", command=self._refresh_models).pack(side="left", padx=6)

        row2 = ttk.Frame(self)
        row2.pack(fill="x", padx=12, pady=6)
        ttk.Button(row2, text="Write Config Only", command=self._write_config_only).pack(side="left")
        ttk.Button(row2, text="Start Codex", command=self._start_codex_cmd).pack(side="left", padx=8)
        ttk.Button(row2, text="Start with Embedded Terminal", command=self._start_with_terminal).pack(side="left", padx=8)
        ttk.Button(row2, text="Copy INSTALL_MANIFEST.md", command=self._copy_manifest).pack(side="left", padx=8)
        ttk.Button(row2, text="Start Codex in New Project", command=self._new_project).pack(side="left", padx=8)

        self.pbar = ttk.Progressbar(self, orient="horizontal", mode="determinate", length=400)
        self.pbar.pack(fill="x", padx=12, pady=8)
        self.status = ttk.Label(self, textvariable=self.status_var)
        self.status.pack(anchor="w", padx=12)

        self.log = tk.Text(self, height=16, bg="#0c1524", fg="#e6f0ff", insertbackground="#e6f0ff", highlightthickness=1)
        self.log.pack(fill="both", expand=True, padx=12, pady=8)

        self.after(200, self._refresh_models)

    # ----- helpers -----

    def _browse_bin(self):
        p = filedialog.askopenfilename(title="Select Codex Rust binary",
                                       initialdir=str(TRANSIT_DIR),
                                       filetypes=[("Executable", "*.exe"), ("All files", "*.*")])
        if p:
            self.codex_path.set(p)

    def _set_status(self, s: str, v: int | None = None):
        self.status_var.set(s)
        if v is not None:
            self.pbar["value"] = max(0, min(100, v))
        self.log.insert("end", s + "\n")
        self.log.see("end")

    # ----- actions -----

    def _download_release(self):
        def work():
            try:
                arch = platform.machine().lower()
                if arch not in ("amd64", "x86_64"):
                    self._set_status(f"[Warn] Detected arch '{arch}'. This downloads x86_64 Windows build.")
                ensure_dirs()
                zip_path = TRANSIT_DIR / ASSET_ZIP
                self._set_status(f"[Info] Downloading {ASSET_ZIP} …", 5)

                def progress(pct: int):
                    self.pbar["value"] = pct

                res = self.api.download_with_progress(ASSET_URL, zip_path, progress_cb=progress)
                if not res.ok or not res.path:
                    raise RuntimeError(res.error or "download failed")
                digest = res.sha256 or sha256_file(zip_path)
                self._set_status(f"[Info] SHA-256: {digest}")
                if digest.lower() != ASSET_ZIP_SHA256.lower():
                    raise RuntimeError("SHA-256 mismatch. Refusing to extract.")
                self._set_status("[Info] Extracting …", 70)
                exe = self.api.extract_zip(zip_path, TRANSIT_DIR)
                self.codex_path.set(str(exe))
                self._set_status(f"[OK] Extracted to: {exe}", 90)
                self._set_status(f"[OK] Version: {self.api.codex_version(exe)}", 100)
            except Exception as e:
                self._set_status(f"[Error] {e}", 0)
                messagebox.showerror("Download error", str(e))
        threading.Thread(target=work, daemon=True).start()

    def _verify_binary(self):
        zp = TRANSIT_DIR / ASSET_ZIP
        if zp.exists():
            digest = sha256_file(zp)
            self._set_status(f"[Verify] SHA-256 of zip: {digest}")
            self._set_status(f"[Verify] Matches official zip: {digest.lower() == ASSET_ZIP_SHA256.lower()}")
        else:
            p = Path(self.codex_path.get().strip())
            if not p.exists():
                messagebox.showerror("Verify error", "Binary not found.")
                return
            digest = sha256_file(p)
            self._set_status(f"[Verify] SHA-256 of exe: {digest}")
            self._set_status("[Verify] Note: official checksum is for the .zip; exe hash differs.")

    def _check_version(self):
        p = Path(self.codex_path.get().strip())
        self._set_status(f"[Info] codex --version => {self.api.codex_version(p)}")

    def _refresh_models(self):
        def work():
            try:
                self._set_status("[Info] Checking Ollama…", 10)
                self.api.ensure_ollama()
                self._set_status("[Info] Listing local models…", 25)
                names = self.api.list_models()
                if not names:
                    raise RuntimeError("No local models found. Use `ollama pull <model>`.")
                ordered = self.api.shortlist(names)
                self.models = ordered
                self.model_combo["values"] = ordered
                if not self.model_var.get() and ordered:
                    self.model_var.set(ordered[0])
                self._set_status("[OK] Models updated.", 45)
            except Exception as e:
                self._set_status(f"[Error] {e}", 0)
                messagebox.showerror("Error", str(e))
        threading.Thread(target=work, daemon=True).start()

    def _write_config_only(self):
        def work():
            try:
                model = self.model_var.get().strip()
                if not model:
                    raise RuntimeError("Select a model.")
                self._set_status("[Info] Writing config…", 55)
                cfg = self.api.write_win_cfg(model)
                self._set_status(f"[OK] Config written: {cfg}", 70)
                write_install_manifest(model, Path(self.codex_path.get().strip()), self.api)
            except Exception as e:
                self._set_status(f"[Error] {e}", 0)
                messagebox.showerror("Error", str(e))
        threading.Thread(target=work, daemon=True).start()

    def _start_codex_cmd(self):
        def work():
            try:
                exe = Path(self.codex_path.get().strip())
                model = self.model_var.get().strip()
                if not model:
                    raise RuntimeError("Select a model.")
                self._set_status("[Info] Ensuring Ollama…", 10)
                self.api.ensure_ollama()
                self._set_status("[Info] Probing tools support…", 20)
                if not self.api.model_supports_tools(model):
                    self._set_status(f"[Warn] {model} lacks tools. Searching fallback…")
                    names = self.models or self.api.list_models()
                    model = self.api.auto_pick_tools_model(model, names)
                    self.model_var.set(model)
                    self._set_status(f"[OK] Using tools-capable model: {model}")
                self._set_status("[Info] Warming model…", 35)
                self.api.warm_model(model)
                self._set_status("[Info] Writing config…", 50)
                self.api.write_win_cfg(model)
                self._set_status("[Info] Ensuring binary…", 60)
                exe = self.api.ensure_release()
                self._set_status(f"[Info] codex --version => {self.api.codex_version(exe)}", 70)
                self._set_status("[Info] Launching Codex…", 80)
                self.api.launch_codex_console(exe, model, TRANSIT_DIR, open_in_cmd=True)
                write_install_manifest(model, exe, self.api)
                self._set_status("[OK] Codex launched. Use /status inside Codex.", 100)
            except Exception as e:
                self._set_status(f"[Error] {e}", 0)
                messagebox.showerror("Error", str(e))
        threading.Thread(target=work, daemon=True).start()

    def _start_with_terminal(self):
        def work():
            try:
                exe = Path(self.codex_path.get().strip())
                model = self.model_var.get().strip() or DEFAULT_MODEL
                self._set_status("[Info] Ensuring Ollama…", 10)
                self.api.ensure_ollama()
                names = self.models or self.api.list_models()
                model = self.api.auto_pick_tools_model(model, names)
                self._set_status("[Info] Warming model…", 35)
                self.api.warm_model(model)
                self._set_status("[Info] Writing config…", 50)
                self.api.write_win_cfg(model)
                self._set_status("[Info] Ensuring binary…", 60)
                exe = self.api.ensure_release()
                self._set_status("[Info] Launching Codex with bridge…", 80)
                self._proc, self._bridge = self.api.launch_codex_with_bridge(exe, model, TRANSIT_DIR)
                write_install_manifest(model, exe, self.api)
                # Visible CMD mirror and embedded terminal client
                self.api.launch_console_client(self._bridge.port, title="Codex Bridge")
                self.after(0, lambda: EmbeddedTerminal(self, "127.0.0.1", self._bridge.port))
                self._set_status(f"[OK] Bridge listening on 127.0.0.1:{self._bridge.port}", 100)
            except Exception as e:
                self._set_status(f"[Error] {e}", 0)
                messagebox.showerror("Error", str(e))
        threading.Thread(target=work, daemon=True).start()

    def _copy_manifest(self):
        def work():
            try:
                self._set_status("[Info] Ensuring binary and manifest…", 10)
                exe = self.api.ensure_release()
                self.api.verify_zip_if_present()
                model = self.model_var.get().strip() or DEFAULT_MODEL
                path = write_install_manifest(model, exe, self.api)
                txt = Path(path).read_text(encoding="utf-8")
                self.clipboard_clear()
                self.clipboard_append(txt)
                self.update()
                self._set_status(f"[OK] Manifest copied to clipboard: {path}", 100)
                messagebox.showinfo("Copied", f"INSTALL_MANIFEST.md copied to clipboard.\n\n{path}")
            except Exception as e:
                self._set_status(f"[Error] {e}", 0)
                messagebox.showerror("Error", str(e))
        threading.Thread(target=work, daemon=True).start()

    def _new_project(self):
        """Pick a folder and deploy a ready-to-run Codex bundle."""
        folder = filedialog.askdirectory(title="Select project folder to receive Codex bundle")
        if not folder:
            return
        target = Path(folder)
        def work():
            try:
                self._set_status("[Info] Preparing project bundle…", 10)
                self.api.ensure_ollama()
                names = self.api.list_models()
                if not names:
                    raise RuntimeError("No local models found. Use `ollama pull <model>`.")
                model = self.model_var.get().strip() or DEFAULT_MODEL
                model = self.api.auto_pick_tools_model(model, names)
                exe = self.api.ensure_release()
                bundle = self.api.create_project_package(target, model, exe)
                self._set_status(f"[OK] Bundle created: {bundle}", 100)
                messagebox.showinfo("Bundle created", f"Codex bundle created at:\n{bundle}\n\nRun start_codex.bat to launch.")
            except Exception as e:
                self._set_status(f"[Error] {e}", 0)
                messagebox.showerror("Error", str(e))
        threading.Thread(target=work, daemon=True).start()

# ========================= Automation (headless) =========================

def automation_flow_defaults(api: CodexBootstrap) -> None:
    print_step("[Info] Checking Ollama…")
    api.ensure_ollama()
    print_step("[Info] Listing local models…")
    models = api.list_models()
    if not models:
        raise RuntimeError("No local models found. Use `ollama pull <model>`.")

    requested = DEFAULT_MODEL if DEFAULT_MODEL in models else None
    ordered = api.shortlist(models)
    if requested is None:
        requested = choose_model_interactive(ordered)

    exe = api.ensure_release()
    api.verify_zip_if_present()
    print_step(f"[Info] codex --version => {api.codex_version(exe)}")

    model = api.auto_pick_tools_model(requested, models)
    print_step("[Info] Warming model…")
    api.warm_model(model)

    print_step("[Info] Writing config…")
    cfg = api.write_win_cfg(model)
    print_step(f"[OK] Config written: {cfg}")

    print_step("[Info] Launching Codex…")
    api.launch_codex_console(exe, model, TRANSIT_DIR, open_in_cmd=True)
    write_install_manifest(model, exe, api)
    print_step("[OK] Codex launched. In Codex run /status.")

def automation_flow_embedded(api: CodexBootstrap) -> None:
    """Headless path that starts bridge and opens a visible CMD client."""
    print_step("[Info] Checking Ollama…")
    api.ensure_ollama()
    print_step("[Info] Listing local models…")
    models = api.list_models()
    if not models:
        raise RuntimeError("No local models found. Use `ollama pull <model>`.")
    requested = DEFAULT_MODEL if DEFAULT_MODEL in models else None
    ordered = api.shortlist(models)
    if requested is None:
        requested = choose_model_interactive(ordered)
    exe = api.ensure_release()
    api.verify_zip_if_present()
    print_step(f"[Info] codex --version => {api.codex_version(exe)}")
    model = api.auto_pick_tools_model(requested, models)
    print_step("[Info] Warming model…")
    api.warm_model(model)
    print_step("[Info] Writing config…")
    api.write_win_cfg(model)
    print_step("[Info] Launching Codex with bridge…")
    proc, bridge = api.launch_codex_with_bridge(exe, model, TRANSIT_DIR)
    write_install_manifest(model, exe, api)
    api.launch_console_client(bridge.port, title="Codex Bridge")
    print_step(f"[OK] Bridge listening on 127.0.0.1:{bridge.port}")
    print_step("[Info] Connect via TCP or use the spawned CMD window to chat.")
    try:
        proc.wait()
    except KeyboardInterrupt:
        pass
    finally:
        bridge.close()

# ========================= Entry =========================

def main():
    # CLI flags:
    #   --configure            force settings GUI
    #   --defaults             headless default automation (visible CMD Codex)
    #   --embedded             headless + TCP bridge + visible CMD client
    #   --copy-manifest        create/update and copy manifest (ensures binary)
    #   --new-project PATH     deploy bundle to PATH
    api = CodexBootstrap()

    args = sys.argv[1:]
    if "--configure" in args:
        SettingsGUI(api).mainloop()
        return

    if "--new-project" in args:
        try:
            idx = args.index("--new-project")
            path = Path(args[idx + 1]).expanduser().resolve()
        except Exception:
            print_step("[Error] Provide a target path after --new-project")
            return
        api.ensure_ollama()
        names = api.list_models()
        if not names:
            raise RuntimeError("No local models found. Use `ollama pull <model>`.")
        requested = DEFAULT_MODEL if DEFAULT_MODEL in names else None
        if requested is None:
            requested = api.shortlist(names)[0]
        exe = api.ensure_release()
        model = api.auto_pick_tools_model(requested, names)
        bundle = api.create_project_package(path, model, exe)
        print_step(f"[OK] Bundle created at: {bundle}")
        return

    if "--defaults" in args:
        automation_flow_defaults(api)
        return

    if "--embedded" in args:
        automation_flow_embedded(api)
        return

    if "--copy-manifest" in args:
        exe = api.ensure_release()
        api.verify_zip_if_present()
        model = DEFAULT_MODEL
        path = write_install_manifest(model, exe, api)
        txt = Path(path).read_text(encoding="utf-8")
        try:
            r = tk.Tk(); r.withdraw()
            r.clipboard_clear(); r.clipboard_append(txt); r.update(); r.destroy()
            print_step(f"[OK] Manifest copied to clipboard: {path}")
        except Exception:
            print_step(f"[OK] Manifest written: {path} (clipboard unavailable)")
        return

    # Friendly popup for double-click users
    choice = first_popup(api)
    if choice == "configure":
        SettingsGUI(api).mainloop()
        return
    if choice == "defaults":
        automation_flow_defaults(api)
        return
    if choice == "embedded":
        # Run embedded flow and open an in-app terminal too
        try:
            # Prepare pieces as in automation_flow_embedded, but also show EmbeddedTerminal
            enable_dpi_awareness()
            root = tk.Tk(); root.withdraw()
            api.ensure_ollama()
            names = api.list_models()
            if not names:
                raise RuntimeError("No local models found. Use `ollama pull <model>`.")
            requested = DEFAULT_MODEL if DEFAULT_MODEL in names else api.shortlist(names)[0]
            exe = api.ensure_release()
            model = api.auto_pick_tools_model(requested, names)
            api.warm_model(model); api.write_win_cfg(model)
            proc, bridge = api.launch_codex_with_bridge(exe, model, TRANSIT_DIR)
            write_install_manifest(model, exe, api)
            api.launch_console_client(bridge.port, title="Codex Bridge")
            term = EmbeddedTerminal(root, "127.0.0.1", bridge.port)
            term.focus_force()
            root.deiconify()
            root.mainloop()
            try:
                proc.terminate()
            except Exception:
                pass
            bridge.close()
        except Exception as e:
            messagebox.showerror("Error", str(e))
        return
    if choice == "copy":
        try:
            exe = api.ensure_release()
            api.verify_zip_if_present()
            model = DEFAULT_MODEL
            path = write_install_manifest(model, exe, api)
            txt = Path(path).read_text(encoding="utf-8")
            r = tk.Tk(); r.withdraw()
            r.clipboard_clear(); r.clipboard_append(txt); r.update(); r.destroy()
            messagebox.showinfo("Copied", f"INSTALL_MANIFEST.md copied to clipboard.\n\n{path}")
        except Exception as e:
            messagebox.showerror("Error", str(e))
        return
    if choice == "new_project":
        # GUI folder picker then deploy the bundle
        try:
            r = tk.Tk(); r.withdraw()
            target = filedialog.askdirectory(title="Select project folder to receive Codex bundle", parent=r)
            r.destroy()
            if not target:
                print_step("[Info] No folder chosen.")
                return
            target_path = Path(target)
            api.ensure_ollama()
            names = api.list_models()
            if not names:
                raise RuntimeError("No local models found. Use `ollama pull <model>`.")
            requested = DEFAULT_MODEL if DEFAULT_MODEL in names else api.shortlist(names)[0]
            exe = api.ensure_release()
            model = api.auto_pick_tools_model(requested, names)
            bundle = api.create_project_package(target_path, model, exe)
            messagebox.showinfo("Bundle created", f"Codex bundle created at:\n{bundle}\n\nRun start_codex.bat to launch.")
        except Exception as e:
            messagebox.showerror("Error", str(e))
        return

    print_step("[Info] Cancelled by user.")

if __name__ == "__main__":
    main()
```

Codex Rust Starter — Portable Installer + Automated + Optional GUI + Bridge API + Project Packager + Embedded Terminal (Windows)

- Double-click friendly launcher with clear choices:
  [Change default settings]  [Launch with defaults]  [Launch with embedded terminal]  [Copy install manifest]  [Start Codex in New Project]  [Cancel]

- Portable: detects its own folder (expects to live inside "Codex-Installer", but runs anywhere). Creates all files relative to this script.
- Automates Codex rust-v0.34.0 download, checksum, extraction, config writing, Ollama detection, model probing, warm-up, and launch.
- Bridge: single Codex process launched headless with pipes. A TCP BridgeServer fans out stdout to multiple clients and forwards any client line to Codex stdin.
- Embedded Terminal: Tk window that shows Codex stdout live and lets you type lines; also spawns an optional visible CMD client that connects to the same bridge so you can minimize or use either.
- Manifest: INSTALL_MANIFEST.md explains A) using this file as an API and B) re-implementing from scratch using Ollama /api/tags (no static model snapshots).
- Project packager: deploy a ready-to-run Codex bundle into any project folder, with start_codex.bat, AGENTS.md, Repo_Snap.md, and a manifest.
- High-contrast rule: light text on dark backgrounds everywhere. No low-contrast pairings. Inline comments mark this requirement.

This single file has no external deps beyond the Python stdlib and Tkinter.
**Classes:** DownloadResult, CodexBootstrap, BridgeServer, EmbeddedTerminal, SettingsGUI
**Functions:** enable_dpi_awareness(), ensure_dirs(), sha256_file(p, chunk), http(url, method, payload, timeout), print_step(msg), render_repo_snapshot(root, max_depth), render_agents_md(model), write_install_manifest(selected_model, exe_path, cb, override_path), first_popup(api), choose_model_interactive(ordered_models), automation_flow_defaults(api), automation_flow_embedded(api), main()


## Module `Dev_Logic\Implemented_logic\Simple_Ollama_Terminal.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agent Virtual Desktop — Ollama Chat UI only (PySide6)
- Shell hooks exist but are not shown; they are background only.
- Visible UI: blue virtual desktop + centered chat card.
- Model dropdown auto-populates from local Ollama via HTTP (/api/tags), with CLI fallback (ollama list --json).
- Chat uses Ollama HTTP API (/api/chat) with streaming; cancelable mid-response.
- High-contrast enforced throughout. Never place similar-value colors together.

No external deps beyond PySide6 and stdlib.
Ollama must be installed and its local server running (default http://127.0.0.1:11434).
"""

from __future__ import annotations

import json
import os
import queue
import re
import shutil
import sys
import threading
import time
import traceback
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from urllib import request, error as urlerror

from PySide6.QtCore import (
    QPoint,
    QRect,
    QRectF,
    Qt,
    QTimer,
    Signal,
    Slot,
    QSize,
)
from PySide6.QtGui import (
    QAction,
    QCloseEvent,
    QColor,
    QFont,
    QGuiApplication,
    QKeySequence,
    QLinearGradient,
    QPainter,
    QPainterPath,
    QPalette,
    QTextCursor,
)
from PySide6.QtWidgets import (
    QApplication,
    QComboBox,
    QDialog,
    QFrame,
    QFileDialog,
    QGraphicsDropShadowEffect,
    QHBoxLayout,
    QLabel,
    QLineEdit,
    QMainWindow,
    QMessageBox,
    QPushButton,
    QSizePolicy,
    QTextBrowser,
    QTextEdit,
    QVBoxLayout,
    QWidget,
)

# ======================================================================================
# Crash capture — never let a traceback vanish
# ======================================================================================

class ErrorPopup(QDialog):
    def __init__(self, title: str, message: str, details: str, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.setWindowTitle(title)
        self.setModal(True)
        self.resize(900, 560)
        layout = QVBoxLayout(self)

        msg = QLabel(message, self)
        msg.setWordWrap(True)
        layout.addWidget(msg)

        self.details = QTextBrowser(self)
        self.details.setPlainText(details)
        self.details.setReadOnly(True)
        layout.addWidget(self.details, 1)

        btns = QHBoxLayout()
        copy_btn = QPushButton("Copy to Clipboard", self)
        copy_btn.clicked.connect(lambda: QApplication.clipboard().setText(self.details.toPlainText()))
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        btns.addStretch(1)
        btns.addWidget(copy_btn)
        btns.addWidget(close_btn)
        layout.addLayout(btns)

def install_global_exception_handler():
    def _hook(exc_type, exc, tb):
        text = "".join(traceback.format_exception(exc_type, exc, tb))
        dlg = ErrorPopup("Unhandled Error", "An unexpected error occurred.", text)
        dlg.setWindowModality(Qt.ApplicationModal)
        dlg.exec()
    sys.excepthook = _hook

# ======================================================================================
# Theme (high-contrast defaults). Text is always high-contrast vs background.
# ======================================================================================

@dataclass
class Theme:
    # Virtual desktop
    desktop_top: str = "#0f3b8e"       # deep blue
    desktop_mid: str = "#1c54cc"       # brighter blue
    desktop_edge_glow: str = "#4aa8ff" # cyan glow
    # Card
    card_bg: str = "#0e1624"
    card_border: str = "#2B3B4C"
    card_radius: int = 10
    shadow_rgba: Tuple[int, int, int, int] = (0, 30, 80, 180)
    # Header
    header_bg: str = "#111b2b"
    header_text: str = "#eaf2ff"
    # Chat text area
    term_bg: str = "#0f1a2d"
    term_fg: str = "#e6f0ff"
    term_border: str = "#2B3B4C"
    # Controls
    accent: str = "#1E5AFF"
    accent_hover: str = "#2f72ff"
    muted: str = "#1c2a3b"
    # Live indicator
    live_ok: str = "#00d17a"

    @classmethod
    def load(cls, path: str) -> "Theme":
        if os.path.isfile(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                base = cls()
                for k, v in data.items():
                    if hasattr(base, k):
                        setattr(base, k, v)
                return base
            except Exception:
                return cls()
        return cls()

# ======================================================================================
# Ollama client (HTTP first; CLI fallback)
# ======================================================================================

def _ollama_url(path: str) -> str:
    base = os.environ.get("OLLAMA_BASE_URL", "http://127.0.0.1:11434")
    return base.rstrip("/") + path

def ollama_http_get(path: str, timeout: float = 5.0) -> tuple[int, str]:
    url = _ollama_url(path)
    req = request.Request(url, method="GET")
    try:
        with request.urlopen(req, timeout=timeout) as resp:
            data = resp.read().decode("utf-8", errors="replace")
            return resp.getcode() or 200, data
    except urlerror.HTTPError as e:
        try:
            return e.code, e.read().decode("utf-8", errors="replace")
        except Exception:
            return e.code, str(e)
    except Exception as e:
        return 0, str(e)

def ollama_http_post_json(path: str, payload: dict, timeout: float = 60.0, stream: bool = True):
    """
    Streaming generator. Yields lines of text from Ollama's event stream.
    If stream=False, yields a single final JSON string.
    """
    url = _ollama_url(path)
    body = json.dumps(payload).encode("utf-8")
    headers = {"Content-Type": "application/json"}
    req = request.Request(url, data=body, headers=headers, method="POST")
    try:
        with request.urlopen(req, timeout=timeout) as resp:
            if not stream:
                yield resp.read().decode("utf-8", errors="replace")
                return
            # Stream lines
            while True:
                chunk = resp.readline()
                if not chunk:
                    break
                yield chunk.decode("utf-8", errors="replace")
    except Exception as e:
        yield json.dumps({"error": str(e)})

def list_local_models() -> List[str]:
    """
    Prefer HTTP /api/tags, fallback to `ollama list --json` parsing.
    Returns a list of model names present locally.
    """
    # HTTP path
    code, data = ollama_http_get("/api/tags", timeout=3.0)
    models: List[str] = []
    try:
        if code >= 200 and code < 300 and data:
            obj = json.loads(data)
            for m in obj.get("models", []) or []:
                name = m.get("name")
                if name:
                    models.append(name)
    except Exception:
        models = []

    if models:
        return sorted(set(models))

    # CLI fallback
    exe = shutil.which("ollama")
    if not exe:
        return []
    # `ollama list --json` outputs one JSON per line
    try:
        import subprocess
        p = subprocess.run([exe, "list", "--json"], capture_output=True, text=True, errors="replace")
        out = p.stdout or ""
        for line in out.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
                nm = obj.get("name")
                if nm:
                    models.append(nm)
            except Exception:
                # fallback: parse table if needed
                pass
    except Exception:
        return []

    # If still empty, try parsing table format
    if not models:
        try:
            import subprocess
            p = subprocess.run([exe, "list"], capture_output=True, text=True, errors="replace")
            out = p.stdout or ""
            for ln in out.splitlines():
                # naive parse: first column is name[:tag]
                m = re.match(r"^(\S+:\S+)", ln.strip())
                if m:
                    models.append(m.group(1))
        except Exception:
            return []

    return sorted(set(models))

def test_ollama_up() -> bool:
    code, _ = ollama_http_get("/api/version", timeout=2.0)
    return code >= 200 and code < 300

# ======================================================================================
# LIVE pill (pulsing)
# ======================================================================================

class LivePill(QWidget):
    def __init__(self, theme: Theme, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.theme = theme
        self._alpha = 1.0
        self.setFixedHeight(24)
        self._width = 96
        self.timer = QTimer(self)
        self.timer.timeout.connect(self._tick)
        self.timer.start(40)  # ~25fps

    def _tick(self):
        import math
        t = time.time() * 2.0
        self._alpha = 0.6 + 0.4 * (0.5 + 0.5 * math.sin(t))
        self.update()

    def sizeHint(self) -> QSize:
        return QSize(self._width, 24)

    def minimumSizeHint(self) -> QSize:
        return self.sizeHint()

    def paintEvent(self, e):
        p = QPainter(self)
        p.setRenderHint(QPainter.Antialiasing, True)
        rect = self.rect().adjusted(0, 0, -1, -1)

        bg = QColor("#1c2a3b")  # dark muted backdrop for contrast
        bg.setAlphaF(0.92)
        path = QPainterPath()
        path.addRoundedRect(QRectF(rect), 12, 12)
        p.fillPath(path, bg)

        p.setPen(QColor("#bcd5ff"))  # light text on dark bg = high-contrast
        font = p.font()
        font.setPointSizeF(9.5)
        font.setBold(True)
        p.setFont(font)

        text = "LIVE"
        metrics = p.fontMetrics()
        tw = metrics.horizontalAdvance(text)
        margin = 10
        dot_d = 8

        p.drawText(QRect(margin, 0, tw + 2, rect.height()), Qt.AlignVCenter | Qt.AlignLeft, text)

        dot_x = rect.right() - margin - dot_d
        dot_y = rect.center().y() - dot_d // 2
        live = QColor(self.theme.live_ok)
        live.setAlphaF(self._alpha)
        p.setBrush(live)
        p.setPen(Qt.NoPen)
        p.drawEllipse(QRect(dot_x, dot_y, dot_d, dot_d))

# ======================================================================================
# Ollama Chat Card (no shell UI; shells remain background-only hooks)
# ======================================================================================

class OllamaChatCard(QFrame):
    append_text_signal = Signal(str)
    set_ui_busy_signal = Signal(bool)
    set_model_list_signal = Signal(list)
    set_status_signal = Signal(str)

    def __init__(self, theme: Theme, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.theme = theme
        self.setObjectName("OllamaChatCard")
        self.setStyleSheet(self._qss(theme))

        shadow = QGraphicsDropShadowEffect(self)
        r, g, b, a = theme.shadow_rgba
        shadow.setColor(QColor(r, g, b, a))
        shadow.setBlurRadius(40)
        shadow.setOffset(0, 14)
        self.setGraphicsEffect(shadow)

        self._stop_stream = threading.Event()
        self._stream_thread: Optional[threading.Thread] = None
        self.messages: List[dict] = []  # conversation memory for /api/chat

        root = QVBoxLayout(self)
        root.setContentsMargins(0, 0, 0, 0)
        root.setSpacing(0)

        # Header
        header = QFrame(self)
        header.setObjectName("Header")
        hbox = QHBoxLayout(header)
        hbox.setContentsMargins(12, 8, 12, 8)
        hbox.setSpacing(8)

        self.title = QLabel("Ollama Chat", header)
        self.title.setObjectName("Title")
        hbox.addWidget(self.title)

        self.model_combo = QComboBox(header)
        self.model_combo.setObjectName("ModelCombo")
        self.model_combo.setMinimumWidth(260)
        hbox.addWidget(self.model_combo)

        self.refresh_btn = QPushButton("↻", header)
        self.refresh_btn.setObjectName("AccentBtn")
        self.refresh_btn.setToolTip("Refresh local models (Ollama)")
        self.refresh_btn.clicked.connect(self.refresh_models)
        hbox.addWidget(self.refresh_btn)

        hbox.addStretch(1)

        self.status_lbl = QLabel("", header)
        self.status_lbl.setObjectName("StatusLabel")
        hbox.addWidget(self.status_lbl)

        root.addWidget(header)

        # Transcript
        self.transcript = QTextBrowser(self)
        self.transcript.setObjectName("Transcript")
        self.transcript.setOpenExternalLinks(True)
        self.transcript.setLineWrapMode(QTextBrowser.WidgetWidth)
        root.addWidget(self.transcript, 1)

        # Input bar
        input_bar = QFrame(self)
        input_bar.setObjectName("InputBar")
        ibox = QHBoxLayout(input_bar)
        ibox.setContentsMargins(10, 10, 10, 10)
        ibox.setSpacing(8)

        self.input = QTextEdit(input_bar)
        self.input.setObjectName("Input")
        self._set_input_rows(self.input, rows=4)  # 4 lines tall
        self.input.setPlaceholderText("Type to chat with the selected local model…")
        ibox.addWidget(self.input, 1)

        controls = QVBoxLayout()
        self.send_btn = QPushButton("Send")
        self.send_btn.setObjectName("AccentBtn")
        self.send_btn.clicked.connect(self._on_send)
        controls.addWidget(self.send_btn)

        self.stop_btn = QPushButton("Stop")
        self.stop_btn.setObjectName("AccentBtn")
        self.stop_btn.clicked.connect(self._on_stop)
        self.stop_btn.setEnabled(False)
        controls.addWidget(self.stop_btn)

        self.clear_btn = QPushButton("New chat")
        self.clear_btn.setObjectName("AccentBtn")
        self.clear_btn.clicked.connect(self._on_clear)
        controls.addWidget(self.clear_btn)
        controls.addStretch(1)

        ibox.addLayout(controls)
        root.addWidget(input_bar)

        # Signals
        self.append_text_signal.connect(self._append_text)
        self.set_ui_busy_signal.connect(self._set_busy)
        self.set_model_list_signal.connect(self._fill_models)
        self.set_status_signal.connect(self._set_status)

        # Initial status + model population
        self._set_status("Checking Ollama…")
        self._async_refresh_models()

        # Add a starter system hint
        self._print_hint()

    # ---------------- UI helpers ----------------

    def _print_hint(self):
        hint = (
            "[Info] Models are discovered from your local Ollama.\n"
            "Select a model then Send to chat via the local API. Shell hooks are background only.\n"
        )
        self._append_text(hint)

    def _set_input_rows(self, edit: QTextEdit, rows: int = 4):
        font = edit.font()
        metrics = edit.fontMetrics()
        line_h = metrics.lineSpacing()
        pad = 16
        edit.setFixedHeight(line_h * rows + pad)

    @Slot(str)
    def _append_text(self, text: str):
        # High-contrast enforced by stylesheet colors
        cursor = self.transcript.textCursor()
        cursor.movePosition(QTextCursor.End)
        self.transcript.setTextCursor(cursor)
        self.transcript.insertPlainText(text)
        self.transcript.moveCursor(QTextCursor.End)

    @Slot(bool)
    def _set_busy(self, busy: bool):
        self.send_btn.setEnabled(not busy)
        self.stop_btn.setEnabled(busy)
        self.refresh_btn.setEnabled(not busy)
        self.model_combo.setEnabled(not busy)

    @Slot(list)
    def _fill_models(self, names: List[str]):
        self.model_combo.clear()
        for n in names:
            self.model_combo.addItem(n)
        if not names:
            self.model_combo.addItem("(no local models)")
        self._set_status(f"Models: {len(names)} found")

    @Slot(str)
    def _set_status(self, text: str):
        self.status_lbl.setText(text)

    # ---------------- Model refresh ----------------

    def refresh_models(self):
        self._async_refresh_models()

    def _async_refresh_models(self):
        def work():
            up = test_ollama_up()
            if not up:
                self.set_status_signal.emit("Ollama is not responding on 11434")
                self.set_model_list_signal.emit([])
                return
            names = list_local_models()
            self.set_model_list_signal.emit(names)
        t = threading.Thread(target=work, daemon=True)
        t.start()

    # ---------------- Chat ----------------

    @Slot()
    def _on_send(self):
        model = self.model_combo.currentText().strip()
        if not model or model == "(no local models)":
            self._append_text("[Error] No local model selected.\n")
            return
        content = self.input.toPlainText().strip()
        if not content:
            return
        self.input.clear()

        # Append user message to transcript and memory
        self._append_text(f"\n> You:\n{content}\n")
        self.messages.append({"role": "user", "content": content})

        # Start streaming thread
        self._stop_stream.clear()
        self.set_ui_busy_signal.emit(True)

        def stream_task():
            try:
                if not test_ollama_up():
                    self.append_text_signal.emit("[Error] Ollama is not reachable on 127.0.0.1:11434.\n")
                    return
                payload = {
                    "model": model,
                    "messages": self.messages,
                    "stream": True,
                }
                self.append_text_signal.emit("\n< Assistant:\n")
                buf = []
                for line in ollama_http_post_json("/api/chat", payload, timeout=0.5 * 60, stream=True):
                    if self._stop_stream.is_set():
                        break
                    if not line:
                        continue
                    # Each line should be a JSON dict: {"message":{"role":"assistant","content":"..."}, "done": false/true}
                    try:
                        ev = json.loads(line)
                    except Exception:
                        # some servers emit keep-alives or blank lines
                        continue
                    if "error" in ev:
                        self.append_text_signal.emit(f"[Error] {ev['error']}\n")
                        break
                    msg = ev.get("message") or {}
                    delta = msg.get("content") or ""
                    if delta:
                        buf.append(delta)
                        self.append_text_signal.emit(delta)
                    if ev.get("done"):
                        break
                # Save assistant message to history
                if buf:
                    self.messages.append({"role": "assistant", "content": "".join(buf)})
                self.append_text_signal.emit("\n")
            finally:
                self.set_ui_busy_signal.emit(False)

        self._stream_thread = threading.Thread(target=stream_task, daemon=True)
        self._stream_thread.start()

    @Slot()
    def _on_stop(self):
        self._stop_stream.set()

    @Slot()
    def _on_clear(self):
        self.messages.clear()
        self.transcript.clear()
        self._print_hint()

    # ---------------- Styling ----------------

    @staticmethod
    def _qss(t: Theme) -> str:
        # High-contrast rule: light text (#eaf2ff / #e6f0ff) on dark surfaces. Never low-contrast pairs.
        return f"""
        QFrame#OllamaChatCard {{
            background-color: {t.card_bg};
            border: 1px solid {t.card_border};
            border-radius: {t.card_radius}px;
        }}
        QFrame#Header {{
            background-color: {t.header_bg};
            border-top-left-radius: {t.card_radius}px;
            border-top-right-radius: {t.card_radius}px;
            border-bottom-left-radius: 0px;
            border-bottom-right-radius: 0px;
        }}
        QLabel#Title {{
            color: {t.header_text};
            font-weight: 600;
            letter-spacing: 0.5px;
        }}
        QLabel#StatusLabel {{
            color: #bcd5ff;
        }}
        QComboBox#ModelCombo {{
            background: #0c1524;
            color: {t.term_fg}; /* high-contrast text on dark */
            border: 1px solid {t.term_border};
            border-radius: 6px;
            padding: 4px 8px;
            min-height: 28px;
        }}
        QTextBrowser#Transcript {{
            background: {t.term_bg};
            color: {t.term_fg}; /* high-contrast */
            border-top: 1px solid {t.term_border};
            border-bottom: 1px solid {t.term_border};
            padding: 10px;
            font-family: Consolas, "Cascadia Code", "Fira Code", monospace;
            font-size: 12.5pt;
        }}
        QFrame#InputBar {{
            background-color: {t.card_bg};
            border-bottom-left-radius: {t.card_radius}px;
            border-bottom-right-radius: {t.card_radius}px;
        }}
        QTextEdit#Input {{
            background: #0c1524;
            color: {t.term_fg};
            border: 1px solid {t.term_border};
            border-radius: 6px;
            padding: 8px 10px;
            selection-background-color: {t.accent};
            selection-color: #ffffff; /* high-contrast selection */
        }}
        QPushButton#AccentBtn {{
            color: #ffffff;
            background-color: {t.accent};
            border: 1px solid {t.term_border};
            border-radius: 6px;
            padding: 6px 12px;
            min-width: 88px;
        }}
        QPushButton#AccentBtn:hover {{
            background-color: {t.accent_hover};
        }}
        QPushButton#AccentBtn:disabled {{
            background-color: #2a3a59;
            color: #9fb3d4;
        }}
        """

# ======================================================================================
# Virtual Desktop container (outer glow, gradient, vignette)
# ======================================================================================

class VirtualDesktop(QFrame):
    def __init__(self, theme: Theme, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.theme = theme
        self.setObjectName("VirtualDesktop")
        self.setAutoFillBackground(False)
        self.setContentsMargins(30, 30, 30, 30)

        self._card = OllamaChatCard(theme, self)

        layout = QVBoxLayout(self)
        layout.setContentsMargins(40, 40, 40, 18)
        layout.addStretch(1)

        mid_row = QHBoxLayout()
        mid_row.addStretch(1)
        self._card.setFixedWidth(900)
        self._card.setMinimumHeight(540)
        mid_row.addWidget(self._card, 0, Qt.AlignCenter)
        mid_row.addStretch(1)
        layout.addLayout(mid_row, 0)

        layout.addStretch(1)

        # Bottom live bar
        live_bar = QHBoxLayout()
        live_bar.setContentsMargins(0, 8, 6, 0)
        live_bar.addStretch(1)
        self.live = LivePill(theme, self)
        self.live.setFixedWidth(96)
        live_bar.addWidget(self.live, 0, Qt.AlignRight)
        layout.addLayout(live_bar)

    def chat(self) -> OllamaChatCard:
        return self._card

    def paintEvent(self, e):
        p = QPainter(self)
        p.setRenderHint(QPainter.Antialiasing, True)
        rect = self.rect()

        # Base vertical gradient
        grad = QLinearGradient(rect.topLeft(), rect.bottomLeft())
        grad.setColorAt(0.0, QColor(self.theme.desktop_top))
        grad.setColorAt(0.55, QColor(self.theme.desktop_mid))
        grad.setColorAt(1.0, QColor(self.theme.desktop_top))
        p.fillRect(rect, grad)

        # Edge cyan glow (inner stroke)
        glow = QColor(self.theme.desktop_edge_glow)
        glow.setAlphaF(0.18)
        p.setPen(glow)
        for i in range(20):
            r = rect.adjusted(10 + i, 10 + i, -10 - i, -10 - i)
            p.drawRoundedRect(r, 18, 18)

        # Vignette cutout
        vignette = QColor(0, 0, 0, 120)
        p.setPen(Qt.NoPen)
        p.setBrush(vignette)
        path = QPainterPath()
        path.addRect(rect)
        inner = rect.adjusted(30, 30, -30, -30)
        inner_path = QPainterPath()
        inner_path.addRoundedRect(QRectF(inner), 26, 26)
        path = path.subtracted(inner_path)
        p.drawPath(path)

# ======================================================================================
# Main window
# ======================================================================================

class MainWindow(QMainWindow):
    def __init__(self, theme: Theme):
        super().__init__()
        self.theme = theme
        self.setWindowTitle("Agent Virtual Desktop — Ollama")
        self.resize(1200, 720)

        pal = self.palette()
        pal.setColor(QPalette.Window, QColor("#0a1430"))
        pal.setColor(QPalette.Base, QColor("#0a1430"))
        pal.setColor(QPalette.Text, QColor("#e6f0ff"))
        pal.setColor(QPalette.WindowText, QColor("#e6f0ff"))
        self.setPalette(pal)

        self.desktop = VirtualDesktop(theme, self)
        self.setCentralWidget(self.desktop)

        self._init_menu()
        self._init_shortcuts()

    def _init_menu(self):
        bar = self.menuBar()

        file_menu = bar.addMenu("&File")

        open_styles = QAction("Load Styles JSON…", self)
        open_styles.triggered.connect(self._load_styles_json)
        file_menu.addAction(open_styles)

        file_menu.addSeparator()
        quit_act = QAction("Quit", self)
        quit_act.setShortcut(QKeySequence.Quit)
        quit_act.triggered.connect(self.close)
        file_menu.addAction(quit_act)

        view_menu = bar.addMenu("&View")
        self.fullscreen_act = QAction("Toggle Fullscreen (Alt+Enter)", self)
        self.fullscreen_act.setShortcut("Alt+Return")
        self.fullscreen_act.triggered.connect(self._toggle_fullscreen)
        view_menu.addAction(self.fullscreen_act)

        # Tools: minimal, Ollama only
        tools_menu = bar.addMenu("&Tools")
        refresh_models = QAction("Refresh Ollama Models", self)
        refresh_models.triggered.connect(self.desktop.chat().refresh_models)
        tools_menu.addAction(refresh_models)

        clear_chat = QAction("New Chat", self)
        clear_chat.triggered.connect(self.desktop.chat()._on_clear)
        tools_menu.addAction(clear_chat)

    def _init_shortcuts(self):
        # Ctrl+Enter to send
        send = QAction(self)
        send.setShortcut(QKeySequence("Ctrl+Return"))
        send.triggered.connect(self.desktop.chat()._on_send)
        self.addAction(send)

        # Alt+Enter to toggle fullscreen
        fs = QAction(self)
        fs.setShortcut(QKeySequence("Alt+Return"))
        fs.triggered.connect(self._toggle_fullscreen)
        self.addAction(fs)

    @Slot()
    def _toggle_fullscreen(self):
        if self.isFullScreen():
            self.showNormal()
        else:
            self.showFullScreen()

    @Slot()
    def _load_styles_json(self):
        path, _ = QFileDialog.getOpenFileName(self, "Select Styles JSON", os.getcwd(), "JSON Files (*.json)")
        if not path:
            return
        new_theme = Theme.load(path)
        self.theme = new_theme
        self.setCentralWidget(None)
        self.desktop = VirtualDesktop(self.theme, self)
        self.setCentralWidget(self.desktop)

    def closeEvent(self, event: QCloseEvent):
        try:
            self.desktop.chat()._on_stop()
        except Exception:
            pass
        return super().closeEvent(event)

# ======================================================================================
# App entry
# ======================================================================================

def locate_styles_json() -> str:
    here = os.path.dirname(os.path.abspath(__file__))
    candidates = [
        os.path.join(here, "Styles", "advanced_styles.json"),
        os.path.join(os.getcwd(), "Styles", "advanced_styles.json"),
    ]
    for c in candidates:
        if os.path.isfile(c):
            return c
    return ""

def main():
    install_global_exception_handler()

    # DPI rounding policy must be set before QApplication. Keeps crisp text.
    QGuiApplication.setHighDpiScaleFactorRoundingPolicy(
        Qt.HighDpiScaleFactorRoundingPolicy.PassThrough
    )
    os.environ.setdefault("QT_ENABLE_HIGHDPI_SCALING", "1")
    os.environ.setdefault("QT_SCALE_FACTOR_ROUNDING_POLICY", "PassThrough")

    app = QApplication(sys.argv)

    theme_json = locate_styles_json()
    theme = Theme.load(theme_json) if theme_json else Theme()

    win = MainWindow(theme)
    win.show()
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
```

Agent Virtual Desktop — Ollama Chat UI only (PySide6)
- Shell hooks exist but are not shown; they are background only.
- Visible UI: blue virtual desktop + centered chat card.
- Model dropdown auto-populates from local Ollama via HTTP (/api/tags), with CLI fallback (ollama list --json).
- Chat uses Ollama HTTP API (/api/chat) with streaming; cancelable mid-response.
- High-contrast enforced throughout. Never place similar-value colors together.

No external deps beyond PySide6 and stdlib.
Ollama must be installed and its local server running (default http://127.0.0.1:11434).
**Classes:** ErrorPopup, Theme, LivePill, OllamaChatCard, VirtualDesktop, MainWindow
**Functions:** install_global_exception_handler(), _ollama_url(path), ollama_http_get(path, timeout), ollama_http_post_json(path, payload, timeout, stream), list_local_models(), test_ollama_up(), locate_styles_json(), main()


## Module `Dev_Logic\Implemented_logic\simple_terminal.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Styles Container — Virtual Desktop + Floating Terminal (PySide6)
With CMD Bridge, external CMD show/hide, persistent settings, background health probe,
tri-state status LED, and transcript save in Settings.

High-contrast rule: Dark surfaces with bright text or vice versa. No low-contrast pairs.
All terminal content uses light text on dark background to maintain readability.

Requires: PySide6 (>= 6.6). External visible CMD control is Windows-only.
"""

from __future__ import annotations

import ctypes
import ctypes.wintypes as wt
import json
import os
import subprocess
import sys
import threading
import time
import traceback
import queue
from dataclasses import dataclass, asdict
from typing import Optional, Tuple, List

from PySide6.QtCore import (
    QEasingCurve,
    QPoint,
    QRect,
    QPropertyAnimation,
    QRectF,
    Qt,
    QTimer,
    Signal,
    Slot,
    QSize,
)
from PySide6.QtGui import (
    QAction,
    QCloseEvent,
    QColor,
    QFont,
    QIcon,
    QKeySequence,
    QPainter,
    QPalette,
    QGuiApplication,       # set DPI rounding policy before any QApplication instance
    QTextCursor,
    QLinearGradient,
    QPainterPath,          # needed by paintEvent
)
from PySide6.QtWidgets import (
    QApplication,
    QCheckBox,
    QDialog,
    QFrame,
    QGraphicsDropShadowEffect,
    QHBoxLayout,
    QLabel,
    QLineEdit,
    QMainWindow,
    QMenu,
    QMessageBox,
    QPushButton,
    QSizePolicy,
    QStyle,
    QTextBrowser,
    QVBoxLayout,
    QWidget,
    QWidget as Widget,     # alias to satisfy Optional[Widget] type hints
    QFileDialog,
)

# --------------------------------------------------------------------------------------
# High-DPI policy must be set before creating the QApplication instance.
# --------------------------------------------------------------------------------------
os.environ.setdefault("QT_ENABLE_HIGHDPI_SCALING", "1")
os.environ.setdefault("QT_SCALE_FACTOR_ROUNDING_POLICY", "PassThrough")
if QGuiApplication.instance() is None:
    QGuiApplication.setHighDpiScaleFactorRoundingPolicy(
        Qt.HighDpiScaleFactorRoundingPolicy.PassThrough
    )

# --------------------------------------------------------------------------------------
# Constants | Win32 flags and helpers
# --------------------------------------------------------------------------------------

IS_WINDOWS = (os.name == "nt")

# For external visible CMD:
CREATE_NEW_CONSOLE = 0x00000010
SW_HIDE = 0
SW_SHOWNORMAL = 1
SW_MINIMIZE = 6
SW_RESTORE = 9

# For hidden core CMD with no flashing window:
CREATE_NO_WINDOW = 0x08000000

# --------------------------------------------------------------------------------------
# Crash capture — never let a traceback vanish
# --------------------------------------------------------------------------------------

class ErrorPopup(QDialog):
    def __init__(self, title: str, message: str, details: str, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.setWindowTitle(title)
        self.setModal(True)
        self.resize(840, 520)
        layout = QVBoxLayout(self)

        msg = QLabel(message, self)
        msg.setWordWrap(True)
        layout.addWidget(msg)

        self.details = QTextBrowser(self)
        self.details.setPlainText(details)
        self.details.setReadOnly(True)
        layout.addWidget(self.details, 1)

        btns = QHBoxLayout()
        self.copy_btn = QPushButton("Copy to Clipboard", self)
        self.copy_btn.clicked.connect(self._copy)
        self.close_btn = QPushButton("Close", self)
        self.close_btn.clicked.connect(self.accept)
        btns.addStretch(1)
        btns.addWidget(self.copy_btn)
        btns.addWidget(self.close_btn)
        layout.addLayout(btns)

    @Slot()
    def _copy(self):
        QApplication.clipboard().setText(self.details.toPlainText())

def install_global_exception_handler():
    def _hook(exc_type, exc, tb):
        text = "".join(traceback.format_exception(exc_type, exc, tb))
        dlg = ErrorPopup("Unhandled Error", "An unexpected error occurred.", text)
        dlg.setWindowModality(Qt.ApplicationModal)
        dlg.exec()
    sys.excepthook = _hook

# --------------------------------------------------------------------------------------
# Settings (persisted JSON)
# --------------------------------------------------------------------------------------

@dataclass
class SettingsData:
    auto_start_bridge: bool = True
    show_external_cmd: bool = False     # toggle to show/minimize the external CMD
    send_delay_seconds: float = 0.2     # slight pacing to avoid jank
    remember_window_geometry: bool = True
    last_transcript_path: str = ""      # remember last save location

class SettingsManager:
    def __init__(self, path: str):
        self.path = path
        self.data = SettingsData()
        self._ensure_folder()

    def _ensure_folder(self):
        d = os.path.dirname(self.path)
        if d and not os.path.isdir(d):
            os.makedirs(d, exist_ok=True)

    def load(self):
        try:
            if os.path.isfile(self.path):
                with open(self.path, "r", encoding="utf-8") as f:
                    raw = json.load(f)
                # Merge with defaults to tolerate missing keys
                base = asdict(SettingsData())
                base.update(raw or {})
                self.data = SettingsData(**base)
        except Exception:
            self.data = SettingsData()

    def save(self):
        try:
            with open(self.path, "w", encoding="utf-8") as f:
                json.dump(asdict(self.data), f, indent=2)
        except Exception:
            pass

# --------------------------------------------------------------------------------------
# Theme loading (JSON override + strong defaults matching prior look)
# --------------------------------------------------------------------------------------

@dataclass
class Theme:
    # Virtual desktop (outer area)
    desktop_top: str = "#0f3b8e"
    desktop_mid: str = "#1c54cc"
    desktop_edge_glow: str = "#4aa8ff"
    desktop_noise_alpha: float = 0.10
    # Card / Terminal
    card_bg: str = "#0e1624"
    card_border: str = "#2B3B4C"
    card_radius: int = 10
    shadow_rgba: Tuple[int, int, int, int] = (0, 30, 80, 180)
    # Header
    header_bg: str = "#111b2b"
    header_text: str = "#eaf2ff"
    # Terminal text area
    term_bg: str = "#0f1a2d"
    term_fg: str = "#e6f0ff"   # High-contrast text on dark background.
    term_dim: str = "#9bb0c9"
    term_caret: str = "#1E5AFF"
    term_border: str = "#2B3B4C"
    # Controls
    accent: str = "#1E5AFF"
    accent_hover: str = "#2f72ff"
    muted: str = "#1c2a3b"
    # Live indicator
    live_ok: str = "#00d17a"
    live_dim: str = "#0b5c3f"
    live_warn: str = "#ffb300"
    live_err: str = "#ff3b30"

    @classmethod
    def load(cls, path: str) -> "Theme":
        if os.path.isfile(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                base = cls()
                for k, v in data.items():
                    if hasattr(base, k):
                        setattr(base, k, v)
                return base
            except Exception:
                return cls()
        return cls()

# --------------------------------------------------------------------------------------
# LIVE pill + Bridge LED
# --------------------------------------------------------------------------------------

class LivePill(QWidget):
    """Breathing 'LIVE' pill. Purely aesthetic."""
    def __init__(self, theme: Theme, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.theme = theme
        self._alpha = 1.0
        self.setFixedHeight(24)
        self._width = 96
        self.timer = QTimer(self)
        self.timer.timeout.connect(self._tick)
        self.timer.start(40)

    def _tick(self):
        import math
        t = time.time() * 2.0
        self._alpha = 0.6 + 0.4 * (0.5 + 0.5 * math.sin(t))
        self.update()

    def sizeHint(self) -> QSize:
        return QSize(self._width, 24)

    def minimumSizeHint(self) -> QSize:
        return self.sizeHint()

    def paintEvent(self, e):
        p = QPainter()
        if not p.begin(self):
            return
        try:
            p.setRenderHint(QPainter.Antialiasing, True)
            rect = self.rect().adjusted(0, 0, -1, -1)

            # Capsule background
            bg = QColor(self.theme.muted)
            bg.setAlphaF(0.90)
            path = QPainterPath()
            path.addRoundedRect(QRectF(rect), 12, 12)
            p.fillPath(path, bg)

            # Label + pulsing dot
            p.setPen(QColor("#bcd5ff"))
            font = p.font()
            font.setPointSizeF(9.5)
            font.setBold(True)
            p.setFont(font)
            text = "LIVE"
            metrics = p.fontMetrics()
            tw = metrics.horizontalAdvance(text)
            margin = 10
            dot_d = 8
            p.drawText(QRect(margin, 0, tw + 2, rect.height()), Qt.AlignVCenter | Qt.AlignLeft, text)

            dot_x = rect.right() - margin - dot_d
            dot_y = rect.center().y() - dot_d // 2
            live = QColor(self.theme.live_ok)
            live.setAlphaF(self._alpha)
            p.setPen(Qt.NoPen)
            p.setBrush(live)
            p.drawEllipse(QRect(dot_x, dot_y, dot_d, dot_d))
        finally:
            p.end()

class BridgeLED(QWidget):
    """
    Small round LED showing bridge status:
      green  = healthy I/O round-trip recently
      yellow = process running, awaiting confirmation
      red    = error
    """
    def __init__(self, theme: Theme, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.theme = theme
        self._state = "yellow"
        self.setFixedSize(14, 14)

    def set_state(self, state: str):
        self._state = state
        self.update()

    def paintEvent(self, e):
        p = QPainter()
        if not p.begin(self):
            return
        try:
            p.setRenderHint(QPainter.Antialiasing, True)
            rect = self.rect().adjusted(1, 1, -1, -1)
            color = QColor({
                "green": self.theme.live_ok,
                "yellow": self.theme.live_warn,
                "red": self.theme.live_err,
            }.get(self._state, self.theme.live_warn))
            p.setPen(Qt.NoPen)
            p.setBrush(color)
            p.drawEllipse(rect)
        finally:
            p.end()

# --------------------------------------------------------------------------------------
# CMD Bridge (core hidden cmd + optional visible external cmd)
# --------------------------------------------------------------------------------------

class CmdBridge:
    """
    Manages:
      - core_proc: hidden cmd.exe with pipes. Feeds GUI transcript. Primary target for input.
      - ext_proc : optional visible cmd.exe in its own console window. Also receives input.
    """
    def __init__(self, send_delay: float = 0.2):
        self.send_delay = max(0.0, float(send_delay))
        self.core_proc: Optional[subprocess.Popen] = None
        self.ext_proc: Optional[subprocess.Popen] = None
        self.core_reader: Optional[threading.Thread] = None
        self.core_kill = threading.Event()
        self.core_out_q: "queue.Queue[str]" = queue.Queue()
        self.health_lock = threading.Lock()
        self.healthy = False
        self.last_output_ts = 0.0

        # ext window handle cache
        self.ext_hwnd: Optional[int] = None
        self._ext_pid: Optional[int] = None

    # ---------------- Core (hidden) ----------------

    def start_core(self) -> None:
        if self.core_proc and self.core_proc.poll() is None:
            return
        try:
            self.core_proc = subprocess.Popen(
                ["cmd.exe"],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True,
                creationflags=CREATE_NO_WINDOW if IS_WINDOWS else 0,
            )
        except Exception as e:
            raise RuntimeError(f"Failed to start core CMD: {e}")

        self.core_kill.clear()
        self.core_reader = threading.Thread(target=self._core_reader_thread, daemon=True)
        self.core_reader.start()
        with self.health_lock:
            self.healthy = False
            self.last_output_ts = 0.0

    def stop_core(self) -> None:
        if not self.core_proc:
            return
        self.core_kill.set()
        try:
            if self.core_proc.stdin:
                self.core_proc.stdin.write("exit\r\n")
                self.core_proc.stdin.flush()
        except Exception:
            pass
        try:
            self.core_proc.terminate()
        except Exception:
            pass
        try:
            self.core_proc.wait(timeout=1.5)
        except Exception:
            try:
                self.core_proc.kill()
            except Exception:
                pass
        self.core_proc = None
        self.core_reader = None

    def _core_reader_thread(self):
        assert self.core_proc and self.core_proc.stdout
        for line in self.core_proc.stdout:
            if self.core_kill.is_set():
                break
            self.core_out_q.put(line.replace("\r\n", "\n"))
            with self.health_lock:
                self.last_output_ts = time.time()
        # drain any leftover
        try:
            rest = self.core_proc.stdout.read()
            if rest:
                self.core_out_q.put(rest.replace("\r\n", "\n"))
                with self.health_lock:
                    self.last_output_ts = time.time()
        except Exception:
            pass

    def read_core_lines_nowait(self) -> List[str]:
        lines: List[str] = []
        while True:
            try:
                lines.append(self.core_out_q.get_nowait())
            except Exception:
                break
        return lines

    def send_line(self, text: str) -> None:
        """Send a line to BOTH core and external cmd, with CRLF. Delay before writing."""
        time.sleep(self.send_delay)
        # core
        if self.core_proc and self.core_proc.poll() is None:
            try:
                if self.core_proc.stdin:
                    self.core_proc.stdin.write(text + "\r\n")
                    self.core_proc.stdin.flush()
            except Exception:
                with self.health_lock:
                    self.healthy = False
        # external (best effort)
        if self.ext_proc and self.ext_proc.poll() is None:
            try:
                if self.ext_proc.stdin:
                    self.ext_proc.stdin.write(text + "\r\n")
                    self.ext_proc.stdin.flush()
            except Exception:
                pass

    # ---------------- External (visible console) ----------------

    def start_external(self) -> None:
        if not IS_WINDOWS:
            raise RuntimeError("External CMD window is Windows-only.")
        if self.ext_proc and self.ext_proc.poll() is None:
            return
        try:
            # Provide a pipe for stdin so we can mirror input. Stdout goes to its console.
            self.ext_proc = subprocess.Popen(
                ["cmd.exe"],
                stdin=subprocess.PIPE,
                stdout=None,
                stderr=None,
                text=True,
                bufsize=1,
                creationflags=CREATE_NEW_CONSOLE,
            )
            self._ext_pid = self.ext_proc.pid
            # Find the console window handle shortly after start
            threading.Thread(target=self._find_ext_console_hwnd_later, daemon=True).start()
        except Exception as e:
            raise RuntimeError(f"Failed to start external CMD: {e}")

    def stop_external(self) -> None:
        if not self.ext_proc:
            return
        try:
            if self.ext_proc.stdin:
                self.ext_proc.stdin.write("exit\r\n")
                self.ext_proc.stdin.flush()
        except Exception:
            pass
        try:
            self.ext_proc.terminate()
        except Exception:
            pass
        try:
            self.ext_proc.wait(timeout=1.0)
        except Exception:
            try:
                self.ext_proc.kill()
            except Exception:
                pass
        self.ext_proc = None
        self.ext_hwnd = None
        self._ext_pid = None

    # -------- Win32 window show/hide for external console --------

    def _find_ext_console_hwnd_later(self):
        time.sleep(0.5)  # allow the window to appear
        self.ext_hwnd = self._find_hwnd_by_pid(self._ext_pid) if self._ext_pid else None

    @staticmethod
    def _find_hwnd_by_pid(pid: Optional[int]) -> Optional[int]:
        if not pid:
            return None
        user32 = ctypes.windll.user32

        EnumWindows = user32.EnumWindows
        EnumWindowsProc = ctypes.WINFUNCTYPE(ctypes.c_bool, wt.HWND, wt.LPARAM)
        GetWindowThreadProcessId = user32.GetWindowThreadProcessId
        IsWindowVisible = user32.IsWindowVisible
        GetClassNameW = user32.GetClassNameW

        result_hwnd = None

        def callback(hwnd, lParam):
            nonlocal result_hwnd
            if not IsWindowVisible(hwnd):
                return True
            _pid = wt.DWORD()
            GetWindowThreadProcessId(hwnd, ctypes.byref(_pid))
            if int(_pid.value) == pid:
                # console class name typically "ConsoleWindowClass" but accept any visible window
                result_hwnd = hwnd
                return False
            return True

        EnumWindows(EnumWindowsProc(callback), 0)
        return result_hwnd

    def show_external_window(self):
        if not self.ext_hwnd:
            self._find_ext_console_hwnd_later()
        if self.ext_hwnd:
            ctypes.windll.user32.ShowWindow(wt.HWND(self.ext_hwnd), SW_RESTORE)

    def hide_external_window(self):
        if self.ext_hwnd:
            ctypes.windll.user32.ShowWindow(wt.HWND(self.ext_hwnd), SW_MINIMIZE)

    # ---------------- Health ----------------

    def set_unhealthy(self):
        with self.health_lock:
            self.healthy = False

    def mark_healthy_if_recent_output(self, within_sec: float = 2.0) -> bool:
        with self.health_lock:
            ok = (time.time() - self.last_output_ts) <= within_sec
            self.healthy = ok
            return ok

# --------------------------------------------------------------------------------------
# Terminal card (Bridge controls + console)
# --------------------------------------------------------------------------------------

class TerminalCard(QFrame):
    append_text_signal = Signal(str)
    # state: True running, False stopped (core bridge)
    proc_state_signal = Signal(bool)
    led_state_signal = Signal(str)  # "green"/"yellow"/"red"

    def __init__(self, theme: Theme, settings: SettingsManager, parent: Optional[Widget] = None):
        super().__init__(parent)
        self.theme = theme
        self.settings = settings
        self.setObjectName("TerminalCard")
        self.setStyleSheet(self._qss(theme))

        shadow = QGraphicsDropShadowEffect(self)
        r, g, b, a = theme.shadow_rgba
        shadow.setColor(QColor(r, g, b, a))
        shadow.setBlurRadius(40)
        shadow.setOffset(0, 14)
        self.setGraphicsEffect(shadow)

        # Bridge
        self.bridge = CmdBridge(send_delay=self.settings.data.send_delay_seconds)
        self._poll_timer = QTimer(self)
        self._poll_timer.timeout.connect(self._poll_core_output)

        root = QVBoxLayout(self)
        root.setContentsMargins(0, 0, 0, 0)
        root.setSpacing(0)

        # Header
        header = QFrame(self)
        header.setObjectName("Header")
        hbox = QHBoxLayout(header)
        hbox.setContentsMargins(12, 8, 12, 8)
        hbox.setSpacing(8)

        self.title = QLabel("Terminal", header)
        self.title.setObjectName("Title")
        hbox.addWidget(self.title)

        # Bridge led + controls
        hbox.addStretch(1)

        self.led = BridgeLED(self.theme, header)
        hbox.addWidget(self.led, 0, Qt.AlignVCenter)

        self.bridge_chk = QCheckBox("Bridge Enabled", header)
        self.bridge_chk.setObjectName("BridgeChk")
        self.bridge_chk.setChecked(self.settings.data.auto_start_bridge)
        self.bridge_chk.toggled.connect(self._on_bridge_toggled)
        hbox.addWidget(self.bridge_chk)

        self.showcmd_chk = QCheckBox("Show CMD Window", header)
        self.showcmd_chk.setObjectName("ShowCmdChk")
        self.showcmd_chk.setChecked(self.settings.data.show_external_cmd)
        self.showcmd_chk.toggled.connect(self._on_showcmd_toggled)
        hbox.addWidget(self.showcmd_chk)

        self.start_btn = QPushButton("Start", header)
        self.start_btn.setObjectName("AccentBtn")
        self.start_btn.clicked.connect(self._start_shell)  # legacy start (bridged)
        hbox.addWidget(self.start_btn)

        self.stop_btn = QPushButton("Stop", header)
        self.stop_btn.setObjectName("AccentBtn")
        self.stop_btn.clicked.connect(self._stop_shell)
        self.stop_btn.setEnabled(False)
        hbox.addWidget(self.stop_btn)

        root.addWidget(header)

        # Console area — HIGH CONTRAST: light text on dark background.
        self.console = QTextBrowser(self)
        self.console.setObjectName("Console")
        self.console.setUndoRedoEnabled(False)
        self.console.setOpenExternalLinks(True)
        self.console.setLineWrapMode(QTextBrowser.NoWrap)
        root.addWidget(self.console, 1)

        # Input line
        input_bar = QFrame(self)
        input_bar.setObjectName("InputBar")
        ibox = QHBoxLayout(input_bar)
        ibox.setContentsMargins(10, 8, 10, 10)
        ibox.setSpacing(8)

        self.prompt_label = QLabel("›", input_bar)
        self.prompt_label.setObjectName("Prompt")
        ibox.addWidget(self.prompt_label)

        self.input = QLineEdit(input_bar)
        self.input.setObjectName("Input")
        self.input.setPlaceholderText("Type a command…  (Enter to send)")
        self.input.returnPressed.connect(self._on_enter)
        ibox.addWidget(self.input, 1)

        self.run_btn = QPushButton("Send", input_bar)
        self.run_btn.setObjectName("AccentBtn")
        self.run_btn.clicked.connect(self._on_enter)
        ibox.addWidget(self.run_btn)

        root.addWidget(input_bar)

        # Signals
        self.append_text_signal.connect(self._append_text)
        self.proc_state_signal.connect(self._update_state)
        self.led_state_signal.connect(self._set_led)

        # Initial message
        self._append_text("[Info] Ready. Bridge runs in the background. Use the header toggles.\n")

        # Auto start
        if self.settings.data.auto_start_bridge:
            self._start_bridge(auto_probe=True)
            if self.settings.data.show_external_cmd and IS_WINDOWS:
                self._start_external_cmd()

    # ---------------------- Public API hooks ----------------------

    def handle_nl_command(self, text: str) -> Optional[str]:
        return None

    # ---------------------- Shell process management (legacy entrypoints) ----------------------

    def _start_shell(self):
        self._start_bridge(auto_probe=False)

    def _stop_shell(self):
        self._stop_bridge()

    # ---------------------- Bridge lifecycle ----------------------

    def _start_bridge(self, auto_probe: bool):
        try:
            self.bridge.start_core()
            self._poll_timer.start(40)
            self.proc_state_signal.emit(True)
            self.led_state_signal.emit("yellow")  # running but unconfirmed
            self._append_text("[Info] Bridge core started.\n")
            if auto_probe:
                # Background proof-of-work: send "hello" silently.
                threading.Thread(target=self._background_probe, daemon=True).start()
        except Exception as e:
            self._append_text(f"[Error] Failed to start bridge: {e}\n")
            self.led_state_signal.emit("red")
            self.proc_state_signal.emit(False)

    def _stop_bridge(self):
        try:
            self._poll_timer.stop()
            self.bridge.stop_core()
            self.proc_state_signal.emit(False)
            self.led_state_signal.emit("red")
            self._append_text("[Info] Bridge core stopped.\n")
        except Exception as e:
            self._append_text(f"[Error] Failed to stop bridge: {e}\n")

    def _background_probe(self):
        try:
            time.sleep(self.settings.data.send_delay_seconds)
            self.bridge.send_line("hello")
            # LED flips to green on first output observed in _poll_core_output
        except Exception:
            self.led_state_signal.emit("red")

    # ---------------------- External CMD window ----------------------

    def _start_external_cmd(self):
        try:
            self.bridge.start_external()
            if self.settings.data.show_external_cmd:
                self.bridge.show_external_window()
            else:
                self.bridge.hide_external_window()
            self._append_text("[Info] External CMD started.\n")
        except Exception as e:
            self._append_text(f"[Error] Failed to start external CMD: {e}\n")

    def _stop_external_cmd(self):
        try:
            self.bridge.stop_external()
            self._append_text("[Info] External CMD stopped.\n")
        except Exception as e:
            self._append_text(f"[Error] Failed to stop external CMD: {e}\n")

    # ---------------------- I/O ----------------------

    @Slot()
    def _on_enter(self):
        text = self.input.text().strip()
        if not text:
            return
        nl = self.handle_nl_command(text)
        cmd = nl if nl else text
        self._append_text(f"> {cmd}\n")
        def worker():
            try:
                if not self.bridge.core_proc or self.bridge.core_proc.poll() is not None:
                    self.bridge.start_core()
                self.bridge.send_line(cmd)
            except Exception as e:
                self._append_text(f"[SendError] {e}\n")
                self.led_state_signal.emit("red")
        threading.Thread(target=worker, daemon=True).start()
        self.input.clear()

    def _poll_core_output(self):
        lines = self.bridge.read_core_lines_nowait()
        if lines:
            for ln in lines:
                self.append_text_signal.emit(ln)
            if self.bridge.mark_healthy_if_recent_output():
                self.led_state_signal.emit("green")
        # else: remain yellow if running but no output yet

    # ---------------------- UI helpers ----------------------

    @Slot(bool)
    def _update_state(self, running: bool):
        self.start_btn.setEnabled(not running)
        self.stop_btn.setEnabled(running)

    @Slot(str)
    def _set_led(self, state: str):
        self.led.set_state(state)

    @Slot(str)
    def _append_text(self, text: str):
        # HIGH CONTRAST: terminal text uses light fg on dark bg (see theme). Do not reduce contrast.
        cursor = self.console.textCursor()
        cursor.movePosition(QTextCursor.End)
        self.console.setTextCursor(cursor)
        self.console.insertPlainText(text)
        self.console.moveCursor(QTextCursor.End)

    # ---------------------- Toggles ----------------------

    @Slot(bool)
    def _on_bridge_toggled(self, checked: bool):
        self.settings.data.auto_start_bridge = checked
        self.settings.save()
        if checked:
            self._start_bridge(auto_probe=True)
        else:
            self._stop_bridge()

    @Slot(bool)
    def _on_showcmd_toggled(self, checked: bool):
        self.settings.data.show_external_cmd = checked
        self.settings.save()
        if not IS_WINDOWS:
            self._append_text("[Warn] External CMD window is Windows-only.\n")
            return
        if checked:
            if not self.bridge.ext_proc or self.bridge.ext_proc.poll() is not None:
                self._start_external_cmd()
            else:
                self.bridge.show_external_window()
        else:
            # Minimize instead of killing to honor hide/minimize request.
            self.bridge.hide_external_window()

    # ---------------------- Styling ----------------------

    @staticmethod
    def _qss(t: Theme) -> str:
        # HIGH CONTRAST RULE: Dark surfaces with bright text and clear borders. No low-contrast pairs.
        return f"""
        QFrame#TerminalCard {{
            background-color: {t.card_bg};
            border: 1px solid {t.card_border};
            border-radius: {t.card_radius}px;
        }}
        QFrame#Header {{
            background-color: {t.header_bg};
            border-top-left-radius: {t.card_radius}px;
            border-top-right-radius: {t.card_radius}px;
            border-bottom-left-radius: 0px;
            border-bottom-right-radius: 0px;
        }}
        QLabel#Title {{
            color: {t.header_text};
            font-weight: 600;
            letter-spacing: 0.5px;
        }}
        QTextBrowser#Console {{
            background: {t.term_bg};
            color: {t.term_fg};
            border-top: 1px solid {t.term_border};
            border-bottom: 1px solid {t.term_border};
            padding: 10px;
            font-family: Consolas, "Cascadia Code", "Fira Code", monospace;
            font-size: 12.5pt;
        }}
        QFrame#InputBar {{
            background-color: {t.card_bg};
            border-bottom-left-radius: {t.card_radius}px;
            border-bottom-right-radius: {t.card_radius}px;
        }}
        QLabel#Prompt {{
            color: {t.accent};
            font: 700 13pt "Cascadia Code";
            padding-left: 2px;
            padding-right: 6px;
        }}
        QLineEdit#Input {{
            background: #0c1524;
            color: {t.term_fg};
            border: 1px solid {t.term_border};
            border-radius: 6px;
            padding: 8px 10px;
            selection-background-color: {t.accent};
            selection-color: #ffffff;
        }}
        QPushButton#AccentBtn {{
            color: #ffffff;
            background-color: {t.accent};
            border: 1px solid {t.term_border};
            border-radius: 6px;
            padding: 6px 12px;
        }}
        QPushButton#AccentBtn:hover {{
            background-color: {t.accent_hover};
        }}
        QPushButton#AccentBtn:disabled {{
            background-color: #2a3a59;
            color: #9fb3d4;
        }}
        QCheckBox#BridgeChk, QCheckBox#ShowCmdChk {{
            color: {t.header_text};
        }}
        """

# --------------------------------------------------------------------------------------
# Virtual desktop container (outer glow, gradient, vignette)
# --------------------------------------------------------------------------------------

class VirtualDesktop(QFrame):
    def __init__(self, theme: Theme, settings: SettingsManager, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.theme = theme
        self.settings = settings
        self.setObjectName("VirtualDesktop")
        self.setAutoFillBackground(False)
        self.setContentsMargins(30, 30, 30, 30)

        self._card = TerminalCard(theme, settings, self)

        layout = QVBoxLayout(self)
        layout.setContentsMargins(40, 40, 40, 18)
        layout.addStretch(1)

        mid_row = QHBoxLayout()
        mid_row.addStretch(1)
        self._card.setFixedWidth(900)
        self._card.setMinimumHeight(480)
        mid_row.addWidget(self._card, 0, Qt.AlignCenter)
        mid_row.addStretch(1)
        layout.addLayout(mid_row, 0)

        layout.addStretch(1)

        # Bottom live bar
        live_bar = QHBoxLayout()
        live_bar.setContentsMargins(0, 8, 6, 0)
        live_bar.addStretch(1)
        self.live = LivePill(theme, self)
        self.live.setFixedWidth(96)
        live_bar.addWidget(self.live, 0, Qt.AlignRight)
        layout.addLayout(live_bar)

    def terminal(self) -> TerminalCard:
        return self._card

    def paintEvent(self, e):
        p = QPainter()
        if not p.begin(self):
            return
        try:
            p.setRenderHint(QPainter.Antialiasing, True)
            rect = self.rect()

            # Base vertical gradient
            grad = QLinearGradient(rect.topLeft(), rect.bottomLeft())
            grad.setColorAt(0.0, QColor(self.theme.desktop_top))
            grad.setColorAt(0.55, QColor(self.theme.desktop_mid))
            grad.setColorAt(1.0, QColor(self.theme.desktop_top))
            p.fillRect(rect, grad)

            # Edge cyan glow (inner stroke)
            glow = QColor(self.theme.desktop_edge_glow)
            glow.setAlphaF(0.18)
            p.setPen(glow)
            for i in range(20):
                r = rect.adjusted(10 + i, 10 + i, -10 - i, -10 - i)
                p.drawRoundedRect(r, 18, 18)

            # Vignette cutout
            vignette = QColor(0, 0, 0, 120)
            p.setPen(Qt.NoPen)
            p.setBrush(vignette)
            path = QPainterPath()
            path.addRect(rect)
            inner = rect.adjusted(30, 30, -30, -30)
            inner_path = QPainterPath()
            inner_path.addRoundedRect(QRectF(inner), 26, 26)
            path = path.subtracted(inner_path)
            p.drawPath(path)
        finally:
            p.end()

# --------------------------------------------------------------------------------------
# Main window + menus
# --------------------------------------------------------------------------------------

class MainWindow(QMainWindow):
    def __init__(self, theme: Theme, settings: SettingsManager):
        super().__init__()
        self.theme = theme
        self.settings = settings
        self.setWindowTitle("Agent Virtual Desktop")
        self.resize(1200, 720)

        pal = self.palette()
        # HIGH CONTRAST: bright text on dark chrome
        pal.setColor(QPalette.Window, QColor("#0a1430"))
        pal.setColor(QPalette.Base, QColor("#0a1430"))
        pal.setColor(QPalette.Text, QColor("#e6f0ff"))
        pal.setColor(QPalette.WindowText, QColor("#e6f0ff"))
        self.setPalette(pal)

        self.desktop = VirtualDesktop(theme, settings, self)
        self.setCentralWidget(self.desktop)

        self._init_menu()
        self._init_shortcuts()

        if self.settings.data.remember_window_geometry:
            self._restore_geometry()

    def _init_menu(self):
        bar = self.menuBar()

        file_menu = bar.addMenu("&File")
        open_styles = QAction("Load Styles JSON…", self)
        open_styles.triggered.connect(self._load_styles_json)
        file_menu.addAction(open_styles)
        file_menu.addSeparator()
        quit_act = QAction("Quit", self)
        quit_act.setShortcut(QKeySequence.Quit)
        quit_act.triggered.connect(self.close)
        file_menu.addAction(quit_act)

        view_menu = bar.addMenu("&View")
        self.fullscreen_act = QAction("Toggle Fullscreen (Alt+Enter)", self)
        self.fullscreen_act.setShortcut("Alt+Return")
        self.fullscreen_act.triggered.connect(self._toggle_fullscreen)
        view_menu.addAction(self.fullscreen_act)

        settings_menu = bar.addMenu("&Settings")
        # Save transcript moved here per request
        save_tx = QAction("Save Transcript…", self)
        save_tx.triggered.connect(self._save_transcript)
        settings_menu.addAction(save_tx)

        settings_menu.addSeparator()

        self.auto_start_act = QAction("Auto-start Bridge on Launch", self, checkable=True)
        self.auto_start_act.setChecked(self.settings.data.auto_start_bridge)
        self.auto_start_act.toggled.connect(self._toggle_auto_start)
        settings_menu.addAction(self.auto_start_act)

        self.show_cmd_act = QAction("Show External CMD Window", self, checkable=True)
        self.show_cmd_act.setChecked(self.settings.data.show_external_cmd)
        self.show_cmd_act.toggled.connect(self._toggle_show_cmd)
        settings_menu.addAction(self.show_cmd_act)

    def _init_shortcuts(self):
        # Ctrl+` to focus terminal input
        focus_term = QAction(self)
        focus_term.setShortcut(QKeySequence("Ctrl+`"))
        focus_term.triggered.connect(lambda: self.desktop.terminal().input.setFocus(Qt.ShortcutFocusReason))
        self.addAction(focus_term)

        # F5 / Shift+F5: start/stop bridge
        start = QAction(self)
        start.setShortcut(QKeySequence("F5"))
        start.triggered.connect(lambda: self.desktop.terminal()._start_bridge(auto_probe=False))
        self.addAction(start)

        stop = QAction(self)
        stop.setShortcut(QKeySequence("Shift+F5"))
        stop.triggered.connect(self.desktop.terminal()._stop_bridge)
        self.addAction(stop)

    # ---------------- Menu handlers ----------------

    @Slot()
    def _toggle_fullscreen(self):
        if self.isFullScreen():
            self.showNormal()
        else:
            self.showFullScreen()

    @Slot()
    def _load_styles_json(self):
        path, _ = QFileDialog.getOpenFileName(self, "Select Styles JSON", os.getcwd(), "JSON Files (*.json)")
        if not path:
            return
        new_theme = Theme.load(path)
        self.theme = new_theme
        self.setCentralWidget(None)
        self.desktop = VirtualDesktop(self.theme, self.settings, self)
        self.setCentralWidget(self.desktop)

    @Slot()
    def _save_transcript(self):
        # Delegate to terminal widget
        term = self.desktop.terminal()
        try:
            path, _ = QFileDialog.getSaveFileName(
                self,
                "Save transcript",
                self.settings.data.last_transcript_path or os.path.join(os.getcwd(), "transcript.txt"),
                "Text (*.txt);;Markdown (*.md);;All files (*.*)",
            )
            if not path:
                return
            data = term.console.toPlainText()
            with open(path, "w", encoding="utf-8", newline="\n") as f:
                f.write(data)
            self.settings.data.last_transcript_path = path
            self.settings.save()
            QMessageBox.information(self, "Saved", f"Transcript saved:\n{path}")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save transcript:\n{e}")

    @Slot(bool)
    def _toggle_auto_start(self, checked: bool):
        self.settings.data.auto_start_bridge = checked
        self.settings.save()
        self.desktop.terminal().bridge_chk.setChecked(checked)

    @Slot(bool)
    def _toggle_show_cmd(self, checked: bool):
        self.settings.data.show_external_cmd = checked
        self.settings.save()
        self.desktop.terminal().showcmd_chk.setChecked(checked)

    # ---------------- Geometry persistence ----------------

    def _restore_geometry(self):
        geom_path = os.path.join(_app_dir(), "Settings", "window_geom.json")
        try:
            with open(geom_path, "r", encoding="utf-8") as f:
                g = json.load(f)
            if isinstance(g, dict):
                x, y, w, h = g.get("x"), g.get("y"), g.get("w"), g.get("h")
                if all(isinstance(v, int) for v in (x, y, w, h)):
                    self.setGeometry(x, y, w, h)
        except Exception:
            pass

    def _save_geometry(self):
        geom_path = os.path.join(_app_dir(), "Settings", "window_geom.json")
        try:
            os.makedirs(os.path.dirname(geom_path), exist_ok=True)
            g = self.geometry()
            data = {"x": g.x(), "y": g.y(), "w": g.width(), "h": g.height()}
            with open(geom_path, "w", encoding="utf-8") as f:
                json.dump(data, f)
        except Exception:
            pass

    def closeEvent(self, event: QCloseEvent):
        try:
            self.desktop.terminal()._stop_external_cmd()
            self.desktop.terminal()._stop_bridge()
        except Exception:
            pass
        if self.settings.data.remember_window_geometry:
            self._save_geometry()
        return super().closeEvent(event)

# --------------------------------------------------------------------------------------
# App entry
# --------------------------------------------------------------------------------------

def _app_dir() -> str:
    return os.path.dirname(os.path.abspath(__file__))

def locate_styles_json() -> str:
    here = _app_dir()
    candidates = [
        os.path.join(here, "Styles", "advanced_styles.json"),
        os.path.join(os.getcwd(), "Styles", "advanced_styles.json"),
    ]
    for c in candidates:
        if os.path.isfile(c):
            return c
    return ""

def main():
    install_global_exception_handler()

    # Settings
    settings_path = os.path.join(_app_dir(), "Settings", "cmd_bridge_settings.json")
    settings = SettingsManager(settings_path)
    settings.load()

    app = QApplication.instance() or QApplication(sys.argv)

    theme_json = locate_styles_json()
    theme = Theme.load(theme_json) if theme_json else Theme()

    win = MainWindow(theme, settings)
    win.show()
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
```

Advanced Styles Container — Virtual Desktop + Floating Terminal (PySide6)
With CMD Bridge, external CMD show/hide, persistent settings, background health probe,
tri-state status LED, and transcript save in Settings.

High-contrast rule: Dark surfaces with bright text or vice versa. No low-contrast pairs.
All terminal content uses light text on dark background to maintain readability.

Requires: PySide6 (>= 6.6). External visible CMD control is Windows-only.
**Classes:** ErrorPopup, SettingsData, SettingsManager, Theme, LivePill, BridgeLED, CmdBridge, TerminalCard, VirtualDesktop, MainWindow
**Functions:** install_global_exception_handler(), _app_dir(), locate_styles_json(), main()


## Module `Dev_Logic\Implemented_logic\Virtual_Desktop.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Virtual_Desktop.py — Windows-style virtual desktop (contained), with Start panel and card window controls.

Directives satisfied:
- All former top toolbar actions moved into Start panel and Settings; no floating top bar.
- Start menu is a docked panel that rises from the taskbar and stays attached to the bottom.
- Window has standard minimize, maximize, close in the top-right (Qt title bar). Starts maximized with border.
- Each Card has its own Minimize, Max/Restore, Close buttons. Minimize hides to taskbar, restore via task button.
- Desktop edge trim removed. Background is clean blue gradient. High contrast enforced for text vs background.
- No drag-out to OS. No file URL clipboard exports. All dialogs non-native and modal to keep containment.
- Explorer and desktop icons support rename with extensions. Type/extension changes reflect immediately.
- Visual refreshes are immediate after file ops. QFileSystemWatcher also keeps UI current.
- Codex_Terminal.py can be launched from Start ▸ Apps ▸ Codex Terminal as an embedded card (factory supports embedded=True).  # See note re: citation in chat.

Notes:
- Contrast rule: inline comments and palettes ensure readable foreground/background in all states.
- Start panel includes: Apps (Explorer, Codex Terminal, Template Terminal), Recent, Settings, Power menu, Search.
- Settings panel collects previous toolbar utilities and view toggles.
"""

from __future__ import annotations

import os, sys, json, time, math, threading, subprocess, importlib.util, argparse, logging, traceback, ctypes, shutil, inspect, socket, difflib, zipfile
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Optional, List, Dict, Tuple, Callable, TYPE_CHECKING, Union, Sequence, Mapping, Iterable, Any
from pathlib import Path

from PySide6.QtCore import (
    Qt, QPoint, QRect, QRectF, QSize, QEvent, QTimer, Signal, Slot, QUrl, QMimeData,
    QFileSystemWatcher, QDateTime, QDir, QFileInfo
)
from PySide6.QtGui import (
    QColor, QGuiApplication, QPainter, QPainterPath, QLinearGradient, QPalette,
    QAction, QKeySequence, QClipboard, QCursor, QIcon, QPixmap, QFont, QResizeEvent,
    QWindowStateChangeEvent,
)
from PySide6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QScrollArea, QFrame, QLabel, QVBoxLayout,
    QHBoxLayout, QBoxLayout, QSizeGrip, QPushButton, QGraphicsDropShadowEffect, QMenuBar,
    QFileDialog, QPlainTextEdit, QMenu, QListWidget, QListWidgetItem, QStyle, QToolButton,
    QMessageBox, QInputDialog, QLineEdit, QDialog, QSplitter, QTextBrowser, QComboBox, QCheckBox,
    QStackedWidget, QGridLayout, QSizePolicy, QLayout, QTableWidget, QTableWidgetItem, QHeaderView,
    QDoubleSpinBox, QFileIconProvider
)

try:  # Optional Windows helpers for native icon conversion
    from PySide6.QtWinExtras import QtWin  # type: ignore
except Exception:  # pragma: no cover - QtWinExtras may be unavailable on non-Windows builds
    QtWin = None  # type: ignore

try:  # Optional plotting dependency
    import pyqtgraph as pg  # type: ignore
    from pyqtgraph import BarGraphItem
    from pyqtgraph.graphicsItems.DateAxisItem import DateAxisItem
except Exception:  # pragma: no cover - optional dependency may be unavailable
    pg = None
    BarGraphItem = None
    DateAxisItem = None

from error_center import ErrorCenterCard
from errors import ProcessErrorCard
from background import (
    BackgroundConfig,
    BackgroundFit,
    BackgroundManager,
    BackgroundMode,
    GifBg,
    GLViewportBg,
    StaticImageBg,
    VideoBg,
)
from metrics_manager import fetch_metrics
from tools.system_metrics import collect_metrics

try:  # Optional User-Guided Notes card factory
    import User_Guided_Notes as _user_guided_notes_module  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    _user_guided_notes_module = None
    _USER_GUIDED_NOTES_FACTORY = None
    _USER_GUIDED_NOTES_WINDOW_CLASS = None
    _USER_GUIDED_NOTES_WIDGET_CLASS = None
else:
    _USER_GUIDED_NOTES_FACTORY = getattr(_user_guided_notes_module, "build_widget", None)
    if not callable(_USER_GUIDED_NOTES_FACTORY):
        _USER_GUIDED_NOTES_FACTORY = getattr(_user_guided_notes_module, "create_card", None)
    if not callable(_USER_GUIDED_NOTES_FACTORY):
        _USER_GUIDED_NOTES_FACTORY = None
    _USER_GUIDED_NOTES_WINDOW_CLASS = getattr(_user_guided_notes_module, "UserGuidedNotesWindow", None)
    _USER_GUIDED_NOTES_WIDGET_CLASS = getattr(_user_guided_notes_module, "UserGuidedNotesWidget", None)

try:  # Optional task bus (absent when tasks module unavailable)
    from tasks.bus import subscribe as bus_subscribe, Subscription as BusSubscription  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    bus_subscribe = None
    BusSubscription = None  # type: ignore

# --------------------------------------------------------------------------------------
# Paths, logging & state
# --------------------------------------------------------------------------------------
SCRIPT_DIR = os.path.abspath(os.path.dirname(__file__))
STATE_PATH = os.path.join(SCRIPT_DIR, "vd_state.json")
LOG_PATH = os.path.join(SCRIPT_DIR, "system.log")
WORKSPACE_ROOT = os.environ.get("CODEX_WORKSPACE")
VDSK_ROOT = WORKSPACE_ROOT or os.path.join(SCRIPT_DIR, "Virtual_Desktop")
os.makedirs(VDSK_ROOT, exist_ok=True)

def workspace_root() -> str:
    return VDSK_ROOT

def _is_contained(path: str) -> bool:
    root = Path(VDSK_ROOT).resolve()
    try:
        resolved = Path(path).resolve()
    except Exception:
        return False
    return resolved == root or root in resolved.parents

def _safe_resolve(path_str: Optional[str]) -> Optional[str]:
    if not path_str:
        return None
    cleaned = path_str.strip().strip('"')
    if not cleaned:
        return None
    try:
        path = Path(cleaned).expanduser()
        if not path.exists():
            return None
        return str(path.resolve())
    except Exception:
        return None

def _build_allowlist() -> set[str]:
    entries: set[str] = set()
    for candidate in (
        sys.executable,
        os.environ.get("COMSPEC"),
        os.environ.get("SHELL"),
        shutil.which("python"),
        shutil.which("python3"),
        shutil.which("cmd"),
        shutil.which("cmd.exe"),
        shutil.which("powershell"),
        shutil.which("powershell.exe"),
        shutil.which("pwsh"),
        shutil.which("bash"),
        shutil.which("sh"),
    ):
        resolved = _safe_resolve(candidate)
        if resolved:
            entries.add(resolved)
    return entries

ALLOWLIST: set[str] = _build_allowlist()

BASE_CARD_WIDTH = 1100
BASE_CARD_HEIGHT = 700
MIN_CARD_WIDTH = 520
MIN_CARD_HEIGHT = 360
CARD_SCALE_MIN = 0.6
CARD_SCALE_MAX = 1.6

_FILE_ICON_PROVIDER: Optional["QFileIconProvider"]
try:
    _FILE_ICON_PROVIDER = QFileIconProvider()
except Exception:  # pragma: no cover - provider may be unavailable in headless environments
    _FILE_ICON_PROVIDER = None

if sys.platform.startswith("win"):
    from ctypes import wintypes  # type: ignore

    class _SHFILEINFOW(ctypes.Structure):  # pragma: no cover - Windows specific helper
        _fields_ = [
            ("hIcon", wintypes.HICON),
            ("iIcon", ctypes.c_int),
            ("dwAttributes", wintypes.DWORD),
            ("szDisplayName", ctypes.c_wchar * 260),
            ("szTypeName", ctypes.c_wchar * 80),
        ]

    _SHGFI_ICON = 0x000000100
    _SHGFI_LARGEICON = 0x000000000
    _SHGFI_SMALLICON = 0x000000001

    def _try_shell_icon(path: Path, large: bool = True) -> Optional[QIcon]:
        if QtWin is None:
            return None
        info = _SHFILEINFOW()
        flags = _SHGFI_ICON | (_SHGFI_LARGEICON if large else _SHGFI_SMALLICON)
        try:
            result = ctypes.windll.shell32.SHGetFileInfoW(  # type: ignore[attr-defined]
                str(path),
                0,
                ctypes.byref(info),
                ctypes.sizeof(info),
                flags,
            )
        except Exception:
            return None
        if not result or not info.hIcon:
            return None
        try:
            pixmap = QtWin.fromHICON(info.hIcon)  # type: ignore[attr-defined]
            if pixmap and not pixmap.isNull():
                return QIcon(pixmap)
        finally:
            try:
                ctypes.windll.user32.DestroyIcon(info.hIcon)  # type: ignore[attr-defined]
            except Exception:
                pass
        return None
else:

    def _try_shell_icon(path: Path, large: bool = True) -> Optional[QIcon]:  # pragma: no cover - non-Windows stub
        return None


def _try_provider_icon(path: Path) -> Optional[QIcon]:
    provider = _FILE_ICON_PROVIDER
    if not provider:
        return None
    try:
        info = QFileInfo(str(path))
        icon = provider.icon(info)
    except Exception:
        return None
    if icon and not icon.isNull():
        return icon
    return None


def _fallback_icon_for_path(path: Path) -> QIcon:
    style = QApplication.style()
    if path.exists() and path.is_dir():
        return style.standardIcon(QStyle.SP_DirIcon)
    ext = path.suffix.lower()
    if ext in {".txt", ".md", ".log", ".ini", ".cfg", ".json"}:
        return QIcon.fromTheme("text-x-generic") or style.standardIcon(QStyle.SP_FileIcon)
    if ext in {".png", ".jpg", ".jpeg", ".gif", ".bmp"}:
        return QIcon.fromTheme("image-x-generic") or style.standardIcon(QStyle.SP_FileIcon)
    if ext == ".py":
        return QIcon.fromTheme("text-x-python") or style.standardIcon(QStyle.SP_FileIcon)
    return style.standardIcon(QStyle.SP_FileIcon)


def _icon_for_path(path_like: os.PathLike[str] | str) -> Tuple[QIcon, bool]:
    path = Path(path_like)
    native = False
    icon: Optional[QIcon] = None
    if path.exists():
        icon = _try_provider_icon(path)
        if icon and not icon.isNull():
            native = True
        else:
            shell_icon = _try_shell_icon(path)
            if shell_icon and not shell_icon.isNull():
                icon = shell_icon
                native = True
    if not icon or icon.isNull():
        icon = _fallback_icon_for_path(path)
        native = False
    return icon, native

def _resolve_executable_path(cmd: List[str], cwd: Optional[str]) -> Optional[str]:
    if not cmd:
        return None
    first = cmd[0]
    resolved = _safe_resolve(first) if os.path.isabs(first) else None
    if resolved:
        return resolved
    search_path = None
    if cwd:
        try:
            candidate = Path(cwd).joinpath(first)
            candidate_resolved = candidate.resolve()
            if candidate_resolved.exists():
                return str(candidate_resolved)
        except Exception:
            pass
        try:
            resolved_cwd = Path(cwd).resolve()
            if resolved_cwd.exists():
                search_path = str(resolved_cwd)
        except Exception:
            search_path = None
    if search_path:
        located = shutil.which(first, path=search_path)
        if located:
            resolved = _safe_resolve(located)
            if resolved:
                return resolved
    located = shutil.which(first)
    if located:
        resolved = _safe_resolve(located)
        if resolved:
            return resolved
    return None

def _validate_process_request(cmd: List[str], cwd: Optional[str]) -> Tuple[bool, str]:
    if not cmd:
        return False, "Blocked: no command specified."
    resolved_cwd = os.path.abspath(cwd or VDSK_ROOT)
    if not os.path.isdir(resolved_cwd):
        return False, f"Blocked: working directory does not exist ({resolved_cwd})."
    if not _is_contained(resolved_cwd):
        return False, "Blocked: working directory is outside the Virtual Desktop workspace."
    exec_path = _resolve_executable_path(cmd, resolved_cwd)
    if not exec_path:
        return False, "Blocked: executable could not be resolved inside the workspace."
    if not (_is_contained(exec_path) or exec_path in ALLOWLIST):
        name = os.path.basename(exec_path) or exec_path
        return False, f"Blocked: {name} is outside the Virtual Desktop workspace."
    return True, exec_path

LOGGER = logging.getLogger("VirtualDesktop")
LOGGER.setLevel(logging.INFO)
if LOGGER.handlers:
    LOGGER.handlers.clear()
_fh = logging.FileHandler(LOG_PATH, mode="w", encoding="utf-8")
_fh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
LOGGER.addHandler(_fh)

def log(msg: str, level=logging.INFO):
    LOGGER.log(level, msg)

def _load_state() -> Dict:
    if os.path.isfile(STATE_PATH):
        try:
            with open(STATE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            log(f"state load failed: {e}", logging.WARNING)
    # defaults
    return {
        "recent": [],
        "geom": {},
        "icon_pos": {},
        "background": BackgroundConfig().to_state(),
        "icon_size": "medium",
        "desktop_sort": "name",
        "ui_scale": 1.0,
        "taskbar_autohide": False,
        "taskbar_side": "bottom",
        "allow_external_browse": False,
        "card_scale": 1.0,
    }

def _save_state(state: Dict):
    try:
        with open(STATE_PATH, "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2)
    except Exception as e:
        log(f"state save failed: {e}", logging.WARNING)

def _remember_card(kind: str, path: str, title: str):
    st = _load_state()
    st["recent"] = [r for r in st.get("recent", []) if r.get("path") != path or r.get("kind") != kind]
    st["recent"].insert(0, {"kind": kind, "path": path, "title": title, "ts": int(time.time())})
    st["recent"] = st["recent"][:24]
    _save_state(st)

def _geom_key_for(kind: str, persist_tag: str) -> str:
    return f"{kind}:{persist_tag}"


def _rect_to_dict(rect: QRect) -> Dict[str, int]:
    """Convert a QRect into a plain dict with integer coordinates."""
    return {
        "x": int(rect.x()),
        "y": int(rect.y()),
        "width": int(rect.width()),
        "height": int(rect.height()),
    }


def _widget_geometry_snapshot(widget: Optional[QWidget]) -> Dict[str, object]:
    """Return local/global geometry information for automation hooks."""
    if widget is None:
        return {}
    try:
        local = _rect_to_dict(widget.geometry())
    except Exception:
        local = {}
    try:
        top_left = widget.mapToGlobal(QPoint(0, 0))
        global_rect = QRect(top_left, widget.geometry().size())
        global_geom = _rect_to_dict(global_rect)
    except Exception:
        global_geom = dict(local)
    snapshot: Dict[str, object] = {
        "local": local,
        "global": global_geom,
        "visible": bool(widget.isVisible()),
        "objectName": widget.objectName() or "",
    }
    return snapshot


# --------------------------------------------------------------------------------------
# System metrics helpers (pure functions for card + tests)
# --------------------------------------------------------------------------------------
_RECENT_SECONDS = 24 * 3600
_SCORE_BUCKET_LABELS: Dict[str, str] = {
    "healthy": "Healthy (≥0.80)",
    "watch": "Watch (0.50–0.79)",
    "critical": "Critical (<0.50)",
    "unknown": "Unknown",
}
_LAST_RUN_LABELS: Dict[str, str] = {
    "recent": "Ran <24h ago",
    "stale": "Ran ≥24h ago",
    "never": "Never run",
}


def _script_type_label(path: str) -> str:
    if not path:
        return "Unknown"
    norm = str(path).replace("\\", "/")
    if norm.startswith("tests/"):
        return "Tests"
    if norm.startswith("tasks/"):
        return "Tasks"
    if norm.startswith("tools/"):
        return "Tools"
    if norm.endswith("Virtual_Desktop.py"):
        return "Desktop"
    if norm.endswith("Codex_Terminal.py"):
        return "Terminal"
    if norm.endswith(".py"):
        return "Python"
    return "Other"


def _score_from_error_count(error_count: Optional[Any]) -> float:
    try:
        errors = int(error_count or 0)
    except (TypeError, ValueError):
        errors = 0
    if errors <= 0:
        return 1.0
    return 1.0 / (1.0 + float(errors))


def _score_bucket_key(score: Optional[float]) -> str:
    if score is None:
        return "unknown"
    try:
        value = float(score)
    except (TypeError, ValueError):
        return "unknown"
    if value >= 0.8:
        return "healthy"
    if value >= 0.5:
        return "watch"
    return "critical"


def _last_run_bucket(last_run_ts: Optional[Any], *, now: Optional[float] = None) -> str:
    if last_run_ts in (None, ""):
        return "never"
    try:
        ts = float(last_run_ts)
    except (TypeError, ValueError):
        return "never"
    ref = float(now) if now is not None else time.time()
    delta = max(0.0, ref - ts)
    if delta <= _RECENT_SECONDS:
        return "recent"
    return "stale"


def _flatten_metrics_summary(
    summary: Mapping[str, Any] | None,
    *,
    now: Optional[float] = None,
) -> List[Dict[str, Any]]:
    if not summary:
        return []
    components = summary.get("components")
    if not isinstance(components, Mapping):
        return []
    rows: List[Dict[str, Any]] = []
    ref_now = float(now) if now is not None else float(summary.get("generated_at") or time.time())
    for component_name, component_data in components.items():
        if not isinstance(component_data, Mapping):
            continue
        scripts = component_data.get("scripts")
        if not isinstance(scripts, Mapping):
            continue
        for script_path, payload in scripts.items():
            if not isinstance(payload, Mapping):
                continue
            script_type = _script_type_label(str(script_path))
            line_count = payload.get("line_count")
            try:
                lines = int(line_count or 0)
            except (TypeError, ValueError):
                lines = 0
            errors = payload.get("error_count")
            try:
                err_count = int(errors or 0)
            except (TypeError, ValueError):
                err_count = 0
            last_modified = payload.get("last_modified")
            try:
                modified_ts = float(last_modified) if last_modified is not None else None
            except (TypeError, ValueError):
                modified_ts = None
            last_run_ts = payload.get("last_run_ts")
            try:
                last_run = float(last_run_ts) if last_run_ts is not None else None
            except (TypeError, ValueError):
                last_run = None
            score = _score_from_error_count(err_count)
            row = {
                "component": str(component_name),
                "script_path": str(script_path),
                "script_type": script_type,
                "line_count": lines,
                "error_count": err_count,
                "score": score,
                "score_bucket": _score_bucket_key(score),
                "last_modified": modified_ts,
                "last_run_ts": last_run,
                "last_run_bucket": _last_run_bucket(last_run, now=ref_now),
            }
            rows.append(row)
    rows.sort(key=lambda item: (item["component"], item["script_path"]))
    return rows


def _filter_metrics_rows(
    rows: Sequence[Mapping[str, Any]],
    *,
    script_type: str = "all",
    last_run: str = "any",
    score_bucket: str = "all",
) -> List[Dict[str, Any]]:
    filtered: List[Dict[str, Any]] = []
    type_key = (script_type or "all").strip()
    last_run_key = (last_run or "any").strip()
    score_key = (score_bucket or "all").strip()
    for row in rows:
        if not isinstance(row, Mapping):
            continue
        if type_key.lower() != "all" and row.get("script_type") != type_key:
            continue
        if last_run_key.lower() not in {"any", "all"} and row.get("last_run_bucket") != last_run_key:
            continue
        if score_key.lower() != "all" and row.get("score_bucket") != score_key:
            continue
        filtered.append(dict(row))
    return filtered


def _score_distribution(rows: Sequence[Mapping[str, Any]]) -> Dict[str, int]:
    counts = {key: 0 for key in _SCORE_BUCKET_LABELS.keys()}
    for row in rows:
        bucket = row.get("score_bucket", "unknown") if isinstance(row, Mapping) else "unknown"
        counts[bucket] = counts.get(bucket, 0) + 1
    return counts

# --------------------------------------------------------------------------------------
# Optional modules fallbacks
# --------------------------------------------------------------------------------------
def _fallback_build_editor_widget(parent=None, initial_path: Optional[str]=None, **_unused) -> QWidget:
    w = QWidget(parent)
    v = QVBoxLayout(w); v.setContentsMargins(10,10,10,10); v.setSpacing(8)
    lab = QLabel(f"Internal Code Viewer{f' — {os.path.basename(initial_path)}' if initial_path else ''}")
    lab.setStyleSheet("color:#eaf2ff; font:600 11pt 'Cascadia Code';")
    v.addWidget(lab)
    edit = QPlainTextEdit(w); edit.setReadOnly(True)
    # High-contrast palette: always set Base/Text with strong contrast
    p = edit.palette()
    bg = QColor("#0b1828"); fg = QColor("#d6e6ff")
    for g in (QPalette.Active, QPalette.Inactive, QPalette.Disabled):
        p.setColor(g, QPalette.Base, bg); p.setColor(g, QPalette.Text, fg)
        p.setColor(g, QPalette.Window, bg); p.setColor(g, QPalette.WindowText, fg)
        p.setColor(g, QPalette.Highlight, QColor("#264f78")); p.setColor(g, QPalette.HighlightedText, QColor("#ffffff"))
    edit.setPalette(p)
    edit.setStyleSheet("QPlainTextEdit{border:1px solid #213040; border-radius:10px; font-family:'Cascadia Code',Consolas,monospace;}")
    try:
        if initial_path and os.path.isfile(initial_path):
            with open(initial_path, "r", encoding="utf-8", errors="replace") as f:
                edit.setPlainText(f.read())
        else:
            edit.setPlainText("No file selected.")
    except Exception as ex:
        edit.setPlainText(f"[open failed] {ex}")
    v.addWidget(edit, 1)
    return w

try:
    from code_editor import build_widget as build_editor_widget  # type: ignore
except Exception:
    build_editor_widget = _fallback_build_editor_widget  # type: ignore

class _FallbackTaskManager:
    def __init__(self, dataset_path: str, workspace_root: Optional[str] = None):
        self.dataset_path = dataset_path
        self._workspace = workspace_root

    def set_workspace(self, workspace_root: Optional[str]) -> None:
        self._workspace = workspace_root

    def start_system_metrics_job(self, *_, **__) -> None:  # pragma: no cover - fallback no-op
        return

    def stop_system_metrics_job(self) -> None:  # pragma: no cover - fallback no-op
        return


def _fallback_open_card(*_args, **_kwargs):  # type: ignore[override]
    QMessageBox.information(None, "Tasks", "Tasks module not available.")
    return None


try:  # pragma: no cover - import guard for optional module
    from tasks.card import TaskManager, open_card  # type: ignore
except Exception:  # pragma: no cover - fallback to placeholder
    TaskManager = _FallbackTaskManager  # type: ignore
    open_card = _fallback_open_card  # type: ignore

from operator_manager import OperatorManagerWidget

if TYPE_CHECKING:  # pragma: no cover - typing helpers
    from tasks.card import TaskCard

# --------------------------------------------------------------------------------------
# Theme
# --------------------------------------------------------------------------------------
@dataclass
class Theme:
    desktop_top: str = "#0f3b8e"
    desktop_mid: str = "#1c54cc"
    edge_glow: str = "#1c54cc"  # kept same as mid but not drawn anymore
    card_bg: str = "#0c1320"
    card_border: str = "#213040"
    card_radius: int = 12
    header_bg: str = "#0a111e"
    header_fg: str = "#eaf2ff"
    text_muted: str = "#c7d5ee"
    text_body: str = "#e9f3ff"
    accent: str = "#1E5AFF"
    accent_hov: str = "#2f72ff"
    editor_bg: str = "#0b1828"
    editor_fg: str = "#d6e6ff"
    editor_sel: str = "#264f78"
    menu_bg: str = "#0a111e"
    menu_fg: str = "#eaf2ff"
    taskbar_bg: str = "#0f1722"
    taskbar_fg: str = "#eaf2ff"
    task_btn_bg: str = "#172532"
    task_btn_fg: str = "#eaf2ff"
    task_btn_hv: str = "#24374a"
    start_bg: str = "#0f2342"
    start_panel: str = "#0d1526"
    start_tile: str = "#13213a"
    start_hv: str = "#1b7fd3"

def apply_contrast_palette(w: QWidget, bg_hex: str, fg_hex: str):
    # High-contrast rule: set strong Base/Text for all states
    p = w.palette(); bg = QColor(bg_hex); fg = QColor(fg_hex)
    for group in (QPalette.Active, QPalette.Inactive, QPalette.Disabled):
        p.setColor(group, QPalette.Base, bg)
        p.setColor(group, QPalette.Text, fg)
        p.setColor(group, QPalette.Window, bg)
        p.setColor(group, QPalette.WindowText, fg)
        p.setColor(group, QPalette.Highlight, QColor("#2a5ea1"))
        p.setColor(group, QPalette.HighlightedText, QColor("#ffffff"))
    w.setPalette(p)

# --------------------------------------------------------------------------------------
# System Console (embedded log window)
# --------------------------------------------------------------------------------------
class SystemConsole(QWidget):
    def __init__(self, theme: Theme, log_path: str):
        super().__init__()
        self.setWindowTitle("System Console")
        self.resize(900, 560)
        self.t = theme
        self.log_path = log_path
        self._pos = 0
        v = QVBoxLayout(self); v.setContentsMargins(10,10,10,10); v.setSpacing(8)
        self.text = QPlainTextEdit(self); self.text.setReadOnly(True)
        apply_contrast_palette(self.text, theme.editor_bg, theme.editor_fg)
        self.text.setStyleSheet(
            f"QPlainTextEdit{{ background:{theme.editor_bg}; color:{theme.editor_fg}; "
            f"selection-background-color:{theme.editor_sel}; border:1px solid {theme.card_border}; "
            f"font-family:'Cascadia Code',Consolas,monospace; }}"
        )
        v.addWidget(self.text, 1)
        row = QHBoxLayout(); row.setSpacing(8)
        def mk_btn(lbl, fn):
            b = QPushButton(lbl); b.clicked.connect(fn)
            b.setStyleSheet(f"QPushButton{{color:#fff;background:{self.t.accent};border:1px solid {self.t.card_border};border-radius:6px;padding:6px 10px;}}"
                            f"QPushButton:hover{{background:{self.t.accent_hov};}}")
            return b
        row.addWidget(mk_btn("Refresh", self.refresh))
        row.addWidget(mk_btn("Clear", self.clear_log))
        row.addStretch(1)
        v.addLayout(row)
        self.timer = QTimer(self); self.timer.setInterval(800); self.timer.timeout.connect(self.refresh)
        self.timer.start()
        self.refresh(initial=True)
    def refresh(self, initial: bool=False):
        try:
            with open(self.log_path, "r", encoding="utf-8", errors="replace") as f:
                f.seek(self._pos)
                chunk = f.read()
                self._pos = f.tell()
            if initial: self.text.setPlainText(chunk)
            else:
                if chunk:
                    self.text.moveCursor(self.text.textCursor().End)
                    self.text.insertPlainText(chunk)
            self.text.moveCursor(self.text.textCursor().End)
        except Exception:
            pass
    def clear_log(self):
        try:
            with open(self.log_path, "w", encoding="utf-8"): pass
            self._pos = 0; self.text.setPlainText("")
        except Exception as e:
            log(f"log clear failed: {e}", logging.WARNING)

# --------------------------------------------------------------------------------------
# Template Terminal (Card How-To)
# --------------------------------------------------------------------------------------
_TEMPLATE_INSTRUCTIONS = """\
Template Terminal — Card How-To
===============================
A Card is a QWidget hosted by the Virtual Desktop. It can be a terminal, editor,
dashboard—anything with a Qt widget.

Load cards in two ways:
1) Verified Card (embedded): define create_card(parent)->QWidget|(QWidget,title) or build_widget(parent)
2) Process Console (fallback): if no factory, we run it as a subprocess and stream output.

Contrast rule: always set Base/Text colors for Active/Inactive/Disabled *or* style with QSS so
read-only and disabled text stays readable.
"""
_TEMPLATE_CODE = r'''# minimal_card.py — simple verified card (high-contrast)
from PySide6.QtWidgets import QWidget, QVBoxLayout, QLabel, QPushButton
from PySide6.QtGui import QPalette, QColor
from PySide6.QtCore import Qt
def _apply_palette(w, bg="#0b1828", fg="#e9f3ff"):
    p=w.palette(); bgc,fgc=QColor(bg),QColor(fg)
    for g in (QPalette.Active,QPalette.Inactive,QPalette.Disabled):
        p.setColor(g,QPalette.Base,bgc); p.setColor(g,QPalette.Text,fgc)
        p.setColor(g,QPalette.Window,bgc); p.setColor(g,QPalette.WindowText,fgc)
    w.setPalette(p)
def create_card(parent=None):
    w=QWidget(parent); _apply_palette(w)
    w.setStyleSheet("QLabel{color:#c7d5ee; font:600 11pt 'Cascadia Code';}"
                    "QPushButton{color:#fff; background:#1E5AFF; border:1px solid #213040; border-radius:6px; padding:6px 10px;}"
                    "QPushButton:hover{background:#2f72ff;}")
    lay=QVBoxLayout(w); lay.setContentsMargins(14,14,14,14); lay.setSpacing(8)
    title=QLabel('🧩 My Card'); title.setAlignment(Qt.AlignCenter)
    btn=QPushButton('Click Me'); lay.addWidget(title); lay.addWidget(btn)
    return w,"My First Card"
'''
class TemplateTerminal(QWidget):
    def __init__(self, theme: Theme):
        super().__init__()
        self.t = theme
        v = QVBoxLayout(self); v.setContentsMargins(12, 12, 12, 12); v.setSpacing(10)
        hdr = QLabel("Template Terminal — Card How-To ✨")
        hdr.setStyleSheet("color:#eaf2ff; font:700 12pt 'Cascadia Code';")
        v.addWidget(hdr)
        self.txt = QPlainTextEdit(self); self.txt.setReadOnly(True)
        self.txt.setPlainText(_TEMPLATE_INSTRUCTIONS)
        apply_contrast_palette(self.txt, theme.editor_bg, theme.editor_fg)
        self.txt.setStyleSheet(
            f"QPlainTextEdit{{ background:{theme.editor_bg}; color:{theme.editor_fg}; "
            f"selection-background-color:{theme.editor_sel}; border:1px solid {theme.card_border}; "
            f"font-family:'Cascadia Code',Consolas,monospace; }}"
        )
        v.addWidget(self.txt, 1)
        row = QHBoxLayout(); row.setSpacing(8)
        btn_copy_info = QPushButton("📋 Copy Instructions")
        btn_copy_tpl = QPushButton("📋 Copy Minimal Card Template")
        for b in (btn_copy_info, btn_copy_tpl):
            b.setStyleSheet(f"QPushButton{{color:#fff;background:{self.t.accent};border:1px solid {self.t.card_border};border-radius:6px;padding:6px 10px;}}"
                            f"QPushButton:hover{{background:{self.t.accent_hov};}}")
        btn_copy_info.clicked.connect(lambda: QApplication.clipboard().setText(_TEMPLATE_INSTRUCTIONS, QClipboard.Clipboard))
        btn_copy_tpl.clicked.connect(lambda: QApplication.clipboard().setText(_TEMPLATE_CODE, QClipboard.Clipboard))
        row.addWidget(btn_copy_info); row.addWidget(btn_copy_tpl); row.addStretch(1)
        v.addLayout(row)
        code_hdr = QLabel("🧪 Minimal Card (verified) — save as minimal_card.py then use Start ▸ Apps ▸ Load Script as Card…")
        code_hdr.setStyleSheet("color:#c7d5ee;")
        v.addWidget(code_hdr)
        self.code = QPlainTextEdit(self); self.code.setReadOnly(True)
        self.code.setPlainText(_TEMPLATE_CODE)
        apply_contrast_palette(self.code, theme.editor_bg, theme.editor_fg)
        self.code.setStyleSheet(
            f"QPlainTextEdit{{ background:{theme.editor_bg}; color:{theme.editor_fg}; "
            f"selection-background-color:{self.t.editor_sel}; border:1px solid {self.t.card_border}; "
            f"font-family:'Cascadia Code',Consolas,monospace; }}"
        )
        v.addWidget(self.code, 1)

# --------------------------------------------------------------------------------------
# Explorer (renames change extension; non-native dialogs to keep containment)
# --------------------------------------------------------------------------------------
def _non_native_open_files(parent, caption, start_dir, filt) -> Tuple[List[str], str]:
    dlg = QFileDialog(parent, caption, start_dir, filt)
    dlg.setOption(QFileDialog.DontUseNativeDialog, True)  # containment: no OS-native surfaces
    dlg.setFileMode(QFileDialog.ExistingFiles)
    if dlg.exec(): return dlg.selectedFiles(), dlg.selectedNameFilter()
    return [], ""

def _non_native_open_file(parent, caption, start_dir, filt) -> Tuple[str, str]:
    files, nf = _non_native_open_files(parent, caption, start_dir, filt)
    return (files[0] if files else ""), nf

def _non_native_open_dir(parent, caption, start_dir) -> str:
    dlg = QFileDialog(parent, caption, start_dir)
    dlg.setOption(QFileDialog.DontUseNativeDialog, True)
    dlg.setFileMode(QFileDialog.Directory)
    dlg.setOption(QFileDialog.ShowDirsOnly, True)
    return dlg.selectedFiles()[0] if dlg.exec() else ""

class ExplorerCard(QWidget):
    def __init__(self, root_path: str, open_cb: Callable[[str], None], theme: Theme, refresh_hook: Optional[Callable[[], None]] = None):
        super().__init__()
        self.root = root_path
        self.open_cb = open_cb
        self.t = theme
        self.refresh_hook = refresh_hook
        v = QVBoxLayout(self); v.setContentsMargins(10,10,10,10); v.setSpacing(8)
        hdr = QFrame(self); hdr.setStyleSheet(f"background:{self.t.header_bg}; border:1px solid {self.t.card_border}; border-radius:8px;")
        h = QHBoxLayout(hdr); h.setContentsMargins(8,6,8,6); h.setSpacing(8)
        self.lbl_path = QLabel(self.root); self.lbl_path.setStyleSheet(f"color:{self.t.header_fg}; font:600 10pt 'Cascadia Code';")
        btn_up = QPushButton("Up"); btn_new = QPushButton("New Folder"); btn_refresh = QPushButton("Refresh"); self.btn_view = QPushButton("List View")
        for b in (btn_up, btn_new, btn_refresh, self.btn_view):
            b.setStyleSheet(
                f"QPushButton{{color:#fff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:4px 10px;}}"
                f"QPushButton:hover{{background:{self.t.accent_hov};}}"
            )
        h.addWidget(self.lbl_path); h.addStretch(1); h.addWidget(self.btn_view); h.addWidget(btn_refresh); h.addWidget(btn_new); h.addWidget(btn_up)
        v.addWidget(hdr)
        self.list = QListWidget(self)
        self.list.setViewMode(QListWidget.IconMode)
        self.list.setIconSize(QSize(48,48))
        self.list.setResizeMode(QListWidget.Adjust)
        self.list.setMovement(QListWidget.Static)
        self.list.setSpacing(12)
        self.list.setStyleSheet(
            f"QListWidget{{ background:{self.t.editor_bg}; color:{self.t.editor_fg}; border:1px solid {self.t.card_border}; border-radius:10px; }}"
        )
        v.addWidget(self.list, 1)
        btn_up.clicked.connect(self._go_up)
        btn_new.clicked.connect(self._new_folder)
        btn_refresh.clicked.connect(self._refresh)
        self.btn_view.clicked.connect(self._toggle_view_mode)
        self.list.itemActivated.connect(self._open_item)
        self.list.setContextMenuPolicy(Qt.CustomContextMenu)
        self.list.customContextMenuRequested.connect(self._icon_context)
        self._cwd = self.root
        self._view_mode = "grid"
        self._thumb_cache: Dict[str, QIcon] = {}
        self._apply_view_mode()
        self._refresh()

    def _style_icon(self, path: str):
        st = QApplication.style()
        if os.path.isdir(path):
            return st.standardIcon(QStyle.SP_DirIcon)
        else:
            ext = Path(path).suffix.lower()
            if ext in {".py"}:
                return st.standardIcon(QStyle.SP_FileDialogDetailedView)
            if ext in {".png",".jpg",".jpeg",".gif",".bmp"}:
                return QIcon.fromTheme("image-x-generic") or st.standardIcon(QStyle.SP_FileIcon)
            if ext in {".txt",".md",".json",".log",".cfg",".ini"}:
                return QIcon.fromTheme("text-x-generic") or st.standardIcon(QStyle.SP_FileIcon)
            return st.standardIcon(QStyle.SP_FileIcon)

    def _apply_view_mode(self):
        if self._view_mode == "list":
            self.list.setViewMode(QListWidget.ListMode)
            self.list.setIconSize(QSize(96, 72))
            self.list.setSpacing(6)
            self.list.setWordWrap(True)
            self.btn_view.setText("Grid View")
        else:
            self.list.setViewMode(QListWidget.IconMode)
            self.list.setIconSize(QSize(64, 64))
            self.list.setSpacing(12)
            self.list.setWordWrap(False)
            self.btn_view.setText("List View")

    def _toggle_view_mode(self):
        self._view_mode = "list" if self._view_mode == "grid" else "grid"
        self._thumb_cache.clear()
        self._apply_view_mode()
        self._refresh()

    def _icon_for_path(self, path: str) -> QIcon:
        if os.path.isdir(path):
            return QApplication.style().standardIcon(QStyle.SP_DirIcon)
        if self._view_mode == "list":
            ext = Path(path).suffix.lower()
            if ext in {".png", ".jpg", ".jpeg", ".gif", ".bmp"}:
                cached = self._thumb_cache.get(path)
                if cached:
                    return cached
                pix = QPixmap(path)
                if not pix.isNull():
                    icon = QIcon(pix.scaled(self.list.iconSize(), Qt.KeepAspectRatio, Qt.SmoothTransformation))
                    self._thumb_cache[path] = icon
                    return icon
        return self._style_icon(path)

    def _refresh(self):
        self.list.clear()
        self.lbl_path.setText(self._cwd)
        try:
            ents = sorted(os.listdir(self._cwd), key=lambda s: s.lower())
        except Exception as e:
            log(f"Explorer list failed: {e}", logging.WARNING)
            ents = []
        if os.path.abspath(self._cwd) != os.path.abspath(self.root):
            it = QListWidgetItem("..")
            it.setIcon(QApplication.style().standardIcon(QStyle.SP_ArrowUp))
            it.setData(Qt.UserRole, os.path.abspath(os.path.join(self._cwd, "..")))
            self.list.addItem(it)
        for name in ents:
            full = os.path.join(self._cwd, name)
            it = QListWidgetItem(name)
            it.setIcon(self._icon_for_path(full))
            it.setData(Qt.UserRole, full)
            self.list.addItem(it)

    def _open_item(self, item: QListWidgetItem):
        path = item.data(Qt.UserRole)
        if not path: return
        if os.path.isdir(path):
            self._cwd = path; self._refresh()
        else:
            self.open_cb(path)

    def _go_up(self):
        if os.path.abspath(self._cwd) == os.path.abspath(self.root):
            return
        self._cwd = os.path.abspath(os.path.join(self._cwd, ".."))
        self._refresh()

    def _new_folder(self):
        base = os.path.join(self._cwd, "New Folder")
        name = base; i = 1
        while os.path.exists(name):
            name = f"{base} {i}"; i += 1
        try:
            os.makedirs(name, exist_ok=False)
            self._refresh()
            if self.refresh_hook: self.refresh_hook(); QApplication.processEvents()
        except Exception as e:
            log(f"mkdir failed: {e}", logging.WARNING)

    def _icon_context(self, pos: QPoint):
        item = self.list.itemAt(pos)
        if not item: return
        path = item.data(Qt.UserRole)
        if not path: return
        m = QMenu(self)
        act_open = m.addAction("Open")
        act_rename = m.addAction("Rename")
        act_delete = m.addAction("Delete")
        act_props = m.addAction("Properties")
        act = m.exec(self.list.mapToGlobal(pos))
        if act == act_open:
            self._open_item(item)
        elif act == act_rename:
            new_name, ok = QInputDialog.getText(self, "Rename", "New name (extensions allowed):", text=os.path.basename(path))
            if ok and new_name:
                try:
                    os.rename(path, os.path.join(self._cwd, new_name))
                    self._refresh()
                    if self.refresh_hook: self.refresh_hook(); QApplication.processEvents()
                except Exception as e:
                    QMessageBox.warning(self, "Rename", f"Rename failed: {e}")
        elif act == act_delete:
            try:
                if os.path.isdir(path): shutil.rmtree(path)
                else: os.remove(path)
                self._refresh()
                if self.refresh_hook: self.refresh_hook(); QApplication.processEvents()
            except Exception as e:
                QMessageBox.warning(self, "Delete", f"Delete failed: {e}")
        elif act == act_props:
            size = os.path.getsize(path) if os.path.isfile(path) else "Folder"
            QMessageBox.information(self, "Properties", f"Path: {path}\nSize: {size}")

# --------------------------------------------------------------------------------------
# Card with Min/Max/Close and taskbar integration
# --------------------------------------------------------------------------------------
class CardSizeGrip(QSizeGrip):
    """Custom size grip that directly resizes the owning :class:`Card`."""

    def __init__(self, card: "Card", corner: Qt.Corner):
        super().__init__(card)
        self._card = card
        self._corner = corner
        self._dragging = False
        self._press_pos = QPoint()
        self._start_geom = QRect()

    def _handles_left(self) -> bool:
        return self._corner in (Qt.TopLeftCorner, Qt.BottomLeftCorner)

    def _handles_right(self) -> bool:
        return self._corner in (Qt.TopRightCorner, Qt.BottomRightCorner)

    def _handles_top(self) -> bool:
        return self._corner in (Qt.TopLeftCorner, Qt.TopRightCorner)

    def _handles_bottom(self) -> bool:
        return self._corner in (Qt.BottomLeftCorner, Qt.BottomRightCorner)

    def mousePressEvent(self, event):
        if event.button() == Qt.LeftButton:
            if getattr(self._card, "_maximized", False):
                event.ignore()
                return
            self._dragging = True
            self._press_pos = event.globalPosition().toPoint()
            self._start_geom = QRect(self._card.geometry())
            self._card.raise_()
            self._card.activateWindow()
            event.accept()
            return
        super().mousePressEvent(event)

    def mouseMoveEvent(self, event):
        if not self._dragging:
            super().mouseMoveEvent(event)
            return
        if getattr(self._card, "_maximized", False):
            self._dragging = False
            event.ignore()
            return
        delta = event.globalPosition().toPoint() - self._press_pos
        dx = delta.x()
        dy = delta.y()
        geom = self._start_geom
        x, y, w, h = geom.x(), geom.y(), geom.width(), geom.height()

        if self._handles_left():
            x += dx
            w -= dx
        elif self._handles_right():
            w += dx

        if self._handles_top():
            y += dy
            h -= dy
        elif self._handles_bottom():
            h += dy

        min_w = max(self._card.minimumWidth(), MIN_CARD_WIDTH)
        min_h = max(self._card.minimumHeight(), MIN_CARD_HEIGHT)

        if w < min_w:
            if self._handles_left():
                x -= (min_w - w)
            w = min_w

        if h < min_h:
            if self._handles_top():
                y -= (min_h - h)
            h = min_h

        parent = self._card.parentWidget()
        margin = 6
        if parent:
            avail_w = max(min_w, parent.width() - margin * 2)
            avail_h = max(min_h, parent.height() - margin * 2)
            if w > avail_w:
                w = avail_w
                if self._handles_left():
                    x = margin
                else:
                    x = parent.width() - margin - w
            if h > avail_h:
                h = avail_h
                if self._handles_top():
                    y = margin
                else:
                    y = parent.height() - margin - h

            max_x = parent.width() - margin - w
            max_y = parent.height() - margin - h
            x = max(margin, min(x, max_x))
            y = max(margin, min(y, max_y))

        new_geom = QRect(x, y, w, h)
        if new_geom != self._card.geometry():
            self._card.setGeometry(new_geom)
        event.accept()

    def mouseReleaseEvent(self, event):
        if self._dragging and event.button() == Qt.LeftButton:
            self._dragging = False
            event.accept()
            return
        super().mouseReleaseEvent(event)


class Card(QFrame):
    moved = Signal()
    resized = Signal()
    closed = Signal(object)     # self on close
    minimized = Signal(object)  # self on minimize
    restored = Signal(object)   # self on restore

    def __init__(self, theme: Theme, title: str = "Card", parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.t = theme
        self._drag = False
        self._press = QPoint()
        self._persist_tag: Optional[str] = None
        self._maximized = False
        self._normal_geom = QRect(0,0,0,0)
        st = QApplication.style()
        self.task_profile = "card"
        self.task_icon = st.standardIcon(QStyle.SP_FileIcon)
        self.task_tooltip = title

        self.setObjectName("Card")
        self.setStyleSheet(
            f"#Card {{ background:{self.t.card_bg}; border:1px solid {self.t.card_border}; border-radius:{self.t.card_radius}px; }}"
        )
        sh = QGraphicsDropShadowEffect(self); sh.setColor(QColor(0, 30, 80, 150))
        sh.setBlurRadius(28); sh.setOffset(0, 12); self.setGraphicsEffect(sh)

        root = QVBoxLayout(self); root.setContentsMargins(0, 0, 0, 0); root.setSpacing(0)
        # Header
        self.header = QFrame(self); self.header.setObjectName("Hdr")
        self.header.setStyleSheet(
            f"#Hdr {{ background:{self.t.header_bg}; border-top-left-radius:{self.t.card_radius}px; "
            f"border-top-right-radius:{self.t.card_radius}px; }}"
            f"QLabel {{ color:{self.t.header_fg}; font:600 10.5pt 'Cascadia Code'; }}"
            f"QPushButton {{ color:#fff; background:{self.t.accent}; border:1px solid {self.t.card_border}; border-radius:6px; padding:3px 8px; }}"
            f"QPushButton:hover {{ background:{self.t.accent_hov}; }}"
        )
        H = QHBoxLayout(self.header); H.setContentsMargins(12, 8, 12, 6); H.setSpacing(8)
        self.title_label = QLabel(title, self.header)

        H.addWidget(self.title_label); H.addStretch(1)

        self.btn_min = QPushButton("—", self.header); self.btn_min.setFixedWidth(28)
        self.btn_max = QPushButton("▢", self.header); self.btn_max.setFixedWidth(28)
        self.close_btn = QPushButton("✕", self.header); self.close_btn.setFixedWidth(28)

        self.btn_min.clicked.connect(self._minimize_card)
        self.btn_max.clicked.connect(self._toggle_max_restore)
        self.close_btn.clicked.connect(self._close_card)

        for b in (self.btn_min, self.btn_max, self.close_btn):
            b.setCursor(Qt.PointingHandCursor)

        H.addWidget(self.btn_min); H.addWidget(self.btn_max); H.addWidget(self.close_btn)
        root.addWidget(self.header)

        # Body
        self.body = QFrame(self); self.body.setObjectName("Body")
        self.body.setStyleSheet(f"#Body {{ background:{self.t.card_bg}; }}")
        root.addWidget(self.body, 1)

        # Size grips
        corners = (
            Qt.BottomLeftCorner,
            Qt.BottomRightCorner,
            Qt.TopLeftCorner,
            Qt.TopRightCorner,
        )
        self._grips = [CardSizeGrip(self, corner) for corner in corners]
        for g in self._grips: g.setFixedSize(16, 16); g.raise_()

    def set_persist_tag(self, tag: str):
        self._persist_tag = tag

    def set_task_metadata(self, profile: Optional[str] = None, icon: Optional[QIcon] = None, tooltip: Optional[str] = None):
        if profile:
            self.task_profile = profile
        if icon is not None and not icon.isNull():
            self.task_icon = icon
        if tooltip:
            self.task_tooltip = tooltip

    def header_geom(self) -> QRect:
        return QRect(0, 0, self.width(), 44)

    def resizeEvent(self, e):
        w, h = self.width(), self.height(); m = 6; g = self._grips
        g[0].move(m, h - g[0].height() - m)
        g[1].move(w - g[1].width() - m, h - g[1].height() - m)
        g[2].move(m, m)
        g[3].move(w - g[3].width() - m, m)
        self.resized.emit()
        super().resizeEvent(e)

    def mousePressEvent(self, ev):
        if ev.button() == Qt.LeftButton and self.header_geom().contains(ev.position().toPoint()):
            self._drag = True; self._press = ev.position().toPoint()
            self.raise_(); self.activateWindow(); self.setFocus(Qt.ActiveWindowFocusReason)
            ev.accept()
        else:
            super().mousePressEvent(ev)

    def mouseMoveEvent(self, ev):
        if not self._drag:
            super().mouseMoveEvent(ev); return
        delta = ev.position().toPoint() - self._press
        new_pos = self.pos() + delta
        canvas = self.parentWidget()
        if canvas:
            r = canvas.rect()
            new_pos.setX(max(6, min(new_pos.x(), r.width() - self.width() - 6)))
            new_pos.setY(max(6, min(new_pos.y(), r.height() - self.height() - 6)))
        self.move(new_pos); ev.accept()

    def mouseReleaseEvent(self, ev):
        if self._drag:
            self._drag = False; self.moved.emit()
        super().mouseReleaseEvent(ev)

    def mouseDoubleClickEvent(self, ev):
        if ev.button() == Qt.LeftButton and self.header_geom().contains(ev.position().toPoint()):
            self._toggle_max_restore()
            ev.accept()
            return
        super().mouseDoubleClickEvent(ev)

    def contextMenuEvent(self, e):
        if not self.header_geom().contains(e.pos()): return
        menu = QMenu(self)
        act_min = menu.addAction("Minimize")
        act_max = menu.addAction("Maximize" if not self._maximized else "Restore")
        act_close = menu.addAction("Close")
        act = menu.exec(e.globalPos())
        if act == act_min: self._minimize_card()
        elif act == act_max: self._toggle_max_restore()
        elif act == act_close: self._close_card()

    def _minimize_card(self):
        self.hide()
        self.minimized.emit(self)

    def _toggle_max_restore(self):
        canvas = self.parentWidget()
        if not canvas: return
        if not self._maximized:
            self._normal_geom = QRect(self.x(), self.y(), self.width(), self.height())
            margin = 8
            insets = {"left": 0, "top": 0, "right": 0, "bottom": 0}
            parent_core = getattr(canvas, "parent", lambda: None)()
            if parent_core and hasattr(parent_core, "taskbar_insets"):
                try:
                    fetched = parent_core.taskbar_insets()
                    if isinstance(fetched, dict):
                        insets.update({k: int(max(0, v)) for k, v in fetched.items()})
                except Exception:
                    insets = {"left": 0, "top": 0, "right": 0, "bottom": 0}
            width = max(200, canvas.width() - insets["left"] - insets["right"] - 2 * margin)
            height = max(160, canvas.height() - insets["top"] - insets["bottom"] - 2 * margin)
            x = margin + insets["left"]
            y = margin + insets["top"]
            self.setGeometry(x, y, width, height)
            self._maximized = True
            self.btn_max.setText("❐")  # restore glyph
        else:
            if self._normal_geom.width() > 0:
                self.setGeometry(self._normal_geom)
            self._maximized = False
            self.btn_max.setText("▢")
        self.raise_(); self.activateWindow()
        self.restored.emit(self)

    def _close_card(self):
        try:
            self.closed.emit(self)
        finally:
            self.deleteLater()


# --------------------------------------------------------------------------------------
# System Overview card
# --------------------------------------------------------------------------------------
class SystemOverviewCard(Card):
    """Interactive dashboard presenting collected system metrics."""

    _DEFAULT_DB_NAME = "system_metrics.db"

    def __init__(
        self,
        theme: Theme,
        datasets_root: os.PathLike[str] | str,
        *,
        parent: Optional[QWidget] = None,
    ) -> None:
        super().__init__(theme, "System Overview", parent)
        self._datasets_root = Path(datasets_root)
        self._datasets_root.mkdir(parents=True, exist_ok=True)
        self._db_path = self._datasets_root / self._DEFAULT_DB_NAME
        self._rows: List[Dict[str, Any]] = []
        self._filtered_rows: List[Dict[str, Any]] = []
        self._history_by_script: Dict[str, List[Dict[str, Any]]] = {}
        self._summary_time: float = time.time()
        self._subscription: Optional[BusSubscription] = None
        self._building_filters = False

        self._build_body()
        self._subscribe_bus()
        QTimer.singleShot(0, self.refresh)

    # ------------------------------------------------------------------
    def _build_body(self) -> None:
        body_layout = QVBoxLayout(self.body)
        body_layout.setContentsMargins(16, 16, 16, 16)
        body_layout.setSpacing(12)

        stats_frame = QFrame(self.body)
        stats_frame.setObjectName("SystemStats")
        stats_frame.setStyleSheet(
            (
                "#SystemStats{background:#0a111e;border:1px solid #1d2b3c;border-radius:12px;}"
                "QLabel{color:#eaf2ff;font:600 10pt 'Segoe UI';}"
            )
        )
        stats_layout = QHBoxLayout(stats_frame)
        stats_layout.setContentsMargins(12, 10, 12, 10)
        stats_layout.setSpacing(18)

        self._components_label = QLabel("Components: 0", stats_frame)
        self._scripts_label = QLabel("Scripts: 0", stats_frame)
        self._score_label = QLabel("Average Score: 0.00", stats_frame)
        self._generated_label = QLabel("Generated: --", stats_frame)
        for label in (
            self._components_label,
            self._scripts_label,
            self._score_label,
            self._generated_label,
        ):
            stats_layout.addWidget(label)
        stats_layout.addStretch(1)
        body_layout.addWidget(stats_frame)

        filter_frame = QFrame(self.body)
        filter_frame.setObjectName("SystemFilters")
        filter_frame.setStyleSheet(
            (
                "#SystemFilters{background:#0a111e;border:1px solid #1d2b3c;border-radius:12px;}"
                "QComboBox{color:#eaf2ff;background:#122035;border:1px solid #1f2b3c;border-radius:8px;padding:4px 8px;}"
                "QPushButton{color:#ffffff;background:#1E5AFF;border:none;border-radius:8px;padding:6px 12px;}"
                "QPushButton:hover{background:#2f72ff;}"
            )
        )
        filter_layout = QHBoxLayout(filter_frame)
        filter_layout.setContentsMargins(12, 10, 12, 10)
        filter_layout.setSpacing(12)

        self.filter_type = QComboBox(filter_frame)
        self.filter_type.setMinimumWidth(180)
        self.filter_last_run = QComboBox(filter_frame)
        self.filter_last_run.setMinimumWidth(160)
        self.filter_score = QComboBox(filter_frame)
        self.filter_score.setMinimumWidth(180)
        self.refresh_button = QPushButton("Refresh", filter_frame)

        self._building_filters = True
        self.filter_type.addItem("All Script Types", "all")
        self.filter_last_run.addItem("Any Last Run", "any")
        for key, label in _LAST_RUN_LABELS.items():
            self.filter_last_run.addItem(label, key)
        self.filter_score.addItem("All Scores", "all")
        for key, label in _SCORE_BUCKET_LABELS.items():
            self.filter_score.addItem(label, key)
        self._building_filters = False

        filter_layout.addWidget(self.filter_type)
        filter_layout.addWidget(self.filter_last_run)
        filter_layout.addWidget(self.filter_score)
        filter_layout.addStretch(1)
        filter_layout.addWidget(self.refresh_button)
        body_layout.addWidget(filter_frame)

        splitter = QSplitter(Qt.Horizontal, self.body)
        splitter.setChildrenCollapsible(False)

        self.table = QTableWidget(0, 6, splitter)
        self.table.setObjectName("SystemTable")
        self.table.setHorizontalHeaderLabels(
            [
                "Script",
                "Component",
                "Type",
                "Last Run",
                "Errors",
                "Score",
            ]
        )
        header = self.table.horizontalHeader()
        header.setSectionResizeMode(0, QHeaderView.Stretch)
        header.setSectionResizeMode(1, QHeaderView.Stretch)
        for idx in range(2, 6):
            header.setSectionResizeMode(idx, QHeaderView.ResizeToContents)
        self.table.verticalHeader().setVisible(False)
        self.table.setAlternatingRowColors(True)
        self.table.setStyleSheet(
            (
                "QTableWidget{background:#0b1828;color:#eaf2ff;border:1px solid #1f2b3c;border-radius:10px;}"
                "QHeaderView::section{background:#122035;color:#d6e6ff;padding:6px;border:none;}"
                "QTableWidget::item:selected{background:#264f78;}"
            )
        )
        self.table.setSelectionBehavior(QTableWidget.SelectionBehavior.SelectRows)
        self.table.setSelectionMode(QTableWidget.SelectionMode.SingleSelection)
        splitter.addWidget(self.table)

        self._charts_container = QWidget(splitter)
        charts_layout = QVBoxLayout(self._charts_container)
        charts_layout.setContentsMargins(0, 0, 0, 0)
        charts_layout.setSpacing(12)

        distribution_label = QLabel("Score Distribution", self._charts_container)
        distribution_label.setStyleSheet("color:#eaf2ff;font:600 10pt 'Segoe UI';")
        charts_layout.addWidget(distribution_label)

        if pg and BarGraphItem is not None:
            self._distribution_plot = pg.PlotWidget(background=self.t.card_bg)
            self._distribution_plot.showGrid(y=True, alpha=0.2)
            charts_layout.addWidget(self._distribution_plot, 1)
        else:
            self._distribution_plot = None
            placeholder = QLabel(
                "PyQtGraph not available — install it to see charts.",
                self._charts_container,
            )
            placeholder.setAlignment(Qt.AlignCenter)
            placeholder.setStyleSheet("color:#9ab0d6;font:600 10pt 'Segoe UI';")
            charts_layout.addWidget(placeholder)

        history_label = QLabel("Score History", self._charts_container)
        history_label.setStyleSheet("color:#eaf2ff;font:600 10pt 'Segoe UI';")
        charts_layout.addWidget(history_label)

        if pg:
            axis_items = {"bottom": DateAxisItem(orientation="bottom")} if DateAxisItem else None
            self._history_plot = pg.PlotWidget(
                axisItems=axis_items,
                background=self.t.card_bg,
            )
            self._history_plot.setYRange(0, 1.05)
            self._history_plot.showGrid(y=True, alpha=0.2)
            charts_layout.addWidget(self._history_plot, 1)
        else:
            self._history_plot = None
            history_placeholder = QLabel(
                "Score history charts require pyqtgraph.",
                self._charts_container,
            )
            history_placeholder.setAlignment(Qt.AlignCenter)
            history_placeholder.setStyleSheet("color:#9ab0d6;font:600 10pt 'Segoe UI';")
            charts_layout.addWidget(history_placeholder)

        self._history_hint = QLabel("Select a script to view trend details.", self._charts_container)
        self._history_hint.setStyleSheet("color:#9ab0d6;font:500 9pt 'Segoe UI';")
        charts_layout.addWidget(self._history_hint)

        splitter.addWidget(self._charts_container)
        splitter.setStretchFactor(0, 3)
        splitter.setStretchFactor(1, 2)
        body_layout.addWidget(splitter, 1)

        self._status_label = QLabel("Collecting metrics…", self.body)
        self._status_label.setStyleSheet("color:#9ab0d6;font:500 9pt 'Segoe UI';")
        body_layout.addWidget(self._status_label)

        self.refresh_button.clicked.connect(lambda: self.refresh(store=True))
        self.filter_type.currentIndexChanged.connect(self._apply_filters)
        self.filter_last_run.currentIndexChanged.connect(self._apply_filters)
        self.filter_score.currentIndexChanged.connect(self._apply_filters)
        self.table.itemSelectionChanged.connect(self._handle_selection_changed)
        self.destroyed.connect(lambda *_: self._cleanup())

    # ------------------------------------------------------------------
    def _subscribe_bus(self) -> None:
        if bus_subscribe is None:
            return
        try:
            self._subscription = bus_subscribe("system.metrics", self._on_metrics_event)
        except Exception:
            log("SystemOverviewCard bus subscription failed", logging.DEBUG)

    # ------------------------------------------------------------------
    def _cleanup(self) -> None:
        if self._subscription is not None:
            try:
                self._subscription.unsubscribe()
            except Exception:
                pass
            finally:
                self._subscription = None

    # ------------------------------------------------------------------
    def _on_metrics_event(self, _payload: dict) -> None:  # pragma: no cover - callback bridge
        QTimer.singleShot(0, self.refresh)

    # ------------------------------------------------------------------
    def refresh(self, store: bool = False) -> None:
        self._status_label.setText("Refreshing metrics…")
        QApplication.processEvents()
        try:
            summary = collect_metrics(store=store, datasets_root=self._datasets_root)
        except Exception as exc:
            self._status_label.setText(f"Metrics refresh failed: {exc}")
            log(f"SystemOverviewCard refresh failed: {exc}", logging.DEBUG)
            return
        try:
            history = fetch_metrics(scope="local", db_paths={"local": str(self._db_path)})
        except Exception as exc:
            history = []
            log(f"Metrics history fetch failed: {exc}", logging.DEBUG)

        generated_at = float(summary.get("generated_at") or time.time()) if summary else time.time()
        self._summary_time = generated_at
        self._rows = _flatten_metrics_summary(summary, now=generated_at)
        self._group_history(history)
        self._update_filters()
        self._apply_filters()
        self._update_stats()
        self._status_label.setText(f"Last updated {self._format_timestamp(generated_at)}")

    # ------------------------------------------------------------------
    def _group_history(self, history: Iterable[Mapping[str, Any]]) -> None:
        grouped: Dict[str, List[Dict[str, Any]]] = {}
        for entry in history or []:
            if not isinstance(entry, Mapping):
                continue
            script = entry.get("script_path")
            if not script:
                continue
            grouped.setdefault(str(script), []).append(dict(entry))
        for values in grouped.values():
            values.sort(key=lambda item: float(item.get("timestamp") or 0.0))
        self._history_by_script = grouped

    # ------------------------------------------------------------------
    def _update_filters(self) -> None:
        self._building_filters = True
        current_type = self.filter_type.currentData()
        self.filter_type.clear()
        self.filter_type.addItem("All Script Types", "all")
        types = sorted({row.get("script_type", "Unknown") for row in self._rows})
        for label in types:
            self.filter_type.addItem(label, label)
        if current_type in {"all", *types}:
            index = self.filter_type.findData(current_type)
            if index >= 0:
                self.filter_type.setCurrentIndex(index)
        else:
            self.filter_type.setCurrentIndex(0)
        self._building_filters = False

    # ------------------------------------------------------------------
    def _apply_filters(self) -> None:
        if self._building_filters:
            return
        script_type = self.filter_type.currentData() or "all"
        last_run = self.filter_last_run.currentData() or "any"
        score_bucket = self.filter_score.currentData() or "all"
        filtered = _filter_metrics_rows(
            self._rows,
            script_type=script_type,
            last_run=last_run,
            score_bucket=score_bucket,
        )
        self._filtered_rows = filtered
        self._populate_table(filtered)
        self._update_distribution_chart(filtered if filtered else self._rows)
        if filtered:
            QTimer.singleShot(0, lambda: self._select_first_row())
        else:
            self._update_history_plot(None)

    # ------------------------------------------------------------------
    def _select_first_row(self) -> None:
        if self.table.rowCount() and not self.table.selectedItems():
            self.table.selectRow(0)

    # ------------------------------------------------------------------
    def _populate_table(self, rows: Sequence[Mapping[str, Any]]) -> None:
        self.table.setRowCount(len(rows))
        for idx, row in enumerate(rows):
            script_path = str(row.get("script_path", ""))
            component = str(row.get("component", ""))
            script_type = str(row.get("script_type", "Unknown"))
            last_run_text = self._format_last_run(row)
            errors = int(row.get("error_count") or 0)
            score = float(row.get("score") or 0.0)
            bucket = row.get("score_bucket", "unknown")
            score_label = _SCORE_BUCKET_LABELS.get(bucket, bucket.title())

            items = [
                QTableWidgetItem(script_path),
                QTableWidgetItem(component),
                QTableWidgetItem(script_type),
                QTableWidgetItem(last_run_text),
                QTableWidgetItem(str(errors)),
                QTableWidgetItem(f"{score:.2f} — {score_label}"),
            ]
            for col, item in enumerate(items):
                if col == 0:
                    item.setData(Qt.UserRole, script_path)
                item.setFlags(item.flags() & ~Qt.ItemIsEditable)
                self.table.setItem(idx, col, item)

    # ------------------------------------------------------------------
    def _format_last_run(self, row: Mapping[str, Any]) -> str:
        bucket = row.get("last_run_bucket")
        if bucket == "never":
            return _LAST_RUN_LABELS["never"]
        ts = row.get("last_run_ts")
        if ts in (None, ""):
            return _LAST_RUN_LABELS.get(str(bucket), "Unknown")
        try:
            timestamp = float(ts)
        except (TypeError, ValueError):
            return _LAST_RUN_LABELS.get(str(bucket), "Unknown")
        relative = self._relative_time(timestamp)
        dt = datetime.fromtimestamp(timestamp, tz=timezone.utc).astimezone()
        return f"{relative} ({dt.strftime('%Y-%m-%d %H:%M')})"

    # ------------------------------------------------------------------
    def _relative_time(self, timestamp: float) -> str:
        delta = max(0.0, self._summary_time - float(timestamp))
        if delta < 60:
            return "Just now"
        if delta < 3600:
            minutes = int(delta // 60)
            return f"{minutes}m ago"
        if delta < 86400:
            hours = int(delta // 3600)
            return f"{hours}h ago"
        days = int(delta // 86400)
        return f"{days}d ago"

    # ------------------------------------------------------------------
    def _update_stats(self) -> None:
        components = {row["component"] for row in self._rows}
        total_scripts = len(self._rows)
        avg_score = sum(row.get("score", 0.0) for row in self._rows)
        avg_value = (avg_score / total_scripts) if total_scripts else 0.0
        self._components_label.setText(f"Components: {len(components)}")
        self._scripts_label.setText(f"Scripts: {total_scripts}")
        self._score_label.setText(f"Average Score: {avg_value:.2f}")
        self._generated_label.setText(f"Generated: {self._format_timestamp(self._summary_time)}")

    # ------------------------------------------------------------------
    def _format_timestamp(self, ts: float) -> str:
        dt = datetime.fromtimestamp(ts, tz=timezone.utc).astimezone()
        return dt.strftime("%Y-%m-%d %H:%M")

    # ------------------------------------------------------------------
    def _handle_selection_changed(self) -> None:
        selected = self.table.selectedItems()
        if not selected:
            self._update_history_plot(None)
            return
        script_path = selected[0].data(Qt.UserRole)
        self._update_history_plot(script_path)

    # ------------------------------------------------------------------
    def _update_distribution_chart(self, rows: Sequence[Mapping[str, Any]]) -> None:
        if not pg or self._distribution_plot is None:
            return
        counts = _score_distribution(rows)
        self._distribution_plot.clear()
        keys = ["healthy", "watch", "critical", "unknown"]
        colors = {
            "healthy": "#1E5AFF",
            "watch": "#f2c744",
            "critical": "#ef5b68",
            "unknown": "#6b7a90",
        }
        ticks = []
        max_height = 1
        for idx, key in enumerate(keys):
            height = counts.get(key, 0)
            max_height = max(max_height, height)
            ticks.append((idx, _SCORE_BUCKET_LABELS.get(key, key.title())))
            if BarGraphItem is None:
                continue
            bar = BarGraphItem(
                x=[idx],
                height=[height],
                width=0.6,
                brush=pg.mkBrush(colors[key]),
                pen=pg.mkPen(colors[key]),
            )
            self._distribution_plot.addItem(bar)
        axis = self._distribution_plot.getAxis("bottom")
        if axis:
            axis.setTicks([ticks])
        self._distribution_plot.setYRange(0, max_height + 1)

    # ------------------------------------------------------------------
    def _update_history_plot(self, script_path: Optional[str]) -> None:
        if not pg or self._history_plot is None:
            return
        self._history_plot.clear()
        if not script_path:
            self._history_hint.setText("Select a script to view trend details.")
            return
        history = self._history_by_script.get(str(script_path), [])
        if not history:
            self._history_hint.setText("No historical scores recorded for this script yet.")
            return
        points = []
        for entry in history:
            try:
                ts = float(entry.get("timestamp"))
            except (TypeError, ValueError):
                continue
            score = entry.get("score")
            if score is None:
                continue
            try:
                val = float(score)
            except (TypeError, ValueError):
                continue
            points.append((ts, val))
        if not points:
            self._history_hint.setText("History available but contains no numeric scores.")
            return
        xs, ys = zip(*points)
        self._history_plot.plot(
            x=list(xs),
            y=list(ys),
            pen=pg.mkPen(self.t.accent, width=2),
            symbol="o",
            symbolBrush=pg.mkBrush(self.t.accent_hov),
        )
        self._history_hint.setText(str(script_path))

# --------------------------------------------------------------------------------------
# Desktop icons (no OS drag-out; internal only)
# --------------------------------------------------------------------------------------
class DesktopIcon(QToolButton):
    request_open = Signal(str)
    request_move_to_folder = Signal(str, str)  # src, dst_folder
    def __init__(self, theme: Theme, path: str, parent: QWidget, grid_size: Tuple[int, int]):
        super().__init__(parent)
        self.t = theme
        self.path = path
        self.grid_size = grid_size
        self.setAcceptDrops(False)  # containment: icons themselves do not accept external drops
        self.setAutoRaise(True)
        self.setToolButtonStyle(Qt.ToolButtonTextUnderIcon)
        self._set_icon_size_from_state()
        self.setCursor(Qt.OpenHandCursor)
        base = os.path.basename(path)
        self.setText(os.path.splitext(base)[0] if os.path.isfile(path) else base)
        self._resolved_icon: Optional[QIcon] = None
        self._resolved_icon_native: bool = False
        self._pick_icon()
        self._drag_active = False
        self._press_pos = QPoint()
        self._moved = False
        self.setStyleSheet("QToolButton{color:#eaf2ff;}")  # high-contrast text

    def _set_icon_size_from_state(self):
        st = _load_state()
        sz = st.get("icon_size", "medium")
        if sz == "small": self.setIconSize(QSize(32, 32))
        elif sz == "large": self.setIconSize(QSize(64, 64))
        else: self.setIconSize(QSize(48, 48))

    def _pick_icon(self):
        path = Path(self.path)
        icon, native = _icon_for_path(path)
        self._resolved_icon = icon
        self._resolved_icon_native = native
        self.setIcon(icon)

    def mousePressEvent(self, ev):
        if ev.button() == Qt.LeftButton:
            self.setCursor(Qt.ClosedHandCursor)
            self._drag_active = True
            self._press_pos = ev.position().toPoint()
            self._moved = False
        super().mousePressEvent(ev)

    def mouseMoveEvent(self, ev):
        if self._drag_active:
            delta = ev.position().toPoint() - self._press_pos
            if delta.manhattanLength() > 4:
                self._moved = True
                new_pos = self.pos() + delta
                parent_rect = self.parentWidget().rect()
                new_pos.setX(max(6, min(new_pos.x(), parent_rect.width() - self.width() - 6)))
                new_pos.setY(max(30, min(new_pos.y(), parent_rect.height() - self.height() - 30)))
                self.move(new_pos)
                self._press_pos = ev.position().toPoint()
        super().mouseMoveEvent(ev)

    def mouseReleaseEvent(self, ev):
        if self._drag_active:
            self.setCursor(Qt.OpenHandCursor)
            moved = self._moved
            self._drag_active = False
            self._moved = False
            if moved:
                # Snap to grid
                gx, gy = self.grid_size
                x = round(self.x() / gx) * gx
                y = round(self.y() / gy) * gy
                self.move(x, y)
                # Move into folder if dropped over a folder
                for sib in self.parentWidget().findChildren(DesktopIcon):
                    if sib != self and sib.geometry().contains(self.mapToParent(QPoint(0,0)) + self.rect().center()) and os.path.isdir(sib.path):
                        self.request_move_to_folder.emit(self.path, sib.path)
                        break
                self.parentWidget().save_icon_position(self.path, self.pos())
            else:
                self.request_open.emit(self.path)
        super().mouseReleaseEvent(ev)

    def mouseDoubleClickEvent(self, ev):
        if ev.button() == Qt.LeftButton: self.request_open.emit(self.path)

    # CONTAINMENT: removed any external clipboard or drag-out behavior

    def contextMenuEvent(self, e):
        m = QMenu(self)
        act_open = m.addAction("Open")
        act_rename = m.addAction("Rename")
        act_delete = m.addAction("Delete")
        act_props = m.addAction("Properties")
        act = m.exec(e.globalPos())
        if act == act_open:
            self.request_open.emit(self.path)
        elif act == act_rename:
            new_name, ok = QInputDialog.getText(self, "Rename", "New name (extensions allowed):", text=os.path.basename(self.path))
            if ok and new_name:
                try:
                    os.rename(self.path, os.path.join(os.path.dirname(self.path), new_name))
                    self.parentWidget()._refresh_icons()
                    QApplication.processEvents()
                except Exception as exc:
                    QMessageBox.warning(self, "Rename", f"Rename failed: {exc}")
        elif act == act_delete:
            try:
                os.remove(self.path) if os.path.isfile(self.path) else shutil.rmtree(self.path)
                self.parentWidget()._refresh_icons()
                QApplication.processEvents()
            except Exception as exc:
                QMessageBox.warning(self, "Delete", f"Delete failed: {exc}")
        elif act == act_props:
            size = os.path.getsize(self.path) if os.path.isfile(self.path) else sum(f.stat().st_size for f in Path(self.path).rglob('*') if f.is_file())
            QMessageBox.information(self, "Properties", f"Path: {self.path}\nSize: {size} bytes")

# --------------------------------------------------------------------------------------
# Desktop canvas
# --------------------------------------------------------------------------------------
class DesktopCanvas(QWidget):
    def __init__(self, theme: Theme, size: QSize, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.t = theme
        self.resize(size)
        self.setAcceptDrops(False)  # CONTAINMENT: do not accept OS drops
        self._icons: Dict[str, DesktopIcon] = {}
        self._fswatcher = QFileSystemWatcher(self)
        self._fswatcher.addPath(VDSK_ROOT)
        self._fswatcher.directoryChanged.connect(self._refresh_icons)
        self._fswatcher.fileChanged.connect(lambda _: self._refresh_icons())
        self._grid_size = (92, 90)  # Windows-like spacing
        self._bg_manager = BackgroundManager(self)
        self._bg_manager.register(BackgroundMode.STATIC, lambda canvas: StaticImageBg(canvas))
        self._bg_manager.register(BackgroundMode.GIF, lambda canvas: GifBg(canvas))
        self._bg_manager.register(BackgroundMode.VIDEO, lambda canvas: VideoBg(canvas))
        self._bg_manager.register(BackgroundMode.GL, lambda canvas: GLViewportBg(canvas))
        self._bg_config = BackgroundConfig.from_state(_load_state().get("background"))
        self._sort_mode = _load_state().get("desktop_sort", "name")
        self._last_sorted_paths: List[str] = []
        self._apply_background_config(self._bg_config, persist=False)
        QTimer.singleShot(0, self._refresh_icons)
        self.setContextMenuPolicy(Qt.CustomContextMenu)
        self.customContextMenuRequested.connect(self._desktop_context)

    def paintEvent(self, _):
        p = QPainter(self); p.setRenderHint(QPainter.Antialiasing)
        r = self.rect()
        # Clean blue desktop. No trim, no inner vignette. High contrast icons ensure readability.
        painted = self._bg_manager.paint(p, r)
        if not painted:
            g = QLinearGradient(r.topLeft(), r.bottomLeft())
            g.setColorAt(0.00, QColor(self.t.desktop_top))
            g.setColorAt(1.00, QColor(self.t.desktop_mid))
            p.fillRect(r, g)

    def resizeEvent(self, ev: QResizeEvent):  # pragma: no cover - trivial wrapper
        super().resizeEvent(ev)
        self._bg_manager.resize(ev.size())

    def _refresh_icons(self):
        current = set(self._icons.keys())
        want_paths = [str(p) for p in self._sorted_workspace_entries()]
        self._last_sorted_paths = want_paths
        want_set = set(want_paths)
        changed = False
        for path in list(current - want_set):
            btn = self._icons.pop(path, None)
            if not btn:
                continue
            btn.setParent(None)
            btn.deleteLater()
            changed = True
        for path in want_paths:
            if path in self._icons:
                continue
            btn = DesktopIcon(self.t, path, self, self._grid_size)
            open_cb = self.parentWidget().open_any_path if hasattr(self.parentWidget(), "open_any_path") else lambda _p: None
            btn.request_open.connect(open_cb)
            btn.request_move_to_folder.connect(self._move_file_to_folder)
            btn.show()
            self._icons[path] = btn
            pos = self.restore_icon_position(path)
            if pos is None:
                idx = len(self._icons) - 1
                cols = max(1, int((self.width() - 60) / self._grid_size[0]))
                row, col = divmod(idx, cols)
                btn.move(30 + col * self._grid_size[0], 40 + row * self._grid_size[1])
            else:
                btn.move(pos)
            changed = True
        for path, btn in self._icons.items():
            btn._set_icon_size_from_state()
        if changed:
            if self._sort_mode in {"type", "date"}:
                self._arrange_icons()
            self._notify_workspace_changed()
        QApplication.processEvents()

    def _sorted_workspace_entries(self) -> List[Path]:
        try:
            entries = list(Path(VDSK_ROOT).iterdir())
        except Exception as exc:
            log(f"list workspace failed: {exc}", logging.DEBUG)
            return []
        mode = self._sort_mode if self._sort_mode in {"name", "type", "date"} else "name"
        def base_key(p: Path) -> int:
            return 0 if p.is_dir() else 1

        if mode == "type":
            entries.sort(key=lambda p: (base_key(p), p.suffix.lower(), p.name.lower()))
        elif mode == "date":
            def mtime(path: Path) -> float:
                try:
                    return float(path.stat().st_mtime)
                except Exception:
                    return 0.0
            entries.sort(key=lambda p: (base_key(p), -mtime(p), p.name.lower()))
        else:
            entries.sort(key=lambda p: (base_key(p), p.name.lower()))
        return entries

    def _notify_workspace_changed(self) -> None:
        core = self.parent()
        if core and hasattr(core, "mark_start_index_stale"):
            try:
                core.mark_start_index_stale()
            except Exception:
                pass

    def _current_icon_size(self) -> str:
        return str(_load_state().get("icon_size", "medium"))

    def _set_sort_mode(self, mode: str) -> None:
        target = mode if mode in {"name", "type", "date"} else "name"
        if target == self._sort_mode:
            return
        self._sort_mode = target
        st = _load_state()
        st["desktop_sort"] = target
        _save_state(st)
        self._refresh_icons()
        self._arrange_icons()

    def _arrange_icons(self) -> None:
        if not self._icons:
            return
        paths = self._last_sorted_paths or [str(p) for p in self._sorted_workspace_entries()]
        cols = max(1, int((self.width() - 60) / self._grid_size[0]))
        for idx, path in enumerate(paths):
            btn = self._icons.get(path)
            if not btn:
                continue
            row, col = divmod(idx, cols)
            pos = QPoint(30 + col * self._grid_size[0], 40 + row * self._grid_size[1])
            btn.move(pos)
            self.save_icon_position(path, pos)

    def _unique_path(self, base_name: str, extension: str = "") -> Path:
        candidate = Path(VDSK_ROOT) / f"{base_name}{extension}"
        if not candidate.exists():
            return candidate
        idx = 1
        while True:
            alt = Path(VDSK_ROOT) / f"{base_name} ({idx}){extension}"
            if not alt.exists():
                return alt
            idx += 1

    def _create_text_file(self, base_name: str, extension: str, contents: str = "") -> None:
        try:
            path = self._unique_path(base_name, extension)
            path.write_text(contents, encoding="utf-8")
            self._refresh_icons()
        except Exception as exc:
            log(f"new file failed: {exc}", logging.WARNING)

    def _move_file_to_folder(self, src: str, dst: str):
        try:
            shutil.move(src, dst)
            self._refresh_icons()
        except Exception as e:
            log(f"move failed: {e}", logging.WARNING)

    def save_icon_position(self, path: str, pos: QPoint):
        st = _load_state()
        st.setdefault("icon_pos", {})[path] = [pos.x(), pos.y()]
        _save_state(st)

    def restore_icon_position(self, path: str) -> Optional[QPoint]:
        st = _load_state()
        xy = st.get("icon_pos", {}).get(path)
        if not xy: return None
        try:
            return QPoint(int(xy[0]), int(xy[1]))
        except Exception:
            return None

    def _desktop_context(self, pos: QPoint):
        m = QMenu(self)
        current_size = self._current_icon_size()
        view_m = m.addMenu("View")
        view_actions = {
            "large": view_m.addAction("Large icons"),
            "medium": view_m.addAction("Medium icons"),
            "small": view_m.addAction("Small icons"),
        }
        for key, action in view_actions.items():
            action.setCheckable(True)
            action.setChecked(current_size == key)
            action.triggered.connect(lambda _checked, size=key: self._set_icon_size(size))
        sort_m = m.addMenu("Sort by")
        for key, label in (("name", "Name"), ("type", "Type"), ("date", "Date modified")):
            act = sort_m.addAction(label)
            act.setCheckable(True)
            act.setChecked(self._sort_mode == key)
            act.triggered.connect(lambda _checked, mode=key: self._set_sort_mode(mode))
        m.addAction("Refresh", self._refresh_icons)
        m.addSeparator()
        new_m = m.addMenu("New")
        new_m.addAction("Folder", self._new_folder_desktop)
        new_m.addAction("Text Document", self._new_text_desktop)
        new_m.addAction("Markdown Document", self._new_markdown_desktop)
        new_m.addAction("JSON Document", self._new_json_desktop)
        new_m.addAction("Python File", self._new_python_desktop)
        new_m.addAction("PowerShell Script", self._new_powershell_desktop)
        new_m.addAction("ZIP Archive", self._new_zip_desktop)
        new_m.addAction("Shortcut", self._new_shortcut_desktop)
        m.addSeparator()
        pers_m = m.addMenu("Personalize")
        pers_m.addAction("Solid color", lambda: self._select_background(BackgroundMode.SOLID))
        pers_m.addAction("Image…", lambda: self._select_background(BackgroundMode.STATIC))
        pers_m.addAction("Animated GIF…", lambda: self._select_background(BackgroundMode.GIF))
        pers_m.addAction("Video…", lambda: self._select_background(BackgroundMode.VIDEO))
        pers_m.addAction("Live GL viewport…", lambda: self._select_background(BackgroundMode.GL))
        m.addSeparator()
        m.addAction("Display settings", self._open_display_settings)
        m.addAction("Desktop settings", self._open_desktop_settings)
        m.exec(self.mapToGlobal(pos))

    def _set_icon_size(self, sz: str):
        st = _load_state(); st["icon_size"] = sz; _save_state(st); self._refresh_icons()

    def _new_folder_desktop(self):
        try:
            path = self._unique_path("New Folder")
            path.mkdir()
            self._refresh_icons()
        except Exception as e:
            log(f"new folder failed: {e}", logging.WARNING)

    def _new_text_desktop(self):
        self._create_text_file("New Text Document", ".txt")

    def _new_markdown_desktop(self):
        self._create_text_file("New Markdown Document", ".md", "# New Markdown Document\n\n")

    def _new_json_desktop(self):
        self._create_text_file("New JSON Document", ".json", "{\n\n}\n")

    def _new_python_desktop(self):
        self._create_text_file(
            "New Python File",
            ".py",
            "#!/usr/bin/env python3\n\n\"\"\"New script.\"\"\"\n\n",
        )

    def _new_powershell_desktop(self):
        self._create_text_file("New PowerShell Script", ".ps1", "Write-Host 'Hello from Virtual Desktop'\n")

    def _new_zip_desktop(self):
        try:
            path = self._unique_path("New Archive", ".zip")
            with zipfile.ZipFile(path, "w") as zf:
                pass
            self._refresh_icons()
        except Exception as e:
            log(f"new zip failed: {e}", logging.WARNING)

    def _new_shortcut_desktop(self):
        try:
            path = self._unique_path("New Shortcut", ".shortcut.json")
            payload = {"target": "", "args": [], "working_dir": ""}
            path.write_text(json.dumps(payload, indent=2) + "\n", encoding="utf-8")
            self._refresh_icons()
        except Exception as e:
            log(f"new shortcut failed: {e}", logging.WARNING)

    def _open_display_settings(self):
        core = self.parent()
        if core and hasattr(core, "_open_settings_panel"):
            core._open_settings_panel(section="display")

    def _open_desktop_settings(self):
        core = self.parent()
        if core and hasattr(core, "_open_settings_panel"):
            core._open_settings_panel(section="desktop")

    def background_config(self) -> BackgroundConfig:
        return self._bg_config

    def set_background_config(self, config: BackgroundConfig) -> None:
        self._apply_background_config(config)

    def _apply_background_config(self, config: BackgroundConfig, *, persist: bool = True) -> None:
        self._bg_config = config
        if persist:
            st = _load_state()
            st["background"] = config.to_state()
            _save_state(st)
        if config.mode == BackgroundMode.SOLID or not config.source:
            self._bg_manager.clear()
        else:
            self._bg_manager.apply(config)
        self.update()
        QApplication.processEvents()

    def _select_background(self, mode: BackgroundMode):
        config = BackgroundConfig.from_state(self._bg_config.to_state()) if self._bg_config else BackgroundConfig()
        config.mode = mode
        if mode == BackgroundMode.SOLID:
            config.source = ""
            self._apply_background_config(config)
            return
        path = self.prompt_background_path(mode)
        if not path:
            return
        config.source = path
        if mode in (BackgroundMode.STATIC, BackgroundMode.GIF) and not isinstance(config.fit, BackgroundFit):
            config.fit = BackgroundFit.FILL
        if mode == BackgroundMode.VIDEO:
            config.loop = True
            config.mute = True
        self._apply_background_config(config)

    def _validate_background_path(self, path: str) -> bool:
        core = self.parent()
        allow_external = bool(getattr(core, "allow_external_browse", lambda: False)()) if core else False
        if not _is_contained(path) and not allow_external:
            if core and hasattr(core, "_toast"):
                core._toast("Background must stay inside the workspace.")
            log(f"Blocked background outside workspace: {path}", logging.WARNING)
            return False
        return True

    def validate_background_source(self, path: str) -> bool:
        return self._validate_background_path(path)

    def _background_prompt_details(self, mode: BackgroundMode) -> Tuple[str, str]:
        filters = {
            BackgroundMode.STATIC: "Images (*.png *.jpg *.jpeg *.bmp *.gif)",
            BackgroundMode.GIF: "GIF images (*.gif)",
            BackgroundMode.VIDEO: "Videos (*.mp4 *.mov *.mkv *.avi *.webm)",
            BackgroundMode.GL: "Python Scripts (*.py)",
        }
        captions = {
            BackgroundMode.STATIC: "Choose Background Image",
            BackgroundMode.GIF: "Choose Animated GIF",
            BackgroundMode.VIDEO: "Choose Background Video",
            BackgroundMode.GL: "Choose GL Background Script",
        }
        return filters.get(mode, "*"), captions.get(mode, "Choose Background")

    def prompt_background_path(self, mode: BackgroundMode) -> Optional[str]:
        path_filter, caption = self._background_prompt_details(mode)
        path, _ = _non_native_open_file(self, caption, VDSK_ROOT, path_filter)
        if not path:
            return None
        if not self._validate_background_path(path):
            return None
        return path

# --------------------------------------------------------------------------------------
# Camera viewport
# --------------------------------------------------------------------------------------
class Camera(QScrollArea):
    def __init__(self, content: DesktopCanvas, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.setWidget(content)
        # Allow the scroll area to resize the canvas with the viewport so edge drags
        # on the main window immediately reflect in the desktop geometry.
        self.setWidgetResizable(True)
        self.setFrameShape(QFrame.NoFrame)
        self.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        self.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        # Drag-to-pan
        self._dragging = False; self._last = QPoint()
        self.viewport().installEventFilter(self)

    def center_on_widget(self, w: QWidget | None):
        if not w: return
        c = w.geometry().center()
        self.center_on_point(c)

    def center_on_point(self, pt: QPoint):
        cont = self.widget(); vw = self.viewport().size()
        x = max(0, min(pt.x() - vw.width() // 2, max(0, cont.width() - vw.width())))
        y = max(0, min(pt.y() - vw.height() // 2, max(0, cont.height() - vw.height())))
        self.horizontalScrollBar().setValue(x)
        self.verticalScrollBar().setValue(y)

    def pan(self, dx: int, dy: int):
        hs = self.horizontalScrollBar(); vs = self.verticalScrollBar()
        hs.setValue(max(hs.minimum(), min(hs.maximum(), hs.value() + dx)))
        vs.setValue(max(vs.minimum(), min(vs.maximum(), vs.value() + dy)))

    def eventFilter(self, obj, ev):
        if obj is self.viewport():
            if ev.type() == QEvent.Type.Wheel:
                delta = ev.angleDelta()
                steps = delta.y() // 120 if delta.y() else delta.x() // 120
                if ev.modifiers() & Qt.ShiftModifier:
                    self.pan(-int(steps) * 120, 0)
                else:
                    self.pan(0, -int(steps) * 120)
                return True
            if ev.type() == QEvent.MouseButtonPress and ev.button() == Qt.MiddleButton:
                self._dragging = True; self._last = ev.position().toPoint(); return True
            elif ev.type() == QEvent.MouseMove and self._dragging:
                cur = ev.position().toPoint()
                delta = cur - self._last; self._last = cur
                self.pan(-delta.x(), -delta.y()); return True
            elif ev.type() in (QEvent.MouseButtonRelease, QEvent.Leave):
                self._dragging = False
        return super().eventFilter(obj, ev)

# --------------------------------------------------------------------------------------
# Taskbar + Start panel
# --------------------------------------------------------------------------------------
class StartPanel(QFrame):
    request_close = Signal()
    cursor_exited = Signal()
    FACETS = [
        ("all", "All"),
        ("apps", "Apps"),
        ("docs", "Docs"),
        ("images", "Images"),
        ("scripts", "Scripts"),
    ]
    _RECENT_KIND_MAP = {
        "text": "docs",
        "image": "images",
        "py_card": "scripts",
        "process": "apps",
        "template": "apps",
        "builtin": "apps",
    }

    def __init__(self, core: "VirtualDesktopCore"):
        super().__init__(core)
        self.core = core
        self.t = core.t
        self.setObjectName("StartPanel")
        self.setAutoFillBackground(False)
        self.setStyleSheet(
            f"""
            QFrame#StartPanel {{
                background:{self.t.start_panel};
                border-top:1px solid {self.t.card_border};
                border-left:1px solid {self.t.card_border};
                border-right:1px solid {self.t.card_border};
                border-top-left-radius:10px;
                border-top-right-radius:10px;
            }}
            QLabel {{ color:{self.t.menu_fg}; }}
            QLineEdit {{
                background:#0b1828; color:#eaf2ff; border:1px solid {self.t.card_border}; border-radius:6px; padding:6px 8px;
            }}
            QToolButton#FacetButton {{
                background:transparent; color:{self.t.menu_fg}; border:1px solid transparent; border-radius:6px; padding:4px 10px;
            }}
            QToolButton#FacetButton:checked {{ background:{self.t.accent}; color:#fff; border:1px solid {self.t.accent}; }}
            QToolButton#ViewToggle {{
                background:transparent; color:{self.t.menu_fg}; border:1px solid {self.t.card_border}; border-radius:6px; padding:4px 8px;
            }}
            QToolButton#ViewToggle:checked {{ background:{self.t.accent}; color:#fff; border:1px solid {self.t.accent}; }}
            QPushButton[class="StartApp"] {{
                background:{self.t.start_tile}; color:#dfe9ff; border:1px solid {self.t.card_border}; border-radius:8px; padding:10px; text-align:left;
            }}
            QPushButton[class="StartApp"]:hover {{ background:{self.t.accent}; color:#fff; }}
            QPushButton[class="RecentItem"] {{
                background:#1b4fbf; color:#fff; border:1px solid #0d214b; border-radius:6px; padding:8px 10px; text-align:left;
            }}
            QPushButton[class="RecentItem"]:hover {{ background:#2a64ff; }}
            QPushButton[class="ResultItem"] {{
                background:#162438; color:#eaf2ff; border:1px solid {self.t.card_border}; border-radius:8px; padding:8px 10px; text-align:left;
            }}
            QPushButton[class="ResultItem"]:hover {{ background:{self.t.accent}; color:#fff; }}
            QPushButton[class="Power"] {{
                background:{self.t.start_tile}; color:#dfe9ff; border:1px solid {self.t.card_border}; border-radius:8px; padding:10px 16px;
            }}
            QPushButton[class="Power"]:hover {{ background:{self.t.accent}; color:#fff; }}
            QPushButton#Shutdown {{
                background:#E04B4B; color:#fff; border:1px solid #3b0f0f; border-radius:8px; padding:10px 16px;
            }}
            QPushButton#Shutdown:hover {{ background:#ff5c5c; }}
            """
        )
        self.view_mode = "grid"
        self._facet = "all"
        self._workspace_items: List[Dict[str, str]] = []
        self._index_stale = True
        self._app_entries = self._build_app_entries()
        self._cursor_inside = False
        self._focus_refresh_pending = True
        self._warm_thread: Optional[threading.Thread] = None

        self._search_timer = QTimer(self)
        self._search_timer.setSingleShot(True)
        self._search_timer.setInterval(180)
        self._cursor_exit_timer = QTimer(self)
        self._cursor_exit_timer.setSingleShot(True)
        self._cursor_exit_timer.setInterval(2000)
        self._cursor_exit_timer.timeout.connect(self._on_cursor_exit_timeout)
        main = QVBoxLayout(self)
        main.setContentsMargins(12, 10, 12, 12)
        main.setSpacing(10)

        search_row = QHBoxLayout(); search_row.setSpacing(8)
        self.search = QLineEdit(self); self.search.setPlaceholderText("Search apps, files, and recents")
        self.search.installEventFilter(self)
        self.search.textChanged.connect(self._on_search_changed)
        self.search.returnPressed.connect(self._run_search)
        self.btn_close = QPushButton("✕"); self.btn_close.setFixedWidth(32)
        self.btn_close.clicked.connect(self.hide)
        search_row.addWidget(self.search, 1)
        search_row.addWidget(self.btn_close, 0)
        main.addLayout(search_row)

        facet_row = QHBoxLayout(); facet_row.setSpacing(6)
        self._facet_buttons: Dict[str, QToolButton] = {}
        for key, label in self.FACETS:
            btn = QToolButton(self)
            btn.setObjectName("FacetButton")
            btn.setText(label)
            btn.setCheckable(True)
            btn.clicked.connect(lambda _checked, f=key: self._set_facet(f))
            if key == self._facet:
                btn.setChecked(True)
            self._facet_buttons[key] = btn
            facet_row.addWidget(btn)
        facet_row.addStretch(1)
        main.addLayout(facet_row)

        self.results_scroll = QScrollArea(self)
        self.results_scroll.setWidgetResizable(True)
        self.results_scroll.setFrameShape(QFrame.NoFrame)
        self.results_scroll.setMaximumHeight(220)
        self._results_widget = QWidget(self.results_scroll)
        self._results_layout = QVBoxLayout(self._results_widget)
        self._results_layout.setContentsMargins(0, 0, 0, 0)
        self._results_layout.setSpacing(6)
        self.results_scroll.setWidget(self._results_widget)
        self._show_results_placeholder()
        self.results_scroll.setVisible(False)
        main.addWidget(self.results_scroll)

        apps_header = QHBoxLayout(); apps_header.setSpacing(6)
        apps_label = QLabel("Pinned apps")
        apps_header.addWidget(apps_label)
        apps_header.addStretch(1)
        self.btn_grid = QToolButton(self)
        self.btn_grid.setObjectName("ViewToggle")
        self.btn_grid.setText("▦")
        self.btn_grid.setCheckable(True)
        self.btn_grid.setChecked(True)
        self.btn_grid.clicked.connect(lambda _=False: self._set_view_mode("grid"))
        self.btn_list = QToolButton(self)
        self.btn_list.setObjectName("ViewToggle")
        self.btn_list.setText("≡")
        self.btn_list.setCheckable(True)
        self.btn_list.clicked.connect(lambda _=False: self._set_view_mode("list"))
        apps_header.addWidget(self.btn_grid)
        apps_header.addWidget(self.btn_list)
        main.addLayout(apps_header)

        self.apps_stack = QStackedWidget(self)
        self.apps_stack.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)
        self.apps_grid_widget = QWidget(self.apps_stack)
        self.apps_grid_layout = QGridLayout(self.apps_grid_widget)
        self.apps_grid_layout.setContentsMargins(0, 0, 0, 0)
        self.apps_grid_layout.setSpacing(10)
        self.apps_list_widget = QWidget(self.apps_stack)
        self.apps_list_layout = QVBoxLayout(self.apps_list_widget)
        self.apps_list_layout.setContentsMargins(0, 0, 0, 0)
        self.apps_list_layout.setSpacing(6)
        self.apps_stack.addWidget(self.apps_grid_widget)
        self.apps_stack.addWidget(self.apps_list_widget)
        main.addWidget(self.apps_stack)
        self._rebuild_apps_views()

        self.recent_frame = QFrame(self)
        self.recent_frame.setObjectName("RecentFrame")
        self.recent_layout = QVBoxLayout(self.recent_frame)
        self.recent_layout.setContentsMargins(0, 0, 0, 0)
        self.recent_layout.setSpacing(6)
        self.recent_title = QLabel("Recent")
        self.recent_layout.addWidget(self.recent_title)
        main.addWidget(self.recent_frame)

        self._populate_recent()

        bottom = QHBoxLayout(); bottom.addStretch(1)
        btn_settings = QPushButton("Settings…"); btn_settings.setProperty("class", "Power")
        btn_settings.clicked.connect(self._make_click_handler(core._open_settings_panel))
        btn_console = QPushButton("System Console"); btn_console.setProperty("class", "Power")
        btn_console.clicked.connect(self._make_click_handler(core._open_system_console))
        btn_errors = QPushButton("Error Center"); btn_errors.setProperty("class", "Power")
        btn_errors.clicked.connect(self._make_click_handler(core._open_error_center))
        btn_quit = QPushButton("Shut down"); btn_quit.setObjectName("Shutdown")
        btn_quit.clicked.connect(self._make_click_handler(lambda: core.window().close() if core.window() else None))
        for b in (btn_settings, btn_console, btn_errors, btn_quit):
            b.setMinimumHeight(38)
        bottom.addWidget(btn_settings)
        bottom.addWidget(btn_console)
        bottom.addWidget(btn_errors)
        bottom.addWidget(btn_quit)
        main.addLayout(bottom)

    def enterEvent(self, event):
        self._cursor_inside = True
        self._cancel_cursor_exit_timer()
        super().enterEvent(event)

    def leaveEvent(self, event):
        was_inside = self._cursor_inside
        self._cursor_inside = False
        super().leaveEvent(event)
        if was_inside:
            self._handle_cursor_exit()

    def hideEvent(self, event):
        self._cursor_inside = False
        self._cancel_cursor_exit_timer()
        super().hideEvent(event)

    def _handle_cursor_exit(self) -> None:
        if not self.isVisible():
            return
        if self.search.hasFocus():
            self._cancel_cursor_exit_timer()
            return
        if self.underMouse():
            return
        try:
            global_pos = QCursor.pos()
        except Exception:
            self._cursor_exit_timer.stop()
            self._cursor_exit_timer.start()
            return
        local_pos = self.mapFromGlobal(global_pos)
        if not self.rect().contains(local_pos):
            self._cursor_exit_timer.stop()
            self._cursor_exit_timer.start()

    def eventFilter(self, obj, event):
        if obj is self.search and event and event.type() == QEvent.FocusIn:
            self._refresh_index_if_pending()
            self._cancel_cursor_exit_timer()
        return super().eventFilter(obj, event)

    def _cancel_cursor_exit_timer(self) -> None:
        if self._cursor_exit_timer.isActive():
            self._cursor_exit_timer.stop()

    def _on_cursor_exit_timeout(self) -> None:
        if not self.isVisible():
            return
        if self.underMouse():
            return
        if self.search.hasFocus():
            self._cancel_cursor_exit_timer()
            return
        try:
            global_pos = QCursor.pos()
        except Exception:
            self.cursor_exited.emit()
            return
        local_pos = self.mapFromGlobal(global_pos)
        if not self.rect().contains(local_pos):
            self.cursor_exited.emit()

    def showEvent(self, event):
        self._populate_recent()
        self._ensure_index()
        self._run_search()
        super().showEvent(event)

    def warm_index_async(self) -> None:
        if self._warm_thread and self._warm_thread.is_alive():
            return

        def _runner():
            try:
                self._ensure_index()
            finally:
                self._warm_thread = None

        thread = threading.Thread(target=_runner, name="StartIndexWarm", daemon=True)
        self._warm_thread = thread
        thread.start()

    def mark_index_stale(self) -> None:
        self._index_stale = True
        self._focus_refresh_pending = True

    def _refresh_index_if_pending(self) -> None:
        if not self._focus_refresh_pending:
            return
        self._focus_refresh_pending = False
        self._ensure_index(force=True)

    def _build_app_entries(self) -> List[Dict[str, object]]:
        style = QApplication.style()
        entries: List[Dict[str, object]] = [
            {
                "id": "explorer",
                "title": "Desktop Explorer",
                "icon": style.standardIcon(QStyle.SP_DirIcon),
                "callback": self.core._open_explorer,
                "kind": "app",
            },
            {
                "id": "tasks",
                "title": "Tasks",
                "icon": style.standardIcon(QStyle.SP_FileDialogListView),
                "callback": self.core._open_tasks,
                "kind": "app",
            },
            {
                "id": "operators",
                "title": "Operator Manager",
                "icon": style.standardIcon(QStyle.SP_DesktopIcon),
                "callback": self.core._open_operator_manager,
                "kind": "app",
            },
            {
                "id": "codex-terminal",
                "title": "Codex Terminal",
                "icon": style.standardIcon(QStyle.SP_DesktopIcon),
                "callback": self.core.open_codex_terminal,
                "kind": "app",
            },
            {
                "id": "codex-terminal-new",
                "title": "New Codex Agent…",
                "icon": style.standardIcon(QStyle.SP_FileDialogNewFolder),
                "callback": self._launch_codex_agent_for_directory,
                "kind": "app",
            },
            {
                "id": "template-terminal",
                "title": "Template Terminal",
                "icon": style.standardIcon(QStyle.SP_ComputerIcon),
                "callback": lambda: self.core.toggle_template_terminal(True),
                "kind": "app",
            },
            {
                "id": "load-script",
                "title": "Load Script as Card…",
                "icon": style.standardIcon(QStyle.SP_FileDialogDetailedView),
                "callback": self.core._load_script_dialog,
                "kind": "app",
            },
        ]

        if self.core.has_user_guided_notes():
            notes_entry = {
                "id": "user-guided-notes",
                "title": "User-Guided Notes",
                "icon": style.standardIcon(QStyle.SP_FileDialogDetailedView),
                "callback": self.core._open_user_guided_notes,
                "kind": "app",
            }
            insert_pos = max(0, len(entries) - 1)
            entries.insert(insert_pos, notes_entry)

        system_entry = {
            "id": "system-overview",
            "title": "System Overview",
            "icon": style.standardIcon(QStyle.SP_DesktopIcon),
            "callback": self.core._open_system_overview,
            "kind": "app",
        }
        entries = [e for e in entries if e.get("id") != system_entry["id"]]
        entries.insert(2, system_entry)
        return entries

    def _launch_codex_agent_for_directory(self) -> None:
        start_dir = workspace_root()
        chosen = _non_native_open_dir(
            self,
            "Select Codex workspace",
            start_dir or SCRIPT_DIR,
        )
        if not chosen:
            return
        script_path = self.core._resolve_codex_terminal_path()
        if not script_path:
            QMessageBox.information(self, "Codex", "Codex_Terminal.py not found.")
            return
        workspace = os.path.abspath(chosen)
        previous_env = os.environ.get("CODEX_WORKSPACE")
        os.environ["CODEX_WORKSPACE"] = workspace
        icon = QApplication.style().standardIcon(QStyle.SP_DesktopIcon)
        try:
            card = self.core._load_python_as_card(
                script_path,
                persist_key=f"{script_path}:{workspace}",
                nice_title="Codex Terminal",
                task_profile="codex-terminal",
                task_icon=icon,
                task_tooltip=f"Workspace: {workspace}",
            )
        except Exception:
            if previous_env is None:
                os.environ.pop("CODEX_WORKSPACE", None)
            else:
                os.environ["CODEX_WORKSPACE"] = previous_env
            raise
        if card is None:
            if previous_env is None:
                os.environ.pop("CODEX_WORKSPACE", None)
            else:
                os.environ["CODEX_WORKSPACE"] = previous_env
            return

        def _restore_env(_=None) -> None:
            if os.environ.get("CODEX_WORKSPACE") != workspace:
                return
            if previous_env is None:
                os.environ.pop("CODEX_WORKSPACE", None)
            else:
                os.environ["CODEX_WORKSPACE"] = previous_env

        card.closed.connect(_restore_env)

    def _make_click_handler(self, callback: Callable[[], None]):
        def handler(_=False):
            self.hide()
            try:
                callback()
            except Exception as exc:
                log(f"Start launch failed: {exc}", logging.DEBUG)
        return handler

    def _rebuild_apps_views(self) -> None:
        self._clear_layout(self.apps_grid_layout)
        self._clear_layout(self.apps_list_layout)
        cols = max(1, min(3, int(len(self._app_entries) ** 0.5) + 1))
        for idx, entry in enumerate(self._app_entries):
            grid_btn = self._make_app_button(entry, large=True)
            row, col = divmod(idx, cols)
            self.apps_grid_layout.addWidget(grid_btn, row, col)
            list_btn = self._make_app_button(entry, large=False)
            self.apps_list_layout.addWidget(list_btn)
        self.apps_list_layout.addStretch(1)
        self._set_view_mode(self.view_mode)

    def _make_app_button(self, entry: Dict[str, object], *, large: bool) -> QPushButton:
        btn = QPushButton(entry["title"], self)
        btn.setProperty("class", "StartApp")
        btn.setIcon(entry["icon"] if isinstance(entry.get("icon"), QIcon) else QIcon())
        btn.setIconSize(QSize(32, 32) if large else QSize(24, 24))
        if large:
            btn.setMinimumSize(140, 72)
        else:
            btn.setMinimumHeight(44)
        cb = entry.get("callback")
        if callable(cb):
            btn.clicked.connect(self._make_click_handler(cb))
        return btn

    def _set_view_mode(self, mode: str) -> None:
        if mode not in {"grid", "list"}:
            mode = "grid"
        if mode == self.view_mode and self.apps_stack.currentIndex() == (0 if mode == "grid" else 1):
            return
        self.view_mode = mode
        self.btn_grid.setChecked(mode == "grid")
        self.btn_list.setChecked(mode == "list")
        self.apps_stack.setCurrentIndex(0 if mode == "grid" else 1)

    def _set_facet(self, facet: str) -> None:
        if facet == self._facet:
            return
        if facet not in {f for f, _ in self.FACETS}:
            facet = "all"
        self._facet = facet
        for key, btn in self._facet_buttons.items():
            btn.setChecked(key == facet)
        self._run_search()

    def _on_search_changed(self, _text: str) -> None:
        self._search_timer.start()

    def _run_search(self) -> None:
        self._search_timer.stop()
        query = self.search.text().strip()
        if not query:
            self._clear_layout(self._results_layout)
            self._show_results_placeholder()
            self.results_scroll.setVisible(False)
            return
        self._ensure_index()
        results = self._perform_search(query)
        self._render_results(results)

    def _ensure_index(self, force: bool = False) -> bool:
        if not force and not self._index_stale and self._workspace_items:
            return False
        root = Path(self.core._workspace or VDSK_ROOT)
        self._workspace_items = self._index_workspace(root)
        self._index_stale = False
        return True

    def _index_workspace(self, root: Path) -> List[Dict[str, str]]:
        items: List[Dict[str, str]] = []
        image_exts = {".png", ".jpg", ".jpeg", ".gif", ".bmp"}
        doc_exts = {".txt", ".md", ".json", ".log", ".cfg", ".ini"}
        try:
            for p in root.rglob("*"):
                if p.is_dir():
                    continue
                ext = p.suffix.lower()
                if ext in image_exts:
                    kind = "image"
                elif ext == ".py":
                    kind = "script"
                elif ext in doc_exts:
                    kind = "doc"
                else:
                    kind = "file"
                items.append({"path": str(p), "title": p.name, "kind": kind})
        except Exception as exc:
            log(f"Start index failed: {exc}", logging.DEBUG)
        return items

    def _perform_search(self, query: str) -> Dict[str, List[Dict[str, object]]]:
        out: Dict[str, List[Dict[str, object]]] = {"Apps": [], "Recent": [], "Files": []}
        # Apps
        if self._facet in {"all", "apps"}:
            names = [entry["title"] for entry in self._app_entries]
            for title in self._fuzzy_names(query, names):
                entry = next((e for e in self._app_entries if e["title"] == title), None)
                if entry:
                    out["Apps"].append(entry)
        # Recent
        recents = self._recent_entries()
        filtered_recents = []
        for rec in recents:
            mapped = self._RECENT_KIND_MAP.get(rec.get("kind"), "apps")
            if self._facet in {"all", mapped}:
                filtered_recents.append(rec)
        recent_pairs = [(rec, rec.get("title") or Path(rec.get("path", "")).name) for rec in filtered_recents]
        rec_titles = [name for _, name in recent_pairs]
        for title in self._fuzzy_names(query, rec_titles):
            for rec, rec_name in recent_pairs:
                if rec_name == title:
                    out["Recent"].append(rec)
                    break
        # Files
        if self._facet in {"all", "docs", "images", "scripts"}:
            kinds = {
                "docs": {"doc"},
                "images": {"image"},
                "scripts": {"script"},
                "all": {"doc", "image", "script", "file"},
            }
            allowed = kinds.get(self._facet, kinds["all"])
            pool = [item for item in self._workspace_items if item.get("kind") in allowed]
            names = [item["title"] for item in pool]
            for title in self._fuzzy_names(query, names):
                item = next((it for it in pool if it["title"] == title), None)
                if item:
                    out["Files"].append(item)
        return out

    def _render_results(self, results: Dict[str, List[Dict[str, object]]]) -> None:
        self._clear_layout(self._results_layout)
        has_results = False
        for section in ("Apps", "Recent", "Files"):
            items = results.get(section, [])
            if not items:
                continue
            has_results = True
            header = QLabel(section)
            header.setStyleSheet("font:600 11pt 'Cascadia Code'; color:#eaf2ff;")
            self._results_layout.addWidget(header)
            for item in items[:12]:
                btn = self._make_result_button(section, item)
                self._results_layout.addWidget(btn)
        if not has_results:
            self._show_results_placeholder()
        self.results_scroll.setVisible(has_results)

    def _make_result_button(self, section: str, item: Dict[str, object]) -> QPushButton:
        btn = QPushButton(str(item.get("title", "")), self)
        btn.setProperty("class", "ResultItem")
        icon = self._icon_for_item(section, item)
        if icon:
            btn.setIcon(icon)
        subtitle = str(item.get("path") or item.get("tooltip") or "")
        if subtitle:
            btn.setToolTip(subtitle)
        if section == "Apps":
            cb = item.get("callback") if callable(item.get("callback")) else None
        else:
            path = item.get("path") or item.get("value")
            cb = (lambda p=path: self.core.open_any_path(p)) if path else None
        if callable(cb):
            btn.clicked.connect(self._make_click_handler(cb))
        return btn

    def _icon_for_item(self, section: str, item: Dict[str, object]) -> Optional[QIcon]:
        style = QApplication.style()
        if section == "Apps":
            icon = item.get("icon")
            return icon if isinstance(icon, QIcon) else style.standardIcon(QStyle.SP_FileIcon)
        kind = item.get("kind", "")
        if kind == "image":
            return style.standardIcon(QStyle.SP_FileDialogContentsView)
        if kind in {"doc", "text"}:
            return style.standardIcon(QStyle.SP_FileDialogDetailedView)
        if kind == "script":
            return style.standardIcon(QStyle.SP_FileDialogInfoView)
        return style.standardIcon(QStyle.SP_FileIcon)

    def _recent_entries(self) -> List[Dict[str, object]]:
        st = _load_state()
        return st.get("recent", [])[:8]

    def _populate_recent(self):
        while True:
            item = self.recent_layout.takeAt(1)  # preserve title at index 0
            if not item:
                break
            if item.widget():
                item.widget().deleteLater()
        for rec in self._recent_entries():
            title = rec.get("title", "")
            path = rec.get("path", "")
            btn = QPushButton(title or path or "Recent Item", self)
            btn.setProperty("class", "RecentItem")
            btn.setToolTip(path)
            btn.clicked.connect(self._make_click_handler(lambda p=path: self.core.open_any_path(p)))
            self.recent_layout.addWidget(btn)
        if self.recent_layout.count() == 1:
            placeholder = QLabel("No recent items yet.")
            placeholder.setStyleSheet("color:#7c8cab;")
            self.recent_layout.addWidget(placeholder)

    def _fuzzy_names(self, query: str, names: List[str], limit: int = 12) -> List[str]:
        if not query:
            return names[:limit]
        picks = difflib.get_close_matches(query, names, n=limit, cutoff=0.3)
        q = query.lower()
        picks += [name for name in names if q in name.lower()]
        seen: set[str] = set()
        out: List[str] = []
        for name in picks:
            if name in seen:
                continue
            seen.add(name)
            out.append(name)
            if len(out) >= limit:
                break
        return out

    def _clear_layout(self, layout: QLayout) -> None:
        while layout.count():
            item = layout.takeAt(0)
            widget = item.widget()
            if widget:
                widget.deleteLater()
            elif item.layout():
                self._clear_layout(item.layout())

    def _show_results_placeholder(self) -> None:
        placeholder = QLabel("Type to search for apps or files.", self._results_widget)
        placeholder.setStyleSheet("color:#7c8cab; font:italic 10pt 'Cascadia Code';")
        self._results_layout.addWidget(placeholder)

@dataclass
class TaskGroup:
    profile: str
    button: QToolButton
    cards: List[Card]
    index: int = 0


class Taskbar(QWidget):
    SIDES = {"bottom", "top", "left", "right"}

    request_start_menu = Signal()

    def __init__(self, theme: Theme, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.t = theme
        self._side = "bottom"
        self.setAutoFillBackground(False)
        self.setStyleSheet(f"QWidget{{background:{self.t.taskbar_bg};}}")

        self.row = QBoxLayout(QBoxLayout.LeftToRight)
        self.row.setContentsMargins(8, 4, 8, 4)
        self.row.setSpacing(6)
        self.setLayout(self.row)

        self.start_btn = QPushButton(" ⊞ Start")
        self.start_btn.setCursor(Qt.PointingHandCursor)
        self.start_btn.setStyleSheet(
            f"QPushButton{{background:{self.t.accent}; color:#fff; border:none; border-radius:6px; padding:0 12px;}}"
            f"QPushButton:hover{{background:{self.t.accent_hov};}}"
        )
        self.start_btn.clicked.connect(lambda: self.request_start_menu.emit())

        self.tasks = QBoxLayout(QBoxLayout.LeftToRight)
        self.tasks.setSpacing(6)
        self.tasks.setContentsMargins(0, 0, 0, 0)
        self._tasks_holder = QWidget()
        self._tasks_holder.setLayout(self.tasks)
        self._tasks_holder.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)

        self.clock = QLabel("")
        self.clock.setStyleSheet(f"color:{self.t.taskbar_fg}; font:600 10pt 'Cascadia Code';")
        self.clock.setAlignment(Qt.AlignVCenter | Qt.AlignRight)

        self.row.addWidget(self.start_btn, 0)
        self.row.addWidget(self._tasks_holder, 1)
        self.row.addWidget(self.clock, 0)
        self.row.setStretch(self.row.indexOf(self._tasks_holder), 1)

        self._timer = QTimer(self)
        self._timer.timeout.connect(self._tick)
        self._timer.start(1000)
        self._tick()

        self._groups: Dict[str, TaskGroup] = {}
        self._card_group: Dict[Card, str] = {}

        self.set_side(self._side)

    def side(self) -> str:
        return self._side

    def thickness(self) -> int:
        if self._side in ("left", "right"):
            value = self.width() or self.sizeHint().width()
        else:
            value = self.height() or self.sizeHint().height()
        return int(max(0, value))

    def set_side(self, side: str) -> None:
        normalized = side if side in self.SIDES else "bottom"
        self._apply_side(normalized)
        self._refresh_group_metrics()

    def _apply_side(self, side: str) -> None:
        self._side = side
        horizontal = side in ("bottom", "top")
        if horizontal:
            self.setMinimumHeight(40)
            self.setMaximumHeight(40)
            self.setFixedHeight(40)
            self.setMinimumWidth(0)
            self.setMaximumWidth(16777215)
            self.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Fixed)
            self.row.setDirection(QBoxLayout.LeftToRight)
            self.row.setContentsMargins(8, 4, 8, 4)
            self.row.setSpacing(6)
            self.tasks.setDirection(QBoxLayout.LeftToRight)
            self.tasks.setSpacing(6)
            self.row.setAlignment(self.start_btn, Qt.AlignVCenter)
            self.row.setAlignment(self._tasks_holder, Qt.AlignVCenter)
            self.row.setAlignment(self.clock, Qt.AlignVCenter | Qt.AlignRight)
            self.clock.setAlignment(Qt.AlignVCenter | Qt.AlignRight)
            self.start_btn.setFixedHeight(30)
            self.start_btn.setMinimumWidth(120)
            self.start_btn.setMaximumWidth(220)
        else:
            self.setMinimumWidth(96)
            self.setMaximumWidth(96)
            self.setFixedWidth(96)
            self.setMinimumHeight(0)
            self.setMaximumHeight(16777215)
            self.setSizePolicy(QSizePolicy.Fixed, QSizePolicy.Expanding)
            self.row.setDirection(QBoxLayout.TopToBottom)
            self.row.setContentsMargins(6, 10, 6, 10)
            self.row.setSpacing(10)
            self.tasks.setDirection(QBoxLayout.TopToBottom)
            self.tasks.setSpacing(6)
            self.row.setAlignment(self.start_btn, Qt.AlignHCenter)
            self.row.setAlignment(self._tasks_holder, Qt.AlignHCenter)
            self.row.setAlignment(self.clock, Qt.AlignHCenter)
            self.clock.setAlignment(Qt.AlignHCenter)
            self.start_btn.setFixedHeight(48)
            self.start_btn.setMinimumWidth(72)
            self.start_btn.setMaximumWidth(140)
        idx = self.row.indexOf(self._tasks_holder)
        if idx >= 0:
            self.row.setStretch(idx, 1)

    def _refresh_group_metrics(self) -> None:
        for group in self._groups.values():
            self._update_group_button_metrics(group)

    def _update_group_button_metrics(self, group: TaskGroup) -> None:
        btn = group.button
        if not btn:
            return
        if self._side in ("left", "right"):
            btn.setIconSize(QSize(28, 28))
            btn.setFixedSize(56, 56)
        else:
            btn.setIconSize(QSize(24, 24))
            btn.setFixedHeight(30)
            btn.setMinimumWidth(44)
            btn.setMaximumWidth(140)
        alignment = Qt.AlignCenter if self._side in ("left", "right") else Qt.AlignVCenter
        self.tasks.setAlignment(btn, alignment)

    def _tick(self):
        self.clock.setText(QDateTime.currentDateTime().toString("hh:mm:ss yyyy-MM-dd"))

    def add_task(self, card: Card):
        profile = getattr(card, "task_profile", None) or card.title_label.text().lower() or f"card-{id(card)}"
        icon = getattr(card, "task_icon", None)
        if icon is None or icon.isNull():
            icon = QApplication.style().standardIcon(QStyle.SP_FileIcon)
        tooltip = getattr(card, "task_tooltip", "") or card.title_label.text()
        group = self._groups.get(profile)
        if group is None:
            btn = QToolButton(self)
            btn.setAutoRaise(True)
            btn.setCheckable(True)
            btn.setCursor(Qt.PointingHandCursor)
            btn.setIcon(icon)
            btn.setToolTip(tooltip)
            btn.setToolButtonStyle(Qt.ToolButtonIconOnly)
            btn.setStyleSheet(
                f"QToolButton{{background:{self.t.task_btn_bg}; border:1px solid {self.t.card_border}; border-radius:8px; padding:4px;}}"
                f"QToolButton:hover{{background:{self.t.task_btn_hv};}}"
                f"QToolButton:checked{{background:{self.t.accent}; border:1px solid {self.t.accent}; color:#fff;}}"
            )
            btn.clicked.connect(lambda _=False, key=profile: self._activate_group(key))
            alignment = Qt.AlignCenter if self._side in ("left", "right") else Qt.AlignVCenter
            self.tasks.addWidget(btn, 0, alignment)
            group = TaskGroup(profile=profile, button=btn, cards=[])
            self._groups[profile] = group
            self._update_group_button_metrics(group)
        if icon and not icon.isNull():
            group.button.setIcon(icon)
        if tooltip:
            group.button.setToolTip(tooltip)
        group.cards.append(card)
        group.index = len(group.cards) - 1
        self._card_group[card] = profile
        group.button.setChecked(True)
        self._refresh_group_tooltip(profile)

        card.closed.connect(lambda _=None, c=card: self._remove_card(c))
        card.minimized.connect(lambda _c, c=card: self._on_card_minimized(c))
        card.restored.connect(lambda _c, c=card: self._on_card_restored(c))

    def _activate_group(self, profile: str):
        group = self._groups.get(profile)
        if not group or not group.cards:
            return
        # prune deleted cards
        group.cards = [c for c in group.cards if c is not None]
        if not group.cards:
            self._remove_group(profile)
            return
        if len(group.cards) == 1:
            card = group.cards[0]
            if card.isVisible() and card.window() and card.window().isActiveWindow():
                card.hide()
                self._set_group_checked(profile)
            else:
                self._show_card(card)
                group.index = 0
            return
        group.index = (group.index + 1) % len(group.cards)
        card = group.cards[group.index]
        self._show_card(card)

    def _show_card(self, card: Card):
        card.show()
        card.raise_()
        card.activateWindow()
        try:
            card.restored.emit(card)
        except Exception:
            pass
        profile = self._card_group.get(card)
        if profile:
            self._set_group_checked(profile)

    def _remove_card(self, card: Card):
        profile = self._card_group.pop(card, None)
        if not profile:
            return
        group = self._groups.get(profile)
        if not group:
            return
        group.cards = [c for c in group.cards if c is not card]
        if not group.cards:
            self._remove_group(profile)
        else:
            group.index = min(group.index, len(group.cards) - 1)
            self._refresh_group_tooltip(profile)
            self._set_group_checked(profile)

    def _remove_group(self, profile: str):
        group = self._groups.pop(profile, None)
        if not group:
            return
        btn = group.button
        if btn:
            btn.setParent(None)
            btn.deleteLater()

    def _set_group_checked(self, profile: str):
        group = self._groups.get(profile)
        if not group:
            return
        any_visible = any(card.isVisible() for card in group.cards)
        group.button.setChecked(any_visible)

    def _on_card_minimized(self, card: Card):
        profile = self._card_group.get(card)
        if profile:
            self._set_group_checked(profile)

    def _on_card_restored(self, card: Card):
        profile = self._card_group.get(card)
        if profile:
            self._set_group_checked(profile)

    def _refresh_group_tooltip(self, profile: str):
        group = self._groups.get(profile)
        if not group:
            return
        cleaned = []
        for card in group.cards:
            text = card.title_label.text() if hasattr(card.title_label, "text") else card.windowTitle()
            if text:
                cleaned.append(text)
        tooltip = "\n".join(cleaned) if cleaned else profile
        group.button.setToolTip(tooltip)

# --------------------------------------------------------------------------------------
# Settings panel (pull former toolbar items here)
# --------------------------------------------------------------------------------------
class SettingsPanel(QWidget):
    def __init__(self, core: "VirtualDesktopCore"):
        super().__init__(core)
        self.core = core
        self.t = core.t
        self.setObjectName("SettingsPanel")
        self._section_frames: Dict[str, QFrame] = {}
        self._pending_section: Optional[str] = None
        self._highlight_timer = QTimer(self)
        self._highlight_timer.setSingleShot(True)
        self._highlight_timer.timeout.connect(self._clear_section_highlight)
        self.setStyleSheet(
            f"QWidget#SettingsPanel{{background:{self.t.card_bg};border:1px solid {self.t.card_border};border-radius:10px;}}"
            f"QLabel{{color:{self.t.header_fg};}} QComboBox,QLineEdit,QPlainTextEdit,QDoubleSpinBox{{background:#0b1828;color:#eaf2ff;border:1px solid {self.t.card_border};border-radius:6px;padding:6px;}}"
            f"QCheckBox{{color:#eaf2ff;}} QPushButton{{background:{self.t.accent};color:#fff;border:1px solid {self.t.card_border};border-radius:6px;padding:6px 10px;}}"
            f"QPushButton:hover{{background:{self.t.accent_hov};}}"
            f"QFrame#SectionFrame{{background:#0b1828;border:1px solid {self.t.card_border};border-radius:8px;}}"
            f"QFrame#SectionFrame[highlighted=\"true\"]{{border:2px solid {self.t.accent};background:#12284a;}}"
        )
        main = QVBoxLayout(self)
        main.setContentsMargins(12, 12, 12, 12)
        main.setSpacing(10)

        title = QLabel("Settings")
        title.setStyleSheet(f"color:{self.t.header_fg}; font:600 12pt 'Cascadia Code';")
        main.addWidget(title)

        self.scroll = QScrollArea(self)
        self.scroll.setWidgetResizable(True)
        self.scroll.setFrameShape(QFrame.NoFrame)
        main.addWidget(self.scroll, 1)

        content = QWidget(self.scroll)
        self.scroll.setWidget(content)
        content_layout = QVBoxLayout(content)
        content_layout.setContentsMargins(0, 0, 0, 0)
        content_layout.setSpacing(10)

        desktop_frame, desktop_layout = self._make_section("desktop", "Desktop")
        content_layout.addWidget(desktop_frame)

        display_frame, display_layout = self._make_section("display", "Display")
        content_layout.addWidget(display_frame)
        content_layout.addStretch(1)

        icon_row = QHBoxLayout()
        icon_row.addWidget(QLabel("Icon size"))
        self.cmb_icon = QComboBox()
        self.cmb_icon.addItems(["small", "medium", "large"])
        self.cmb_icon.setCurrentText(_load_state().get("icon_size", "medium"))
        icon_row.addWidget(self.cmb_icon)
        icon_row.addStretch(1)
        desktop_layout.addLayout(icon_row)

        autohide_row = QHBoxLayout()
        autohide_row.addWidget(QLabel("Taskbar autohide"))
        self.chk_autohide = QCheckBox()
        self.chk_autohide.setChecked(bool(_load_state().get("taskbar_autohide", False)))
        autohide_row.addWidget(self.chk_autohide)
        autohide_row.addStretch(1)
        desktop_layout.addLayout(autohide_row)

        side_row = QHBoxLayout()
        side_row.addWidget(QLabel("Taskbar position"))
        self.cmb_taskbar_side = QComboBox()
        for label, value in (
            ("Bottom", "bottom"),
            ("Top", "top"),
            ("Left", "left"),
            ("Right", "right"),
        ):
            self.cmb_taskbar_side.addItem(label, value)
        stored_side = str(_load_state().get("taskbar_side", "bottom")).lower()
        if stored_side not in Taskbar.SIDES:
            stored_side = "bottom"
        idx_side = self.cmb_taskbar_side.findData(stored_side)
        if idx_side >= 0:
            self.cmb_taskbar_side.setCurrentIndex(idx_side)
        side_row.addWidget(self.cmb_taskbar_side)
        side_row.addStretch(1)
        desktop_layout.addLayout(side_row)

        external_row = QHBoxLayout()
        external_row.addWidget(QLabel("Allow browsing outside workspace"))
        self.chk_external = QCheckBox()
        self.chk_external.setChecked(bool(_load_state().get("allow_external_browse", False)))
        external_row.addWidget(self.chk_external)
        external_row.addStretch(1)
        desktop_layout.addLayout(external_row)

        bg_cfg = core.canvas.background_config()

        scale_row = QHBoxLayout()
        scale_row.addWidget(QLabel("Card scale"))
        self.spin_card_scale = QDoubleSpinBox()
        self.spin_card_scale.setRange(CARD_SCALE_MIN, CARD_SCALE_MAX)
        self.spin_card_scale.setDecimals(2)
        self.spin_card_scale.setSingleStep(0.05)
        self.spin_card_scale.setKeyboardTracking(False)
        self.spin_card_scale.setValue(core.card_scale())
        self.spin_card_scale.setSuffix("×")
        scale_row.addWidget(self.spin_card_scale)
        scale_row.addStretch(1)
        display_layout.addLayout(scale_row)

        mode_row = QHBoxLayout()
        mode_row.addWidget(QLabel("Background mode"))
        self.cmb_bg_mode = QComboBox()
        self.cmb_bg_mode.addItem("Solid (gradient)", BackgroundMode.SOLID)
        self.cmb_bg_mode.addItem("Image", BackgroundMode.STATIC)
        self.cmb_bg_mode.addItem("Animated GIF", BackgroundMode.GIF)
        self.cmb_bg_mode.addItem("Video", BackgroundMode.VIDEO)
        self.cmb_bg_mode.addItem("Live GL viewport", BackgroundMode.GL)
        idx_mode = self.cmb_bg_mode.findData(bg_cfg.mode)
        if idx_mode >= 0:
            self.cmb_bg_mode.setCurrentIndex(idx_mode)
        mode_row.addWidget(self.cmb_bg_mode)
        mode_row.addStretch(1)
        display_layout.addLayout(mode_row)

        path_row = QHBoxLayout()
        path_row.addWidget(QLabel("Background source"))
        self.bg_path_edit = QLineEdit(bg_cfg.source)
        self.bg_path_edit.setReadOnly(True)
        path_row.addWidget(self.bg_path_edit, 1)
        self.btn_bg_browse = QPushButton("Browse…")
        path_row.addWidget(self.btn_bg_browse)
        display_layout.addLayout(path_row)

        fit_row = QHBoxLayout()
        fit_row.addWidget(QLabel("Image fit"))
        self.cmb_bg_fit = QComboBox()
        self.cmb_bg_fit.addItem("Fill", BackgroundFit.FILL)
        self.cmb_bg_fit.addItem("Fit", BackgroundFit.FIT)
        self.cmb_bg_fit.addItem("Center", BackgroundFit.CENTER)
        self.cmb_bg_fit.addItem("Tile", BackgroundFit.TILE)
        idx_fit = self.cmb_bg_fit.findData(bg_cfg.fit)
        if idx_fit >= 0:
            self.cmb_bg_fit.setCurrentIndex(idx_fit)
        fit_row.addWidget(self.cmb_bg_fit)
        fit_row.addStretch(1)
        display_layout.addLayout(fit_row)

        flags_row = QHBoxLayout()
        self.chk_bg_loop = QCheckBox("Loop playback")
        self.chk_bg_loop.setChecked(bool(bg_cfg.loop))
        self.chk_bg_mute = QCheckBox("Mute audio")
        self.chk_bg_mute.setChecked(bool(bg_cfg.mute))
        flags_row.addWidget(self.chk_bg_loop)
        flags_row.addWidget(self.chk_bg_mute)
        flags_row.addStretch(1)
        display_layout.addLayout(flags_row)

        self.cmb_bg_mode.currentIndexChanged.connect(self._update_bg_controls)
        self.btn_bg_browse.clicked.connect(self._browse_background)
        self._update_bg_controls()

        action_row = QHBoxLayout()
        btn_apply = QPushButton("Apply")
        btn_close = QPushButton("Close")
        action_row.addStretch(1)
        action_row.addWidget(btn_apply)
        action_row.addWidget(btn_close)
        main.addLayout(action_row)

        btn_apply.clicked.connect(self._apply)
        btn_close.clicked.connect(self.core._close_settings)

    def _apply(self):
        st = _load_state()
        st["icon_size"] = self.cmb_icon.currentText().strip()
        st["taskbar_autohide"] = bool(self.chk_autohide.isChecked())
        side_data = self.cmb_taskbar_side.currentData()
        side_value = side_data if isinstance(side_data, str) else "bottom"
        if side_value not in Taskbar.SIDES:
            side_value = "bottom"
        st["taskbar_side"] = side_value
        st["allow_external_browse"] = bool(self.chk_external.isChecked())
        st["card_scale"] = float(self.spin_card_scale.value())
        _save_state(st)
        self.core.set_taskbar_autohide(st["taskbar_autohide"])
        self.core.set_taskbar_side(st["taskbar_side"], persist=False)
        self.core.set_allow_external_browse(st["allow_external_browse"])
        self.core.set_card_scale(st["card_scale"])
        cfg = BackgroundConfig.from_state(self.core.canvas.background_config().to_state())
        mode_data = self.cmb_bg_mode.currentData()
        mode = mode_data if isinstance(mode_data, BackgroundMode) else BackgroundMode.SOLID
        cfg.mode = mode
        if mode == BackgroundMode.SOLID:
            cfg.source = ""
        else:
            cfg.source = self.bg_path_edit.text().strip()
        fit_data = self.cmb_bg_fit.currentData()
        cfg.fit = fit_data if isinstance(fit_data, BackgroundFit) else BackgroundFit.FILL
        cfg.loop = bool(self.chk_bg_loop.isChecked())
        cfg.mute = bool(self.chk_bg_mute.isChecked())
        if cfg.source and not self.core.canvas.validate_background_source(cfg.source):
            return
        self.core.canvas.set_background_config(cfg)
        self.core.canvas._refresh_icons()
        QApplication.processEvents()

    def _current_mode(self) -> BackgroundMode:
        mode_data = self.cmb_bg_mode.currentData()
        return mode_data if isinstance(mode_data, BackgroundMode) else BackgroundMode.SOLID

    def _update_bg_controls(self):
        mode = self._current_mode()
        is_solid = mode == BackgroundMode.SOLID
        is_image = mode in (BackgroundMode.STATIC, BackgroundMode.GIF)
        is_video = mode == BackgroundMode.VIDEO
        self.bg_path_edit.setEnabled(not is_solid)
        self.btn_bg_browse.setEnabled(not is_solid)
        self.cmb_bg_fit.setEnabled(is_image)
        self.chk_bg_loop.setEnabled(mode in (BackgroundMode.GIF, BackgroundMode.VIDEO))
        self.chk_bg_mute.setEnabled(is_video)

    def _browse_background(self):
        mode = self._current_mode()
        if mode == BackgroundMode.SOLID:
            return
        path = self.core.canvas.prompt_background_path(mode)
        if path:
            self.bg_path_edit.setText(path)

    def _make_section(self, key: str, title: str) -> Tuple[QFrame, QVBoxLayout]:
        frame = QFrame(self)
        frame.setObjectName("SectionFrame")
        frame.setProperty("highlighted", "false")
        layout = QVBoxLayout(frame)
        layout.setContentsMargins(12, 10, 12, 12)
        layout.setSpacing(8)
        header = QLabel(title)
        header.setStyleSheet(f"color:{self.t.header_fg}; font:600 11pt 'Cascadia Code';")
        layout.addWidget(header)
        self._section_frames[key] = frame
        return frame, layout

    def _set_section_highlight(self, frame: QFrame, highlighted: bool) -> None:
        frame.setProperty("highlighted", "true" if highlighted else "false")
        style = frame.style()
        if style:
            style.unpolish(frame)
            style.polish(frame)
        frame.update()

    def _clear_section_highlight(self) -> None:
        for frame in self._section_frames.values():
            self._set_section_highlight(frame, False)

    def _apply_section_focus(self) -> None:
        if not self._pending_section:
            return
        frame = self._section_frames.get(self._pending_section)
        self._pending_section = None
        if not frame:
            return
        self._clear_section_highlight()
        self._set_section_highlight(frame, True)
        self.scroll.ensureWidgetVisible(frame, 0, 48)
        focus_target = None
        for child in frame.findChildren(QWidget):
            if child.focusPolicy() != Qt.NoFocus:
                focus_target = child
                break
        if focus_target:
            focus_target.setFocus(Qt.OtherFocusReason)
        self._highlight_timer.start(1600)

    def focus_section(self, section: Optional[str]) -> None:
        if not section:
            return
        key = section.lower()
        if key not in self._section_frames:
            return
        self._pending_section = key
        QTimer.singleShot(0, self._apply_section_focus)

    def showEvent(self, event):
        super().showEvent(event)
        if self._pending_section:
            QTimer.singleShot(0, self._apply_section_focus)

# --------------------------------------------------------------------------------------
# Core desktop widget
# --------------------------------------------------------------------------------------
class VirtualDesktopCore(QWidget):
    """Embeddable desktop widget."""
    def __init__(self, workspace: Optional[str] = None, parent: Optional[QWidget] = None):
        super().__init__(parent)
        self.t = Theme()
        self._workspace = workspace or VDSK_ROOT
        self._template_card: Optional[Card] = None
        self._tasks_card: Optional[Card] = None
        self._tasks_widget: Optional["TaskCard"] = None
        self._operator_card: Optional[Card] = None
        self._notes_card: Optional[Card] = None
        self._notes_widget: Optional[QWidget] = None
        self._notes_window: Optional[QMainWindow] = None
        self._notes_card_tag: Optional[str] = None
        self._sys_console: Optional[SystemConsole] = None
        self._error_card: Optional[Card] = None
        self._error_widget: Optional[ErrorCenterCard] = None
        self._system_card: Optional[SystemOverviewCard] = None
        st = _load_state()
        self._card_scale: float = self._clamp_card_scale(st.get("card_scale", 1.0))
        self._allow_external_browse = bool(st.get("allow_external_browse", False))
        self._taskbar_autohide = bool(st.get("taskbar_autohide", False))
        self._taskbar_side = self._normalize_taskbar_side(st.get("taskbar_side", "bottom"))
        tasks_dataset = os.path.join(SCRIPT_DIR, "datasets", "tasks.jsonl")
        self.task_mgr = TaskManager(tasks_dataset, self._workspace)
        if hasattr(self.task_mgr, "start_system_metrics_job"):
            try:
                self.task_mgr.start_system_metrics_job()
            except Exception:
                log("Unable to start system metrics job", logging.DEBUG)
        if hasattr(self.task_mgr, "stop_system_metrics_job"):
            self.destroyed.connect(lambda *_: self.task_mgr.stop_system_metrics_job())

        self._layout = QGridLayout(self)
        self._layout.setContentsMargins(0, 0, 0, 0)
        self._layout.setSpacing(0)

        # Canvas + camera
        canvas_size = self._current_screen_size()
        self.canvas = DesktopCanvas(self.t, canvas_size, self)
        self.camera = Camera(self.canvas, self)

        # Taskbar
        self.taskbar = Taskbar(self.t, self)
        self.taskbar.request_start_menu.connect(self._toggle_start_panel)
        self.taskbar.set_side(self._taskbar_side)
        self._apply_taskbar_side()

        # Docked Start panel (hidden initially)
        self.start_panel = StartPanel(self)
        self.start_panel.cursor_exited.connect(self._hide_start_panel)
        self.start_panel.hide()
        try:
            self.start_panel.warm_index_async()
        except Exception:
            pass

        # Settings panel (card-like small)
        self._settings_card: Optional[Card] = None
        self._settings_panel_widget: Optional[SettingsPanel] = None

        # Automation state
        self._card_seq: int = 0
        self._card_lookup: Dict[int, Card] = {}
        self._last_focus: Optional[Card] = None

        # Debounced screen sync
        self._last_synced_size: Optional[QSize] = None
        self._force_native_taskbar_offset = False
        self._sync_timer = QTimer(self); self._sync_timer.setSingleShot(True)
        self._sync_timer.timeout.connect(self._sync_canvas_to_screen)
        QTimer.singleShot(0, self._sync_canvas_to_screen)

        # Initial workspace
        self.load_workspace(self._workspace)

    # ---------- actions ----------
    def load_workspace(self, folder: Optional[str] = None) -> None:
        folder = folder or self._workspace
        if not folder or not os.path.isdir(folder): return
        if hasattr(self.task_mgr, "set_workspace"):
            try:
                self.task_mgr.set_workspace(folder)
            except Exception:
                log("Task manager workspace update failed", logging.DEBUG)
        self.canvas._refresh_icons()

    def clear_icons(self):
        self.canvas._icons.clear()

    def _iter_cards(self) -> List[Card]:
        return [w for w in self.canvas.findChildren(Card) if isinstance(w, Card)]

    @staticmethod
    def _clamp_card_scale(value: object) -> float:
        try:
            scale = float(value)
        except (TypeError, ValueError):
            return 1.0
        return max(CARD_SCALE_MIN, min(scale, CARD_SCALE_MAX))

    @staticmethod
    def _normalize_taskbar_side(value: object) -> str:
        try:
            side = str(value).lower()
        except Exception:
            return "bottom"
        return side if side in Taskbar.SIDES else "bottom"

    def card_scale(self) -> float:
        return float(self._card_scale)

    def _scaled_card_dimensions(self) -> Tuple[int, int]:
        width = max(MIN_CARD_WIDTH, int(round(BASE_CARD_WIDTH * self._card_scale)))
        height = max(MIN_CARD_HEIGHT, int(round(BASE_CARD_HEIGHT * self._card_scale)))
        return width, height

    def _apply_scale_to_card(self, card: Card, ratio: float) -> None:
        if ratio <= 0:
            return
        geom = card.geometry()
        center = geom.center()
        width = max(MIN_CARD_WIDTH, int(round(geom.width() * ratio)))
        height = max(MIN_CARD_HEIGHT, int(round(geom.height() * ratio)))
        card.resize(width, height)
        new_geom = card.geometry()
        new_geom.moveCenter(center)
        x, y = new_geom.x(), new_geom.y()
        parent = card.parentWidget()
        if parent:
            rect = parent.rect()
            max_x = max(8, rect.width() - width - 8)
            max_y = max(8, rect.height() - height - 8)
            x = max(8, min(x, max_x))
            y = max(8, min(y, max_y))
        card.move(x, y)
        setattr(card, "_vd_scale", self._card_scale)

    def set_card_scale(self, scale: float, *, persist: bool = True) -> None:
        target = self._clamp_card_scale(scale)
        if math.isclose(target, self._card_scale, rel_tol=1e-3):
            return
        previous = self._card_scale if self._card_scale else 1.0
        self._card_scale = target
        ratio = target / previous if previous else 1.0
        for card in self._iter_cards():
            self._apply_scale_to_card(card, ratio)
        if persist:
            st = _load_state()
            st["card_scale"] = self._card_scale
            _save_state(st)
        QApplication.processEvents()

    def taskbar_side(self) -> str:
        return getattr(self, "_taskbar_side", "bottom")

    def set_taskbar_side(self, side: str, *, persist: bool = True) -> None:
        normalized = self._normalize_taskbar_side(side)
        previous = getattr(self, "_taskbar_side", "bottom")
        self._taskbar_side = normalized
        self._apply_taskbar_side()
        if persist and normalized != previous:
            st = _load_state()
            st["taskbar_side"] = normalized
            _save_state(st)
        if normalized != previous:
            self._sync_canvas_to_screen()
        else:
            self._position_start_panel()

    def _apply_taskbar_side(self) -> None:
        layout = getattr(self, "_layout", None)
        if layout is None:
            return
        camera = getattr(self, "camera", None)
        taskbar = getattr(self, "taskbar", None)
        if not camera or not taskbar:
            return
        layout.removeWidget(camera)
        layout.removeWidget(taskbar)
        taskbar.set_side(self._taskbar_side)
        # reset stretches for 2x2 grid
        for row in range(2):
            layout.setRowStretch(row, 0)
        for col in range(2):
            layout.setColumnStretch(col, 0)
        side = self._taskbar_side
        if side == "top":
            layout.addWidget(taskbar, 0, 0)
            layout.addWidget(camera, 1, 0)
            layout.setRowStretch(1, 1)
            layout.setColumnStretch(0, 1)
        elif side == "bottom":
            layout.addWidget(camera, 0, 0)
            layout.addWidget(taskbar, 1, 0)
            layout.setRowStretch(0, 1)
            layout.setColumnStretch(0, 1)
        elif side == "left":
            layout.addWidget(taskbar, 0, 0)
            layout.addWidget(camera, 0, 1)
            layout.setColumnStretch(1, 1)
            layout.setRowStretch(0, 1)
        else:  # right
            layout.addWidget(camera, 0, 0)
            layout.addWidget(taskbar, 0, 1)
            layout.setColumnStretch(0, 1)
            layout.setRowStretch(0, 1)
        layout.invalidate()
        if hasattr(self, "start_panel") and self.start_panel.isVisible():
            self._position_start_panel()

    def taskbar_insets(self) -> Dict[str, int]:
        insets = {"left": 0, "top": 0, "right": 0, "bottom": 0}
        bar = getattr(self, "taskbar", None)
        if not bar:
            return insets
        if getattr(self, "_taskbar_autohide", False) and not bar.underMouse():
            thickness = 0
        else:
            thickness = bar.thickness()
        if thickness <= 0:
            return insets
        side = self._taskbar_side
        if side == "left":
            insets["left"] = thickness
        elif side == "right":
            insets["right"] = thickness
        elif side == "top":
            insets["top"] = thickness
        else:
            insets["bottom"] = thickness
        return insets

    def _position_start_panel(self) -> None:
        panel = getattr(self, "start_panel", None)
        if not panel or not panel.isVisible():
            return
        geom = self._compute_start_panel_rect(panel.size())
        panel.setGeometry(geom)
        panel.raise_()

    def _compute_start_panel_rect(self, size: QSize) -> QRect:
        side = self._taskbar_side
        core_rect = self.rect()
        taskbar_rect = self.taskbar.geometry() if self.taskbar else QRect()
        start_pos = self.taskbar.start_btn.mapTo(self, QPoint(0, 0)) if self.taskbar else QPoint(0, 0)
        start_rect = QRect(start_pos, self.taskbar.start_btn.size() if self.taskbar else QSize(0, 0))
        return self._start_panel_geometry_for_side(side, core_rect, taskbar_rect, start_rect, size)

    @staticmethod
    def _start_panel_geometry_for_side(
        side: str,
        core_rect: QRect,
        taskbar_rect: QRect,
        start_rect: QRect,
        panel_size: QSize,
    ) -> QRect:
        normalized = VirtualDesktopCore._normalize_taskbar_side(side)
        width = max(0, int(panel_size.width()))
        height = max(0, int(panel_size.height()))
        pad = 10

        def clamp(value: int, low: int, high: int) -> int:
            if high < low:
                return low
            return max(low, min(value, high))

        max_x = core_rect.width() - width - pad
        max_y = core_rect.height() - height - pad
        if normalized in ("bottom", "top"):
            anchor_x = clamp(start_rect.left(), pad, max_x)
            if normalized == "bottom":
                anchor_y = clamp(taskbar_rect.top() - height + 2, pad, max_y)
            else:
                anchor_y = clamp(taskbar_rect.bottom() + 2, pad, max_y)
        else:
            anchor_y = clamp(start_rect.top(), pad, max_y)
            if normalized == "left":
                anchor_x = clamp(taskbar_rect.right() + 2, pad, max_x)
            else:
                anchor_x = clamp(taskbar_rect.left() - width - 2, pad, max_x)
        return QRect(anchor_x, anchor_y, width, height)

    def _attach_card(
        self,
        card: Card,
        *,
        task_profile: Optional[str] = None,
        task_icon: Optional[QIcon] = None,
        task_tooltip: Optional[str] = None,
    ) -> Card:
        card.setParent(self.canvas)
        card_id = self._register_card(card)
        card.setMinimumSize(MIN_CARD_WIDTH, MIN_CARD_HEIGHT)
        if card.width() <= 0 or card.height() <= 0:
            width, height = self._scaled_card_dimensions()
            card.resize(width, height)
        setattr(card, "_vd_scale", self._card_scale)
        self._center_card(card)
        card.show()
        card.raise_()
        card.activateWindow()
        tooltip = task_tooltip or self._card_title(card) or "Card"
        profile = task_profile or self._derive_task_profile(self._card_title(card))
        card.set_task_metadata(profile, task_icon, tooltip)
        card.moved.connect(lambda: self._maybe_refocus(card))
        card.closed.connect(self._on_card_closed)
        self.taskbar.add_task(card)
        self._last_focus = card
        log(f"Card added: {self._card_title(card)} (id={card_id})")
        return card

    def add_card(
        self,
        widget: QWidget,
        title: str = "Card",
        *,
        task_profile: Optional[str] = None,
        task_icon: Optional[QIcon] = None,
        task_tooltip: Optional[str] = None,
    ) -> Card:
        card = Card(self.t, title, self.canvas)
        widget.setParent(card.body)
        lay = QVBoxLayout(card.body); lay.setContentsMargins(10, 10, 10, 10); lay.addWidget(widget)
        tooltip = task_tooltip or title
        profile = task_profile or self._derive_task_profile(title)
        return self._attach_card(card, task_profile=profile, task_icon=task_icon, task_tooltip=tooltip)

    def _derive_task_profile(self, title: str) -> str:
        base = title.split("—")[0].strip().lower() if title else "card"
        base = base.replace(" ", "-") or "card"
        return base

    def _center_card(self, card: Card) -> None:
        canvas = self.canvas
        if not canvas:
            return
        viewport = self.camera.viewport() if self.camera else None
        h_scroll = self.camera.horizontalScrollBar() if self.camera else None
        v_scroll = self.camera.verticalScrollBar() if self.camera else None
        offset_x = h_scroll.value() if h_scroll else 0
        offset_y = v_scroll.value() if v_scroll else 0
        if viewport:
            vw = viewport.size()
            cx = offset_x + vw.width() // 2 - card.width() // 2
            cy = offset_y + vw.height() // 2 - card.height() // 2
        else:
            rect = canvas.rect()
            cx = rect.center().x() - card.width() // 2
            cy = rect.center().y() - card.height() // 2
        bounds = canvas.rect()
        max_x = bounds.width() - card.width() - 8
        max_y = bounds.height() - card.height() - 8
        x = max(8, min(cx, max_x))
        y = max(8, min(cy, max_y))
        card.move(x, y)

    def _bring_card_forward(self, card: Card):
        try:
            card.show(); card.raise_(); card.activateWindow()
            self.raise_(); self.activateWindow()
            self.camera.center_on_widget(card)
        except Exception:
            pass

    def _maybe_refocus(self, w: QWidget):
        self.camera.center_on_widget(w)

    def _maybe_clear_focus(self, w: QWidget):
        if getattr(self, "_last_focus", None) is w:
            self._last_focus = None

    def _register_card(self, card: Card) -> int:
        self._card_seq += 1
        card_id = self._card_seq
        setattr(card, "_automation_id", card_id)
        self._card_lookup[card_id] = card
        try:
            card.destroyed.connect(lambda _=None, ident=card_id: self._card_lookup.pop(ident, None))
        except Exception:
            pass
        return card_id

    def _card_title(self, card: Card) -> str:
        if hasattr(card, "title_label") and card.title_label.text():
            return str(card.title_label.text())
        title = card.windowTitle() if hasattr(card, "windowTitle") else ""
        return str(title or "")

    @Slot(object)
    def _on_card_closed(self, card: object) -> None:
        if not isinstance(card, Card):
            return
        self._maybe_clear_focus(card)
        card_id = getattr(card, "_automation_id", None)
        if isinstance(card_id, int):
            self._card_lookup.pop(card_id, None)

    def taskbar_offset(self) -> int:
        return int(self.taskbar_insets().get("bottom", 0))

    def set_taskbar_autohide(self, enabled: bool) -> None:
        self._taskbar_autohide = bool(enabled)

    def allow_external_browse(self) -> bool:
        return bool(getattr(self, "_allow_external_browse", False))

    def set_allow_external_browse(self, enabled: bool) -> None:
        self._allow_external_browse = bool(enabled)

    def has_user_guided_notes(self) -> bool:
        return _USER_GUIDED_NOTES_FACTORY is not None

    def mark_start_index_stale(self) -> None:
        panel = getattr(self, "start_panel", None)
        if panel and hasattr(panel, "mark_index_stale"):
            panel.mark_index_stale()

    def _current_screen(self) -> Optional["QScreen"]:
        win = self.window()
        screen = None
        if win and hasattr(win, "windowHandle"):
            try:
                handle = win.windowHandle()
            except Exception:
                handle = None
            if handle is not None:
                try:
                    screen = handle.screen()
                except Exception:
                    screen = None
        if screen is None:
            try:
                global_pos = self.mapToGlobal(self.rect().center())
            except Exception:
                global_pos = QPoint()
            screen = QGuiApplication.screenAt(global_pos)
        if screen is None:
            screen = QGuiApplication.primaryScreen()
        return screen

    def _current_screen_size(self) -> QSize:
        screen = self._current_screen()
        if screen is None:
            return QSize(0, 0)
        geom = screen.geometry()
        return geom.size()

    def set_force_native_taskbar_offset(self, enabled: bool) -> None:
        self._force_native_taskbar_offset = bool(enabled)

    def _sync_canvas_to_screen(self, force_native_taskbar: bool = False):
        if force_native_taskbar:
            self._force_native_taskbar_offset = True
        screen = self._current_screen()
        is_fullscreen = self._is_borderless_fullscreen()
        is_maximized = self._is_window_maximized()
        use_screen_bounds = is_fullscreen or is_maximized

        top_margin = 0
        bottom_margin = 0
        adjusted = QSize()

        if use_screen_bounds:
            geom = None
            available = None
            if screen is not None:
                try:
                    geom = screen.geometry()
                except Exception:
                    geom = None
                try:
                    available = screen.availableGeometry()
                except Exception:
                    available = None
            if geom is not None:
                base_width = geom.width()
                base_height = geom.height()
            else:
                base_size = self._current_screen_size()
                base_width = base_size.width()
                base_height = base_size.height()
            target_width = base_width
            if geom is not None and available is not None:
                top_margin = max(0, available.top() - geom.top())
                bottom_margin = max(0, geom.bottom() - available.bottom())
                target_width = available.width()
            should_use_native_taskbar = (
                screen is not None
                and (self._force_native_taskbar_offset or self._should_use_native_taskbar_offset())
            )
            if should_use_native_taskbar:
                try:
                    native_offset = int(self._native_windows_taskbar_height())
                except Exception:
                    native_offset = 0
                bottom_margin = max(bottom_margin, native_offset)
            target_height = max(0, base_height - top_margin - bottom_margin)
            if geom is not None and available is not None:
                target_height = min(target_height, available.height())
            adjusted = QSize(max(0, target_width), target_height)
        else:
            camera = getattr(self, "camera", None)
            viewport_size = QSize()
            if camera is not None:
                try:
                    viewport = camera.viewport()
                except Exception:
                    viewport = None
                if viewport is not None:
                    viewport_size = viewport.size()
                if (not viewport_size.isValid() or viewport_size.isEmpty()) and hasattr(camera, "size"):
                    try:
                        viewport_size = camera.size()
                    except Exception:
                        viewport_size = QSize()
            if not viewport_size.isValid() or viewport_size.isEmpty():
                viewport_size = self.size()
            adjusted = QSize(max(0, viewport_size.width()), max(0, viewport_size.height()))

        layout = getattr(self, "_layout", None)
        if layout is not None:
            margins = layout.contentsMargins()
            if (
                margins.left() != 0
                or margins.top() != top_margin
                or margins.right() != 0
                or margins.bottom() != bottom_margin
            ):
                layout.setContentsMargins(0, top_margin, 0, bottom_margin)
        if self._last_synced_size and adjusted == self._last_synced_size:
            return
        self._last_synced_size = QSize(adjusted)
        self.canvas.resize(adjusted)
        self.camera.center_on_widget(self.canvas)
        log(f"Canvas synced to screen: {adjusted.width()}x{adjusted.height()}")

    def _should_use_native_taskbar_offset(self) -> bool:
        if self.taskbar_side() != "bottom":
            return False
        if self._is_borderless_fullscreen():
            return False
        return self._is_window_maximized()

    def _is_borderless_fullscreen(self) -> bool:
        win = self.window()
        if not win:
            return False
        try:
            return bool(win.isFullScreen())
        except Exception:
            return False

    def _is_window_maximized(self) -> bool:
        win = self.window()
        if not win:
            return False
        try:
            if hasattr(win, "isMaximized") and win.isMaximized():
                return True
        except Exception:
            return False
        try:
            state = win.windowState() if hasattr(win, "windowState") else None
        except Exception:
            state = None
        if state is None:
            return False
        try:
            return bool(state & Qt.WindowMaximized)
        except Exception:
            return False

    @staticmethod
    def _native_windows_taskbar_height() -> int:
        return _query_windows_taskbar_height()

    def _toast(self, msg: str, *, kind: str = "info"):
        box = QWidget()
        box.setAttribute(Qt.WA_StyledBackground, True)
        v = QVBoxLayout(box); v.setContentsMargins(12, 12, 12, 12); v.setSpacing(4)
        lab = QLabel(msg)
        lab.setWordWrap(True)
        if kind == "error":
            box.setStyleSheet("background:#3a0f19; border:1px solid #ff6d88; border-radius:12px;")
            lab.setStyleSheet("color:#ffeef4; font:600 10pt 'Cascadia Code';")
            icon = QApplication.style().standardIcon(QStyle.SP_MessageBoxCritical)
            title = "Blocked"
            profile = "toast-blocked"
            timeout = 3200
        else:
            box.setStyleSheet("background:#0f1d33; border:1px solid #2f72ff; border-radius:12px;")
            lab.setStyleSheet("color:#eaf2ff; font:600 10pt 'Cascadia Code';")
            icon = QApplication.style().standardIcon(QStyle.SP_MessageBoxInformation)
            title = "Notice"
            profile = "toast"
            timeout = 2000
        v.addWidget(lab)
        card = self.add_card(box, title, task_profile=profile, task_icon=icon, task_tooltip=msg)
        QTimer.singleShot(timeout, lambda: card._close_card())
        log(f"Toast[{kind}]: {msg}")

    # ---------- Automation hooks ----------
    def list_cards(self) -> List[Dict[str, object]]:
        """Return metadata for all open cards in a deterministic order."""
        cards: List[Dict[str, object]] = []
        for card in sorted(self._iter_cards(), key=lambda c: getattr(c, "_automation_id", 0)):
            card_id = getattr(card, "_automation_id", None)
            if not isinstance(card_id, int):
                card_id = self._register_card(card)
            cards.append(self._serialize_card(card, card_id))
        return cards

    def _serialize_card(self, card: Card, card_id: int) -> Dict[str, object]:
        title = self._card_title(card)
        geometry = {
            "card": _widget_geometry_snapshot(card),
            "header": _widget_geometry_snapshot(getattr(card, "header", None)),
            "body": _widget_geometry_snapshot(getattr(card, "body", None)),
        }
        data: Dict[str, object] = {
            "id": card_id,
            "title": title,
            "profile": getattr(card, "task_profile", ""),
            "tooltip": getattr(card, "task_tooltip", title),
            "persist_tag": getattr(card, "_persist_tag", None),
            "visible": bool(card.isVisible()),
            "maximized": bool(getattr(card, "_maximized", False)),
            "geometry": geometry,
        }
        return data

    def focus_card(self, identifier: Union[int, str]) -> bool:
        """Focus the first card matching the identifier (id or title)."""
        target: Optional[Card] = None
        if isinstance(identifier, int):
            target = self._card_lookup.get(identifier)
        else:
            name = str(identifier or "").strip()
            if not name:
                return False
            # Prefer exact match, then case-insensitive, then substring
            for card in self._iter_cards():
                if self._card_title(card) == name:
                    target = card
                    break
            if target is None:
                lowered = name.lower()
                for card in self._iter_cards():
                    if self._card_title(card).lower() == lowered:
                        target = card
                        break
            if target is None:
                lowered = name.lower()
                for card in self._iter_cards():
                    if lowered in self._card_title(card).lower():
                        target = card
                        break
        if target is None:
            return False
        if not target.isVisible():
            target.show()
        self._bring_card_forward(target)
        self._last_focus = target
        return True

    def list_icons(self) -> List[Dict[str, object]]:
        """List desktop icons with geometry suitable for automation."""
        icons: List[Dict[str, object]] = []
        icon_widgets = getattr(self.canvas, "_icons", {})
        for path in sorted(icon_widgets.keys()):
            widget = icon_widgets.get(path)
            if widget is None:
                continue
            entry: Dict[str, object] = {
                "path": path,
                "title": widget.text() if hasattr(widget, "text") else os.path.basename(path),
                "kind": "folder" if os.path.isdir(path) else "file",
                "geometry": _widget_geometry_snapshot(widget),
            }
            icons.append(entry)
        return icons

    def open(self, path: str) -> Dict[str, object]:
        """Open a path inside the Virtual Desktop and report success."""
        result: Dict[str, object] = {"success": False, "card_id": None, "path": path}
        if not path:
            result["error"] = "empty path"
            return result
        target = path
        if not os.path.isabs(target):
            base = self._workspace or VDSK_ROOT
            target = os.path.join(base, path)
        target = os.path.abspath(target)
        result["resolved_path"] = target
        if not os.path.exists(target):
            result["error"] = "path not found"
            return result
        before = set(self._card_lookup.keys())
        try:
            self.open_any_path(target)
        except Exception as exc:
            log(f"Automation open failed: {exc}", logging.WARNING)
            result["error"] = str(exc)
            return result
        app = QApplication.instance()
        if app is not None:
            try:
                app.processEvents()
            except Exception:
                pass
        after = set(self._card_lookup.keys())
        new_ids = sorted(after - before)
        result["success"] = True
        if new_ids:
            result["card_id"] = new_ids[-1]
        return result

    def search(self, query: str, facet: Optional[str] = None) -> Dict[str, object]:
        """Run the Start menu search without mutating UI state."""
        panel = getattr(self, "start_panel", None)
        if panel is None:
            return {"query": query, "facet": facet or "all", "Apps": [], "Recent": [], "Files": []}
        q = (query or "").strip()
        if not q:
            return {"query": q, "facet": facet or panel._facet, "Apps": [], "Recent": [], "Files": []}
        allowed = {key for key, _ in getattr(panel, "FACETS", [])}
        prev_facet = panel._facet
        facet_to_use = prev_facet
        if facet:
            candidate = str(facet).strip().lower()
            facet_to_use = candidate if candidate in allowed else "all"
        try:
            panel._facet = facet_to_use
            panel._ensure_index()
            results = panel._perform_search(q)
        finally:
            panel._facet = prev_facet
        return self._serialize_search_results(results, facet_to_use, q)

    def _serialize_search_results(
        self, results: Dict[str, List[Dict[str, object]]], facet: str, query: str
    ) -> Dict[str, object]:
        payload: Dict[str, object] = {"query": query, "facet": facet, "Apps": [], "Recent": [], "Files": []}
        apps_serialized: List[Dict[str, object]] = []
        for item in results.get("Apps", []):
            apps_serialized.append(
                {
                    "id": str(item.get("id", "")),
                    "title": str(item.get("title", "")),
                    "tooltip": str(item.get("tooltip", item.get("title", ""))),
                }
            )
        payload["Apps"] = apps_serialized
        recent_serialized: List[Dict[str, object]] = []
        for item in results.get("Recent", []):
            entry: Dict[str, object] = {
                "title": str(item.get("title") or item.get("path") or ""),
                "path": str(item.get("path", "")),
                "kind": str(item.get("kind", "")),
            }
            if item.get("ts") is not None:
                try:
                    entry["ts"] = int(item.get("ts"))
                except Exception:
                    pass
            recent_serialized.append(entry)
        payload["Recent"] = recent_serialized
        files_serialized: List[Dict[str, object]] = []
        for item in results.get("Files", []):
            files_serialized.append(
                {
                    "title": str(item.get("title", "")),
                    "path": str(item.get("path", "")),
                    "kind": str(item.get("kind", "")),
                }
            )
        payload["Files"] = files_serialized
        return payload

    def geometry_snapshot(self) -> Dict[str, object]:
        """Provide geometry for key widgets (camera, taskbar, start)."""
        snapshot: Dict[str, object] = {
            "workspace_root": self._workspace or VDSK_ROOT,
            "taskbar_autohide": bool(self._taskbar_autohide),
            "taskbar_offset": self.taskbar_offset(),
            "taskbar_side": self.taskbar_side(),
            "core": _widget_geometry_snapshot(self),
            "camera": _widget_geometry_snapshot(self.camera),
            "camera_viewport": _widget_geometry_snapshot(self.camera.viewport() if self.camera else None),
            "canvas": _widget_geometry_snapshot(self.canvas),
            "taskbar": _widget_geometry_snapshot(self.taskbar),
            "start_button": _widget_geometry_snapshot(self.taskbar.start_btn if self.taskbar else None),
        }
        snapshot["start_panel"] = _widget_geometry_snapshot(self.start_panel if self.start_panel.isVisible() else None)
        snapshot["cards"] = self.list_cards()
        snapshot["icons"] = self.list_icons()
        return snapshot

    # ---------- Start panel ----------
    def _hide_start_panel(self) -> None:
        if getattr(self, "start_panel", None) and self.start_panel.isVisible():
            self.start_panel.hide()

    def _toggle_start_panel(self):
        if self.start_panel.isVisible():
            self._hide_start_panel()
            return
        horizontal = self._taskbar_side in ("bottom", "top")
        thickness = self.taskbar.thickness() if self.taskbar else 0
        available_width = self.width() - (thickness if not horizontal else 0) - 30
        available_height = self.height() - (thickness if horizontal else 0) - 30
        available_width = max(200, available_width)
        available_height = max(200, available_height)
        if horizontal:
            width = int(min(780, max(260, available_width)))
            height = int(
                min(
                    460,
                    max(240, int(self.height() * 0.55), available_height),
                )
            )
        else:
            width = int(min(560, max(240, available_width)))
            height = int(min(600, max(260, available_height)))
        panel_size = QSize(width, height)
        geom = self._compute_start_panel_rect(panel_size)
        self.start_panel.setParent(self)
        self.start_panel.setProperty("side", self._taskbar_side)
        panel_style = self.start_panel.style()
        if panel_style:
            panel_style.unpolish(self.start_panel)
            panel_style.polish(self.start_panel)
        self.start_panel.setGeometry(geom)
        self.start_panel._populate_recent()
        self.start_panel.show()
        self.start_panel.raise_()

    # ---------- Settings ----------
    def _open_settings_panel(self, section: Optional[str] = None):
        if self._settings_card and self._settings_card.isVisible():
            self._bring_card_forward(self._settings_card)
            if section and isinstance(self._settings_panel_widget, SettingsPanel):
                self._settings_panel_widget.focus_section(section)
            return
        panel = SettingsPanel(self)
        self._settings_panel_widget = panel
        settings_icon = QApplication.style().standardIcon(QStyle.SP_FileDialogDetailedView)
        self._settings_card = self.add_card(
            panel,
            "Settings",
            task_profile="settings",
            task_icon=settings_icon,
            task_tooltip="Desktop Settings",
        )
        tag = "(builtin:settings)"
        self._settings_card.set_persist_tag(tag)
        _restore_card_geom(self._settings_card, "template", tag)
        self._settings_card.moved.connect(lambda: _save_card_geom(self._settings_card, "template", tag))
        self._settings_card.resized.connect(lambda: _save_card_geom(self._settings_card, "template", tag))
        self._settings_card.closed.connect(lambda _=None: self._on_settings_closed())
        if section:
            panel.focus_section(section)

    def _close_settings(self):
        if self._settings_card:
            self._settings_card._close_card()
        self._on_settings_closed()

    def _on_settings_closed(self) -> None:
        self._settings_card = None
        self._settings_panel_widget = None

    # ---------- App launchers ----------
    def _load_script_dialog(self):
        path, _ = _non_native_open_file(self, "Load Script as Card…", self._workspace or SCRIPT_DIR,
                                        "Python (*.py);;Executables (*.exe *.bat *.cmd *.sh);;All files (*.*)")
        if not path: return
        self.open_any_path(path)

    def open_any_path(self, path: str):
        if not path:
            return
        resolved = os.path.abspath(path)
        if not _is_contained(resolved) and not self.allow_external_browse():
            self._toast("Blocked: path is outside the Virtual Desktop workspace.", kind="error")
            log(f"Blocked open outside workspace: {resolved}", logging.WARNING)
            return
        if os.path.isdir(resolved):
            widget = ExplorerCard(resolved, self.open_any_path, self.t, refresh_hook=self.canvas._refresh_icons)
            explorer_icon = QApplication.style().standardIcon(QStyle.SP_DirIcon)
            card = self.add_card(
                widget,
                f"Explorer — {os.path.basename(resolved) or resolved}",
                task_profile="explorer",
                task_icon=explorer_icon,
                task_tooltip=resolved,
            )
            tag = f"(explorer:{resolved})"
            card.set_persist_tag(tag)
            _restore_card_geom(card, "template", tag)
            card.moved.connect(lambda: _save_card_geom(card, "template", tag))
            card.resized.connect(lambda: _save_card_geom(card, "template", tag))
            self._bring_card_forward(card)
            self.mark_start_index_stale()
            return

        ext = os.path.splitext(resolved)[1].lower()
        if ext in {".txt", ".md", ".log", ".ini", ".cfg", ".json"}:
            widget = TextViewer(resolved, self.t)
            title = f"Text — {os.path.basename(resolved)}"
            text_icon = QApplication.style().standardIcon(QStyle.SP_FileDialogDetailedView)
            card = self.add_card(
                widget,
                title,
                task_profile="text-viewer",
                task_icon=text_icon,
                task_tooltip=resolved,
            )
            tag = resolved
            card.set_persist_tag(tag)
            _restore_card_geom(card, "text", tag)
            card.moved.connect(lambda: _save_card_geom(card, "text", tag))
            card.resized.connect(lambda: _save_card_geom(card, "text", tag))
            self._bring_card_forward(card)
            _remember_card("text", resolved, title)
        elif ext in {".png", ".jpg", ".jpeg", ".gif", ".bmp"}:
            widget = ImageViewer(resolved, self.t)
            title = f"Image — {os.path.basename(resolved)}"
            image_icon = QApplication.style().standardIcon(QStyle.SP_FileDialogContentsView)
            card = self.add_card(
                widget,
                title,
                task_profile="image-viewer",
                task_icon=image_icon,
                task_tooltip=resolved,
            )
            tag = resolved
            card.set_persist_tag(tag)
            _restore_card_geom(card, "image", tag)
            card.moved.connect(lambda: _save_card_geom(card, "image", tag))
            card.resized.connect(lambda: _save_card_geom(card, "image", tag))
            self._bring_card_forward(card)
            _remember_card("image", resolved, title)
        elif ext == ".py":
            if self._load_python_as_card(resolved, persist_key=resolved) is None:
                self._load_process_card(resolved, os.path.basename(resolved), persist_key=resolved)
        else:
            self._load_process_card(resolved, os.path.basename(resolved), persist_key=resolved)
        self.mark_start_index_stale()
        QApplication.processEvents()

    def _call_factory(self, factory):
        sig = inspect.signature(factory)
        if "embedded" in sig.parameters:
            return factory(None, embedded=True)
        return factory(None)

    def _instantiate_card_from_factory(
        self,
        factory: Callable[..., object],
        *,
        default_title: str,
        task_profile: Optional[str] = None,
        task_icon: Optional[QIcon] = None,
        task_tooltip: Optional[str] = None,
    ) -> Tuple[Card, Dict[str, object]]:
        output = self._call_factory(factory)
        title = default_title
        profile = task_profile
        icon = task_icon
        tooltip = task_tooltip
        metadata: Dict[str, object] = {}

        payload: object = output
        extras: Sequence[object] = []
        if isinstance(output, (list, tuple)):
            seq = list(output)
            payload = seq[0] if seq else None
            extras = seq[1:]
            if extras and isinstance(extras[0], str):
                maybe_title = extras[0].strip()
                if maybe_title:
                    title = maybe_title
                extras = extras[1:]
            if extras and isinstance(extras[0], Mapping):
                meta_map = dict(extras[0])
                maybe_title = meta_map.get("title")
                if isinstance(maybe_title, str) and maybe_title.strip():
                    title = maybe_title.strip()
                maybe_profile = meta_map.get("task_profile")
                if isinstance(maybe_profile, str) and maybe_profile.strip():
                    profile = maybe_profile.strip()
                maybe_tooltip = meta_map.get("task_tooltip")
                if isinstance(maybe_tooltip, str) and maybe_tooltip.strip():
                    tooltip = maybe_tooltip.strip()
                maybe_icon = meta_map.get("task_icon")
                if isinstance(maybe_icon, QIcon):
                    icon = maybe_icon
                if meta_map.get("persist_tag") is not None:
                    metadata["persist_tag"] = str(meta_map["persist_tag"])

        final_title = title or default_title
        final_profile = profile
        final_icon = icon
        final_tooltip = tooltip or final_title

        if isinstance(payload, Card):
            card = payload
            if final_title and final_title != self._card_title(card) and hasattr(card, "title_label"):
                card.title_label.setText(final_title)
            if not final_profile:
                existing_profile = getattr(card, "task_profile", None)
                if isinstance(existing_profile, str) and existing_profile:
                    final_profile = existing_profile
                else:
                    final_profile = "card"
            if final_icon is None:
                existing_icon = getattr(card, "task_icon", None)
                if isinstance(existing_icon, QIcon) and not existing_icon.isNull():
                    final_icon = existing_icon
            if not final_tooltip:
                existing_tooltip = getattr(card, "task_tooltip", None)
                if isinstance(existing_tooltip, str) and existing_tooltip:
                    final_tooltip = existing_tooltip
                else:
                    final_tooltip = final_title
            card = self._attach_card(
                card,
                task_profile=final_profile,
                task_icon=final_icon,
                task_tooltip=final_tooltip,
            )
        elif isinstance(payload, QWidget):
            final_profile = final_profile or "python-card"
            card = self.add_card(
                payload,
                final_title,
                task_profile=final_profile,
                task_icon=final_icon,
                task_tooltip=final_tooltip,
            )
        else:
            raise RuntimeError("factory returned unsupported object")

        metadata.setdefault("title", final_title)
        metadata.setdefault("task_profile", final_profile)
        if final_icon is not None:
            metadata.setdefault("task_icon", final_icon)
        metadata.setdefault("task_tooltip", final_tooltip)
        return card, metadata

    def _load_python_as_card(
        self,
        path: str,
        persist_key: Optional[str]=None,
        nice_title: Optional[str]=None,
        task_profile: Optional[str]=None,
        task_icon: Optional[QIcon]=None,
        task_tooltip: Optional[str]=None,
    ) -> Optional[Card]:
        log(f"Load python as card: {path}")
        try:
            name = f"card_{int(time.time())}_{os.path.splitext(os.path.basename(path))[0]}"
            spec = importlib.util.spec_from_file_location(name, path)
            if not spec or not spec.loader:
                raise RuntimeError("spec loader failed")
            mod = importlib.util.module_from_spec(spec)
            sys.modules[name] = mod
            spec.loader.exec_module(mod)  # type: ignore
        except Exception as e:
            self._toast(f"Import failed: {e}")
            log(f"Import failed: {e}", logging.ERROR)
            return None

        factory = getattr(mod, "build_widget", None)
        if not callable(factory):
            factory = getattr(mod, "create_card", None)
        if not callable(factory):
            self._toast("No build_widget/create_card; running as process instead.")
            log("card factory not found; falling back to process", logging.INFO)
            return None

        default_title = nice_title or os.path.basename(path)
        default_icon = task_icon or QApplication.style().standardIcon(QStyle.SP_DesktopIcon)
        default_profile = task_profile or "python-card"
        default_tooltip = task_tooltip or path

        old_flag = os.environ.get("CODEX_EMBEDDED")
        os.environ["CODEX_EMBEDDED"] = "1"  # hint for embedded-compatible widgets
        try:
            card, card_meta = self._instantiate_card_from_factory(
                factory,
                default_title=default_title,
                task_profile=default_profile,
                task_icon=default_icon,
                task_tooltip=default_tooltip,
            )
        except Exception as e:
            if old_flag is None:
                os.environ.pop("CODEX_EMBEDDED", None)
            else:
                os.environ["CODEX_EMBEDDED"] = old_flag
            self._toast(f"factory error: {e}")
            log(
                f"factory error: {e}\n{traceback.format_exc()}",
                logging.ERROR,
            )
            return None
        finally:
            if old_flag is None:
                os.environ.pop("CODEX_EMBEDDED", None)
            else:
                os.environ["CODEX_EMBEDDED"] = old_flag

        persist_tag = persist_key or str(card_meta.get("persist_tag", "")).strip() or None
        if persist_tag:
            card.set_persist_tag(persist_tag)
            _restore_card_geom(card, "py_card", persist_tag)
            card.moved.connect(lambda: _save_card_geom(card, "py_card", persist_tag))
            card.resized.connect(lambda: _save_card_geom(card, "py_card", persist_tag))

        title_for_log = str(card_meta.get("title", default_title))
        card.closed.connect(lambda _: log(f"Card closed: {title_for_log}"))
        self._bring_card_forward(card)
        _remember_card("py_card", path, title_for_log)
        log(f"Card loaded: {title_for_log}")
        return card

    def _load_process_card(self, path: str, title: str, persist_key: Optional[str]=None):
        cmd = [path]
        if path.lower().endswith(".py"):
            cmd = [sys.executable, path]
        log(f"Run process as card: {cmd}")
        widget = ProcessErrorCard(
            self.t,
            cmd,
            cwd=os.path.dirname(path) or SCRIPT_DIR,
            guard=_validate_process_request,
            violation_cb=lambda m: self._toast(m, kind="error"),
        )
        widget.isolation_requested.connect(
            lambda message, code: self._handle_process_isolation(message, code, path)
        )
        proc_icon, _ = _icon_for_path(path)
        card = self.add_card(
            widget,
            f"Process — {title}",
            task_profile="process",
            task_icon=proc_icon,
            task_tooltip=path,
        )
        widget.close_requested.connect(card.close)
        card.closed.connect(lambda _=None: widget.stop())
        if persist_key:
            card.set_persist_tag(persist_key)
            _restore_card_geom(card, "process", persist_key)
            card.moved.connect(lambda: _save_card_geom(card, "process", persist_key))
            card.resized.connect(lambda: _save_card_geom(card, "process", persist_key))
        self._bring_card_forward(card)
        _remember_card("process", path, title)

    def _handle_process_isolation(self, message: str, code: Optional[int], path: str) -> None:
        detail = message or "Process failure detected."
        if code is not None:
            detail = f"{detail} (exit code {code})"
        self._toast(detail, kind="error")
        log(f"[process-error] {detail} — {path}", logging.ERROR)

    def _open_system_console(self):
        if self._sys_console and self._sys_console.isVisible():
            self._sys_console.raise_(); self._sys_console.activateWindow(); return
        self._sys_console = SystemConsole(self.t, LOG_PATH)
        self._sys_console.setParent(self.window())  # containment
        self._sys_console.show()
        log("System Console opened")

    def _open_error_center(self) -> None:
        if self._error_card and self._error_card.isVisible():
            self._bring_card_forward(self._error_card)
            self.camera.center_on_widget(self._error_card)
            return
        can_open_tasks = not isinstance(self.task_mgr, _FallbackTaskManager)
        callback = self._open_tasks_from_error_center if can_open_tasks else None
        widget = ErrorCenterCard(self.t, LOG_PATH, open_task=callback)
        if can_open_tasks:
            widget.task_requested.connect(self._open_tasks_from_error_center)
        else:
            widget.set_open_task_callback(None)
        error_icon = QApplication.style().standardIcon(QStyle.SP_MessageBoxCritical)
        card = self.add_card(
            widget,
            "Error Center",
            task_profile="error-center",
            task_icon=error_icon,
            task_tooltip="Error Center",
        )
        tag = "(builtin:error-center)"
        card.set_persist_tag(tag)
        _restore_card_geom(card, "builtin", tag)
        card.moved.connect(lambda: _save_card_geom(card, "builtin", tag))
        card.resized.connect(lambda: _save_card_geom(card, "builtin", tag))
        card.closed.connect(self._on_error_center_closed)
        self._error_card = card
        self._error_widget = widget
        self._bring_card_forward(card)
        self.camera.center_on_widget(card)
        _remember_card("builtin", tag, "Error Center")
        log("Error Center opened")

    def _on_error_center_closed(self, *_):
        self._error_card = None
        self._error_widget = None

    def _open_tasks_from_error_center(self, task_id: Optional[str]) -> None:
        if not task_id:
            return
        self._open_tasks(task_id=task_id)

    def _open_code_editor(self, path: Optional[str] = None) -> None:
        if not path:
            self._toast("No file selected for editor.")
            return
        resolved = path
        if not os.path.isabs(resolved):
            base = self._workspace or VDSK_ROOT
            resolved = os.path.join(base, path)
        if not os.path.isfile(resolved):
            self._toast(f"File not found: {resolved}")
            log(f"Editor open skipped; missing file {resolved}", logging.WARNING)
            return
        try:
            storage_root = Path(self._workspace or VDSK_ROOT) / "memory"
            widget = build_editor_widget(
                parent=None,
                initial_path=resolved,
                storage_root=storage_root,
            )
        except Exception as exc:
            self._toast("Unable to open editor card.")
            log(f"Editor widget failed for {resolved}: {exc}", logging.ERROR)
            return
        title = f"Editor — {os.path.basename(resolved)}"
        editor_icon = QApplication.style().standardIcon(QStyle.SP_FileDialogDetailedView)
        card = self.add_card(
            widget,
            title,
            task_profile="editor",
            task_icon=editor_icon,
            task_tooltip=resolved,
        )
        tag = f"(editor:{resolved})"
        card.set_persist_tag(tag)
        _restore_card_geom(card, "editor", tag)
        card.moved.connect(lambda: _save_card_geom(card, "editor", tag))
        card.resized.connect(lambda: _save_card_geom(card, "editor", tag))
        self._bring_card_forward(card)
        self.camera.center_on_widget(card)
        _remember_card("editor", resolved, title)
        log(f"Editor opened for {resolved}")

    def _open_terminal_at(self, directory: Optional[str] = None) -> None:
        base = directory or self._workspace or SCRIPT_DIR
        cwd = base if os.path.isdir(base) else os.path.dirname(base) or (self._workspace or SCRIPT_DIR)
        if not os.path.isdir(cwd):
            self._toast(f"Folder not found: {cwd}")
            log(f"Terminal launch skipped; missing folder {cwd}", logging.WARNING)
            return
        if os.name == "nt":
            shell = os.environ.get("COMSPEC", "cmd.exe")
            cmd = [shell]
        else:
            shell = os.environ.get("SHELL", "/bin/bash")
            cmd = [shell]
        title = f"Terminal — {os.path.basename(cwd) or cwd}"
        widget = ProcessConsole(
            self.t,
            cmd,
            cwd=cwd,
            guard=_validate_process_request,
            violation_cb=lambda m: self._toast(m, kind="error"),
        )
        term_icon = QApplication.style().standardIcon(QStyle.SP_ComputerIcon)
        card = self.add_card(
            widget,
            title,
            task_profile="terminal",
            task_icon=term_icon,
            task_tooltip=cwd,
        )
        tag = f"(terminal:{cwd})"
        card.set_persist_tag(tag)
        _restore_card_geom(card, "process", tag)
        card.moved.connect(lambda: _save_card_geom(card, "process", tag))
        card.resized.connect(lambda: _save_card_geom(card, "process", tag))
        self._bring_card_forward(card)
        self.camera.center_on_widget(card)
        _remember_card("process", cwd, title)
        log(f"Terminal card opened at {cwd}")

    def _open_explorer(self):
        widget = ExplorerCard(self._workspace, self.open_any_path, self.t, refresh_hook=self.canvas._refresh_icons)
        explorer_icon = QApplication.style().standardIcon(QStyle.SP_DirIcon)
        card = self.add_card(
            widget,
            "Desktop Explorer",
            task_profile="explorer",
            task_icon=explorer_icon,
            task_tooltip=self._workspace,
        )
        tag = "(builtin:explorer)"
        card.set_persist_tag(tag)
        _restore_card_geom(card, "template", tag)
        card.moved.connect(lambda: _save_card_geom(card, "template", tag))
        card.resized.connect(lambda: _save_card_geom(card, "template", tag))
        self._bring_card_forward(card)

    def _open_operator_manager(self) -> None:
        if self._operator_card:
            self._bring_card_forward(self._operator_card)
            return
        widget = OperatorManagerWidget(self.t)
        ops_icon = QApplication.style().standardIcon(QStyle.SP_DesktopIcon)
        card = self.add_card(
            widget,
            "Operator Manager",
            task_profile="operator-manager",
            task_icon=ops_icon,
            task_tooltip="Operator Manager",
        )
        tag = "(builtin:operators)"
        card.set_persist_tag(tag)
        card.closed.connect(lambda _: setattr(self, "_operator_card", None))
        self._operator_card = card
        self._bring_card_forward(card)
        _remember_card("builtin", tag, "Operator Manager")
        log("Operator Manager opened")

    def _open_tasks(self, task_id: Optional[str] = None) -> None:
        if self._tasks_card and self._tasks_card.isVisible():
            self._bring_card_forward(self._tasks_card)
            self.camera.center_on_widget(self._tasks_card)
            if task_id:
                QTimer.singleShot(0, lambda: self._focus_task(task_id))
            return
        widget = open_card(
            self.task_mgr,
            self.t,
            self._open_code_editor,
            self._open_terminal_at,
            workspace_root=self._workspace,
            source="desktop",
        )
        if widget is None:
            return
        tasks_icon = QApplication.style().standardIcon(QStyle.SP_FileDialogListView)
        card = self.add_card(
            widget,
            "Tasks",
            task_profile="tasks",
            task_icon=tasks_icon,
            task_tooltip="Tasks",
        )
        tag = "(builtin:tasks)"
        card.set_persist_tag(tag)
        _restore_card_geom(card, "template", tag)
        card.moved.connect(lambda: _save_card_geom(card, "template", tag))
        card.resized.connect(lambda: _save_card_geom(card, "template", tag))
        card.closed.connect(self._on_tasks_card_closed)
        self._tasks_card = card
        self._tasks_widget = widget
        self._bring_card_forward(card)
        self.camera.center_on_widget(card)
        _remember_card("template", "(builtin:tasks)", "Tasks")
        log("Tasks card opened")
        if task_id:
            QTimer.singleShot(200, lambda: self._focus_task(task_id))

    def _open_user_guided_notes(self) -> Optional[Card]:
        if _USER_GUIDED_NOTES_FACTORY is None:
            self._toast("User-Guided Notes is unavailable.", kind="error")
            log("User_Guided_Notes factory unavailable", logging.INFO)
            return None
        if self._notes_window and self._notes_window.isVisible():
            try:
                self._notes_window.show()
                self._notes_window.raise_()
                self._notes_window.activateWindow()
            except Exception:
                pass
            return None
        if self._notes_card and self._notes_card.isVisible():
            self._bring_card_forward(self._notes_card)
            self.camera.center_on_widget(self._notes_card)
            return self._notes_card
        notes_icon = QApplication.style().standardIcon(QStyle.SP_FileDialogDetailedView)
        try:
            card, meta = self._instantiate_card_from_factory(
                _USER_GUIDED_NOTES_FACTORY,
                default_title="User-Guided Notes",
                task_profile="notes",
                task_icon=notes_icon,
                task_tooltip="User-Guided Notes",
            )
        except Exception as exc:
            self._toast("Unable to open Notes card.", kind="error")
            log(
                f"Notes card factory failed: {exc}\n{traceback.format_exc()}",
                logging.ERROR,
            )
            return None

        tag = str(meta.get("persist_tag") or "(builtin:user-guided-notes)")
        if tag:
            self._notes_card_tag = tag
            self._configure_notes_card(card, tag)
        else:
            self._notes_card_tag = None
            card.closed.connect(self._on_notes_card_closed)
        self._notes_card = card
        widget = self._extract_notes_widget(card)
        if widget is not None:
            self._install_notes_widget(widget)
        self._bring_card_forward(card)
        self.camera.center_on_widget(card)
        title = str(meta.get("title", "User-Guided Notes"))
        _remember_card("builtin", tag, title)
        log("User-Guided Notes card opened")
        return card

    def _configure_notes_card(self, card: Card, tag: str) -> None:
        card.set_persist_tag(tag)
        _restore_card_geom(card, "builtin", tag)
        card.moved.connect(lambda: _save_card_geom(card, "builtin", tag))
        card.resized.connect(lambda: _save_card_geom(card, "builtin", tag))
        card.closed.connect(self._on_notes_card_closed)

    def _extract_notes_widget(self, card: Card) -> Optional[QWidget]:
        widget: Optional[QWidget] = None
        if _USER_GUIDED_NOTES_WIDGET_CLASS is not None:
            try:
                widget = card.findChild(_USER_GUIDED_NOTES_WIDGET_CLASS)  # type: ignore[arg-type]
            except Exception:
                widget = None
        if widget is None:
            body_layout = card.body.layout()
            if body_layout and body_layout.count():
                candidate = body_layout.itemAt(0).widget()
                if isinstance(candidate, QWidget):
                    widget = candidate
        return widget

    def _install_notes_widget(self, widget: QWidget) -> None:
        if self._notes_widget is widget:
            self._set_notes_embedded_state(True)
            return
        if self._notes_widget is not None and self._notes_widget is not widget:
            self._disconnect_notes_widget()
        self._notes_widget = widget
        self._set_notes_embedded_state(True)
        try:
            widget.request_detach.connect(self._detach_notes_widget)  # type: ignore[attr-defined]
            widget.request_redock.connect(self._redock_notes_widget)  # type: ignore[attr-defined]
        except Exception:
            pass
        try:
            widget.destroyed.connect(self._clear_notes_widget)  # type: ignore[attr-defined]
        except Exception:
            pass

    def _disconnect_notes_widget(self) -> None:
        if self._notes_widget is None:
            return
        try:
            self._notes_widget.request_detach.disconnect(self._detach_notes_widget)  # type: ignore[attr-defined]
        except Exception:
            pass
        try:
            self._notes_widget.request_redock.disconnect(self._redock_notes_widget)  # type: ignore[attr-defined]
        except Exception:
            pass
        try:
            self._notes_widget.destroyed.disconnect(self._clear_notes_widget)  # type: ignore[attr-defined]
        except Exception:
            pass

    def _set_notes_embedded_state(self, embedded: bool) -> None:
        widget = self._notes_widget
        if widget is None:
            return
        apply_state = getattr(widget, "apply_embedded_state", None)
        if callable(apply_state):
            try:
                apply_state(embedded)
            except Exception:
                pass

    def _detach_notes_widget(self, widget: object) -> None:
        if widget is not self._notes_widget or self._notes_widget is None:
            return
        if _USER_GUIDED_NOTES_WINDOW_CLASS is None:
            self._toast("Pop-out window unavailable.", kind="error")
            self._set_notes_embedded_state(True)
            return
        card = self._notes_card
        if card is None:
            if self._notes_window:
                try:
                    self._notes_window.show()
                    self._notes_window.raise_()
                    self._notes_window.activateWindow()
                except Exception:
                    pass
            return
        if self._notes_card_tag:
            _save_card_geom(card, "builtin", self._notes_card_tag)
        body_layout = card.body.layout()
        if body_layout:
            body_layout.removeWidget(self._notes_widget)
        self._notes_widget.setParent(None)
        self._set_notes_embedded_state(False)
        try:
            window = _USER_GUIDED_NOTES_WINDOW_CLASS(self._notes_widget)  # type: ignore[misc]
        except Exception as exc:
            self._toast("Unable to pop out Notes window.", kind="error")
            log(f"Notes window creation failed: {exc}", logging.ERROR)
            if body_layout:
                body_layout.addWidget(self._notes_widget)
            self._set_notes_embedded_state(True)
            return
        self._notes_window = window
        try:
            window.destroyed.connect(self._on_notes_window_destroyed)
        except Exception:
            pass
        _restore_window_geom(window, "notes")
        try:
            window.show()
            window.raise_()
            window.activateWindow()
        except Exception:
            pass
        self._notes_card = None
        card.close()

    def _redock_notes_widget(self, widget: object) -> None:
        if widget is not self._notes_widget or self._notes_widget is None:
            return
        window = self._notes_window
        if window is None:
            self._set_notes_embedded_state(True)
            return
        _save_window_geom(window, "notes")
        taken_widget: Optional[QWidget] = None
        try:
            taken_widget = window.takeCentralWidget()
        except Exception:
            taken_widget = None
        if taken_widget is not None and taken_widget is not self._notes_widget:
            self._install_notes_widget(taken_widget)
        widget_obj = self._notes_widget
        if widget_obj is None:
            window.close()
            self._notes_window = None
            return
        widget_obj.setParent(None)
        notes_icon = QApplication.style().standardIcon(QStyle.SP_FileDialogDetailedView)
        card = self.add_card(
            widget_obj,
            "User-Guided Notes",
            task_profile="notes",
            task_icon=notes_icon,
            task_tooltip="User-Guided Notes",
        )
        self._notes_card = card
        if self._notes_card_tag:
            self._configure_notes_card(card, self._notes_card_tag)
        else:
            card.closed.connect(self._on_notes_card_closed)
        self._set_notes_embedded_state(True)
        self._bring_card_forward(card)
        self.camera.center_on_widget(card)
        window.close()
        self._notes_window = None

    def _on_notes_card_closed(self, card: object) -> None:
        if self._notes_card is card:
            self._notes_card = None
        if not self._notes_window:
            self._notes_card_tag = None

    def _on_notes_window_destroyed(self, *args) -> None:
        self._notes_window = None

    def _clear_notes_widget(self, *args) -> None:
        self._disconnect_notes_widget()
        self._notes_widget = None
        if not self._notes_window:
            self._notes_card = None
            self._notes_card_tag = None
    def _open_system_overview(self) -> None:
        if self._system_card and self._system_card.isVisible():
            self._bring_card_forward(self._system_card)
            self.camera.center_on_widget(self._system_card)
            return
        dataset_path = getattr(self.task_mgr, "dataset_path", None)
        try:
            dataset_root = Path(dataset_path).resolve().parent if dataset_path else Path(SCRIPT_DIR, "datasets")
        except Exception:
            dataset_root = Path(SCRIPT_DIR, "datasets")
        card = SystemOverviewCard(self.t, dataset_root, parent=self.canvas)
        tag = "(builtin:system-overview)"
        system_icon = QApplication.style().standardIcon(QStyle.SP_DesktopIcon)
        card = self._attach_card(
            card,
            task_profile="system-overview",
            task_icon=system_icon,
            task_tooltip="System Overview",
        )
        card.set_persist_tag(tag)
        _restore_card_geom(card, "builtin", tag)
        card.moved.connect(lambda: _save_card_geom(card, "builtin", tag))
        card.resized.connect(lambda: _save_card_geom(card, "builtin", tag))
        card.closed.connect(self._on_system_card_closed)
        self._system_card = card
        _remember_card("builtin", tag, "System Overview")
        self._bring_card_forward(card)
        self.camera.center_on_widget(card)
        log("System Overview opened")

    def _on_tasks_card_closed(self, *_):
        self._tasks_card = None
        self._tasks_widget = None

    def _on_system_card_closed(self, *_):
        self._system_card = None

    def _focus_task(self, task_id: Optional[str]) -> None:
        if not task_id or not self._tasks_widget:
            return
        panel = getattr(self._tasks_widget, "panel", None)
        if panel is None:
            return
        try:
            panel.refresh()
        except Exception:
            log(f"Task panel refresh failed for focus: {task_id}", logging.DEBUG)
        list_widget = getattr(panel, "list", None)
        if list_widget is None:
            return
        for idx in range(list_widget.count()):
            item = list_widget.item(idx)
            if item and item.data(Qt.UserRole) == task_id:
                list_widget.setCurrentItem(item)
                list_widget.scrollToItem(item)
                break

    def toggle_template_terminal(self, on: bool):
        tag = "(builtin:template)"
        if on:
            if self._template_card:
                self._bring_card_forward(self._template_card); self.camera.center_on_widget(self._template_card); return
            widget = TemplateTerminal(self.t)
            template_icon = QApplication.style().standardIcon(QStyle.SP_ComputerIcon)
            card = self.add_card(
                widget,
                "Template Terminal",
                task_profile="template-terminal",
                task_icon=template_icon,
                task_tooltip="Template Terminal",
            )
            card.set_persist_tag(tag)
            _restore_card_geom(card, "template", tag)
            card.moved.connect(lambda: _save_card_geom(card, "template", tag))
            card.resized.connect(lambda: _save_card_geom(card, "template", tag))
            def on_closed(_):
                self._template_card = None
            card.closed.connect(on_closed)
            self._template_card = card
            _remember_card("template", "(builtin)", "Template Terminal")
            self._bring_card_forward(card)
            self.camera.center_on_widget(card)
            log("Template Terminal opened")
        else:
            if self._template_card:
                c = self._template_card; self._template_card = None
                try: c._close_card()
                except Exception: pass
                log("Template Terminal closed")

    def _resolve_codex_terminal_path(self) -> Optional[str]:
        candidates = [
            os.environ.get("CODEX_TERMINAL_PATH", "").strip(),
            os.path.join(SCRIPT_DIR, "Codex_Terminal.py"),
            os.path.join(os.getcwd(), "Codex_Terminal.py"),
        ]
        path = next((p for p in candidates if p and os.path.isfile(p)), None)
        if path:
            return path
        selected, _ = _non_native_open_file(
            self,
            "Select Codex_Terminal.py",
            SCRIPT_DIR,
            "Python (*.py)",
        )
        return selected or None

    def open_codex_terminal(self):
        # Try common locations or prompt. Keep containment via non-native dialog.
        path = self._resolve_codex_terminal_path()
        if not path:
            QMessageBox.information(self, "Codex", "Codex_Terminal.py not found.")
            return
        codex_icon = QApplication.style().standardIcon(QStyle.SP_DesktopIcon)
        previous_env = os.environ.get("CODEX_WORKSPACE")
        workspace = workspace_root()
        applied_env = False
        if workspace:
            os.environ["CODEX_WORKSPACE"] = workspace
            applied_env = True
        try:
            card = self._load_python_as_card(
                path,
                persist_key=path,
                nice_title="Codex Terminal",
                task_profile="codex-terminal",
                task_icon=codex_icon,
                task_tooltip=path,
            )
        finally:
            if applied_env:
                if previous_env is None:
                    os.environ.pop("CODEX_WORKSPACE", None)
                else:
                    os.environ["CODEX_WORKSPACE"] = previous_env
        if card is None:
            log("[Codex] embed failed; showing System Console.", logging.ERROR)
            self._open_system_console()

# --------------------------------------------------------------------------------------
# Text/Image viewers
# --------------------------------------------------------------------------------------
class TextViewer(QWidget):
    def __init__(self, path: str, theme: Theme):
        super().__init__()
        v = QVBoxLayout(self); v.setContentsMargins(10,10,10,10); v.setSpacing(8)
        self.info = QLabel(os.path.basename(path)); self.info.setStyleSheet(f"color:{theme.text_muted}; font:600 10pt 'Cascadia Code';")
        v.addWidget(self.info)
        self.edit = QPlainTextEdit(self); self.edit.setReadOnly(True)
        apply_contrast_palette(self.edit, theme.editor_bg, theme.editor_fg)
        self.edit.setStyleSheet(
            f"QPlainTextEdit{{ background:{theme.editor_bg}; color:{theme.editor_fg}; border:1px solid {theme.card_border}; "
            f"selection-background-color:{theme.editor_sel}; font-family:'Cascadia Code',Consolas,monospace; }}"
        )
        try:
            with open(path, "r", encoding="utf-8", errors="replace") as f:
                self.edit.setPlainText(f.read())
        except Exception as e:
            self.edit.setPlainText(f"[Error] {e}")
        v.addWidget(self.edit, 1)

class ImageViewer(QWidget):
    def __init__(self, path: str, theme: Theme):
        super().__init__()
        v = QVBoxLayout(self); v.setContentsMargins(10,10,10,10); v.setSpacing(8)
        self.info = QLabel(os.path.basename(path)); self.info.setStyleSheet(f"color:{theme.text_muted}; font:600 10pt 'Cascadia Code';")
        v.addWidget(self.info)
        self.label = QLabel(self); self.label.setAlignment(Qt.AlignCenter)
        self.label.setStyleSheet(f"background:{theme.editor_bg}; border:1px solid {theme.card_border};")
        pix = QPixmap(path)
        if pix.isNull():
            self.label.setText("Unable to load image.")
        else:
            self.label.setPixmap(pix.scaled(1024, 768, Qt.KeepAspectRatio, Qt.SmoothTransformation))
        v.addWidget(self.label, 1)
        self.label.setScaledContents(False)

# --------------------------------------------------------------------------------------
# Process console (fallback)
# --------------------------------------------------------------------------------------
class ProcessConsole(QWidget):
    def __init__(
        self,
        theme: Theme,
        cmd: List[str],
        cwd: Optional[str] = None,
        guard: Optional[Callable[[List[str], Optional[str]], Tuple[bool, str]]] = None,
        violation_cb: Optional[Callable[[str], None]] = None,
    ):
        super().__init__()
        self.t = theme
        self.cmd = list(cmd)
        self.cwd = os.path.abspath(cwd or SCRIPT_DIR)
        self.proc: Optional[subprocess.Popen] = None
        self.reader: Optional[threading.Thread] = None
        self._kill = threading.Event()
        self._guard = guard
        self._violation_cb = violation_cb

        v = QVBoxLayout(self); v.setContentsMargins(10, 10, 10, 10); v.setSpacing(8)
        row = QHBoxLayout(); row.setSpacing(8)
        self.btn_start = QPushButton("Start"); self.btn_stop = QPushButton("Stop"); self.btn_stop.setEnabled(False)
        for b in (self.btn_start, self.btn_stop):
            b.setStyleSheet(f"QPushButton{{color:#fff;background:{self.t.accent};border:1px solid {self.t.card_border};border-radius:6px;padding:6px 10px;}}"
                            f"QPushButton:hover{{background:{self.t.accent_hov};}}")
        row.addWidget(self.btn_start); row.addWidget(self.btn_stop); row.addStretch(1)
        v.addLayout(row)

        self.console = QPlainTextEdit(self); self.console.setReadOnly(True)
        apply_contrast_palette(self.console, theme.editor_bg, theme.editor_fg)
        self.console.setStyleSheet(
            f"QPlainTextEdit{{ background:{theme.editor_bg}; color:{theme.editor_fg}; "
            f"selection-background-color:{self.t.editor_sel}; border:1px solid {self.t.card_border}; "
            f"font-family:'Cascadia Code',Consolas,monospace; }}"
        )
        v.addWidget(self.console, 1)
        self.btn_start.clicked.connect(self._start)
        self.btn_stop.clicked.connect(self._stop)

    def _println(self, s: str):
        self.console.appendPlainText(s)
        log(f"[process] {s}")

    def _start(self):
        if self.proc and self.proc.poll() is None: return
        detail = None
        if self._guard:
            allowed, detail = self._guard(self.cmd, self.cwd)
            if not allowed:
                message = detail or "Blocked: command rejected."
                self._println(message)
                log(f"[process] blocked: {' '.join(self.cmd)} — {message}", logging.WARNING)
                if self._violation_cb:
                    try:
                        self._violation_cb(message)
                    except Exception:
                        log("[process] violation callback failed", logging.DEBUG)
                return
        try:
            self._println(f"Run: {' '.join(self.cmd)}")
            if detail:
                log(f"[process] launching {detail} (cwd={self.cwd})")
            self.proc = subprocess.Popen(self.cmd, cwd=self.cwd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        except Exception as e:
            self._println(f"Error: {e}"); return
        self._kill.clear()
        self.reader = threading.Thread(target=self._reader, daemon=True); self.reader.start()
        self.btn_start.setEnabled(False); self.btn_stop.setEnabled(True)
        self._println("Streaming output…")

    def _stop(self):
        if not self.proc: return
        self._kill.set()
        try: self.proc.terminate()
        except Exception: pass
        self.btn_start.setEnabled(True); self.btn_stop.setEnabled(False)
        self._println("Terminated")

    def _reader(self):
        assert self.proc and self.proc.stdout
        for line in self.proc.stdout:
            if self._kill.is_set(): break
            s = line.rstrip("\n")
            self.console.appendPlainText(s)
            log(f"[out] {s}")
        self.btn_start.setEnabled(True); self.btn_stop.setEnabled(False)

# --------------------------------------------------------------------------------------
# Persistence helpers
# --------------------------------------------------------------------------------------
def _restore_card_geom(card: Card, kind: str, persist_tag: str):
    st = _load_state(); key = _geom_key_for(kind, persist_tag)
    g = st.get("geom", {}).get(key)
    if not g: return
    try:
        saved_x = int(g["x"])
        saved_y = int(g["y"])
        saved_w = int(g["w"])
        saved_h = int(g["h"])
        saved_scale = float(g.get("scale", 1.0)) if g.get("scale") is not None else 1.0
        current_scale = float(getattr(card, "_vd_scale", saved_scale or 1.0))
        x, y, w, h = saved_x, saved_y, saved_w, saved_h
        if saved_scale > 0 and current_scale > 0 and not math.isclose(saved_scale, current_scale, rel_tol=1e-3):
            ratio = current_scale / saved_scale
            w = max(MIN_CARD_WIDTH, int(round(saved_w * ratio)))
            h = max(MIN_CARD_HEIGHT, int(round(saved_h * ratio)))
            center_x = saved_x + saved_w / 2
            center_y = saved_y + saved_h / 2
            x = int(round(center_x - w / 2))
            y = int(round(center_y - h / 2))
        parent = card.parentWidget()
        if parent:
            rect = parent.rect()
            max_x = max(8, rect.width() - w - 8)
            max_y = max(8, rect.height() - h - 8)
            x = max(8, min(x, max_x))
            y = max(8, min(y, max_y))
        card.resize(w, h); card.move(x, y)
        setattr(card, "_vd_scale", current_scale)
    except Exception:
        pass

def _save_card_geom(card: Card, kind: str, persist_tag: str):
    st = _load_state(); key = _geom_key_for(kind, persist_tag)
    st.setdefault("geom", {})[key] = {
        "x": card.x(),
        "y": card.y(),
        "w": card.width(),
        "h": card.height(),
        "scale": float(getattr(card, "_vd_scale", 1.0)),
    }
    _save_state(st)

def _restore_window_geom(window: QWidget, key: str) -> None:
    st = _load_state()
    payload = st.get("window_geom", {}).get(key)
    if not isinstance(payload, dict):
        return
    try:
        x = int(payload.get("x"))
        y = int(payload.get("y"))
        w = int(payload.get("w"))
        h = int(payload.get("h"))
    except Exception:
        return
    window.setGeometry(x, y, max(w, 1), max(h, 1))

def _save_window_geom(window: QWidget, key: str) -> None:
    geom = window.geometry()
    st = _load_state()
    st.setdefault("window_geom", {})[key] = {
        "x": geom.x(),
        "y": geom.y(),
        "w": geom.width(),
        "h": geom.height(),
    }
    _save_state(st)

# --------------------------------------------------------------------------------------
# Window wrapper
# --------------------------------------------------------------------------------------
class VirtualDesktopWindow(QMainWindow):
    def __init__(self, workspace: Optional[str] = None):
        super().__init__()
        self.t = Theme()
        pal = self.palette()
        # High-contrast window and text
        pal.setColor(QPalette.Window, QColor("#0a1430"))
        pal.setColor(QPalette.Base, QColor("#0a1430"))
        pal.setColor(QPalette.Text, QColor("#e6f0ff"))
        pal.setColor(QPalette.WindowText, QColor("#e6f0ff"))
        self.setPalette(pal)
        self.setWindowTitle("Virtual Desktop")
        self.core = VirtualDesktopCore(workspace=workspace, parent=self)
        self.setCentralWidget(self.core)

        # Menubar retains system-level items; former top toolbar actions moved into Start/Settings
        self._menu()
        self._shortcuts()

        # Start maximized with border so Min/Max/Close work; Fullscreen toggle is optional
        QTimer.singleShot(0, self.showMaximized)

        self.installEventFilter(self)
        self._is_fitting = False
        self._last_window_state = self.windowState()
        self._current_screen = self.windowHandle().screen() if self.windowHandle() else None
        if self.windowHandle():
            self.windowHandle().screenChanged.connect(self._handle_screen_changed)
        self._fit_timer = QTimer(self); self._fit_timer.setSingleShot(True)
        self._fit_timer.timeout.connect(self.fit_to_current_screen)
        self._force_taskbar_clear_timer = QTimer(self)
        self._force_taskbar_clear_timer.setSingleShot(True)
        self._force_taskbar_clear_timer.timeout.connect(self._clear_forced_native_taskbar_offset)
        self._pending_maximize_fit = False

    def _menu(self):
        bar: QMenuBar = self.menuBar()
        bar.setStyleSheet(
            f"""
            QMenuBar {{
                background: {self.t.menu_bg};
                color: {self.t.menu_fg};
                border: none;
            }}
            QMenuBar::item {{
                background: transparent;
                padding: 4px 8px;
            }}
            QMenuBar::item:selected {{ background: #0f1d33; }}
            QMenu {{
                background: #0b1828;
                color: {self.t.menu_fg};
                border: 1px solid {self.t.card_border};
            }}
            QMenu::item:selected {{ background: {self.t.accent}; color: #ffffff; }}
            """
        )
        view = bar.addMenu("&View")
        a_full = QAction("Toggle Fullscreen (Alt+Enter)", self); a_full.setShortcut("Alt+Return")
        a_full.triggered.connect(self._toggle_fullscreen); view.addAction(a_full)
        a_center = QAction("Center on Desktop (Ctrl+Home)", self); a_center.setShortcut("Ctrl+Home")
        a_center.triggered.connect(lambda: self.core.camera.center_on_widget(self.core.canvas)); view.addAction(a_center)
        a_fit = QAction("Fit to Current Screen", self); a_fit.setShortcut("Ctrl+0")
        a_fit.triggered.connect(self.fit_to_current_screen); view.addAction(a_fit)

        tools = bar.addMenu("&Tools")
        tools.addAction("Settings…", self.core._open_settings_panel)
        tools.addAction("System Console", self.core._open_system_console)
        tools.addAction("Error Center", self.core._open_error_center)
        tools.addAction("Open Desktop Explorer", self.core._open_explorer)
        tools.addAction("Template Terminal", lambda: self.core.toggle_template_terminal(True))
        tools.addAction("Load Script as Card…", self.core._load_script_dialog)
        tools.addAction("Open Codex_Terminal.py", self.core.open_codex_terminal)

        bar.addMenu("&Help").addAction("About", lambda: QMessageBox.information(self, "Virtual Desktop", "Contained virtual desktop. All dialogs non-native to keep containment.\nMin/Max/Close on each card.\nStart panel attached to taskbar."))

    def _shortcuts(self):
        def pan_guarded(dx, dy): self.core.camera.pan(dx, dy)
        self.addAction(self._mk_action("Ctrl+Left", lambda: pan_guarded(-160, 0)))
        self.addAction(self._mk_action("Ctrl+Right", lambda: pan_guarded(+160, 0)))
        self.addAction(self._mk_action("Ctrl+Up", lambda: pan_guarded(0, -160)))
        self.addAction(self._mk_action("Ctrl+Down", lambda: pan_guarded(0, +160)))

    def _mk_action(self, shortcut: str, fn):
        a = QAction(self); a.setShortcut(QKeySequence(shortcut)); a.triggered.connect(fn); return a

    def resizeEvent(self, event: QResizeEvent):
        super().resizeEvent(event)
        if self._is_fitting:
            return
        if self.isFullScreen():
            return
        if bool(self.windowState() & Qt.WindowMaximized):
            return
        timer = getattr(self.core, "_sync_timer", None)
        if timer is not None:
            timer.start(0)
        else:
            QTimer.singleShot(0, self.core._sync_canvas_to_screen)

    def showEvent(self, e):
        super().showEvent(e)
        QTimer.singleShot(0, self.fit_to_current_screen)

    def eventFilter(self, obj, ev):
        if ev.type() == QEvent.WindowStateChange:
            state_event: QWindowStateChangeEvent | None = None
            if isinstance(ev, QWindowStateChangeEvent):
                state_event = ev
            old_state = None
            if state_event is not None:
                getter = getattr(state_event, "oldState", None)
                if callable(getter):
                    try:
                        old_state = getter()
                    except Exception:
                        old_state = None
            if old_state is None:
                old_state = Qt.WindowStates(self._last_window_state)
            new_state = self.windowState()
            was_maximized = bool(old_state & Qt.WindowMaximized)
            is_maximized = bool(new_state & Qt.WindowMaximized)
            self._last_window_state = new_state
            if self._is_fitting:
                return super().eventFilter(obj, ev)
            if is_maximized and not was_maximized:
                self._pending_maximize_fit = True
                if not self._fit_timer.isActive():
                    self._fit_timer.start(10)
            elif was_maximized and not is_maximized:
                self._pending_maximize_fit = False
                self._fit_timer.stop()
        return super().eventFilter(obj, ev)

    def _handle_screen_changed(self, screen):
        if screen is self._current_screen:
            return
        self._current_screen = screen
        if self._is_fitting:
            return
        self._pending_maximize_fit = bool(self.windowState() & Qt.WindowMaximized)
        self._fit_timer.start(10)

    def _clear_forced_native_taskbar_offset(self):
        self.core.set_force_native_taskbar_offset(False)

    def fit_to_current_screen(self, *, force_native_taskbar: bool = False):
        if self._is_fitting:
            return
        self._is_fitting = True
        try:
            self._fit_timer.stop()
            if self.isFullScreen():
                if force_native_taskbar:
                    self.core.set_force_native_taskbar_offset(True)
                    self._force_taskbar_clear_timer.stop()
                self.core._sync_canvas_to_screen(force_native_taskbar=force_native_taskbar)
                if force_native_taskbar:
                    self._force_taskbar_clear_timer.start(0)
                self._pending_maximize_fit = False
                return
            scr = None
            if self.windowHandle() and self.windowHandle().screen():
                scr = self.windowHandle().screen()
            if not scr:
                scr = QGuiApplication.screenAt(self.frameGeometry().center())
            if not scr:
                scr = QGuiApplication.primaryScreen()
            self._current_screen = scr
            target_geom = QRect(scr.availableGeometry())
            applied = False
            should_force_taskbar = force_native_taskbar or self._pending_maximize_fit
            tolerance_px = 2

            def _within_tolerance(rect: QRect, target: QRect, tol: int) -> bool:
                return (
                    abs(rect.left() - target.left()) <= tol
                    and abs(rect.top() - target.top()) <= tol
                    and abs(rect.width() - target.width()) <= tol
                    and abs(rect.height() - target.height()) <= tol
                )

            handle = self.windowHandle()
            current_client = QRect()
            if handle is not None:
                try:
                    candidate = QRect(handle.geometry())
                except Exception:
                    candidate = QRect()
                if candidate.isValid() and not candidate.isNull():
                    current_client = candidate
            if not current_client.isValid() or current_client.isNull():
                geom_candidate = QRect(self.geometry())
                if geom_candidate.isValid() and not geom_candidate.isNull():
                    current_client = geom_candidate
            if (not current_client.isValid() or current_client.isNull()) and bool(self.windowState() & Qt.WindowMaximized):
                normal_candidate = QRect(self.normalGeometry())
                if normal_candidate.isValid() and not normal_candidate.isNull():
                    current_client = normal_candidate

            margins = None
            if handle is not None:
                try:
                    margins = handle.frameMargins()
                except Exception:
                    margins = None

            frame_rect = QRect()
            if handle is not None:
                try:
                    frame_rect = QRect(handle.frameGeometry())
                except Exception:
                    frame_rect = QRect()
            if not frame_rect.isValid() or frame_rect.isNull():
                frame_candidate = QRect(self.frameGeometry())
                if frame_candidate.isValid() and not frame_candidate.isNull():
                    frame_rect = frame_candidate

            if margins is not None and frame_rect.isValid() and not frame_rect.isNull():
                def _margin_value(name: str) -> int:
                    getter = getattr(margins, name, None)
                    value = 0.0
                    if callable(getter):
                        try:
                            value = getter()
                        except Exception:
                            value = 0.0
                    elif getter is not None:
                        value = getter
                    try:
                        return int(round(float(value)))
                    except Exception:
                        return 0

                left = _margin_value("left")
                top = _margin_value("top")
                right = _margin_value("right")
                bottom = _margin_value("bottom")
                adjusted_frame = QRect(frame_rect)
                adjusted_frame.adjust(left, top, -right, -bottom)
                if adjusted_frame.isValid() and not adjusted_frame.isNull():
                    current_client = adjusted_frame

            if current_client.isNull() or not current_client.isValid():
                current_client = QRect(target_geom)

            if bool(self.windowState() & Qt.WindowMaximized):
                matches_target = _within_tolerance(current_client, target_geom, tolerance_px)
                if not matches_target:
                    should_force_taskbar = True
                    self.core.set_force_native_taskbar_offset(True)
                    self._force_taskbar_clear_timer.stop()
                    previous_state = self.windowState()
                    try:
                        self.setWindowState(Qt.WindowNoState)
                    except Exception:
                        previous_state = None
                    self.setGeometry(target_geom)
                    if previous_state is not None:
                        try:
                            self.setWindowState(previous_state)
                        except Exception:
                            self.showMaximized()
                    elif not bool(self.windowState() & Qt.WindowMaximized):
                        self.showMaximized()
                    applied = True
            if should_force_taskbar and not applied:
                self.core.set_force_native_taskbar_offset(True)
                self._force_taskbar_clear_timer.stop()
            self.core._sync_canvas_to_screen(force_native_taskbar=should_force_taskbar)
            if should_force_taskbar:
                self._force_taskbar_clear_timer.start(0)
            self._pending_maximize_fit = False
            if applied:
                log(
                    f"Window fit to monitor: {target_geom.width()}x{target_geom.height()} @ {scr.name()}"
                )
            elif bool(self.windowState() & Qt.WindowMaximized):
                log(
                    "Window fit skipped — already aligned within tolerance; "
                    f"screen {scr.name()} available {target_geom.width()}x{target_geom.height()}"
                )
            else:
                log(
                    "Window fit skipped — not maximized; "
                    f"screen {scr.name()} available {target_geom.width()}x{target_geom.height()}"
                )
        finally:
            self._is_fitting = False

    def _toggle_fullscreen(self):
        if self.isFullScreen(): self.showNormal(); log("Exit fullscreen")
        else: self.showFullScreen(); log("Enter fullscreen")
        QTimer.singleShot(50, self.core._sync_canvas_to_screen)

# --------------------------------------------------------------------------------------
# Elevation helpers (Windows)
# --------------------------------------------------------------------------------------
def _is_windows() -> bool:
    return os.name == "nt"


def _query_windows_taskbar_height() -> int:
    if not _is_windows():
        return 0
    try:
        from ctypes import wintypes
    except Exception:
        return 0

    class RECT(ctypes.Structure):
        _fields_ = [
            ("left", ctypes.c_long),
            ("top", ctypes.c_long),
            ("right", ctypes.c_long),
            ("bottom", ctypes.c_long),
        ]

    class APPBARDATA(ctypes.Structure):
        _fields_ = [
            ("cbSize", ctypes.c_uint),
            ("hWnd", wintypes.HWND),
            ("uCallbackMessage", ctypes.c_uint),
            ("uEdge", ctypes.c_uint),
            ("rc", RECT),
            ("lParam", ctypes.c_long),
        ]

    ABM_GETTASKBARPOS = 0x00000005
    data = APPBARDATA()
    data.cbSize = ctypes.sizeof(APPBARDATA)
    try:
        result = ctypes.windll.shell32.SHAppBarMessage(ABM_GETTASKBARPOS, ctypes.byref(data))
    except Exception:
        return 0
    if not result:
        return 0
    if data.uEdge != 3:  # only bottom-aligned taskbar contributes to height offset
        return 0
    height = int(data.rc.bottom - data.rc.top)
    return max(0, height)


def _is_admin_windows() -> bool:
    if not _is_windows(): return True
    try:
        return ctypes.windll.shell32.IsUserAnAdmin()
    except Exception:
        return False
def _elevate_windows_if_needed():
    if not _is_windows(): return
    if os.environ.get("VD_NO_ELEVATE") == "1": return
    if _is_admin_windows(): return
    try:
        r = ctypes.windll.shell32.ShellExecuteW(None, "runas", sys.executable, f"\"{os.path.abspath(__file__)}\"", None, 1)
        if r > 32: sys.exit(0)
    except Exception as e:
        log(f"[elevate] failed: {e}", logging.WARNING)

# --------------------------------------------------------------------------------------
# Embedding API
# --------------------------------------------------------------------------------------
def build_widget(parent: Optional[QWidget] = None, workspace: Optional[str] = None):
    return VirtualDesktopCore(workspace=workspace, parent=parent)

def create_card(parent: Optional[QWidget] = None):
    w = build_widget(parent=parent, workspace=VDSK_ROOT)
    return w, "Virtual Desktop"

# --------------------------------------------------------------------------------------
# CLI
# --------------------------------------------------------------------------------------
def _parse_args():
    ap = argparse.ArgumentParser(description="Virtual Desktop")
    ap.add_argument("--open", dest="open_path", help="Load a script/binary as a Card")
    ap.add_argument("--show-template", action="store_true", help="Show the Template Terminal on launch")
    ap.add_argument("--workspace", help="Folder to scan for files on launch")
    return ap.parse_args()

def main():
    _elevate_windows_if_needed()
    args = _parse_args()
    app = QApplication(sys.argv)
    win = VirtualDesktopWindow(workspace=args.workspace)
    if args.show_template:
        QTimer.singleShot(0, lambda: win.core.toggle_template_terminal(True))
    if args.open_path:
        QTimer.singleShot(0, lambda: win.core.open_any_path(args.open_path))
    win.show()
    log("Application exec()")
    rc = app.exec()
    log(f"Application exit code: {rc}")
    sys.exit(rc)

if __name__ == "__main__":
    main()
```

Virtual_Desktop.py — Windows-style virtual desktop (contained), with Start panel and card window controls.

Directives satisfied:
- All former top toolbar actions moved into Start panel and Settings; no floating top bar.
- Start menu is a docked panel that rises from the taskbar and stays attached to the bottom.
- Window has standard minimize, maximize, close in the top-right (Qt title bar). Starts maximized with border.
- Each Card has its own Minimize, Max/Restore, Close buttons. Minimize hides to taskbar, restore via task button.
- Desktop edge trim removed. Background is clean blue gradient. High contrast enforced for text vs background.
- No drag-out to OS. No file URL clipboard exports. All dialogs non-native and modal to keep containment.
- Explorer and desktop icons support rename with extensions. Type/extension changes reflect immediately.
- Visual refreshes are immediate after file ops. QFileSystemWatcher also keeps UI current.
- Codex_Terminal.py can be launched from Start ▸ Apps ▸ Codex Terminal as an embedded card (factory supports embedded=True).  # See note re: citation in chat.

Notes:
- Contrast rule: inline comments and palettes ensure readable foreground/background in all states.
- Start panel includes: Apps (Explorer, Codex Terminal, Template Terminal), Recent, Settings, Power menu, Search.
- Settings panel collects previous toolbar utilities and view toggles.
**Classes:** _FallbackTaskManager, Theme, SystemConsole, TemplateTerminal, ExplorerCard, CardSizeGrip, Card, SystemOverviewCard, DesktopIcon, DesktopCanvas, Camera, StartPanel, TaskGroup, Taskbar, SettingsPanel, VirtualDesktopCore, TextViewer, ImageViewer, ProcessConsole, VirtualDesktopWindow
**Functions:** workspace_root(), _is_contained(path), _safe_resolve(path_str), _build_allowlist(), _try_provider_icon(path), _fallback_icon_for_path(path), _icon_for_path(path_like), _resolve_executable_path(cmd, cwd), _validate_process_request(cmd, cwd), log(msg, level), _load_state(), _save_state(state), _remember_card(kind, path, title), _geom_key_for(kind, persist_tag), _rect_to_dict(rect), _widget_geometry_snapshot(widget), _script_type_label(path), _score_from_error_count(error_count), _score_bucket_key(score), _last_run_bucket(last_run_ts), _flatten_metrics_summary(summary), _filter_metrics_rows(rows), _score_distribution(rows), _fallback_build_editor_widget(parent, initial_path), _fallback_open_card(), apply_contrast_palette(w, bg_hex, fg_hex), _non_native_open_files(parent, caption, start_dir, filt), _non_native_open_file(parent, caption, start_dir, filt), _non_native_open_dir(parent, caption, start_dir), _restore_card_geom(card, kind, persist_tag), _save_card_geom(card, kind, persist_tag), _restore_window_geom(window, key), _save_window_geom(window, key), _is_windows(), _query_windows_taskbar_height(), _is_admin_windows(), _elevate_windows_if_needed(), build_widget(parent, workspace), create_card(parent), _parse_args(), main()


## Module `Loader\ant_launcher.py`

```python
"""Entry point for bootstrapping the ANT-enabled cell lineage."""
from __future__ import annotations

from pathlib import Path
from typing import Callable, Optional

from ant_api.mesh import ANTMesh
from cells.lineage import Cell, CellLineage

from .immune_system import ImmuneSystem

DEFAULT_CELL_SOURCE = """"""# Auto-generated ANT cell\n\n""""""


class ANTLauncher:
    """Create and manage the first generation of ANT cells."""

    def __init__(
        self,
        storage_root: Path,
        *,
        mesh: Optional[ANTMesh] = None,
        immune_system: Optional[ImmuneSystem] = None,
    ) -> None:
        self.storage_root = storage_root
        self.mesh = mesh or ANTMesh()
        self.immune_system = immune_system or ImmuneSystem(storage_root)
        self.lineage = CellLineage(self.storage_root, self.mesh, self.immune_system)

    def launch_cell_zero(self, source: str = DEFAULT_CELL_SOURCE) -> Cell:
        """Instantiate ``cell_0`` if it does not already exist."""

        if self.lineage.has_cell("cell_0"):
            return self.lineage.get_cell("cell_0")
        return self.lineage.create_initial_cell(source, metadata={"rank": 0})

    def spawn_successor(
        self,
        parent: Cell,
        template: Optional[Callable[[Cell], str]] = None,
        *,
        metadata: Optional[dict] = None,
    ) -> Cell:
        """Create the next cell in the lineage using ``template``."""

        def default_template(cell: Cell) -> str:
            return f"# Derived from {cell.identifier}\n" + cell.introspect()

        template_fn = template or default_template
        return self.lineage.spawn_successor(parent, template_fn, metadata=metadata)


__all__ = ["ANTLauncher"]
```

Entry point for bootstrapping the ANT-enabled cell lineage.
**Classes:** ANTLauncher


## Module `Loader\immune_system.py`

```python
"""Utilities that ensure safe self-modification for cells.

The immune system is responsible for the persistence guarantees used by each
cell script.  It provides atomic writes, backups, and restore helpers so that a
cell can edit its own source and relaunch without corrupting the lineage.
"""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Optional
import os
import shutil
import tempfile


@dataclass
class RewriteReport:
    """Metadata describing a self-write attempt."""

    target: Path
    backup: Optional[Path]
    version: int


class ImmuneSystem:
    """Guard rails for self-modifying cell scripts.

    The immune system owns a storage root on disk.  All cell script rewrites go
    through :meth:`rewrite_cell`, which performs an atomic replace and tracks a
    backup copy.  The helpers are intentionally small so tests can exercise the
    persistence logic without requiring subprocess launches.
    """

    def __init__(self, storage_root: Path):
        self.storage_root = storage_root
        self.storage_root.mkdir(parents=True, exist_ok=True)

    def _safe_write(self, path: Path, data: str) -> Optional[Path]:
        """Write ``data`` to ``path`` using a temporary file and backup copy."""

        path.parent.mkdir(parents=True, exist_ok=True)
        backup_path: Optional[Path] = None
        if path.exists():
            backup_path = path.with_suffix(path.suffix + ".bak")
            shutil.copy2(path, backup_path)

        fd, tmp_path = tempfile.mkstemp(dir=str(path.parent), prefix=path.name, suffix=".tmp")
        try:
            with os.fdopen(fd, "w", encoding="utf-8") as handle:
                handle.write(data)
            os.replace(tmp_path, path)
        finally:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        return backup_path

    def bootstrap_cell(self, script_path: Path, source: str) -> RewriteReport:
        """Create the initial script for a cell."""

        backup = self._safe_write(script_path, source)
        return RewriteReport(target=script_path, backup=backup, version=0)

    def rewrite_cell(self, script_path: Path, source: str, version: int) -> RewriteReport:
        """Rewrite ``script_path`` with ``source`` and return the resulting report."""

        backup = self._safe_write(script_path, source)
        return RewriteReport(target=script_path, backup=backup, version=version)

    def restore_backup(self, report: RewriteReport) -> None:
        """Restore the backup captured in ``report`` if it still exists."""

        if report.backup and report.backup.exists():
            os.replace(report.backup, report.target)


__all__ = ["ImmuneSystem", "RewriteReport"]
```

Utilities that ensure safe self-modification for cells.

The immune system is responsible for the persistence guarantees used by each
cell script.  It provides atomic writes, backups, and restore helpers so that a
cell can edit its own source and relaunch without corrupting the lineage.
**Classes:** RewriteReport, ImmuneSystem


## Module `Loader\__init__.py`

```python
"""Loader package for cell lineage bootstrapping."""

from .ant_launcher import ANTLauncher
from .immune_system import ImmuneSystem

__all__ = ["ANTLauncher", "ImmuneSystem"]
```

Loader package for cell lineage bootstrapping.


## Module `tests\conftest.py`

```python
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))
```



## Module `tests\test_ant_loader.py`

```python
from pathlib import Path

import pytest

from Loader.ant_launcher import ANTLauncher


@pytest.fixture()
def launcher(tmp_path: Path) -> ANTLauncher:
    return ANTLauncher(tmp_path)


def test_launch_cell_zero_creates_script(launcher: ANTLauncher, tmp_path: Path) -> None:
    cell = launcher.launch_cell_zero(source="print('hello')\n")
    assert cell.identifier == "cell_0"
    assert cell.script_path.read_text(encoding="utf-8") == "print('hello')\n"
    assert (tmp_path / "cell_0.py").exists()


def test_spawn_successor_inherits_source(launcher: ANTLauncher) -> None:
    parent = launcher.launch_cell_zero(source="print('parent')\n")

    def template(cell):
        return cell.introspect() + "# child\n"

    child = launcher.spawn_successor(parent, template=template, metadata={"role": "child"})
    assert child.identifier == "cell_1"
    assert "# child" in child.script_path.read_text(encoding="utf-8")
    history = launcher.mesh.get_history()
    assert any(payload.get("type") == "spawn" and payload.get("child") == "cell_1" for _, payload in history)
```

**Functions:** launcher(tmp_path), test_launch_cell_zero_creates_script(launcher, tmp_path), test_spawn_successor_inherits_source(launcher)


## Module `tests\test_ant_mesh_schema.py`

```python
from pathlib import Path
from typing import List

from Loader.immune_system import ImmuneSystem
from ant_api.mesh import ANTMesh
from cells.lineage import CellLineage


def test_schema_exchange_and_broadcast(tmp_path: Path) -> None:
    mesh = ANTMesh()
    immune = ImmuneSystem(tmp_path)
    lineage = CellLineage(tmp_path, mesh, immune)
    cell = lineage.create_initial_cell("print('schema')\n")

    events: List[dict] = []
    mesh.subscribe(lambda source, payload: events.append(payload))

    schema_payload = {"name": "primary", "fields": {"button": "Start"}}
    cell.publish_schema(schema_payload)

    stored = lineage.schema_registry.get(cell.identifier)
    assert stored is not None
    assert stored.name == "primary"
    assert stored.fields["button"] == "Start"
    assert any(event.get("type") == "schema" for event in events)
```

**Functions:** test_schema_exchange_and_broadcast(tmp_path)


## Module `tests\test_cell_self_edit.py`

```python
from pathlib import Path
from typing import List, Tuple

import pytest

from Loader.immune_system import ImmuneSystem
from ant_api.mesh import ANTMesh
from cells.lineage import CellLineage


@pytest.fixture()
def lineage(tmp_path: Path) -> CellLineage:
    mesh = ANTMesh()
    immune = ImmuneSystem(tmp_path)
    return CellLineage(tmp_path, mesh, immune)


def test_cell_self_edit_creates_backup(lineage: CellLineage) -> None:
    cell = lineage.create_initial_cell("print('v0')\n")
    history: List[Tuple[str, dict]] = []
    lineage.mesh.subscribe(lambda source, payload: history.append((source, payload)))

    cell.self_edit(lambda src: src.replace("v0", "v1"), message="upgrade")

    assert "v1" in cell.introspect()
    assert cell.metadata["last_backup"].endswith(".bak")
    assert any(payload.get("type") == "self_edit" and payload.get("message") == "upgrade" for _, payload in history)


def test_cell_reload_broadcasts(lineage: CellLineage) -> None:
    cell = lineage.create_initial_cell("print('hi')\n")
    events: List[Tuple[str, dict]] = []
    lineage.mesh.subscribe(lambda source, payload: events.append((source, payload)))

    cell.reload()
    assert any(payload.get("type") == "reload" for _, payload in events)
```

**Functions:** lineage(tmp_path), test_cell_self_edit_creates_backup(lineage), test_cell_reload_broadcasts(lineage)


## Module `tests\test_clarification_flow.py`

```python
import pytest

pytest.importorskip("PySide6")

from typing import List

from planner_service import PlannerDecision
from Voice_Guided_Tools import AppConfig, ChatReply, MainWindow


class StubDesktop:
    def __init__(self) -> None:
        self.last_bubble: str | None = None
        self.commands: List[str] = []

    def set_bubble(self, text: str) -> None:
        self.last_bubble = text

    def set_command_suggestions(self, commands: List[str]) -> None:
        self.commands = commands

    def stop_autopilot(self) -> None:  # pragma: no cover - required by interface
        pass


class StubChatResponder:
    def __init__(self) -> None:
        self.helper = object()
        self.prompts: List[str] = []
        self.reply_text = "Here's a chat fallback."

        self.metadata: List[dict | None] = []

    def reply(self, text: str, *, metadata: dict | None = None) -> ChatReply:
        self.prompts.append(text)
        self.metadata.append(metadata)
        return ChatReply(self.reply_text, ["[chat] stub"], True)


class StubSession:
    def __init__(self) -> None:
        self.entries: List[dict] = []

    def write(self, payload: dict) -> None:
        self.entries.append(payload)


@pytest.fixture
def window() -> MainWindow:
    mw = MainWindow.__new__(MainWindow)
    mw.cfg = AppConfig()
    mw.desktop = StubDesktop()
    mw._directive_buckets = []
    mw._pending_magic_learn = None
    mw._paused = False
    mw._last_nonmagic = None
    mw._snapshot = None
    mw._directive_state = {"metadata": {}}
    mw._session = StubSession()
    mw._narrations: List[str] = []
    mw._narrate = lambda text: mw._narrations.append(text)
    mw._log = lambda *args, **kwargs: None
    mw._update_command_suggestions = lambda *args, **kwargs: None
    mw.chat_responder = StubChatResponder()
    mw.planner_service = type(
        "Recorder",
        (),
        {"record_execution": staticmethod(lambda *args, **kwargs: None)},
    )()
    return mw


def make_decision(*, needs_clarification: bool, question: str | None = None) -> PlannerDecision:
    return PlannerDecision(
        intent="clarify" if needs_clarification else "none",
        needs_clarification=needs_clarification,
        question=question,
        plan=None,
        confidence=0.0,
        raw={},
        raw_response="{}",
    )


def test_followup_question_includes_history(window: MainWindow) -> None:
    utterance = "Draft the plan"
    first = make_decision(needs_clarification=True, question="Which part should I plan?")
    handled = window._handle_planner_decision(first, utterance)
    assert handled is True

    bucket = window._directive_buckets[0]
    assert len(bucket.clarification_attempts) == 1
    assert bucket.clarification_attempts[0]["question"] == "Which part should I plan?"

    second = make_decision(needs_clarification=True, question=None)
    handled = window._handle_planner_decision(
        second,
        utterance,
        clarification_answer="Focus on the API",
    )
    assert handled is True

    assert bucket.clarification_attempts[0]["answer"] == "Focus on the API"
    assert len(bucket.clarification_attempts) == 2
    followup = bucket.clarification_attempts[-1]["question"]
    assert "Focus on the API" in followup
    assert followup.startswith("I'm still not sure how to handle")
    assert window.desktop.last_bubble == followup[:48]


def test_escalates_to_chat_after_second_retry(window: MainWindow) -> None:
    utterance = "Draft the plan"
    window._handle_planner_decision(
        make_decision(needs_clarification=True, question="Which part should I plan?"),
        utterance,
    )
    window._handle_planner_decision(
        make_decision(needs_clarification=True, question=None),
        utterance,
        clarification_answer="Focus on the API",
    )

    escalation_decision = make_decision(needs_clarification=True, question="Anything else?")
    handled = window._handle_planner_decision(
        escalation_decision,
        utterance,
        clarification_answer="Use the samples",
    )
    assert handled is True

    bucket = window._directive_buckets[0]
    assert len(bucket.clarification_attempts) == 2
    assert bucket.clarification_attempts[-1].get("escalated") is True
    assert window._session.entries[-1]["type"] == "planner-clarification-escalated"
    prompt = window.chat_responder.prompts[-1]
    assert "Use the samples" in prompt
    assert "Which part should I plan?" in prompt
    assert any("chat fallback" in narration.lower() for narration in window._narrations[-2:])
    assert window._get_pending_clarification() is None
    metadata = window.chat_responder.metadata[-1]
    assert metadata is not None
    assert metadata.get("directive_bucket_id")
    assert metadata.get("directive_status") == "collecting"
    topics = metadata.get("directive_topics", "")
    assert "draft" in topics or "plan" in topics
```

**Classes:** StubDesktop, StubChatResponder, StubSession
**Functions:** window(), make_decision(), test_followup_question_includes_history(window), test_escalates_to_chat_after_second_retry(window)


## Module `tests\test_codex_terminal_panel.py`

```python
import json
from pathlib import Path

import pytest

pytest.importorskip("PySide6", reason="PySide6 is required to import the Codex terminal module")

import VoiceGuidedCodexTerminal as terminal


@pytest.fixture()
def temp_config(tmp_path, monkeypatch):
    cfg_path = tmp_path / "codex.json"
    cfg_path.write_text(json.dumps({"audio": {"tts_rate": 5}}, indent=2), encoding="utf-8")
    monkeypatch.setattr(terminal, "CONFIG_PATH", cfg_path)
    return cfg_path


def test_load_config_populates_ui_defaults(temp_config):
    config = terminal.load_config()
    assert config["ui"]["audio_panel"] == {"visible": False, "pinned": False}
    saved = json.loads(Path(temp_config).read_text(encoding="utf-8"))
    assert saved["ui"]["audio_panel"] == {"visible": False, "pinned": False}
```

**Functions:** temp_config(tmp_path, monkeypatch), test_load_config_populates_ui_defaults(temp_config)


## Module `tests\test_command_panel.py`

```python
import pytest

pytest.importorskip("PySide6")
from types import SimpleNamespace

from PySide6.QtWidgets import QApplication

from Voice_Guided_Tools import AppConfig, MainWindow, PendingMagicLearn, VirtualDesktop


def _collect_labels(desktop: VirtualDesktop):
    return [row.suggestion.label for row in desktop._suggestion_rows]


def _find_row(desktop: VirtualDesktop, label: str):
    for row in desktop._suggestion_rows:
        if row.suggestion.label == label:
            return row
    raise AssertionError(f"Suggestion '{label}' not found")


@pytest.fixture
def qapp():
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    return app


def test_available_commands_panel_updates(qapp):
    cfg = AppConfig()
    window = MainWindow.__new__(MainWindow)
    window.cfg = cfg
    window.desktop = VirtualDesktop(cfg)
    window.desktop.suggestion_confirmed.connect(window._on_suggestion_confirmed)
    window.desktop.suggestion_denied.connect(window._on_suggestion_denied)
    window.desktop.history_action_requested.connect(window._on_history_action_requested)
    window._mic_running = False
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_buckets = []
    window._session = None
    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None

    try:
        window._update_command_suggestions()
        items = _collect_labels(window.desktop)
        assert window.desktop.panel_commands.title() == "Available Commands"
        assert any("magic pause" in text for text in items)

        window._set_paused(True)
        paused_items = _collect_labels(window.desktop)
        assert any("magic start" in text for text in paused_items)

        window._set_pending_magic_learn(
            PendingMagicLearn(
                requested_at=0.0,
                last_heard_at=0.0,
                prompt="",
                segments=[],
                state="collecting",
            )
        )
        magic_items = _collect_labels(window.desktop)
        assert any("Magic Learn Segments" in text for text in magic_items)
        row = None
        for candidate in window.desktop._suggestion_rows:
            if "Magic Learn Segments" in candidate.suggestion.label:
                row = candidate
                break
        assert row is not None
        assert row.confirm.text() == "Magic Done"
        assert row.deny.text() == "Magic Stop"
        assert row.input is not None

        fake_plan = SimpleNamespace(title="Mock Plan", to_payload=lambda: {})
        decision = SimpleNamespace(
            intent="directive",
            needs_clarification=False,
            plan=fake_plan,
            error=None,
            question=None,
        )
        bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
        window._directive_buckets.append(bucket)
        window._set_pending_plan_decision(decision, bucket=bucket, utterance="mock plan")
        window._set_pending_sensitive({"echo_text": "structured_plan", "plan": {}}, bucket=bucket)
        plan_items = _collect_labels(window.desktop)
        assert any("Confirm Directives" in text for text in plan_items)
        assert any("Cancel Directives" in text for text in plan_items)

        window._set_pending_magic_learn(None)
        window._set_pending_plan_decision(None, bucket=bucket)
        bucket.pending_sensitive = None
        bucket.status = "idle"
        window._set_paused(False)
        final_items = _collect_labels(window.desktop)
        assert any("magic pause" in text for text in final_items)
    finally:
        window.desktop._anim.stop()
        window.desktop._overlay.deleteLater()
        window.desktop.deleteLater()


def test_waiting_buffer_suggestions_toggle(qapp):
    cfg = AppConfig()
    window = MainWindow.__new__(MainWindow)
    window.cfg = cfg
    window.desktop = VirtualDesktop(cfg)
    window.desktop.suggestion_confirmed.connect(window._on_suggestion_confirmed)
    window.desktop.suggestion_denied.connect(window._on_suggestion_denied)
    window.desktop.history_action_requested.connect(window._on_history_action_requested)
    window._mic_running = False
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_buckets = []
    window._session = None
    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None
    window._speech_buffer_initialized = True
    window._speech_buffer = ["hello"]
    window._speech_buffer_timer = SimpleNamespace(start=lambda *args, **kwargs: None)

    try:
        window._speech_buffer_waiting = False
        window._update_command_suggestions()
        labels = _collect_labels(window.desktop)
        assert "Need more time" not in labels
        assert "Summarize now" not in labels

        window._speech_buffer_waiting = True
        window._update_command_suggestions()
        labels = _collect_labels(window.desktop)
        assert "Need more time" in labels
        assert "Summarize now" in labels

        window._speech_buffer_waiting = False
        window._update_command_suggestions()
        labels = _collect_labels(window.desktop)
        assert "Need more time" not in labels
    finally:
        window.desktop._anim.stop()
        window.desktop._overlay.deleteLater()
        window.desktop.deleteLater()


def test_need_more_time_ctrl_magic_rearms_timer(qapp):
    cfg = AppConfig()
    window = MainWindow.__new__(MainWindow)
    window.cfg = cfg
    window.desktop = VirtualDesktop(cfg)
    window.desktop.suggestion_confirmed.connect(window._on_suggestion_confirmed)
    window.desktop.suggestion_denied.connect(window._on_suggestion_denied)
    window.desktop.history_action_requested.connect(window._on_history_action_requested)
    window._mic_running = True
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_buckets = []
    window._session = None
    narrations = []
    window._narrate = lambda text, *args, **kwargs: narrations.append(text)
    window._log = lambda *args, **kwargs: None
    window._speech_buffer_initialized = True
    window._speech_buffer = ["chunk one", "chunk two"]
    window._speech_buffer_waiting = True

    gap_ms = int(window._speech_buffer_gap() * 1000)
    timer_calls = []

    class DummyTimer:
        def start(self, ms):
            timer_calls.append(ms)

    window._speech_buffer_timer = DummyTimer()

    flush_calls = []

    original_flush = window._flush_speech_buffer

    def guard_flush(*args, **kwargs):
        flush_calls.append(kwargs.get("reason"))
        return original_flush(*args, **kwargs)

    window._flush_speech_buffer = guard_flush

    try:
        window._update_command_suggestions()
        window._handle_ctrl_magic("need_more_time")
        assert timer_calls and timer_calls[-1] == gap_ms
        assert window._speech_buffer_waiting is False
        assert window._speech_buffer  # buffer preserved
        assert any("keep listening" in msg.lower() for msg in narrations)
        assert not flush_calls  # guard ensures flush not used
    finally:
        window._flush_speech_buffer = original_flush
        window.desktop._anim.stop()
        window.desktop._overlay.deleteLater()
        window.desktop.deleteLater()


def test_summarize_now_ctrl_magic_flushes_buffer(qapp):
    cfg = AppConfig()
    window = MainWindow.__new__(MainWindow)
    window.cfg = cfg
    window.desktop = VirtualDesktop(cfg)
    window.desktop.suggestion_confirmed.connect(window._on_suggestion_confirmed)
    window.desktop.suggestion_denied.connect(window._on_suggestion_denied)
    window._mic_running = False
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_buckets = []
    window._session = None
    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None
    window._speech_buffer_initialized = True
    window._speech_buffer = ["chunk"]
    window._speech_buffer_waiting = True

    flush_calls = []

    def fake_flush(*, reason, maintain_indicator=True):
        flush_calls.append(reason)
        window._speech_buffer_waiting = False
        return "chunk"

    original_flush = window._flush_speech_buffer
    window._flush_speech_buffer = fake_flush

    try:
        window._handle_ctrl_magic("summarize_now")
        assert flush_calls == ["user-confirmed"]
        assert window._speech_buffer_waiting is False
    finally:
        window._flush_speech_buffer = original_flush
        window.desktop._anim.stop()
        window.desktop._overlay.deleteLater()
        window.desktop.deleteLater()


def test_confirm_button_triggers_ctrl_magic(qapp, monkeypatch):
    cfg = AppConfig()
    window = MainWindow.__new__(MainWindow)
    window.cfg = cfg
    window.desktop = VirtualDesktop(cfg)
    window.desktop.suggestion_confirmed.connect(window._on_suggestion_confirmed)
    window.desktop.suggestion_denied.connect(window._on_suggestion_denied)
    window._mic_running = False
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_buckets = []
    window._session = None
    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None

    captured = []

    def capture_ctrl(cmd: str):
        captured.append(cmd)

    monkeypatch.setattr(window, "_handle_ctrl_magic", capture_ctrl)
    window.planner_service = None  # attribute placeholder for handlers that expect it

    try:
        fake_plan = SimpleNamespace(title="Mock Plan", to_payload=lambda: {})
        decision = SimpleNamespace(
            intent="directive",
            needs_clarification=False,
            plan=fake_plan,
            error=None,
            question=None,
        )
        bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
        window._directive_buckets.append(bucket)
        window._set_pending_plan_decision(decision, bucket=bucket, utterance="mock plan")
        window._set_pending_sensitive({"echo_text": "structured_plan", "plan": {}}, bucket=bucket)

        row = _find_row(window.desktop, "Confirm Directives")
        row.confirm.click()
        assert captured and captured[-1] == "confirm"
    finally:
        window.desktop._anim.stop()
        window.desktop._overlay.deleteLater()
        window.desktop.deleteLater()
```

**Functions:** _collect_labels(desktop), _find_row(desktop, label), qapp(), test_available_commands_panel_updates(qapp), test_waiting_buffer_suggestions_toggle(qapp), test_need_more_time_ctrl_magic_rearms_timer(qapp), test_summarize_now_ctrl_magic_flushes_buffer(qapp), test_confirm_button_triggers_ctrl_magic(qapp, monkeypatch)


## Module `tests\test_dataset_manager.py`

```python
from pathlib import Path
from typing import List

from dataset_manager import DatasetManager


class StubHelper:
    def __init__(self) -> None:
        self.calls: List[str] = []

    def embed(self, text: str):
        self.calls.append(text)
        # deterministic one-dimensional vector for cosine similarity
        return True, [float(len(text) or 1)], ""


class FailingHelper(StubHelper):
    def embed(self, text: str):  # type: ignore[override]
        self.calls.append(text)
        return False, [], "offline"


def make_manager(
    tmp_path: Path,
    helper: StubHelper,
    *,
    enabled: bool,
) -> DatasetManager:
    data_dir = tmp_path / "data"
    data_dir.mkdir(parents=True, exist_ok=True)
    return DatasetManager(helper, data_dir=data_dir, enable_embeddings=enabled)


def test_append_persists_history_and_embeddings(tmp_path: Path) -> None:
    helper = StubHelper()
    manager = make_manager(tmp_path, helper, enabled=True)

    user_entry = manager.append(
        "user",
        "hello",
        {"source": "unit"},
    )
    assistant_entry = manager.append(
        "assistant",
        "world",
        {"source": "unit"},
    )

    dataset_file = manager.dataset_path
    index_file = manager.index_path
    assert dataset_file.exists()
    assert index_file.exists()

    history = manager.recent_history()
    assert [item.text for item in history] == ["hello", "world"]

    results = manager.semantic_search("hello")
    assert results
    assert {item.text for item in results} >= {"hello", "world"}

    assert user_entry.embedding
    assert assistant_entry.embedding
    # embeddings requested for both user and assistant text
    assert helper.calls


def test_embeddings_skipped_when_disabled(tmp_path: Path) -> None:
    helper = StubHelper()
    manager = make_manager(tmp_path, helper, enabled=False)

    entry = manager.append("user", "hi there")

    assert not entry.embedding
    assert helper.calls == []


def test_embedding_failure_does_not_block_append(tmp_path: Path) -> None:
    helper = FailingHelper()
    manager = make_manager(tmp_path, helper, enabled=True)

    entry = manager.append("user", "hello again")

    assert entry.embedding == []
    assert helper.calls == ["hello again"]

    # search returns no matches when embeddings cannot be produced
    assert manager.semantic_search("hello again") == []
```

**Classes:** StubHelper, FailingHelper
**Functions:** make_manager(tmp_path, helper), test_append_persists_history_and_embeddings(tmp_path), test_embeddings_skipped_when_disabled(tmp_path), test_embedding_failure_does_not_block_append(tmp_path)


## Module `tests\test_directive_buckets.py`

```python
import pytest

pytest.importorskip("PySide6")

from planner_service import PlannerDecision, PlannerPlan
from Voice_Guided_Tools import AppConfig, MainWindow


class StubDesktop:
    def __init__(self) -> None:
        self.commands: list[str] = []
        self.last_bubble: str | None = None
        self.history: list = []

    def set_bubble(self, text: str) -> None:
        self.last_bubble = text

    def set_command_suggestions(
        self,
        commands: list,
        history: list | None = None,
    ) -> None:
        labels: list[str] = []
        for item in commands:
            label = getattr(item, "label", None)
            if label is None:
                label = str(item)
            labels.append(label)
        self.commands = labels
        self.history = list(history or [])

    def stop_autopilot(self) -> None:  # pragma: no cover - required by handler
        pass


@pytest.fixture
def stub_window() -> MainWindow:
    window = MainWindow.__new__(MainWindow)
    window.cfg = AppConfig()
    window.desktop = StubDesktop()
    window._directive_buckets = []
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_state = {"metadata": {}}
    window._session = type("S", (), {"write": staticmethod(lambda *args, **kwargs: None)})()
    window._narrations: list[str] = []
    window._narrate = lambda text: window._narrations.append(text)
    window._log = lambda *args, **kwargs: None
    window.planner_service = type(
        "Recorder",
        (),
        {"record_execution": staticmethod(lambda *args, **kwargs: None)},
    )()
    return window


def test_cancel_preserves_bucket_history(stub_window: MainWindow) -> None:
    plan = PlannerPlan(title="Sample Plan")
    decision = PlannerDecision(
        intent="directive",
        needs_clarification=False,
        question=None,
        plan=plan,
        confidence=0.9,
        raw={},
        raw_response="{}",
    )

    handled = stub_window._handle_planner_decision(decision, "create a sample plan")
    assert handled is True
    assert len(stub_window._directive_buckets) == 1
    bucket = stub_window._directive_buckets[0]
    assert bucket.status == "awaiting-confirmation"

    stub_window._handle_ctrl_magic("cancel_directives")
    assert bucket.status == "canceled"
    assert bucket.plan_payload == plan.to_payload()
    history = stub_window._bucket_history_cards()
    assert any(card.status == "canceled" for card in history)

    stub_window._handle_ctrl_magic("reinstate_directives")
    assert bucket.status == "awaiting-confirmation"
    pending = stub_window._get_pending_sensitive()
    assert isinstance(pending, dict)
    assert pending.get("plan", {}) == plan.to_payload()
    assert any("Confirm Directives" in cmd for cmd in stub_window.desktop.commands)
```

**Classes:** StubDesktop
**Functions:** stub_window(), test_cancel_preserves_bucket_history(stub_window)


## Module `tests\test_directive_history.py`

```python
import pytest

pytest.importorskip("PySide6")

from pathlib import Path
from typing import List

from dataset_manager import DatasetManager
from Voice_Guided_Tools import AppConfig, ChatReply, MainWindow


class RecordingDataset:
    def __init__(self) -> None:
        self.entries: List[tuple[str, str, dict]] = []

    def append(self, role: str, text: str, metadata: dict | None = None):
        record = (role, text, metadata or {})
        self.entries.append(record)
        return type("Entry", (), {"embedding": []})()


class RecordingChatResponder:
    def __init__(self) -> None:
        self.dataset = RecordingDataset()

    def reply(self, text: str, *, metadata: dict | None = None) -> ChatReply:
        return ChatReply("stub", [], True)


class StubDesktop:
    def set_bubble(self, text: str) -> None:
        pass

    def set_command_suggestions(
        self, commands: List[str], history: List | None = None
    ) -> None:
        pass

    def stop_autopilot(self) -> None:
        pass


def make_window() -> MainWindow:
    window = MainWindow.__new__(MainWindow)
    window.cfg = AppConfig()
    window.desktop = StubDesktop()
    window._directive_buckets = []
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_state = {"metadata": {"filename": "draft.py", "directory": "workspace/"}}
    window._session = type("S", (), {"write": staticmethod(lambda *args, **kwargs: None)})()
    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None
    window._update_command_suggestions = lambda *args, **kwargs: None
    window.chat_responder = RecordingChatResponder()
    window.planner_service = type(
        "Recorder",
        (),
        {"record_execution": staticmethod(lambda *args, **kwargs: None)},
    )()
    return window


def test_confirm_directive_records_metadata() -> None:
    window = make_window()
    plan_payload = {"title": "Sample Build", "metadata": {"themes": ["analysis pipeline"]}}
    bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
    bucket.title = "Sample Build"
    bucket.plan_payload = plan_payload
    window._directive_buckets.append(bucket)
    window._set_pending_sensitive({"echo_text": "structured_plan", "plan": plan_payload}, bucket=bucket)

    window._confirm_directives()

    role, text, metadata = window.chat_responder.dataset.entries[-1]
    assert role == "system"
    assert "Directive confirmed" in text
    assert metadata.get("directive_event") == "directive-confirmed"
    assert metadata.get("directive_bucket_id") == bucket.bucket_id
    assert metadata.get("directive_status") == bucket.status
    assert "sample" in metadata.get("directive_topics", "")


def test_cancel_directive_records_metadata() -> None:
    window = make_window()
    plan_payload = {"title": "Cancel Plan"}
    bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
    bucket.title = "Cancel Plan"
    bucket.plan_payload = plan_payload
    window._directive_buckets.append(bucket)
    window._set_pending_sensitive({"echo_text": "structured_plan", "plan": plan_payload}, bucket=bucket)

    window._cancel_directives()

    role, text, metadata = window.chat_responder.dataset.entries[-1]
    assert role == "system"
    assert metadata.get("directive_event") == "directive-canceled"
    assert metadata.get("directive_status") == "canceled"
    assert metadata.get("directive_bucket_id") == bucket.bucket_id
    assert "cancel" in metadata.get("directive_topics", "")


def test_reinstate_directive_records_metadata() -> None:
    window = make_window()
    plan_payload = {"title": "Reinstate Plan"}
    bucket = MainWindow.DirectiveBucket(status="awaiting-confirmation")
    bucket.title = "Reinstate Plan"
    bucket.plan_payload = plan_payload
    window._directive_buckets.append(bucket)
    window._set_pending_sensitive({"echo_text": "structured_plan", "plan": plan_payload}, bucket=bucket)

    window._cancel_directives()
    window.chat_responder.dataset.entries.clear()

    window._reinstate_directives()

    role, text, metadata = window.chat_responder.dataset.entries[-1]
    assert role == "system"
    assert metadata.get("directive_event") == "directive-reinstated"
    assert metadata.get("directive_status") == "awaiting-confirmation"
    assert metadata.get("directive_bucket_id") == bucket.bucket_id
    assert "reinstate" in metadata.get("directive_topics", "")


class StubEmbeddingHelper:
    def __init__(self) -> None:
        self.calls: List[str] = []

    def embed(self, text: str):
        self.calls.append(text)
        return True, [float(len(text) or 1)], ""


def make_manager(tmp_path: Path, *, enabled: bool) -> DatasetManager:
    data_dir = tmp_path / "data"
    data_dir.mkdir(parents=True, exist_ok=True)
    helper = StubEmbeddingHelper()
    return DatasetManager(helper, data_dir=data_dir, enable_embeddings=enabled)


def test_directive_metadata_filters(tmp_path: Path) -> None:
    manager = make_manager(tmp_path, enabled=True)

    manager.append(
        "system",
        "Directive confirmed: Build pipeline.",
        {
            "source": "directive",
            "directive_bucket_id": "bucket-a",
            "directive_status": "executed",
            "directive_topics": "build,pipeline",
        },
    )
    manager.append(
        "system",
        "Directive canceled: Build pipeline.",
        {
            "source": "directive",
            "directive_bucket_id": "bucket-a",
            "directive_status": "canceled",
            "directive_topics": "build,pipeline",
        },
    )
    manager.append(
        "system",
        "Directive reinstated: Build pipeline.",
        {
            "source": "directive",
            "directive_bucket_id": "bucket-b",
            "directive_status": "awaiting-confirmation",
            "directive_topics": "build,pipeline",
        },
    )

    executed = manager.filter_by_metadata({"directive_status": "executed"})
    assert len(executed) == 1
    assert executed[0].metadata.get("directive_status") == "executed"

    bucket_specific = manager.filter_by_metadata({"directive_bucket_id": "bucket-b"})
    assert len(bucket_specific) == 1
    assert bucket_specific[0].metadata.get("directive_status") == "awaiting-confirmation"

    search_results = manager.semantic_directive_search(
        "list past directives",
        statuses=["executed"],
    )
    assert search_results
    assert all(entry.metadata.get("directive_status") == "executed" for entry in search_results)
    assert executed[0].text in {entry.text for entry in search_results}
```

**Classes:** RecordingDataset, RecordingChatResponder, StubDesktop, StubEmbeddingHelper
**Functions:** make_window(), test_confirm_directive_records_metadata(), test_cancel_directive_records_metadata(), test_reinstate_directive_records_metadata(), make_manager(tmp_path), test_directive_metadata_filters(tmp_path)


## Module `tests\test_directive_history_cards.py`

```python
from types import SimpleNamespace

import pytest

pytest.importorskip("PySide6")

from PySide6.QtWidgets import QApplication

from Voice_Guided_Tools import AppConfig, MainWindow, VirtualDesktop


@pytest.fixture
def qapp():
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    return app


def _make_window(cfg: AppConfig) -> MainWindow:
    window = MainWindow.__new__(MainWindow)
    window.cfg = cfg
    window.desktop = VirtualDesktop(cfg)
    window.desktop.suggestion_confirmed.connect(window._on_suggestion_confirmed)
    window.desktop.suggestion_denied.connect(window._on_suggestion_denied)
    window.desktop.history_action_requested.connect(window._on_history_action_requested)
    window._mic_running = False
    window._pending_magic_learn = None
    window._paused = False
    window._last_nonmagic = None
    window._snapshot = None
    window._directive_buckets = []
    window._directive_state = {"metadata": {}}
    window._session = SimpleNamespace(write=lambda *args, **kwargs: None)
    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None
    return window


def test_history_card_reinstate_targets_single_bucket(qapp):
    cfg = AppConfig()
    window = _make_window(cfg)

    try:
        plan_one = {"title": "First Plan", "steps": [{"summary": "Step one"}]}
        bucket_one = MainWindow.DirectiveBucket(status="awaiting-confirmation")
        bucket_one.title = "First Plan"
        bucket_one.plan_payload = plan_one
        window._directive_buckets.append(bucket_one)
        window._set_pending_sensitive({"echo_text": "structured_plan", "plan": plan_one}, bucket=bucket_one)
        window._cancel_directives()

        plan_two = {"title": "Second Plan", "steps": [{"summary": "Step two"}]}
        bucket_two = MainWindow.DirectiveBucket(status="awaiting-confirmation")
        bucket_two.title = "Second Plan"
        bucket_two.plan_payload = plan_two
        window._directive_buckets.append(bucket_two)
        window._set_pending_sensitive({"echo_text": "structured_plan", "plan": plan_two}, bucket=bucket_two)
        window._cancel_directives()

        window._update_command_suggestions()

        rows = window.desktop._history_card_rows
        target_row = next(row for row in rows if row.card.bucket_id == bucket_one.bucket_id)
        other_row = next(row for row in rows if row.card.bucket_id == bucket_two.bucket_id)

        assert target_row.card.status == "canceled"
        assert other_row.card.status == "canceled"

        target_row.buttons["reinstate"].click()

        assert bucket_one.status == "awaiting-confirmation"
        assert bucket_two.status == "canceled"

        window._update_command_suggestions()
        updated_rows = {row.card.bucket_id: row for row in window.desktop._history_card_rows}
        assert updated_rows[bucket_one.bucket_id].widget.property("historyState") == "active"
        assert updated_rows[bucket_two.bucket_id].widget.property("historyState") == "archived"
    finally:
        window.desktop._anim.stop()
        window.desktop._overlay.deleteLater()
        window.desktop.deleteLater()
```

**Functions:** qapp(), _make_window(cfg), test_history_card_reinstate_targets_single_bucket(qapp)


## Module `tests\test_dispatch_errors.py`

```python
from __future__ import annotations

import pytest

PySide6 = pytest.importorskip("PySide6")
from PySide6.QtWidgets import QApplication

from Voice_Guided_Tools import AppConfig, MainWindow


class DummySession:
    def __init__(self) -> None:
        self.entries: list[dict] = []

    def write(self, obj: dict) -> None:
        self.entries.append(obj)


@pytest.fixture(scope="module")
def qapp():
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    yield app


def test_goto_unknown_target_uses_canonical_phrase(qapp):
    cfg = AppConfig()
    window = MainWindow(cfg)
    narrated: list[str] = []
    window._narrate = lambda text: narrated.append(text)
    window._log = lambda text: None

    dummy_session = DummySession()
    window._session = dummy_session

    try:
        window._dispatch("go to imaginary zone")

        assert window.desktop._bubble_lines[0] == "Input unrecognized."
        assert narrated[-1] == "Input unrecognized."

        # Ensure dispatch metadata includes canonical status details.
        matching_entries = [
            entry
            for entry in dummy_session.entries
            if entry.get("status") == "unknown-target"
        ]
        assert matching_entries, "expected session metadata for unknown target"
        helper_entry = matching_entries[-1]
        assert helper_entry["type"] == "dispatch"
        assert helper_entry["status"] == "unknown-target"
        assert helper_entry["intent"] == "goto"
        assert helper_entry["target"] == "imaginary zone"
    finally:
        window.close()
        window.deleteLater()
```

**Classes:** DummySession
**Functions:** qapp(), test_goto_unknown_target_uses_canonical_phrase(qapp)


## Module `tests\test_expressionary.py`

```python
"""Tests for builtin expressionary parsing helpers."""

from typing import Tuple

from typing import Tuple

import pytest

pytest.importorskip("PySide6")

from Voice_Guided_Tools import parse_expressionary


@pytest.mark.parametrize(
    "utterance",
    [
        "Create a script",
        "build a script",
        "Start a new code",
        "make a script",
        "Spin up a python script",
        "Start coding some python code",
        "Draft a python script",
        "Generate some python code",
        "Create python code for automation",
        "Start coding a script",
    ],
)
def test_parse_expressionary_recognizes_script_creation(utterance: str) -> None:
    intent, payload = parse_expressionary(utterance)
    assert intent == "directive"
    assert payload == {"plan": "create_python_script", "text": utterance}


@pytest.mark.parametrize(
    "utterance, expected",
    [
        ("magic proceed", ("ctrl_magic", {"cmd": "confirm"})),
        ("magic continue", ("ctrl_magic", {"cmd": "start"})),
        ("magic teach", ("magic_learn", {"payload": ""})),
        (
            "magic teach about loops",
            ("magic_learn", {"payload": "about loops"}),
        ),
    ],
)
def test_parse_expressionary_magic_synonyms(utterance: str, expected: Tuple[str, dict]) -> None:
    intent, payload = parse_expressionary(utterance)
    assert (intent, payload) == expected


@pytest.mark.parametrize(
    "utterance, expected",
    [
        ("magic send", ("ctrl_magic", {"cmd": "flush_buffer"})),
        ("magic flush buffer", ("ctrl_magic", {"cmd": "flush_buffer"})),
        ("magic cancel buffer", ("ctrl_magic", {"cmd": "cancel_buffer"})),
    ],
)
def test_parse_expressionary_buffer_controls(utterance: str, expected: Tuple[str, dict]) -> None:
    intent, payload = parse_expressionary(utterance)
    assert (intent, payload) == expected


@pytest.mark.parametrize(
    "utterance, expected_text",
    [
        ("I want you to type a story", "a story"),
        ("please write hello world", "hello world"),
        ("Could you type out The Plan", "The Plan"),
        ("Would you kindly write about the ocean", "the ocean"),
    ],
)
def test_parse_expressionary_polite_type_intents(
    utterance: str, expected_text: str
) -> None:
    intent, payload = parse_expressionary(utterance)
    assert intent == "type"
    assert payload == {"text": expected_text}


@pytest.mark.parametrize(
    "utterance", [
        "go to the code editor",
        "move to the terminal",
        "focus on the browser",
    ],
)
def test_parse_expressionary_goto_navigation(utterance: str) -> None:
    intent, payload = parse_expressionary(utterance)
    assert intent == "goto"
    assert "name" in payload
    assert payload["name"]


@pytest.mark.parametrize(
    "utterance",
    [
        "list your commands to me",
        "tell me how to create a script",
        "could you explain how to go to the editor",
    ],
)
def test_parse_expressionary_conversational_to_phrases(utterance: str) -> None:
    intent, payload = parse_expressionary(utterance)
    assert intent == "chat"
    assert payload == {"text": utterance}


def test_parse_expressionary_bucket_alias_commands() -> None:
    intent, payload = parse_expressionary("magic reinstate bucket ab12")
    assert intent == "ctrl_magic"
    assert payload["cmd"] == "reinstate_bucket"
    assert payload.get("metadata", {}).get("bucket_token") == "ab12"

    review_intent, review_payload = parse_expressionary("magic review bucket card42")
    assert review_intent == "ctrl_magic"
    assert review_payload["cmd"] == "review_bucket"
    assert review_payload.get("metadata", {}).get("bucket_token") == "card42"
```

Tests for builtin expressionary parsing helpers.
**Functions:** test_parse_expressionary_recognizes_script_creation(utterance), test_parse_expressionary_magic_synonyms(utterance, expected), test_parse_expressionary_buffer_controls(utterance, expected), test_parse_expressionary_polite_type_intents(utterance, expected_text), test_parse_expressionary_goto_navigation(utterance), test_parse_expressionary_conversational_to_phrases(utterance), test_parse_expressionary_bucket_alias_commands()


## Module `tests\test_keyboard_typing.py`

```python
from __future__ import annotations

import pytest

pytest.importorskip("PySide6")

from PySide6.QtCore import QPointF
from PySide6.QtWidgets import QApplication, QPlainTextEdit, QVBoxLayout, QWidget

from Voice_Guided_Tools import AppConfig, MainWindow, OnScreenKeyboard


class DesktopHarness(QWidget):
    def __init__(self) -> None:
        super().__init__()
        self.moves: list[tuple[float, float]] = []
        self.flashes = 0
        self.animations: list[tuple[QPointF, QPointF, float, float]] = []
        self._cursor = QPointF(0.0, 0.0)

        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(0)

        self.code_edit = QPlainTextEdit(self)
        layout.addWidget(self.code_edit)

        self.keyboard = OnScreenKeyboard(self)
        layout.addWidget(self.keyboard)

    def move_to(self, x: float, y: float) -> None:
        self.moves.append((float(x), float(y)))
        self._cursor = QPointF(float(x), float(y))

    def click_flash(self) -> None:
        self.flashes += 1

    def cursor_position(self) -> QPointF:
        return QPointF(self._cursor)

    def begin_typing_motion(self, start: QPointF, target: QPointF, travel: float, hold: float) -> None:
        self.animations.append((QPointF(start), QPointF(target), float(travel), float(hold)))

    def clear_ghosts(self) -> None:  # pragma: no cover - compatibility shim
        pass


@pytest.fixture(scope="module")
def qapp() -> QApplication:
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    return app


def test_type_text_uses_keyboard_clicks(qapp: QApplication) -> None:
    cfg = AppConfig()
    cfg.typing_travel_time = 0.0
    cfg.typing_hold_time = 0.0

    desktop = DesktopHarness()
    desktop.resize(720, 360)
    desktop.show()
    qapp.processEvents()

    window = MainWindow.__new__(MainWindow)
    window.cfg = cfg
    window.desktop = desktop

    typed_keys: list[str] = []
    original_emit = desktop.keyboard.emit_key

    def capture_emit(key: str) -> None:
        typed_keys.append(key)
        original_emit(key)

    desktop.keyboard.emit_key = capture_emit  # type: ignore[assignment]

    desktop.code_edit.setPlainText("")
    desktop.code_edit.setFocus()

    window._type_text("Hi!")
    qapp.processEvents()

    assert desktop.code_edit.toPlainText() == "Hi!"
    assert desktop.moves
    assert desktop.flashes == len(typed_keys)
    assert len(desktop.animations) == len(typed_keys)
    assert typed_keys.count("Shift") == 2
    assert "H" in typed_keys and "I" in typed_keys and "1" in typed_keys
    assert len(typed_keys) == 5
```

**Classes:** DesktopHarness
**Functions:** qapp(), test_type_text_uses_keyboard_clicks(qapp)


## Module `tests\test_magic_learn.py`

```python
from __future__ import annotations

import types
from pathlib import Path

import pytest

PySide6 = pytest.importorskip("PySide6")
from PySide6.QtWidgets import QApplication

from Voice_Guided_Tools import (
    AppConfig,
    MainWindow,
    PendingMagicLearn,
    normalize,
    set_lexicon_manager,
)
from lexicon_manager import LexiconManager


@pytest.fixture(scope="module")
def qapp():
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    yield app


def test_magic_learn_multi_segment_flow(qapp, tmp_path: Path):
    cfg = AppConfig()
    window = MainWindow(cfg)
    window.lexicon = LexiconManager(
        storage_path=tmp_path / "lexicon.json",
        normalizer=normalize,
    )
    set_lexicon_manager(window.lexicon)

    narrated: list[str] = []
    window._narrate = lambda text: narrated.append(text)
    logs: list[str] = []
    window._log = lambda text: logs.append(text)

    try:
        window._handle_magic_learn("")
        assert window._pending_magic_learn is not None
        assert window._pending_magic_learn.segments == []
        assert window._pending_magic_learn.state == "collecting"
        assert any("magic done" in entry.lower() for entry in narrated)
        assert any("awaiting magic learn payload" in entry.lower() for entry in logs)
        assert window.desktop._bubble_lines[0].lower().startswith("listening for magic")

        window._dispatch("snap => move left")
        assert window._pending_magic_learn is not None
        assert window._pending_magic_learn.segments == ["snap => move left"]
        assert any("captured magic learn segment #1" in entry.lower() for entry in logs)

        window._dispatch("50")
        assert window._pending_magic_learn is not None
        assert window._pending_magic_learn.segments == ["snap => move left", "50"]
        assert any("captured magic learn segment #2" in entry.lower() for entry in logs)

        window._dispatch("magic done")

        assert window._pending_magic_learn is None
        assert any("finalizing magic learn payload" in entry.lower() for entry in logs)
        assert any("magic learn learned" in entry.lower() for entry in logs)
        assert any("i'll remember" in entry.lower() for entry in narrated)

        match = window.lexicon.match("snap")
        assert match is not None
        intent, params = match
        assert intent == "move"
        assert params.get("dir") == "left"
        assert params.get("units") == 50
    finally:
        set_lexicon_manager(None)
        window.close()
        window.deleteLater()


def test_magic_learn_direct_payload(qapp, tmp_path: Path):
    cfg = AppConfig()
    window = MainWindow(cfg)
    window.lexicon = LexiconManager(
        storage_path=tmp_path / "lexicon.json",
        normalizer=normalize,
    )
    set_lexicon_manager(window.lexicon)

    logs: list[str] = []
    window._log = lambda text: logs.append(text)

    try:
        window._handle_magic_learn("snap => move right 25")
        assert window._pending_magic_learn is None
        assert any("magic learn learned" in entry.lower() for entry in logs)

        match = window.lexicon.match("snap")
        assert match is not None
        intent, params = match
        assert intent == "move"
        assert params.get("dir") == "right"
        assert params.get("units") == 25
    finally:
        set_lexicon_manager(None)
        window.close()
        window.deleteLater()


def test_magic_done_without_pending_learn_errors(qapp):
    cfg = AppConfig()
    window = MainWindow(cfg)

    prompts: list[str] = []
    window._narrate = lambda text: prompts.append(text)
    window._log = lambda *args, **kwargs: None

    session_entries: list[dict] = []
    window._session = types.SimpleNamespace(write=lambda obj: session_entries.append(obj))

    try:
        window._dispatch("magic done")

        assert prompts, "expected narration for unsupported magic done"
        assert prompts[-1] == "There's no shortcut waiting for magic done."
        assert session_entries, "expected session log entry"
        assert session_entries[-1].get("reason") == "magic-done-no-pending"
    finally:
        window.close()
        window.deleteLater()


def test_magic_learn_unrecognized_action_uses_canonical_phrase(qapp, tmp_path: Path):
    cfg = AppConfig()
    window = MainWindow(cfg)
    window.lexicon = LexiconManager(
        storage_path=tmp_path / "lexicon.json",
        normalizer=normalize,
    )
    set_lexicon_manager(window.lexicon)

    narrated: list[str] = []
    window._narrate = lambda text: narrated.append(text)

    class DummySession:
        def __init__(self) -> None:
            self.entries: list[dict] = []

        def write(self, obj: dict) -> None:
            self.entries.append(obj)

    dummy_session = DummySession()
    window._session = dummy_session

    try:
        window._handle_magic_learn("snap => magic learn")

        assert window.desktop._bubble_lines[0] == "Input unrecognized."
        assert narrated[-1] == "Input unrecognized."

        assert dummy_session.entries, "expected session entry for unrecognized action"
        entry = dummy_session.entries[-1]
        assert entry["type"] == "lexicon"
        assert entry["status"] == "unrecognized-action"
        assert entry["phrase"] == "snap"
        assert entry["action"] == "magic learn"
    finally:
        set_lexicon_manager(None)
        window.close()
        window.deleteLater()


def test_magic_learn_cancel_with_magic_stop(qapp, tmp_path: Path):
    cfg = AppConfig()
    window = MainWindow(cfg)
    window.lexicon = LexiconManager(
        storage_path=tmp_path / "lexicon.json",
        normalizer=normalize,
    )
    set_lexicon_manager(window.lexicon)

    narrated: list[str] = []
    window._narrate = lambda text: narrated.append(text)
    logs: list[str] = []
    window._log = lambda text: logs.append(text)

    try:
        window._handle_magic_learn("")
        assert window._pending_magic_learn is not None

        window._dispatch("magic stop")

        assert window._pending_magic_learn is None
        assert any("magic learn canceled" in entry.lower() for entry in logs)
        assert any("canceling the pending shortcut request" in entry.lower() for entry in narrated)
    finally:
        set_lexicon_manager(None)
        window.close()
        window.deleteLater()


def test_magic_learn_ui_confirmation_without_spoken_done(qapp, tmp_path: Path):
    cfg = AppConfig()
    window = MainWindow(cfg)
    window.lexicon = LexiconManager(
        storage_path=tmp_path / "lexicon.json",
        normalizer=normalize,
    )
    set_lexicon_manager(window.lexicon)

    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None

    try:
        window._handle_magic_learn("")
        assert window._pending_magic_learn is not None

        window._dispatch("snap => move left")
        assert window._pending_magic_learn is not None

        rows = window.desktop._suggestion_rows
        payload_row = None
        for row in rows:
            if "Magic Learn Segments" in row.suggestion.label:
                payload_row = row
                break

        assert payload_row is not None, "Expected magic learn suggestion row"
        assert payload_row.input is not None

        payload_row.input.setText("snap => type hello world")
        payload_row.confirm.click()

        assert window._pending_magic_learn is None

        match = window.lexicon.match("snap")
        assert match is not None
        intent, params = match
        assert intent == "type"
        assert params.get("text") == "hello world"
    finally:
        set_lexicon_manager(None)
        window.close()
        window.deleteLater()
```

**Functions:** qapp(), test_magic_learn_multi_segment_flow(qapp, tmp_path), test_magic_learn_direct_payload(qapp, tmp_path), test_magic_done_without_pending_learn_errors(qapp), test_magic_learn_unrecognized_action_uses_canonical_phrase(qapp, tmp_path), test_magic_learn_cancel_with_magic_stop(qapp, tmp_path), test_magic_learn_ui_confirmation_without_spoken_done(qapp, tmp_path)


## Module `tests\test_ollama_helper.py`

```python
from __future__ import annotations

from typing import Dict, List

import ollama_helper
from ollama_helper import OllamaHelper


class DummyCompletedProcess:
    def __init__(
        self,
        stdout: str = "",
        stderr: str = "",
        returncode: int = 0,
    ) -> None:
        self.stdout = stdout
        self.stderr = stderr
        self.returncode = returncode


def test_chat_cli_fallback_when_requests_unavailable(monkeypatch) -> None:
    monkeypatch.setattr(ollama_helper, "requests", None)

    captured: Dict[str, List[str]] = {}

    def fake_run(args, check, capture_output, text, timeout):
        captured["args"] = args
        return DummyCompletedProcess(stdout="hi there")

    monkeypatch.setattr(ollama_helper.subprocess, "run", fake_run)

    helper = OllamaHelper(host="http://example")
    result = helper.chat(
        [{"role": "user", "content": "hello"}],
        model="test",
        timeout=1.0,
    )

    assert result.ok
    assert result.content == "hi there"
    assert result.diagnostics == {"transport": "cli"}
    assert captured["args"][0:3] == ["ollama", "run", "test"]


def test_list_models_uses_cli_when_http_unavailable(monkeypatch) -> None:
    monkeypatch.setattr(ollama_helper, "requests", None)

    listing = "NAME\nmodel-a\nmodel-b\n"

    def fake_run(args, check, capture_output, text, timeout):
        return DummyCompletedProcess(stdout=listing)

    monkeypatch.setattr(ollama_helper.subprocess, "run", fake_run)

    helper = OllamaHelper(host="http://example")
    models = helper.list_models()

    assert models == ["model-a", "model-b"]
```

**Classes:** DummyCompletedProcess
**Functions:** test_chat_cli_fallback_when_requests_unavailable(monkeypatch), test_list_models_uses_cli_when_http_unavailable(monkeypatch)


## Module `tests\test_planner_service.py`

```python
import json
from pathlib import Path

from ollama_helper import OllamaResult
from planner_service import PlannerService


class DummyHelper:
    def __init__(self, results):
        self._results = list(results)
        self.calls = []

    def chat(self, messages, model="", timeout=0.0, stream=False):
        self.calls.append({"messages": messages, "model": model, "timeout": timeout})
        return self._results.pop(0)


def read_jsonl(path: Path):
    return [json.loads(line) for line in path.read_text(encoding="utf-8").splitlines() if line.strip()]


def test_planner_service_parses_plan_and_logs(tmp_path: Path):
    payload = {
        "intent": "plan",
        "title": "Open Editor",
        "confidence": 0.82,
        "steps": [
            {"action": "goto", "summary": "Move focus to the code editor"},
            {"action": "ask", "summary": "Confirm next action"},
        ],
    }
    helper = DummyHelper([OllamaResult(True, json.dumps(payload))])
    service = PlannerService(helper=helper, data_dir=tmp_path)

    decision = service.plan("open the editor", context={"bubble": "Ready"})

    assert decision.plan is not None
    assert decision.plan.title == "Open Editor"
    assert len(decision.plan.steps) == 2
    assert helper.calls, "planner should invoke the helper"

    json_entries = read_jsonl(service.json_log)
    assert json_entries and json_entries[0]["event"] == "decision"

    md_text = service.md_log.read_text(encoding="utf-8")
    assert "Open Editor" in md_text


def test_planner_service_falls_back_to_clarification(tmp_path: Path):
    helper = DummyHelper([OllamaResult(False, "", "network error")])
    service = PlannerService(helper=helper, data_dir=tmp_path)

    decision = service.plan("design something")

    assert decision.needs_clarification is True
    assert decision.question
    json_entries = read_jsonl(service.json_log)
    assert json_entries[0]["decision"]["needs_clarification"] is True
```

**Classes:** DummyHelper
**Functions:** read_jsonl(path), test_planner_service_parses_plan_and_logs(tmp_path), test_planner_service_falls_back_to_clarification(tmp_path)


## Module `tests\test_plan_execution.py`

```python
from __future__ import annotations

import pytest

pytest.importorskip("PySide6")

from PySide6.QtCore import QPointF
from PySide6.QtGui import QTextCursor
from PySide6.QtWidgets import QApplication, QPlainTextEdit

from Voice_Guided_Tools import MainWindow


class DummyPoint:
    def __init__(self, x: float, y: float) -> None:
        self._x = x
        self._y = y

    def x(self) -> float:
        return self._x

    def y(self) -> float:
        return self._y


class DummyDesktop:
    def __init__(self) -> None:
        self.code_edit = QPlainTextEdit()
        self._cursor = QPointF(0.0, 0.0)
        self.moves: list[tuple[float, float]] = []

    def move_to(self, x: float, y: float) -> None:
        self.moves.append((x, y))

    def _keyboard_area_ghosts(self) -> list[object]:
        return []

    def show_ghosts(self, ghosts) -> None:  # pragma: no cover - UI hint
        pass

    def clear_ghosts(self) -> None:
        pass


class DummyRecorder:
    def __init__(self) -> None:
        self.calls: list[tuple[tuple, dict]] = []

    def record_execution(self, *args, **kwargs) -> None:
        self.calls.append((args, kwargs))


@pytest.fixture(scope="module")
def qapp() -> QApplication:
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    return app


def test_execute_plan_writes_expected_script(qapp: QApplication) -> None:
    assert qapp is not None
    imports = "import argparse\nimport logging\nfrom pathlib import Path\n\n"
    scaffold = (
        "def main():\n"
        "    print('hello')\n\n"
        "if __name__ == '__main__':\n"
        "    main()\n"
    )
    expected_script = f"{imports}{scaffold}"

    window = MainWindow.__new__(MainWindow)
    window.desktop = DummyDesktop()
    window.desktop.code_edit.setPlainText("pre-existing text")
    cursor = window.desktop.code_edit.textCursor()
    cursor.movePosition(QTextCursor.End)
    window.desktop.code_edit.setTextCursor(cursor)

    window._directive_buckets = []
    window._narrations: list[str] = []
    window._logs: list[str] = []
    window._snapshot_tags: list[str] = []
    window._directive_state = {"metadata": {}}

    window._narrate = lambda text: window._narrations.append(text)
    window._log = lambda text: window._logs.append(text)
    window._snapshot_state = lambda tag: window._snapshot_tags.append(tag)
    window._capture_plan_context = lambda tag, title: None
    window._nearest_target = lambda name: DummyPoint(1.0, 2.0) if name == "code editor" else None
    window.planner_service = DummyRecorder()

    type_calls: list[str] = []
    caret_positions: list[int] = []

    def fake_type_text(text: str) -> None:
        caret_positions.append(window.desktop.code_edit.textCursor().position())
        window.desktop.code_edit.insertPlainText(text)
        type_calls.append(text)

    window._type_text = fake_type_text

    window._execute_plan({"title": "Draft script"})

    assert window.desktop.code_edit.toPlainText() == expected_script
    assert type_calls == [expected_script]
    assert caret_positions == [0]
    assert window._get_pending_sensitive() == {"echo_text": "post_plan_question"}


def test_execute_plan_honors_filename_and_directory_metadata(qapp: QApplication) -> None:
    assert qapp is not None
    imports = "import argparse\nimport logging\nfrom pathlib import Path\n\n"
    scaffold = (
        "def main():\n"
        "    print('hello')\n\n"
        "if __name__ == '__main__':\n"
        "    main()\n"
    )
    expected_script = f"# File: workflows/easy_script.py\n\n{imports}{scaffold}"

    window = MainWindow.__new__(MainWindow)
    window.desktop = DummyDesktop()
    window.desktop.code_edit.setPlainText("")

    window._directive_buckets = []
    window._narrations = []
    window._logs = []
    window._snapshot_tags = []

    utterance = "create a script called easy_script.py in workflows/"
    plan = window._directive_plan("create_python_script", utterance)
    window._initialize_directive_plan_state(plan, utterance)

    window._narrate = lambda text: window._narrations.append(text)
    window._log = lambda text: window._logs.append(text)
    window._snapshot_state = lambda tag: window._snapshot_tags.append(tag)
    window._capture_plan_context = lambda tag, title: None
    window._nearest_target = lambda name: DummyPoint(0.0, 0.0)
    window.planner_service = DummyRecorder()

    type_calls: list[str] = []

    def fake_type_text(text: str) -> None:
        window.desktop.code_edit.insertPlainText(text)
        type_calls.append(text)

    window._type_text = fake_type_text

    window._execute_plan(plan)

    assert window.desktop.code_edit.toPlainText() == expected_script
    assert type_calls == [expected_script]
```

**Classes:** DummyPoint, DummyDesktop, DummyRecorder
**Functions:** qapp(), test_execute_plan_writes_expected_script(qapp), test_execute_plan_honors_filename_and_directory_metadata(qapp)


## Module `tests\test_script_metadata.py`

```python
import pytest

pytest.importorskip("PySide6")

from Voice_Guided_Tools import MainWindow

def make_window() -> MainWindow:
    window = MainWindow.__new__(MainWindow)
    return window


def test_extract_script_metadata_normalizes_filename_and_directory() -> None:
    window = make_window()
    transcript = (
        "Let's plan a helper; the script name is easy script and save it under "
        "automation/tools path that processes csv exports."
    )
    metadata = window._extract_script_metadata(transcript)
    assert metadata["filename"] == "easy_script.py"
    assert metadata["directory"] == "automation/tools/"
    assert metadata["themes"] == ["processes csv exports"]


def test_extract_script_metadata_handles_inside_of_folder_phrase() -> None:
    window = make_window()
    transcript = (
        "Call it cleanup helper please and place it inside of the utilities folder "
        "which handles log cleanup."
    )
    metadata = window._extract_script_metadata(transcript)
    assert metadata["filename"] == "cleanup_helper.py"
    assert metadata["directory"] == "utilities/"
    assert metadata["themes"] == ["handles log cleanup"]
```

**Functions:** make_window(), test_extract_script_metadata_normalizes_filename_and_directory(), test_extract_script_metadata_handles_inside_of_folder_phrase()


## Module `tests\test_speech_buffer.py`

```python
import types

import pytest

pytest.importorskip("PySide6")
from PySide6.QtWidgets import QApplication

import Voice_Guided_Tools as vgt
from Voice_Guided_Tools import AppConfig, ChatReply, MainWindow
from planner_service import PlannerDecision


@pytest.fixture(scope="module")
def qapp():
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    yield app


def _make_window(cfg: AppConfig) -> MainWindow:
    window = MainWindow(cfg)
    window._narrate = lambda *args, **kwargs: None
    window._log = lambda *args, **kwargs: None
    return window


def test_speech_buffer_summary_requires_confirmation(qapp):
    cfg = AppConfig()
    cfg.speech_buffer_silence = 0.25
    window = _make_window(cfg)
    prompts: list[str] = []
    window._narrate = lambda message, *args, **kwargs: prompts.append(message)

    def fake_reply(prompt: str, *, metadata: dict | None = None) -> ChatReply:
        if prompt.startswith("Summarize"):
            return ChatReply("Create workflow script with logging", [], True)
        return ChatReply("Acknowledged", [], True)

    window.chat_responder.reply = fake_reply

    plan_calls: list[tuple[str, dict | None]] = []

    def fake_plan(text: str, *, context: dict | None = None) -> PlannerDecision:
        plan_calls.append((text, context or {}))
        return PlannerDecision(
            intent="chat",
            needs_clarification=False,
            question=None,
            plan=None,
            confidence=0.5,
            raw={},
            raw_response="stub",
        )

    window.planner_service.plan = fake_plan

    dispatched: list[tuple[str, str | None]] = []
    original_dispatch = window._dispatch

    def capturing_dispatch(self, text: str, *, summary: str | None = None):
        dispatched.append((text, summary))
        return original_dispatch(text, summary=summary)

    window._dispatch = types.MethodType(capturing_dispatch, window)

    original_parse = vgt.parse_expressionary
    vgt.parse_expressionary = lambda text: ("chat", {"text": text})

    bucket = MainWindow.DirectiveBucket(status="collecting")
    window._directive_buckets.append(bucket)

    try:
        window._on_mic_text("Please create a workflow automation script for me.")
        window._on_mic_text("Make sure it logs output and saves into the workflows directory.")

        combined = window._flush_speech_buffer(reason="test")
        assert combined.startswith("Please create")
        assert bucket.status == "awaiting-confirmation"
        assert not dispatched
        assert not plan_calls
        assert prompts and prompts[-1].startswith("Summary: ")
        assert "workflow" in prompts[-1].lower()
        assert window.desktop.user_chat.toPlainText().strip().startswith("Please create")

        labels = [suggestion.label for suggestion in window.desktop._current_suggestions]
        assert "Confirm Directives" in labels
        assert "Correct Directive" in labels

        window._handle_ctrl_magic("confirm")

        assert dispatched, "dispatch should occur after confirmation"
        confirmed_text, confirmed_summary = dispatched[0]
        assert confirmed_text.startswith("Please create")
        assert confirmed_summary == "Create workflow script with logging"
        assert plan_calls and plan_calls[0][0] == confirmed_text
        assert plan_calls[0][1].get("summary") == confirmed_summary
    finally:
        vgt.parse_expressionary = original_parse
        window.close()
        window.deleteLater()


def test_cancel_directives_clears_pending_summary(qapp):
    cfg = AppConfig()
    cfg.speech_buffer_silence = 0.25
    window = _make_window(cfg)
    window._narrate = lambda *args, **kwargs: None

    window.chat_responder.reply = lambda prompt, *, metadata=None: ChatReply("Summarized directive", [], True)

    dispatched: list[tuple[str, str | None]] = []

    def capturing_dispatch(self, text: str, *, summary: str | None = None):
        dispatched.append((text, summary))

    window._dispatch = types.MethodType(capturing_dispatch, window)

    bucket = MainWindow.DirectiveBucket(status="collecting")
    window._directive_buckets.append(bucket)

    try:
        window._on_mic_text("Draft a status report")
        window._on_mic_text("Summarize blockers and next steps")

        window._flush_speech_buffer(reason="test")
        assert bucket.pending_utterance
        assert bucket.status == "awaiting-confirmation"

        window._handle_ctrl_magic("cancel_directives")

        assert bucket.pending_utterance is None
        assert bucket.pending_summary is None
        assert bucket.status == "canceled"
        assert not dispatched
    finally:
        window.close()
        window.deleteLater()


def test_magic_done_confirms_buffer_when_waiting(qapp):
    cfg = AppConfig()
    window = _make_window(cfg)
    window._ensure_speech_buffer()
    window._speech_buffer_waiting = True
    window._pending_magic_learn = None

    prompts: list[str] = []
    window._narrate = lambda message, *args, **kwargs: prompts.append(message)

    reasons: list[str] = []
    original_flush = window._flush_speech_buffer

    def fake_flush(*, reason: str, maintain_indicator: bool = True):
        reasons.append(reason)
        return "Buffered directive"

    window._flush_speech_buffer = fake_flush  # type: ignore[assignment]

    try:
        window._dispatch("magic done")

        assert reasons == ["magic-done"], "expected buffered confirmation via magic done"
        assert not window._speech_buffer_waiting
        assert prompts, "expected narration acknowledging confirmation"
        assert "continue" in prompts[-1].lower()
    finally:
        window._flush_speech_buffer = original_flush  # type: ignore[assignment]
        window.close()
        window.deleteLater()
```

**Functions:** qapp(), _make_window(cfg), test_speech_buffer_summary_requires_confirmation(qapp), test_cancel_directives_clears_pending_summary(qapp), test_magic_done_confirms_buffer_when_waiting(qapp)


## Module `tests\test_tts_barge_in.py`

```python
import pytest

pytest.importorskip("PySide6")
from PySide6.QtWidgets import QApplication

from Voice_Guided_Tools import AppConfig, MainWindow


@pytest.fixture(scope="module")
def qapp():
    app = QApplication.instance()
    if app is None:
        app = QApplication([])
    yield app


def test_user_speech_stops_active_tts_until_resume(qapp):
    cfg = AppConfig()
    window = MainWindow(cfg)
    window.cfg.tts_full_duplex = False
    window.cfg.tts_engine = "pyttsx3"

    stop_events: list[str] = []
    resume_events: list[str] = []
    window.tts_stop.connect(lambda: stop_events.append("stop"))
    window.tts_say.connect(lambda text: resume_events.append(text))

    try:
        window._on_tts_speaking("Narration in progress")
        assert window._tts_speaking

        window._on_user_speech_start()

        assert stop_events, "Expected barge-in to emit stop() on the TTS engine"
        assert window._tts_pending_resume == "Narration in progress"
        assert not window._tts_speaking
        assert not resume_events, "Narration should not resume until pending TTS is flushed"

        window._resume_pending_tts_if_needed()

        assert resume_events == ["Narration in progress"]
        assert window._tts_pending_resume is None
    finally:
        window.close()
        window.deleteLater()
```

**Functions:** qapp(), test_user_speech_stops_active_tts_until_resume(qapp)


## Module `tests\test_virtual_desktop_shell.py`

```python
import pytest

pytest.importorskip("PySide6")

import os
import sys
from pathlib import Path

from PySide6.QtWidgets import QApplication

import Virtual_Desktop as vd


@pytest.fixture
def qapp():
    app = QApplication.instance()
    if app is None:
        # Ensure the offscreen platform is used when tests run headlessly.
        os.environ.setdefault("QT_QPA_PLATFORM", "offscreen")
        app = QApplication([])
    return app


def test_workspace_root_defaults_to_repo_root():
    repo_root = Path(__file__).resolve().parent.parent
    assert Path(vd.workspace_root()) == repo_root


def test_validate_process_request_allows_python_in_workspace(tmp_path):
    cwd = vd.workspace_root()
    ok, resolved = vd.validate_process_request([sys.executable, "-c", "print('ok')"], cwd=cwd)
    assert ok
    assert resolved == sys.executable


def test_validate_process_request_blocks_external_cwd(tmp_path):
    outside = tmp_path  # pytest tmp paths live outside the repo workspace
    ok, message = vd.validate_process_request([sys.executable], cwd=str(outside))
    assert not ok
    assert "outside" in message.lower()


def test_start_panel_registers_voice_codex_entry(qapp):
    window = vd.VirtualDesktopWindow()
    try:
        entry_ids = {entry.identifier for entry in window._start_panel.entries()}
        assert "voice-codex-terminal" in entry_ids
    finally:
        window.close()
        window.deleteLater()
```

**Functions:** qapp(), test_workspace_root_defaults_to_repo_root(), test_validate_process_request_allows_python_in_workspace(tmp_path), test_validate_process_request_blocks_external_cwd(tmp_path), test_start_panel_registers_voice_codex_entry(qapp)


## Module `tools\codex_pr_sentinel.py`

```python
#!/usr/bin/env python3
"""Codex PR Sentinel utilities.

This lightweight script is invoked by the watcher and sentinel GitHub Actions
workflows to compose canonical status comments. It intentionally avoids any
network side effects so that CI can exercise the logic without needing a
GitHub token when running locally.
"""

from __future__ import annotations

import argparse
import json
import sys
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Optional

COMMENT_TAG = "<!-- CODEX-SENTINEL-COMMENT -->"


@dataclass
class PRStatus:
    head_ref: str = "unknown"
    base_ref: str = "main"
    head_sha: str = ""
    mergeable_state: str = "unknown"
    checks: str = "No checks found"
    blockers: str = "No blockers recorded"

    @classmethod
    def from_event(cls, payload: Dict[str, Any]) -> "PRStatus":
        pr = payload.get("pull_request") or {}
        check_runs = payload.get("check_runs") or []
        checks = "No checks found"
        if check_runs:
            failing = [
                run
                for run in check_runs
                if run.get("conclusion") not in ("success", None)
            ]
            if failing:
                checks = ", ".join(
                    f"{run.get('name')}: {run.get('conclusion')}"
                    for run in failing
                )
            else:
                checks = "All checks passing"
        blockers = []
        if pr.get("draft"):
            blockers.append("Draft PR")
        if pr.get("mergeable_state") and pr["mergeable_state"] != "clean":
            blockers.append(f"mergeable_state={pr['mergeable_state']}")
        reviews = payload.get("reviews") or []
        if any(r.get("state") == "CHANGES_REQUESTED" for r in reviews):
            blockers.append("Changes requested")
        blocker_text = "; ".join(blockers) if blockers else "None"
        return cls(
            head_ref=pr.get("head", {}).get("ref", "unknown"),
            base_ref=pr.get("base", {}).get("ref", "main"),
            head_sha=pr.get("head", {}).get("sha", ""),
            mergeable_state=pr.get("mergeable_state", "unknown"),
            checks=checks,
            blockers=blocker_text,
        )

    def canonical_comment(self) -> str:
        timestamp = datetime.now(timezone.utc).isoformat()
        lines = [
            COMMENT_TAG,
            f"**{self.head_ref} → {self.base_ref}**",
            f"- Mergeable state: `{self.mergeable_state}`",
            f"- Head SHA: `{self.head_sha}`",
            f"- CI Status: {self.checks}",
            f"- Blockers: {self.blockers}",
            "",
            "@codex — Next Actions:",
            "- Ensure branch is rebased onto main.",
            "- Run full validation suite (lint, tests, inbox).",
            "- Update Dev_Logic ledger entries before requesting merge.",
            "",
            f"_Generated {timestamp}_",
        ]
        return "\n".join(lines)


def load_event(event_path: Optional[str]) -> Dict[str, Any]:
    if not event_path:
        return {}
    path = Path(event_path)
    if not path.exists():
        return {}
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except json.JSONDecodeError:
        return {}


def watcher_mode() -> int:
    print("[watcher] Codex PR Watcher executed", file=sys.stderr)
    print("This job validates repository state for Codex automation.")
    return 0


def sentinel_mode(event_path: Optional[str]) -> int:
    payload = load_event(event_path)
    status = PRStatus.from_event(payload)
    comment = status.canonical_comment()
    print(comment)
    return 0


def main(argv: Optional[list[str]] = None) -> int:
    parser = argparse.ArgumentParser(
        description="Codex PR Sentinel utilities",
    )
    parser.add_argument(
        "--mode",
        choices={"watcher", "sentinel"},
        required=True,
    )
    parser.add_argument("--event-path", default=None)
    args = parser.parse_args(argv)

    if args.mode == "watcher":
        return watcher_mode()
    return sentinel_mode(args.event_path)


if __name__ == "__main__":
    sys.exit(main())
```

Codex PR Sentinel utilities.

This lightweight script is invoked by the watcher and sentinel GitHub Actions
workflows to compose canonical status comments. It intentionally avoids any
network side effects so that CI can exercise the logic without needing a
GitHub token when running locally.
**Classes:** PRStatus
**Functions:** load_event(event_path), watcher_mode(), sentinel_mode(event_path), main(argv)


## Module `tools\logic_inbox.py`

```python
#!/usr/bin/env python3
"""Logic inbox utilities for Codex governance."""

from __future__ import annotations

import argparse
import json
import sys
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Iterable, List

INBOX_PATH = (
    Path(__file__).resolve().parents[1] / "memory" / "logic_inbox.jsonl"
)
VALID_STATES = {"pending", "in_progress", "done", "dropped"}


@dataclass
class InboxItem:
    id: str
    title: str
    state: str = "pending"
    created_at: str = datetime.now(timezone.utc).isoformat()
    updated_at: str = datetime.now(timezone.utc).isoformat()
    notes: str = ""

    def to_json(self) -> str:
        return json.dumps(asdict(self), ensure_ascii=False)

    @classmethod
    def from_line(cls, line: str) -> "InboxItem":
        data = json.loads(line)
        return cls(**data)

    def validate(self) -> List[str]:
        errors: List[str] = []
        if self.state not in VALID_STATES:
            errors.append(f"Invalid state {self.state} for item {self.id}")
        return errors


class Inbox:
    def __init__(self, path: Path = INBOX_PATH):
        self.path = path

    def read_items(self) -> List[InboxItem]:
        items: List[InboxItem] = []
        if not self.path.exists():
            return items
        with self.path.open("r", encoding="utf-8") as handle:
            for line in handle:
                line = line.strip()
                if not line:
                    continue
                try:
                    items.append(InboxItem.from_line(line))
                except Exception as exc:  # pragma: no cover
                    raise ValueError(f"Invalid inbox entry: {line}") from exc
        return items

    def write_items(self, items: Iterable[InboxItem]) -> None:
        with self.path.open("w", encoding="utf-8") as handle:
            for item in items:
                handle.write(item.to_json() + "\n")

    def append(self, item: InboxItem) -> None:
        items = self.read_items()
        items.append(item)
        self.write_items(items)


def cmd_validate(inbox: Inbox) -> int:
    items = inbox.read_items()
    errors: List[str] = []
    for item in items:
        errors.extend(item.validate())
    if errors:
        for err in errors:
            print(err, file=sys.stderr)
        return 1
    print(f"Inbox OK ({len(items)} items)")
    return 0


def cmd_list(inbox: Inbox) -> int:
    items = inbox.read_items()
    if not items:
        print("Inbox empty")
        return 0
    for item in items:
        print(item.to_json())
    return 0


def cmd_add(inbox: Inbox, args: argparse.Namespace) -> int:
    item = InboxItem(
        id=args.id,
        title=args.title,
        state=args.state,
        notes=args.notes or "",
        created_at=datetime.now(timezone.utc).isoformat(),
        updated_at=datetime.now(timezone.utc).isoformat(),
    )
    inbox.append(item)
    print(f"Added inbox item {item.id}")
    return 0


def cmd_update(inbox: Inbox, args: argparse.Namespace) -> int:
    items = inbox.read_items()
    updated = False
    for item in items:
        if item.id == args.id:
            if args.state:
                item.state = args.state
            if args.notes is not None:
                item.notes = args.notes
            item.updated_at = datetime.now(timezone.utc).isoformat()
            updated = True
            break
    if not updated:
        print(f"Item {args.id} not found", file=sys.stderr)
        return 1
    inbox.write_items(items)
    print(f"Updated inbox item {args.id}")
    return 0


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Manage the Codex logic inbox",
    )
    sub = parser.add_subparsers(dest="command", required=True)

    validate = sub.add_parser("validate", help="Validate inbox entries")
    validate.set_defaults(
        func=lambda inbox, args: cmd_validate(inbox),
    )

    list_cmd = sub.add_parser("list", help="List inbox entries")
    list_cmd.set_defaults(
        func=lambda inbox, args: cmd_list(inbox),
    )

    add = sub.add_parser("add", help="Add a new inbox item")
    add.add_argument("id", help="Unique identifier for the item")
    add.add_argument("title", help="Brief description")
    add.add_argument(
        "--state",
        default="pending",
        choices=sorted(VALID_STATES),
    )
    add.add_argument("--notes", default="")
    add.set_defaults(func=cmd_add)

    update = sub.add_parser("update", help="Update an existing inbox item")
    update.add_argument("id")
    update.add_argument("--state", choices=sorted(VALID_STATES))
    update.add_argument("--notes")
    update.set_defaults(func=cmd_update)

    return parser


def main(argv: list[str] | None = None) -> int:
    if argv is None:
        argv = sys.argv[1:]
    if argv and argv[0] == "--validate":
        argv = ["validate", *argv[1:]]
    parser = build_parser()
    args = parser.parse_args(argv)
    inbox = Inbox()
    return args.func(inbox, args)


if __name__ == "__main__":
    sys.exit(main())
```

Logic inbox utilities for Codex governance.
**Classes:** InboxItem, Inbox
**Functions:** cmd_validate(inbox), cmd_list(inbox), cmd_add(inbox, args), cmd_update(inbox, args), build_parser(), main(argv)


## Module `tools\manage_tests.py`

```python
#!/usr/bin/env python3
"""Test management utility placeholder.

The Codex Global Protocol expects this entry point to run bespoke validations.
For now it simply ensures the repository can import its tooling modules.
"""

from __future__ import annotations

import importlib
import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))


def main() -> int:
    modules = ["tools.logic_inbox", "tools.codex_pr_sentinel"]
    for name in modules:
        importlib.import_module(name)
    print("Test management checks passed.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
```

Test management utility placeholder.

The Codex Global Protocol expects this entry point to run bespoke validations.
For now it simply ensures the repository can import its tooling modules.
**Functions:** main()



---
**Generation Parameters**


```text

You are an expert software engineer.  Carefully read every
file under the target directory (skipping any virtual environment
folders) and produce a comprehensive, well‑structured README in
Markdown.  Focus most of your attention on Python (.py) files: parse
their module‑level docstrings, enumerate classes and functions, and
describe what each does.  Summarise the purpose of non‑Python files
(such as JSON, YAML, text, images) briefly.  Provide an overview of
the project architecture and any dependencies you can infer from the
code.  Include usage notes or examples where appropriate.  Do not
invent information – base your summary solely on the source content.
Use headings, subheadings and lists to organise the README.

```